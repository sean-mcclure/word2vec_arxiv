

Autoencoder-Based Incremental Class Learning without Retraining on Old Data
Euntae Choi
1
,Kyungmi Lee
2
,Kiyoung Choi
3
1,3
Seoul National University
2
Massachusetts Institute of Technology
echoi@dal.snu.ac.kr, kyungmi@mit.edu, kchoi@snu.ac.kr
Abstract
Incremental  class  learning,  a  scenario  in  contin-
ual learning context where classes and their train-
ing data are sequentially and disjointedly observed,
challenges a problem widely known ascatastrophic
forgetting.   In  this  work,  we  propose  a  novel  in-
cremental  class  learning  method  that  can  signifi-
cantly reduce memory overhead compared to pre-
vious  approaches.   Apart  from  conventional  clas-
sification scheme using softmax, our model bases
on an autoencoder to extract prototypes for given
inputs  so  that  no  change  in  its  output  unit  is  re-
quired.   It stores only the mean of prototypes per
class to perform metric-based classification, unlike
rehearsal approaches which rely on large memory
or generative model.  To mitigate catastrophic for-
getting, regularization methods are applied on our
model when a new task is encountered.  We eval-
uate our method by experimenting on CIFAR-100
and CUB-200-2011 and show that its performance
is  comparable  to  the  state-of-the-art  method  with
much lower additional memory cost.
1    Introduction
Modern deep neural networks (DNNs) have made an unques-
tionable success in various fields, especially under offline set-
ting  where  the  task  for  a  network  is  fixed  and  all  training
data are provided simultaneously.  In many real-world appli-
cations, however, DNNs are also required to perform well un-
der continual settings.  For instance, there can be a large set
of medical images collected over a long period, say, longer
than 10 years and each image is deleted after some period due
to  privacy  concerns.   Even  worse,  some  images  may  come
from  previously  unseen  classes.   Unfortunately,  if  a  DNN
that  has  been  trained  offline  is  naively  fine-tuned  on  new
set of data, it loses most of the representations for old ones.
This notorious phenomenon is widely known ascatastrophic
forgetting(orinterference)
[
McCloskey  and  Cohen,  1989;
French, 1999
]
.  The most basic way to avoid forgetting is to
mix both old and new data together to construct a new batch,
and then re-train the network offline (joint training). Consid-
ering large datasets and complex network architectures used
nowadays, this solution requires too much computation and
memory cost, making it unscalable.
Researchers are paying great attention to the problem of
catastrophic forgetting in Continual Learning(CL) and mak-
ing  progress  with  various  approaches.   They  either  extend
loss  function  to  prevent  important  parameters  from  drastic
changes
[
Zenkeet al., 2017
]
, use an external memory module
to store a part exemplars of old tasks
[
Rebuffiet al., 2017
]
, or
employ a generative model to generate exemplars to remove
additional memory cost
[
Kemker and Kanan, 2018
]
.  At the
same time, there is also a controversy with the standard on
how we should evaluate CL approaches and make fair com-
parisons
[
Maltoni  and  Lomonaco,  2018;  Hsuet  al.,  2018
]
.
This issue is raised because some methods like
[
Kirkpatrick
et al., 2017; Zenkeet al., 2017
]
work quite well in a multi-
task learning scenario, but show significant performance drop
in incremental class learning (ICL) scenario
[
Hsuet al., 2018;
Parisiet al., 2018
]
.
We  propose  a  novel  ICL  algorithm  that  stores  only  one
code vector (mean) per class and does not retrain any other
data from old tasks,  thereby reducing memory and compu-
tation cost and alleviating the privacy issues simultaneously.
The base of our model is an autoencoder which learns how to
(1) find an important sub-manifold of data distribution and (2)
make code vectors well separated in cosine metric space so
that a metric-based classification method (the cosine-version
ofnearest-class-mean(NCM)
[
Mensinket al., 2013
]
) works
well.    The  autoencoder  is  first  trained  on  a  fixed  number
of classes and then Synaptic Intelligence (SI)
[
Zenkeet al.,
2017
]
or  Memory  Aware  Synapses  (MAS)
[
Aljundiet  al.,
2018
]
loss is added during incremental training steps to re-
sist forgetting.  So basically,  our model can be viewed as a
combination of architectural and regularization methodology.
Alternatively, this is an approach that makes previous regu-
larization methodologies applicable to ICL context with min-
imal overhead.
In the rest of this paper, we first review numerous previous
CL approaches in theRelated Works.   We then explain the
details  of  ours  in  theMethodology.   Experimental  settings,
results, and comparisons with previous works are presented in
theExperiments. Finally, we summarize and suggest possible
future works in theConclusion.
arXiv:1907.07872v1  [cs.LG]  18 Jul 2019

2    Related Works
Recent studies on CL can be categorized into (1)regulariza-
tion, (2)rehearsal, and (3)dual memory systemapproaches.
Regularization  Strategies
[
Li  and  Hoiem,   2018;  Kirk-
patricket al., 2017; Zenkeet al., 2017; Aljundiet al., 2018;
Serraet al., 2018
]
focus on designing loss term to retain the
representations for old tasks by e.g., prohibiting drastic up-
date  of  important  parameters.   Learning  without  Forgetting
(LwF)
[
Li and Hoiem, 2018
]
records the network’s response
to  old  tasks  used  in  Knowledge  Distillation
[
Hintonet  al.,
2015
]
loss term and uses them to encourage the network to
make  similar  prediction  after  being  trained  for  new  tasks.
In Elastic Weight Consolidation (EWC)
[
Kirkpatricket al.,
2017
]
, it is assumed that keeping the value of loss function
for old tasks low can lead to less forgetting.  Therefore, each
parameter’s contribution (or importance) to the change in loss
function is approximated as the diagonal of the Fisher infor-
mation matrix.  Then it is combined with quadratic penalty
term  on  the  parameter  change  to  compose  surrogate  loss.
Intuitively, EWC mitigates forgetting by forcing parameters
that contributed a lot for old tasks to settle.  SI
[
Zenkeet al.,
2017
]
is a variant of EWC which replaces the Fisher informa-
tion  matrix-based  importance  measure  with  the  summation
of the approximated change in loss function divided by the
amount of update for each parameter, thus reducing compu-
tation cost. And an extra phase for computing the measure is
spared because SI’s measure can be computed online. Mem-
ory  Aware  Synapses(MAS)
[
Aljundiet  al.,  2018
]
suggests
using the averaged L2 norm of per-parameter gradient as the
importance measure.
However,  some  papers
[
Hsuet  al.,  2018;  Parisiet  al.,
2018
]
report that under ICL setting, recent regularization ap-
proaches have no clear advantage over simply fine-tuning the
network.  Compared to several rehearsal approaches
[
Rebuffi
et al., 2017; Gepperth and Karaoguz, 2016
]
, the accuracy gap
was significantly large (70% for Split MNIST and 30% for
CUB-200).
Rehearsal  approaches
[
Gepperth  and  Karaoguz,   2016;
Rebuffiet al., 2017; Wuet al., 2018; Lopez-Paz and Ranzato,
2017; Kemker and Kanan, 2018
]
store or generate old data to
augment new training batches that helps the network retain its
old representations. Notably, Incremental Classifier and Rep-
resentation Learning (iCaRL)
[
Rebuffiet al., 2017
]
is a mix-
ture ofrehearsalandregularizationapproaches. It has an ex-
ternal memory with fixed capacity to save previous exemplars
that augment loss function with distillation term.  Classifica-
tion is done withnearest-mean-of-exemplarsrule, which uses
the average of extracted feature vectors as the class mean in-
stead of true class mean used in NCM
[
Mensinket al., 2013
]
classifier.  To maintain memory capacity, the number of ex-
emplars per class decreases by selecting those closest to their
class mean after learning each task. While the memory helps
iCaRL’s strong performance, it still poses scalability problem
as the number of classes grows. Incremental Classifier Learn-
ing with GAN (ICwGAN)
[
Wuet al., 2018
]
does not use real
exemplars as in iCaRL, but trains a GAN to get generated data
(pseudo-rehearsal).  This improves performance because the
data from the GAN are more likely to be close to the real dis-
tribution of dataset than the sampled real ones. On top of that,
the GAN used here resolves the privacy issue by not generat-
ing individual-specific data. Although ICwGAN is relatively
free from the scalability problem, computation overhead by
training and running GAN is inevitable.  Gradient Episodic
Memory (GEM)
[
Lopez-Paz and Ranzato,  2017
]
adopts an
external memory like iCaRL, but aims to not only reduce for-
getting but also make positive backward transfer possible by
using  inequality  constraints  and  solving  dual  problem  of  a
quadratic program with them.
The following works implementdual memory systemin-
spired by complementary learning system (CLS) theory
[
Mc-
Clellandet  al.,  1995;  Kumaranet  al.,  2016
]
that  investi-
gated  the  interaction  between  hippocampus  and  neocortex
in  mammalian  brain.    GeppNet
[
Gepperth  and  Karaoguz,
2016
]
makes use of self-organized map algorithm to obtain
topology-preserving  representation  at  the  hidden  layer;  the
representation  is  updated  only  when  current  classification
with  linear  regression  produces  uncertain  or  wrong  result.
Thus, the hidden layer can serve as a stable long-term mem-
ory. FearNet
[
Kemker and Kanan, 2018
]
is a recent approach
that does not store previous exemplars for retraining. Its long-
term memory is modelled by an autoencoder network, which
is capable of generating previously learned examples.  When
new classes are observed, FearNet first stores those observa-
tions in its short-term memory,  then consolidates those ob-
servations into the long-term memory along with generated
examples.  The short-term memory is erased after consolida-
tion, thus acts as a finite-sized episodic memory.
3    Methodology
In  this  section,  we  briefly  introduce  ICL  and  describe  the
components of our model, each of which is followed byback-
groundsubsection to explain motivation and details.
3.1    Incremental Class Learning
The  inputs  under  ICL  setting  are  given  asX
1
,X
2
,...,
whereX
t
={x
t
1
,x
t
2
,...,x
t
N
t
}is  a  set  of  data  andY
t
=
{y
t
1
,y
t
2
,...,y
t
N
t
c
}is a set of classes present inX
t
whereN
t
c
denotes the number of classes for a taskt.N
t
1
c
is set to a
half of total number of classes in the dataset we use, and the
other tasks contain the same number of classes of our choice
(e.g., with CIFAR100,N
t
1
c
equals 50, andN
t
2
c
,N
t
3
c
,...,N
t
51
c
are all 1).
An ICL model is required to learnt
1
, which we callbase
training.  Then, it should learnt
2
,t
3
,...sequentially and we
call this asincremental training. The classes are disjointedly
split among tasks.
3.2    Architecture and Classification
Autoencoder-Based Architecture
We use an autoencoder as a classifier, instead of conventional
multi-layer perceptrons (MLP) or convolutional neural net-
work (CNN) architectures trained with the softmax at the fi-
nal layer. The outputs of the encoder (i.e., the code vectors of
the autoencoder) are used as theprototypesfor given inputs
(see Figure 1). Since a fraction of the entire dataset is not suf-
ficient to train the whole network in case of the datasets we

Figure 1: Overall architecture of our model.
experiment on (CIFAR-100 and CUB-200),  a VGG-19
[
Si-
monyan and Zisserman, 2014
]
pretrained on ImageNet is at-
tached in front of the encoder and works as a fixed feature ex-
tractorφ. This is similar to FearNet, which uses a pretrained
ResNet-50
[
Heet al., 2016
]
as its feature extractor.
Cosine Similarity-Based Classification
The cosine version of NCM is used for classification.  In our
model, the predicted class for a given inputxis
y=argmin
i∈{0,1,...,N
c
−1}
cos(h(x),μ
i
)(1)
where0,1,...,N
c
−1indicate labels for totalN
c
classes ob-
served so far,h(·)indicates the encoder operation,μ
i
indi-
cates the class mean of prototypes forith class, andcos(·,·)
is cosine similarity distance.
Class means are calculated only once after training the au-
toencoder for each task. That is, whole training data in taskt
is fed to the autoencoder in mini-batches and the class means
are calculated, as proposed by
[
Guerrieroet al., 2018
]
.
Background
A lot of previous approaches make their prediction by inter-
preting a network’s softmax output as a class probability and
this can be problematic for ICL. First, the number of nodes
at the output layer always has to grow and the total number
of classes may not be known in real-world applications. Sec-
ond,  unlike  in  multi-task  learning,  a  network  has  only  one
growing output layer (i.e., which task a given input belongs
to  is  not  known  to  the  network).   This  makes  ICL  training
harder because the possibility that a network predicts an input
from new class as one of old classes is left open
[
Maltoni and
Lomonaco, 2018
]
. In other words, a network has to solve two
problems  simultaneously  for  ICL;  one  for  classifying  task,
the other for predicting correct class.
Autoencoder architecture can readily be used in this con-
text as it does not require softmax output unit, hence free from
the  aforementioned  concerns.   The  choice  of  metric-based
classification  rule  is  followed  naturally  because  it  does  not
assume a specific number of classes. More importantly, small
drifts in the model less affect classification performance, as
far as the drifted output remains in the neighborhood of the
original output.
3.3    Loss Function for Base Training
We  propose  a  loss  function  to  train  on  base  classes  which
consists of three components. The first term is pixel-by-pixel
MSE reconstruction loss commonly used to train an autoen-
coder, given as:
L
MSE
=‖g(h(x))−x‖
2
2
(2)
whereh(·)andg(·)denote the encoder and the decoder oper-
ation, respectively. The second term is cosine embedding loss
to make code vectors well separated in cosine metric space
according to the class they belong to, which is calculated as:
L
cos
=
{
1−cos(x
1
,x
2
),ify
1
=y
2
max(0,cos(x
1
,x
2
)),ify
1
6=y
2
.(3)
Though there are
(
N
b
2
)
many possible pairs for(x
1
,x
2
), we
randomly selectN
b
many pairs to reduce computation over-
head (N
b
denotes the mini-batch size).  The last term is L1
penalty loss to make code vectors sparse, thus aiding the co-
sine embedding loss and is defined as:
L
L1
=
∑
i
|h
i
(x)|(4)
whereh
i
(x)meansith component of a code vector.
The  total  loss  function  to  minimize  is  a  weighted  linear
sum of the three:
L
base
=λ
MSE
L
MSE
+λ
cos
L
cos
+λ
L1
L
L1
(5)
where the lambdas are hyperparameters to choose.
Background
If an autoencoder is trained solely by the reconstruction loss,
the  prototypes  are  not  guaranteed  to  be  useful  for  classifi-
cation  tasks  since  information  that  is  important  for  imitat-
ing every single sample is learned, rather than favorable in-
variant features to discriminate different classes, as noted by
[
Rasmuset al., 2015
]
.  This is why we apply the supervised
cosine embedding loss term that can bring the prototypes of
the same class closer and ones of different classes far away.
Plus, adding L1 penalty to the prototypes can further improve
classification performance.  As sparse vectors lie in narrower
regions (that consists of fewer orthants) than dense vectors,
the network can concentrate on choosing proper orthants ac-
cording to the class information, which is simply selecting a
few non-zero elements of code vectors.  Here, cosine metric
gives more advantage due to its magnitude ignorant nature,
reducing the degree of freedom of the optimization problem
to solve.
3.4    Outlier Exclusion and Additional Training for
Base Classes
To further increase our model’s ability to learn new tasks, we
enhance the mean prototypes of base classes via applying Lo-
cal Outlier Factor (LOF,
[
Breuniget al., 2000
]
) and addition-
ally training the encoder to fit to the altered mean prototypes.
After base training is complete, the prototypes of all training
data are collected class by class, and the outliers in terms of
cosine similarity are excluded by LOF to calculate new mean
prototypes{μ
new,i
}.  Then, the encoder is trained again on
the same training data with new loss function consisting of
L
center
andL
cos
, where
L
center
=
∑
i
‖h(x)−μ
new,i
‖
2
2
(6)
is a term analogous to the center loss proposed in
[
Wanget
al., 2018
]
and the total loss function is given as
L
add
=λ
center
L
center
+λ
cos
L
cos
(7)
with  the  lambdas  are  hyperparameters  to  determine  each
term’s strength.

Background
We observed that the prototypes after base training were not
separated well to show good performance in our cosine sim-
ilarity based classification rule, thus lowering discriminabil-
ity of the calculated mean prototypes.  A natural solution to
this problem is excluding outliers before calculating means,
however, applying only the outlier exclusion was not power-
ful enough to enhance our model’s performance.  We believe
this is because the exclusion technique does not change the
autoencoder’s representation, so the bad prototypes can still
be generated from test data, degrading classification accuracy
even though mean prototypes are enhanced. Therefore, an ad-
ditional training step is required to update the encoder to drag
outlier prototypes to the enhanced class means and it appears
the center loss is adequate to this task.
3.5    Loss Function for Incremental Training
Directly fine-tuning the autoencoder also leads to catastrophic
forgetting. Therefore, we adopt regularization techniques (SI
and MAS) into our model.
SI computes the contribution (or importance) of a parame-
terθ
k
to the change in the loss function for a taskt
n
as fol-
lows:
ω
n
k
=
∫
t
n
t
n−1
grad
k
(θ(t))
dθ
k
(t)
dt
dt(8)
wheregrad
k
(θ(t))represents the gradient values of the loss
function w.r.t.θ
k
(t), and
dθ
k
(t)
dt
represents the amount of the
parameter update.ω
n
k
is then normalized as:
Ω
n
k
=
∑
n
i
<n
ω
n
i
k
(∆
n
i
k
)
2
+ξ
(9)
where∆
n
i
k
represents  the  the  difference  in  parameter  val-
ues  before  and  after  training  on  a  taskt
n
i
,  that  is∆
n
i
k
=
θ
k
(t
n
i
)−θ
k
(t
n
i−1
), andξrepresents a small nonzero damp-
ing  parameter  to  prevent  numerical  overflow.Ω
n
k
accumu-
lates as more tasks are learned, preserving information from
the old tasks.  It can be combined with quadratic penalty on
the parameter drift to form a loss term:
L
SI
=
∑
k
Ω
n
k
(
 ̃
θ
k
−θ
k
)
2
(10)
where
 ̃
θ
k
is the reference parameter value from the previous
taskt
n−1
andθ
k
is the value immediately after learning a task
t
n
.
MAS focuses on the functionFlearned by a network, so
suggests an alternative importance measure of a parameterθ
k
given as:
Ω
n
k
=
1
N
N
∑
i=1
‖grad
k
(x
i
)‖(11)
where N is the total number of observed data at a taskt
n
and
grad
k
(x
i
)  =
∂(F(x
i
;θ))
∂θ
k
for  an  inputx
i
.   The loss  term  of
MAS is defined likewise:
L
MAS
=
∑
k
Ω
n
k
(
 ̃
θ
k
−θ
k
)
2
(12)
where
 ̃
θ
k
andθ
k
mean the same as in SI.
The total loss function for learning new tasks is similar to
L
base
exceptL
cos
can be excluded according to class split.
That is:
L
inc
=λ
MSE
L
MSE
+λ
reg
L
reg
+λ
cos
L
cos
+λ
L1
L
L1
(13)
whereL
reg
is one ofL
SI
andL
MAS
.
Background
The reason SI and MAS are preferred to EWC is that they
are more apt for online updates with small additional compu-
tation costs, and more scalable to higher output dimensions
(the Fisher information matrix used in EWC is computation-
ally expensive).
Given that ReLU activation is used, we can selectFmen-
tioned in MAS to be either the loss function or the activation
output  of  any  hidden  layer  of  the  network  (alocalversion
as proposed in
[
Aljundiet al., 2018
]
).  But we just setFto
the total loss function because if a specific hidden layer is se-
lected, it might be biased to a part of tasks the autoencoder
has to perform (e.g., the hidden layer of the decoder is likely
to be optimized for reconstruction).
3.6    Training
We design procedures for base training and incremental train-
ing, respectively. Since the two regularization techniques’ re-
quirement differs, we also make this point clear.
Base Training
The autoencoder is trained ont
1
. In an epoch, training dataset
X
1
is randomly shuffled and divided into mini-batches of size
N
b
.  The initial values of autoencoder parametersΘ ={θ
k
}
are stored to
 ̃
Θ.  For each mini-batch, input images are fed
to  the  feature  extractor  to  obtain  embeddingsφ(x)which
are  flattened  to  have  shape  of(N
b
,−).L
MSE
(φ(x))and
L
L1
(φ(x))are  calculated  straightforward.ForL
cos
,N
b
many pairs of(φ(x
1
),φ(x
2
))are randomly sampled (x
1
6=
x
2
). IfL
SI
is used for incremental training, both the parame-
ter values before updateΘ
∗
and gradient values ofL
base
w.r.t.
Θ
∗
is stored.  In case ofL
MAS
, only the gradient values are
kept.  Then we updateΘvia back-propagation and accumu-
late per-parameter importance values ({ω
1
k
}in Eq.  6 for SI,
{Ω
1
k
}in Eq.   9 for MAS). After the final epoch,  the whole
training dataset is fed to the autoencoder and we separately
collect the output of the encoderh(φ(x))class by class to
make class mean of prototypes{μ
i
}.  If the outlier exclusion
and the additional training is used,  LOF is applied to{μ
i
}
to obtain{μ
new,i
}and the encoder is trained by minimizing
L
add
in Eq. 7. Here, per-parameter importance values are ac-
cumulated in the same way, now w.r.t.L
add
.  Then, the final
importance value is normalized and then saved. For SI,∆
k
is
computed asθ
k
−
 ̃
θ
k
andΩ
1
k
is computed as in Eq. 9. And for
MAS,Ω
1
k
is divided by the total number of inputs in training
dataset.
Incremental Training
Next, the rest of taskst
2
,t
3
,...are learned.  Most of the pro-
cedures are the same as in base training, however, only the
encoder is updated.L
base
is replaced byL
inc
and the outlier
exclusion and the additional training are not applied because
they make the encoder overfit to data from new tasks (only
one class included in each task). At training for each task, the
importance measure obtained in the last task is used to com-
puteL
SI
orL
MAS
, and a new importance measure is calcu-
lated for the task following right after.  When the training is
completed,{μ
i
}is appended with new class means. It is no-
table that eachΩ
j
k
forj≥2embraces information about pa-
rameter importance from all the previous tasks, thus showing

CIFAR-100CUB-200-2011
Classes100200
Train Samples50,0005,994
Train Samples / Class50029 to 30
Test Samples10,0005,794
Test Samples / Class10011 to 30
Table 1: Dataset statistics
CIFAR-100CUB-200-2011
Input Image Dim.3×32×323×224×224
Feature ExtractorφTo first 9 conv. layersTo first FC layer
Input Embedding Dim.81924096
Prototype Dim.20481024
Enc./Dec. Architecture
[8192-2048-2048]
Activation: ELU
[4096-1024-1024]
Activation: ELU
Table 2: Experimental settings for each dataset
implicit effect of Knowledge Distillation without depending
on rehearsal or pseudo-rehearsal techniques.
4    Experiments
We demonstrate the performance of our model in various ICL
settings. In this section, we explain our experimental settings,
and  then  show  results  along  with  comparison  with  notable
previous approaches.
4.1    Experimental Settings
Dataset
We evaluate our model on two datasets in Table 1:CIFAR-100
[
Krizhevsky and Hinton, 2009
]
andCUB-200-2011
[
Wahet
al., 2011
]
.CIFAR-100is one of the most popular RGB image
datasets for classification.  The image shape is 3×32×32
pixels and 100 classes of various objects are included.CUB-
200-2011is a challenging dataset containing 200 species of
birds,  with much smaller number of examples per class.  It
also provides additional information for object detection, but
we use it solely for classification task. The image shapes are
not uniform, so we preprocess the images as follows: 1) resize
an image so that the smaller spatial dimension is set to 224,
2) crop at the center to get the final shape as 3×224×224
pixels.
Implementation Details
The architectures and settings of our model for each dataset
are shown in Table 2.  ForCIFAR-100, the feature map after
first 9 convolutional layers of VGG-19
[
Simonyan and Zis-
serman,  2014
]
pretrained on ImageNet is used as the fixed
feature extractorφ. ForCUB-200-2011, the activation output
of the first fully-connected layer from the same VGG-19 is
used asφ.  For all dataset, our model is trained with AMS-
Grad
[
Reddiet al.,  2018
]
with mini-batches of size 64 and
ELU
[
Clevertet al., 2015
]
is used as activation function. We
implemented our model with PyTorch.
Evaluation Scheme
We  evaluate  our  model’s  performance  when  each  dataset
is  split  into  disjoint  subsets.    Specifically,  the  first  subset
contains  a  half  of  all  classes  in  a  dataset  and  each  other
subset  contains  a  single  class.   For  direct  comparison  with
previous  works,  we  use  evaluation  metrics  suggested  by
[
Kemkeret al., 2018
]
.  Three metrics were proposed:Ψ
base
,
Ψ
new
,  andΨ
all
(the  original  notationΩfrom  Kemker  et
al.   is changed toΨto eliminate confusion withΩ
n
k
for SI
and MAS), whereΨ
base
=
1
T−1
∑
T
i=2
α
base,i
α
ideal
represents a
model’s ability to maintain its performance on base classes it
first learned (referred to as the ”base knowledge”),Ψ
new
=
1
T−1
∑
T
i=2
α
new,i
represents  a  model’s  ability  to  perform
well on newly learned classes, andΨ
all
=
1
T−1
∑
T
i=2
α
all,i
α
ideal
represents a model’s overall classification performance on all
learned  classes.   Notations  withαstands  for  accuracy,  for
exampleα
base,i
means the accuracy on the base knowledge
after theith training session.α
ideal
is a regularizing term rep-
resenting the ideal accuracy when all classes are presented at
once  (offline  setting),  thereby  meaning  the  upper  bound  of
model’s performance. The value is 0.699 forCIFAR-100and
0.598  forCUB-200-2011.Tis  the  total  number  of  tasks,
which  becomes  51  forCIFAR-100and  101  forCUB-200-
2011.
Model Configurations
Our model is experimented with 4 different configurations.
SIandMASmean thatL
SI
andL
MAS
was used in Eq.  13
for incremental training steps, respectively.  InSI+LOFand
MAS+LOF, outlier exclusion and additional training are fur-
ther applied at the base training, and the rest is the same with
SIandMAS.
4.2    Results
CIFAR-100
ModelΨ
base
Ψ
new
Ψ
all
1-NN
1
0.8780.6480.879
GeppNet
1
0.8330.5290.754
iCaRL
1
0.7460.8070.749
FearNet
1
0.9270.8240.947
Ours w/ MAS0.8870.6410.850
Ours w/ SI0.8640.6180.857
Ours w/ MAS+LOF0.8590.7460.823
Ours w/ SI+LOF0.8330.6970.814
Table 3: Incremental classification metrics on CIFAR-100
Model100 Classes1,000 Classes
1-NN
1
4.1GB40.9GB
GeppNet
1
4.1GB41GB
iCaRL24.8MB247.8MB
FearNet
3.3MB18MB
Ours0.8MB8.2MB
Table  4:  Estimated  extra  memory  requirement  values  on  CIFAR-
100.  Note that for iCaRL,K(total capacity of stored exemplars)
was set to 2,000 for 100 classes and 20,000 for 1,000 classes.  And
for FearNet, the number of exemplars stored per classmis set to 20
and sleep frequency is 10 epochs.
Table 3 shows the metrics by Kemker et al.  measured with
CIFAR-100.    ForOurs  w/  MASandOurs  w/  SI,  the  base

knowledge is trained for 100 epochs with fixed learning rate
of 1e-4, and the incremental training is done for 50 epochs
with  fixed  learning  rate  of  2e-4  and  10  epochs  with  fixed
learning rate of 1e-4, respectively.  ForOurs w/ MAS+LOF
andOurs w/ SI+LOF, the base knowledge is trained for 100
epochs with learning rate decay of 0.2 for every 25 epochs,
starting with 2e-4, and the incremental training is done for 50
epochs with fixed learning rate of 1e-4 and 25 epochs with
fixed learning rate of 2e-4, respectively. Hyperparameter set-
tings are consistent among all configurations, withλ
MSE
=1,
λ
cos
=10,λ
L1
=1e-3,λ
reg
=10, andλ
center
=1.
Our  model,  especiallyOurs  w/  MAS,  shows  competitive
incremental  classification  results,  withΨ
all
slightly  worse
than 1-NN, but better than GeppNet and iCaRL. While they
must  explicitly  store  previous  examples,  we  achieve  better
or comparable incremental classification ability with storing
only one mean prototype per class.  Also, our model is bet-
ter at retaining knowledge for base classes compared to all
three of them as shown inΨ
base
values, and this explains the
goodΨ
all
values of our model despite relatively lowΨ
new
(to iCaRL); although our model might not immediately show
good performance on the most recent class, it forgets less as
the learning progresses.  Applying LOF increasesΨ
new
with
slightly decreasedΨ
base
andΨ
all
, making our model’s abil-
ity to learn new class closer to iCaRL.
However, our model does not perform as well as FearNet.
FearNet  essentially  emulates  joint  training  with  generated
training examples from previous classes when its generator
(decoder) is perfect,  which explains its higher performance
compared to models that only rely on new examples like ours,
or that use a fraction of previous examples instead of full joint
training like iCaRL. Thus, although FearNet has higher per-
formance,  its  training  cost  and  time  scale  with  the  number
of learned classes.  Furthermore, FearNet’s performance de-
pends on the frequency of ”sleep” (consolidation) phase, and
for betterΨ
all
, data from more classes should be stored in its
short-term memory before consolidation happens, which fur-
ther increases memory cost.  On the other hand, our model’s
training cost and time is constant regardless of the number of
classes observed so far because only the data from a new class
is used for every task.   Moreover,  our model’s memory re-
quirement grows much slower than FearNet’s since whatever
configuration we choose, the number of stored mean proto-
types is the same as the number of classes. This point is made
clear in Table 4 where the estimated extra memory require-
ment after learning 100 and 1,000 classes are shown. To cal-
culate the values, we included all additional data or statistics
required to perform the final incremental training step given
the number of classes, such as stored exemplars, class means,
or variances.
CUB-200-2011
Table  5  shows  the  same  metric  in  Table  3  measured  with
CUB-200-2011.  ForOurs w/ MASandOurs w/ SI, the base
knowledge is trained for 100 epochs with learning rate decay
of 0.5 every 25 epochs, starting with 2e-4, and the incremen-
tal training is done for 50 epochs with fixed learning rate of
2e-4. ForOurs w/ MAS+LOFandOurs w/ SI+LOF, the base
1
The numbers are from
[
Kemker and Kanan, 2018
]
ModelΨ
base
Ψ
new
Ψ
all
1-NN
1
0.7460.4340.694
GeppNet
1
0.7270.5580.645
iCaRL
1
0.9420.5470.864
FearNet
1
0.9240.5980.891
Ours w/ MAS+LOF0.8360.7800.727
Ours w/ MAS0.8370.6720.769
Ours w/ SI
0.8240.7260.762
Ours w/ SI+LOF0.8130.6390.737
Table 5: Incremental classification metrics on CUB-200-2011
knowledge is trained for 100 epochs with learning rate de-
cay of 0.2 for every 25 epochs,  starting with 2e-4,  and the
incremental training is done for 50 epochs with fixed learn-
ing rate of 2e-4 and 25 epochs with fixed learning rate of 2e-
4, respectively.  Hyperparameter settings are the same as in
CIFAR-100.
Ψ
base
andΨ
all
of  our  model  are  lower  than  iCaRL  and
FearNet possibly due to the same reason argued inCIFAR-
100subsection.  However, in general, our model (especially
Ours w/ MAS+LOF) shows significantly higherΨ
new
than
any other model with much smaller and scalable extra mem-
ory requirement as can be inferred from Table 4 (i.e., the di-
mension of class mean prototype is decreased to 1,024 and
the number of them is doubled to 200 classes, thus requiring
the same amount of extra memory as inCIFAR-100whereas
the others’ memory has to increase due to higher input dimen-
sion).
5    Conclusion
We  propose  a  novel  ICL  algorithm  that  leverages  1)  the
autoencoder  architecture  to  extract  prototypes  of  inputs,  2)
metric-based classification rule (the cosine version of NCM),
3) loss functions for base and incremental training, 4) outlier
exclusion and additional training to enhance our model’s abil-
ity to learn new class, and 5) regularization methods to mit-
igate catastrophic forgetting (SI and MAS). We demonstrate
the  performance  of  our  model  in  various  experimental  set-
tings, involving different datasets and model configurations.
Furthermore, our model does not rely on stored or generated
examples, providing memory-efficient approach to ICL. This
is possible as regularization method prevent the model from
drastic semantic drift, then small changes in the output of the
encoder after incremental training steps do not hurt classifica-
tion accuracy as far as the output has same near neighbors as
before in terms of cosine similarity, while not relying on re-
hearsal or pseudo-rehearsal technique that causes more mem-
ory overhead. We believe future work on extending represen-
tation learning to complex datasets instead of transferring a
pretrained model can improve the performance, because fea-
tures pretrained on a different dataset might not be optimal to
the given dataset at hand.
References
[
Aljundiet al., 2018
]
Rahaf   Aljundi,   Francesca   Babiloni,   Mo-
hamed  Elhoseiny,   Marcus  Rohrbach,   and  Tinne  Tuytelaars.
Memory aware synapses: Learning what (not) to forget. InCom-
puter Vision – ECCV 2018, pages 144–161, 2018.

[
Breuniget al., 2000
]
Markus   M   Breunig,   Hans-Peter   Kriegel,
Raymond T Ng, and J
 ̈
org Sander. Lof: identifying density-based
local outliers. InACM sigmod record, volume 29, pages 93–104.
ACM, 2000.
[
Clevertet al., 2015
]
Djork-Arn
 ́
e Clevert, Thomas Unterthiner, and
Sepp  Hochreiter.   Fast  and  accurate  deep  network  learning  by
exponential linear units (elus).arXiv preprint arXiv:1511.07289,
2015.
[
French, 1999
]
Robert M French.   Catastrophic forgetting in con-
nectionist networks.Trends in cognitive sciences, 3(4):128–135,
1999.
[
Gepperth and Karaoguz, 2016
]
Alexander    Gepperth   and    Cem
Karaoguz. A Bio-Inspired Incremental Learning Architecture for
Applied Perceptual Problems.Cognitive Computation, 8:924 –
934, 2016.
[
Guerrieroet al., 2018
]
Samantha Guerriero, Barbara Caputo, and
Thomas  Mensink.   Deepncm:  Deep  nearest  class mean  classi-
fiers.  InInternational Conference on Learning Representations,
Workshop Track, 2018.
[
Heet al., 2016
]
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and
Jian Sun. Deep residual learning for image recognition. InCom-
puter Vision and Pattern Recognition (CVPR), pages 770–778.
IEEE, 2016.
[
Hintonet al., 2015
]
Geoffrey  Hinton,  Oriol  Vinyals,  and  Jeffrey
Dean.   Distilling the knowledge in a neural network.   InNIPS
Deep Learning and Representation Learning Workshop, 2015.
[
Hsuet al., 2018
]
Yen-Chang Hsu, Yen-Cheng Liu, and Zsolt Kira.
Re-evaluating continual learning scenarios: A categorization and
case  for  strong  baselines.arXiv  preprint  arXiv:1810.12488,
2018.
[
Kemker and Kanan, 2018
]
RonaldKemkerandChristopher
Kanan.  Fearnet:  Brain-inspired model for incremental learning.
InInternational Conference on Learning Representations, 2018.
[
Kemkeret al., 2018
]
Ronald  Kemker,  Marc  McClure,  Angelina
Abitino,  Tyler  L  Hayes,  and  Christopher  Kanan.Measuring
catastrophic  forgetting  in  neural  networks.InThirty-Second
AAAI Conference on Artificial Intelligence, 2018.
[
Kirkpatricket al., 2017
]
James Kirkpatrick, Razvan Pascanu, Neil
Rabinowitz, Joel Veness, Guillaume Desjardins, Andrei A Rusu,
Kieran Milan, John Quan, Tiago Ramalho, Agnieszka Grabska-
Barwinska, et al.  Overcoming catastrophic forgetting in neural
networks.Proceedings of the national academy of sciences, page
201611835, 2017.
[
Krizhevsky and Hinton, 2009
]
Alex   Krizhevsky   and   Geoffrey
Hinton.   Learning multiple layers of features from tiny images.
Technical report, Citeseer, 2009.
[
Kumaranet al., 2016
]
Dharshan  Kumaran,  Demis  Hassabis,  and
James L McClelland. What learning systems do intelligent agents
need?  complementary learning systems theory updated.Trends
in cognitive sciences, 20(7):512–534, 2016.
[
Li and Hoiem, 2018
]
Zhizhong  Li  and  Derek  Hoiem.    Learning
without forgetting.IEEE Transactions on Pattern Analysis and
Machine Intelligence, 40(12):2935–2947, 2018.
[
Lopez-Paz and Ranzato, 2017
]
David Lopez-Paz and Marc Aure-
lio Ranzato.   Gradient episodic memory for continual learning.
InAdvances in Neural Information Processing Systems 30, pages
6467–6476. Curran Associates, Inc., 2017.
[
Maltoni and Lomonaco, 2018
]
Davide    Maltoni    and    Vincenzo
Lomonaco.Continuous  learning  in  single-incremental-task
scenarios.arXiv preprint arXiv:1806.08568, 2018.
[
McClellandet al., 1995
]
James   L   McClelland,   Bruce   L   Mc-
Naughton, and Randall C O’reilly.   Why there are complemen-
tary learning systems in the hippocampus and neocortex: insights
from the successes and failures of connectionist models of learn-
ing and memory.Psychological review, 102(3):419, 1995.
[
McCloskey and Cohen, 1989
]
Michael McCloskey and Neal J Co-
hen.   Catastrophic interference in connectionist networks:  The
sequential learning problem.  InPsychology of learning and mo-
tivation, volume 24, pages 109–165. 1989.
[
Mensinket al., 2013
]
T.  Mensink,  J.  Verbeek,  F.  Perronnin,  and
G.  Csurka.   Distance-based  image  classification:  Generalizing
to  new  classes  at  near-zero  cost.IEEE  Transactions  on  Pat-
tern Analysis and Machine Intelligence, 35(11):2624–2637, Nov
2013.
[
Parisiet al., 2018
]
German I Parisi, Ronald Kemker, Jose L Part,
Christopher  Kanan,  and  Stefan  Wermter.Continual  lifelong
learning  with  neural  networks:    A  review.arXiv  preprint
arXiv:1802.07569, 2018.
[
Rasmuset al., 2015
]
Antti  Rasmus,   Mathias  Berglund,   Mikko
Honkala,  Harri  Valpola,  and  Tapani  Raiko.Semi-supervised
learning with ladder networks.  InAdvances in Neural Informa-
tion Processing Systems, pages 3546–3554, 2015.
[
Rebuffiet al., 2017
]
Sylvestre-AlviseRebuffi,Alexander
Kolesnikov,  Georg  Sperl,  and  Christoph  H.  Lampert.icarl:
Incremental  classifier  and  representation  learning.InThe
IEEE Conference on Computer Vision and Pattern Recognition
(CVPR), July 2017.
[
Reddiet al., 2018
]
Sashank J. Reddi, Satyen Kale, and Sanjiv Ku-
mar.  On the convergence of adam and beyond.  InInternational
Conference on Learning Representations, 2018.
[
Serraet al., 2018
]
Joan  Serra,  D
 ́
ıdac  Sur
 ́
ıs,  Marius  Miron,  and
Alexandros  Karatzoglou.    Overcoming  catastrophic  forgetting
with hard attention to the task.arXiv preprint arXiv:1801.01423,
2018.
[
Simonyan and Zisserman, 2014
]
Karen   Simonyan   and   Andrew
Zisserman. Very deep convolutional networks for large-scale im-
age recognition.arXiv preprint arXiv:1409.1556, 2014.
[
Wahet al., 2011
]
C. Wah, S. Branson, P. Welinder, P. Perona, and
S. Belongie. The Caltech-UCSD Birds-200-2011 Dataset. Tech-
nical Report CNS-TR-2011-001, California Institute of Technol-
ogy, 2011.
[
Wanget al., 2018
]
Shuai Wang, Zili Huang, Yanmin Qian, and Kai
Yu. Deep discriminant analysis for i-vector based robust speaker
recognition.arXiv preprint arXiv:1805.01344, 2018.
[
Wuet al., 2018
]
YueWu,YinpengChen,LijuanWang,
Yuancheng  Ye,  Zicheng  Liu,  Yandong  Guo,  Zhengyou  Zhang,
and  Yun  Fu.Incremental  classifier  learning  with  generative
adversarial networks.arXiv preprint arXiv:1802.00853, 2018.
[
Zenkeet al., 2017
]
Friedemann Zenke, Ben Poole, and Surya Gan-
guli.  Continual learning through synaptic intelligence.  InPro-
ceedings of the 34th International Conference on Machine Learn-
ing, volume 70 ofProceedings of Machine Learning Research,
pages 3987–3995. PMLR, 06–11 Aug 2017. 

Modern CNNs for IoT Based Farms
Patrick Kinyua Gikunda
1,2
and Nicolas Jouandeau
2
1
Department of Information Technology
Dedan Kimathi University of Technology, Kenya
patrick.gikunda@dkut.ac.ke
2
Le Laboratoire d’Informatique Avance de Saint-Denis (LIASD)
University of Paris 8, France
n@ai.univ-paris8.fr
Abstract.Recent  introduction  of  ICT  in  agriculture  has  brought  a
number  of  changes  in  the  way  farming  is  done.  This  means  use  of  In-
ternet of Things(IoT), Cloud Computing(CC), Big Data (BD) and au-
tomation to gain better control over the process of farming. As the use of
these technologies in farms has grown exponentially with massive data
production,  there  is  need  to  develop  and  use  state-of-the-art  tools  in
order  to  gain  more  insight  from  the  data  within  reasonable  time.  In
this paper, we present an initial understanding of Convolutional Neural
Network  (CNN),  the  recent  architectures  of  state-of-the-art  CNN  and
their  underlying  complexities.  Then  we  propose  a  classification  taxon-
omy tailored for agricultural application of CNN. Finally, we present a
comprehensive review of research dedicated to applications of state-of-
the-art  CNNs  in  agricultural  production  systems.  Our  contribution  is
in two-fold. First, for end users of agricultural deep learning tools, our
benchmarking finding can serve as a guide to selecting appropriate ar-
chitecture  to  use.  Second,  for  agricultural  software  developers  of  deep
learning tools, our in-depth analysis explains the state-of-the-art CNN
complexities and points out possible future directions to further optimize
the running performance.
Keywords:Convolutional Neural Network, Farming, Internet of Things
1  Introduction
The  global  population  is  set  to  touch  9.6  billion  mark  by  year  2050  [4].  The
continous  population  growth  means  increase  in  demand  for  food  to  feed  the
population [5]. Agriculture is the practice of cultivation of land and breeding of
animals  &  plants  to  provide  food  and  other  products  in  order  to  sustain  and
enhance life [6]. Due to the extreme weather conditions, rising climate change
and environmental impact resulting from intensive farming practices [8], farm-
ers  are  now  forced  to  change  their  farming  practices.  To  cope  with  the  new
farming challenges, farmers are forced to practice smart farming [9], which of-
fers solutions of farming management and environment management for better
arXiv:1907.07772v1  [cs.CY]  15 Jul 2019

2Gikunda and Jouandeau.
production. Smart farming focuses on the use of information and communica-
tion technology(ICT) in the cyber-physical farm management cycle for efficient
farming [10].
Curent ICT technologies relevant for use in smart farming include IoT [11],
remote sensing [12], CC [13] and BD [14]. Remote sensing is the science of gath-
ering information about objects or areas from a distance without having physi-
cal contact with objects or areas being investigated. Data collected through re-
mote sensing and distributed devices is managed by cloud computing technology,
which offers the tools for pre-processing and modelling of huge amounts of data
coming from various heterogeneous sources [15]. These four technologies could
create applications to provide solutions to todays’s agricultural challenges. The
solutions include real time analytics required to carry out agile actions especially
in case of suddenly changed operational or environmental condition (e.g. weather
or disease alert). The continous monitoring, measuring, storing and analysing of
various physical aspects has led to a phenomena of big data [16]. To get insight
for practical action from this large type of data requires tools and methods that
can process multidimensional data from different sources while leveraging on the
processing time.
One of the sucessful data processing tool applied in this kind of large dataset
is the biologically inspired Convolutional Neural Networks (CNNs), which have
achieved state-of-the-art results [17] in computer vision [18] and data mining [19].
As deep learning has been successfully applied in various domains, it has recently
entered in the domain of agriculture [10]. CNN is a subset method of Deep Learn-
ing(DL) [20], defined as deep, feed-forward Artificial Neural Network(ANN)[21].
The CNN covolutions allow data representations in a hierarchical way [22]. The
common  characteristics  of  CNN  models  is  that  they  follow  the  same  general
design principles of successive applying convolutional layers to the input, peri-
odically  downsampling  the  spatial  dimensions  while  increasing  the  number  of
feature maps. These architectures serve as rich feature extractors which can be
used  for  image  classification,  object  detection,  image  segmentation  and  many
more  other  advanced  tasks.  This  study  investigates  the  agricultural  problems
that employ the major state-of-the-art CNN archtectures that have participated
in the ImageNet Large Scale Visual Recognition Challenge (ILSVRC) [23] with
highest accuracy in a multi-class classification problem. ImageNet [26] classifi-
cation challange has played a critical role in advancing the CNN state-of-the-art
[17].  The  motivation  for  carrying  out  the  study  include:  a)  CNNs  has  better
precision  compared  to  other  popular  image-processing  techniques  in  the  large
majority of problems [27]. b) CNN has entered in the agricultural domain with
promising  potential  [28].  c)  all  the  CNN  models  that  have  achieved  the  top-5
error are successful when applied in other computer vision domain with remark-
able results [27]. This review aims to provide insight on use of state-of-the-art
CNN models in relation to smart farming and to identify smart farming research
and development challenges related to computer vision. Therefore the analysis
will  primarily  focus  on  the  success  on  use  of  state-of-the-art  CNN  models  in
smart farms with a intention to provide this relevant information to the future

Modern CNNs for IoT Based Farms3
researchers. From that perspective the research questions to be addressed in the
study are:
(a)  What is the role of CNN in smart farming?
(b)  What type of the state-of-the-art CNN architecture should be used?
(c)  What are the benefits of using state-of-the-art CNN in IoT based agricultural
systems?
The  rest  of  the  paper  is  organized  as  follows:  in  Section  2,  we  present  an
overview of existing state-of-the-art CNNs architectures including their recent
updates. Then we propose a taxonomy to provide a systematic classification of
agricultural  issues  for  CNN  application.  In  Section  3,  we  present  the  existing
state-of-the-art CNNs and their scope of application in agri-systems. We con-
clude the paper in Section 4.
2  Methodology
In order to address the research questions a bibliographic analysis in the domain
under study was done between 2012 and 2018, it involved two steps: a) collec-
tion  of  related  works  and,  b)  detailed  review  and  analysis  of  the  works.  The
choice of the period is from the fact that CNN is rather a recent phenomenon.
In the first step, a keyword-based search using all combinations of two groups
of keywords of which the first group addresses CNN models (LeNet, AlexNet,
NIN,  ENet,  GoogLeNet,  ResNet,  DenseNet,  VGG,  Inception)  and  the  second
group refers to farming (i.e. agriculture, farming, smart farming). The analysis
was done while considering the following research questions: a) smart farm prob-
lem they addressed, b)dataset used, c) accuracy based on author’s performance
metric, d) state-of-the-art CNN model used. Its important to note that use of
state-of-the-art  deep  learning  has  great  potential,  and  there  have  been  recent
small  comparative  studies  to  analyse  and  compare  the  most  efficient  archtec-
ture to use in agricultural systems. They include: Comparison between LeNet,
AlexNet, and VGGNet on automatic identification of center pivot irrigation [29]
and comparison between VGG-16, Inception-V4, Resnet and DenseNet for plant
disease identification [30].
3  State-of-the-art CNN: An Overview
CNNs typically perform best when they are large, meaning when they have more
deeper  and  highly  interconnected  layers  [31].  The  primary  drawback  of  these
archtectures is the computational cost, thus large CNNs are typically imprac-
tically slow especially for embedded IoT devices [32]. There are recent research
efforts  on  how  to  reduce  the  computation  cost  of  deep  learning  networks  for
everyday application while maintaining the prediction accuracy [33]. In order to
understand the application of the state-of-the-art CNN archtectures in agricul-
tural systems, we reviewed the accuracy and computational requirements from

4Gikunda and Jouandeau.
relevant literature including recent updates of networks as shown in Fig 1. The
classical state-of-the-art deep network architectures include; LeNet [34], AlexNet
[35], NIN [36], ENet[37], ZFNet [38], GoogleLeNet [39] and VGG 16 [40]. Modern
architectures include; Inception [41], ResNet [42], and DenseNet [43].
Fig. 1.Top-1 Accuracy vs the computational cost. The size of the circles is propor-
taional to number of parameters. Legend;the grey cirles at the botton right represents
number of parameters in millions. [32]
LeNet-5 is a 7-layer pioneer convolutional network by LeCun et al. [34] to
classify digits, used to recognise hand-written numbers digitized in 32x32 pixel
greyscale input images. High resolution images require more convolutional layers,
so the model is constrained by the availability of the computing resources.
AlexNet is a 5-layer network similar to LeNet-5 but with more filters [35].
It  outperformed  Lenet-5  and  won  the  LSVRC  challenge  by  reducing  the  top-
5  error  from  26.2%  to  15.3%.  Use  Rectified  Linear  Unit  (Relu)  [1]  instead  of
Hyperbolic Tangent (Tanh) [2] to add non-linearity and accelerates the speed
by 6 times. Droupout was employed to reduce over-fitting in the fully-connected
layers. Overlap pooling was used to reduce the size of the network while reducing
top-1 error by 0.4% and top-5 error by 0.3%.
Lin  et  al.  [36]  created  a  Network  in  Network(NIN)  which  inspired  the  in-
ception architecture of googlenet. In their paper, they replaced the linear filters
with nonlinear multi linear perceptrons that had better feature extraction and
accuracy. They also replaced the fully connected layers with activation maps and
global average pooling. This move helped reduce the parameters and network
complexity.
In  their  article  Paszke  et  al.  [37]  introduced  an  Efficient  Neural  Network
(ENet)  for  running  on  low-power  mobile  devices  while  achieving  state-of-the-
art  results.  ENet  architecture  is  largely  based  on  ResNets.  The  structure  has
one master and several branches that separate from the master but concatenate
back.
In  their  work  Zeiler  and  Fergus  [38]  created  ZFNet  which  won  a  ILSVRC
2013 [25] image classification. It was able to achieve a top-5 rate of 14.8% an

Modern CNNs for IoT Based Farms5
improvement of the AlexNet. They were able to do this by tweaking the hyper-
parameters  of  AlexNet  while  maintaining  the  same  structure  with  additional
deep learning elements. There is no record observed of use of ZFNet in agricul-
tural systems despite the accuracy improvement. Each branch consists of three
convolutional layers. The first 1 x 1 projection reduces the dimensionality while
the latter 1 x 1 projection expands the dimensionality. In between these convo-
lutions, a regular (no annotation / asymmetric X), dilated (dilated X) or full
convolution (no annotation) takes place. Batch normalization [60] and PReLU
[61] are placed between all convolutions. As regularizer in the bottleneck, Spatial
Dropout is used. MaxPooling on the master is added only when the bottleneck
is downsampling which is true.
GoogleNet,  a  2014  ILSVRC  image  classification  winner,  was  inspired  by
LeNet but implemented a novel inception module. The Inception cell performs
series of convolutions at different scales and subsequently aggregate the results.
This module is based on several very small convolutions in order to drastically
reduce the number of parameters. There has been tremedious efforts done to im-
prove the performance of the architecture: a) Inception v1 [39] which performs
convolution on an input, with 3 different sizes of filters (1x1, 3x3, 5x5). Addi-
tionally, max pooling is also performed. The outputs are concatenated and sent
to the next inception module. b) Inception v2 and Inception v3 [41] factorize 5x5
convolution to two 3x3 convolution operations to improve computational speed.
Although this may seem counterintuitive, a 5x5 convolution is 2.78 times more
expensive than a 3x3 convolution. So stacking two 3x3 convolutions infact leads
to  a  boost  in  performance.  c)  In  Inception  v4  and  Inception-ResNet  [44]  the
initial set of operations were modified before introducing the Inception blocks.
Simonyan and Zisserman created VGGNet while doing investigation on the
effect  of  convolutional  network  depth  on  its  accuracy  in  the  large-scale  image
recognition setting. The VGGNet took the second place after GoogLeNet in the
competation.  The  model  is  made  up  of  16  convolutional  layers  which  is  simi-
lar to [35] but with many filters. There have been a number of update to the
VGGNet archtecture starting with pioneer VGG-11(11 layers) which obtained
10.4% error rate[40]. VGG-13 (13 layers) obtains 9.9% error rate, which means
the additional convolutional layers helps the classification accuracy. VGG-16(16
layers) obtained a 9.4% error rate, which means the additional 3x1x1 conv layers
help the classification accuracy. 1x1 convolution helps increase non-linearlity of
the decision function, without changing the dimensions of input and output, 1x1
convolution is able to do the projection mapping in the same high dimension-
ality. This approach is used in NIN [36] GoogLeNet [39] and ResNet [42]. After
updating to VGG-16 it obtained 8.8% error rate which means the deep learning
network was still improving by adding number of layers. VGG-19(19 layers) was
developed to further improve the performance but it obtained 9.0% showing no
improvement even after adding more layers.
When deeper networks starts converging, a degradation problem is exposed:
with the network depth increasing, accuracy gets saturated and then degrades
rapidly. Deep Residual Neural Network(ResNet) created by Kaiming He al. [42]

6Gikunda and Jouandeau.
introduced a norvel architecture with insert shortcut connections which turn the
network  into  its  counterpart  residual  version.  This  was  a  breakthrough  which
enabled the development of much deeper networks. The residual function is a
refinement step in which the network learn how to adjust the input feature map
for higher quality features. Following this intuition, the network residual block
was refined and proposed a pre-activation variant of residual block [45], in which
the gradients can flow through the shortcut connections to any other earlier layer
unimpeded. Each ResNet block is either 2 layer deep (used in small networks like
ResNet 18, 34) or 3 layer deep(ResNet 50, 101, 152). This technique is able to
train a network with 152 layers while still having lower complexity than VGGNet.
It achieves a top-5 error rate of 3.57% which beats human-level performance on
this dataset. Although the original ResNet paper focused on creating a network
architecture to enable deeper structures by alleviating the degradation problem,
other  researchers  have  since  pointed  out  that  increasing  the  network’s  width
(channel depth) can be a more efficient way of expanding the overall capacity of
the network.
In DenseNet which is a logical extension of ResNet, there is improved effi-
ciency by concatenating each layer feature map to every successive layer within a
dense block [43]. This allows later layers within the network to directly leverage
the features from earlier layers, encouraging feature reuse within the network.
For each layer, the feature-maps of all preceding layers are used as inputs, and
its  own  feature-maps  are  used  as  inputs  into  all  subsequent  layers,  this  helps
alleviate  the  vanishing-gradient  problem,  feature  reuse  and  reduce  number  of
parameters.
3.1    Proposed agricultural issues classification taxonomy
Many  agricultural  CNN  solutions  have  been  developed  depending  on  specific
agriculture issues. For the study purpose, a classification taxonomy tailored to
CNN application in the smart farming was developed as shown Fig 2. In this
section, we categorize use of state-of-the-art CNN based on the agricultural issue
they solve:
(a)  Plant management includes solutions geared towards crop welfare and pro-
duction. This includes classification(species), detection(disease and pest) and
prediction(yield production).
(b)  Livestock management address solutions for livestock production(prediction
and quality management) and animal welfare(animal identification, species
detection and disease and pest control).
(c)  Environment management addresses solutions for land and water manage-
ment.
3.2    Use of state-of-the-art CNN in Smart Farms
The table 1, shows use of state-of-the-art CNN in agriculture and in particular
the  areas  of  plant  and  leaf  disease  detection,  animal  face  identification,  plant

Modern CNNs for IoT Based Farms7
Fig. 2.Proposed classification taxonomy for CNN use in smart farm
recognition, land cover classification, fruit counting and identification of weeds.
It consist of 5 columns to show: the problem description, size of data used, accu-
racy according to the metrics used, the state-of-the-art CNN used and reference
literature.
In their paper, Amara et al. [54] use the LeNet architecture to classify the
banana leaves diseases. The model was able to effectively classify the leaves after
several experiments. The approach was able to classify leaves images with differ-
ent illumination, complex background, resolution, size, pose, and orientation. We
also reviwed use of CaffeNet archtecture [59] in agricultural application, which
is a 1-GPU version of AlexNet. The success of this model at LSVRC 2012 [24]
encourage many computer vision community to explore more on the application
of deep learning in computer vision. Mohanty et al. [7] combined both AlexNet
and GoogLeNet to identify 14 crop species and 26 diseases(or absence thereof)
from a dataset of 54,305 images. The approach records an impressive accuracy of
99.35% demonstrating the feasibility of the state-of-the-art CNN architectures.
Other areas AlexNet has been used with high accuracy record include; identify
plants using different plant views [49], identify plant species [48], identify obsta-
cles in the farm [50] and leaf disease detection [3]. Because of its achievement
to improve utilization of the computing resources GoogLeNet has been used in
fruit count  [53] and plant  species  classification [7]. VGGNet has been used  in
classifying weed [56], detect obstacles in the farm [51], fruit detection [47] and
animal face recognition [55]. Like ResNet, DenseNet is a recent model that ex-
plains  why  it  has  not  been  employeed  significantly  in  farming,  nevertheless  it
has  been  used  in  thistle  identification  in  winter  wheat  and  spring  barley  [52].
Since ResNet is a such a recent model, it have only been used by one author in

8Gikunda and Jouandeau.
Table 1.Use of state-of-the-art CNN in Smart Farm
No.Smartfarm Problem descriptionData usedAccuracyCNN
Framework
used
Article
1Fruit detectionImages   of   three
fruitvarieties:
apples   (726),   al-
monds  (385)  and
mangoes (1154)
F1    (precicion    score)
of0.904(apples)
0.908   (mango)   0.775
(almonds)
VGGNet[46]
2Detection  of  sweet  pepper  and
rock melon fruits
122 images0.838 (F1)VGGNet[47]
3Recognize different plant speciesData   set   of   44
classes
99.60%  (CA  -  correct
prediction)
AlexNet[48]
4Recognize different plant91 759 images48.60%(LC-correct
species classification)
AlexNet[49]
5Identify  obstacles  in  row  crops
and grass mowing
437 images99.9% in row crops and
90.8% in grass mowing
(CA)
AlexNet[50]
6Identify  crop  species  and  dis-
eases
54 306 images0.9935 (F1)AlexNet    +
GoogLeNet
[7]
7Detect  obstacles  that  are  dis-
tant,  heavily  occluded  and  un-
known
48 images0.72 (F1)AlexNet    +
VGG
[51]
8Leaf disease detection4483 images96.30% (CA)CaffeNet[3]
9Identify  thistle  in  winter  wheat
and spring barley images
4500 images97.00% (CA)DenseNet[52]
10Predict  number  of  tomatoes  in
images
24 000 images91%(RFC-Ratioof
total    fruits    counted)
on   real   images,   93%
(RFC)onsynthetic
images
GoogLeNet
+ ResNet
[53]
11Classify banana leaf diseases3700 images96% (CA), 0.968 (F1)LeNet[54]
12Indentify pig face1553 images96.7%( CA)VGGNet[55]
13Classify weed from crop species
based  on  22  different  species  in
total
10413 images86.20% (CA)VGGNet[56]
14Detecting  and  categorizing  the
criticalness  of  Fusarium  wilt  of
radish  based  on  thresholding  a
range of color features
1500 imagesGoogLeNet[57]
15Fruit counting24 000 images91% accuracyInception-
ResNet
[53]
16Automatic Plant disease diagno-
sis for early disease symptoms
8178 imagesoverall improvement of
the  balanced  accuracy
from 0.78 to 0.87 from
previous 2017 study
Deep
ResNet
[58]
fruit counting [53]. Many of the CNN developed for agricultural use depend on
the problem or challenge they solve.

Modern CNNs for IoT Based Farms9
4  Conclusions and Recommendations
Despite  remarkable  achievement  in  use  state-of-the-art  CNN  in  agriculture  in
general, there exist grey areas in relation to smart farm that future researchers
may look at. These areas may include; real-time image classification, interactive
image classification and interactive object detection. State-of-the-art CNN is rel-
atively a new technology that explain why the finding of the study about their
use in smart farm is relatively small. However, its is important to note that mod-
els built from  state-of-the-art architectures have a impressive record of better
precision performance. In this paper, we aimed at establishing the potential of
state-of-the-art CNN in IoT based smart farms. In particular we first discussed
the architectures of state-of-the-art CNNs and their respective prediction accu-
racy at the ILSVRC challenge. Then a survey on application of the identified
CNNs in Agriculture was performed; to examine the particular application in
a smart farm, listed technical details of the architecture employed and overall
prediction  accuracy  achieved  according  to  the  author  precision  metrics.  From
the study its evident of continuous accuracy improvement of the state-of-the-art
CNN architectures as computer vision community put effort to perfect the meth-
ods. The findings indicate that state-of-the-art CNN has achieved better preci-
sion in all the cases applied in the agricultural domain, scoring higher accuracy
in majority of the problem as compared to other image-processing techniques.
Considering that the state-of-the-art CNN has achieved state-of-the-art results
in prediction in general and high precision in the few farming cases observed,
there is great potential that can be achieved in using the methods in smart farm-
ing. It has been observed that many authors apply more than one architecture
in order to optimize the performance of the network without compromising the
expected accuracy. This approach is very efficient in the observed cases, and we
recommend similar hybrid approach when building robust IoT based networks
which are computationally fair to the mobile devices. This study aims to moti-
vate researchers to experiment and apply the state-of-the-art methods in smart
farms problems related to computer vision and data analysis in general.
References
1.  Xu, B., Wang, N., Chen, T., Li, M. Empirical Evaluation of Rectified Activations
in Convolutional Network. CoRR, abs/1505.00853 (2015).
2.  Luo, P., Li, H. Research on Quantum Neural Network and its Applications Based
on Tanh Activation Function. Comput. Digit. Eng, 16, 3339 (2016).
3.  Sladojevic, S., Arsenovic, M., Anderla, A., Culibrk, D., Stefanovic, D. (2016). Deep
Neural Networks Based Recognition of Plant Diseases by Leaf Image Classification.
Comp. Int. and Neuroscience (2016).
4.  Godfray,  H.C.,  Beddington,  J.R.,  Crute,  I.R.,  Haddad,  L.,  Lawrence,  D.,  Muir,
J.F.,  Pretty,  J.N.,  Robinson,  S.,  Thomas,  S.M.,  Toulmin,  C.  Food  security:  the
challenge of feeding 9 billion people. Science, 327 5967, 812-8 (2010).
5.  Lutz, W.L., Sanderson, W.C., Scherbov, S. The coming acceleration of global pop-
ulation ageing. Nature, 451, 716-719 (2008).

10Gikunda and Jouandeau.
6.  Bruinsma, J. (Ed.). World Agriculture: Towards 2015/2030. An FAO Perspective.
Earthscan, London (2003).
7.  Mohanty,  S.P.,  Hughes,  D.P.,  Salath,  M.  Using  Deep  Learning  for  Image-Based
Plant Disease Detection. Front. Plant Science (2016).
8.  Gebbers, R., Adamchuk, V.I. Precision agriculture and food security. Science, 327
5967, 828-31 (2010).
9.  Krintz,   C.,   Wolski,   R.,   Golubovic,   N.,   Lampel,   B.,   Kulkarni,   V.,   Sethura-
masamyraja, B.B., Roberts, B. SmartFarm : Improving Agriculture Sustainability
Using Modern Information Technology (2016).
10.  Kamilaris,  Andreas  Prenafeta  Bold,  Francesc.  A  review  of  the  use  of  convolu-
tional neural networks in agriculture. The Journal of Agricultural Science. 1-11.
10.1017/S0021859618000436 (2018).
11.  Weber  R.  H.  Weber  R.  Internet  of  Things:  Legal perspectives.  Berlin: Springer-
Verlag Berlin Heidelberg. 10.1007/978-3-642-11710-7 (2010).
12.  Anindya  Sunday,  Remote  Sensing  in  Agriculture,  International  Journal  of  Envi-
ronment, Agriculture and Biotechnology (IJEAB), Vol-1, Issue-3 (2016).
13.  Jinbo, C., Xiangliang, C., Han-Chi, F. et al. Cluster Computing.https://doi.org/
10.1007/s10586-018-2022-5
14.  Chi  M,  Plaza  A,  Benediktsson  JA,  Sun  Z,  Shen  J  and  Zhu  Y.  Big  data  for  re-
mote sensing: challenges and opportunities. Proceedings of the IEEE 104, 22072219
(2016).
15.  Waga D and Rabah K. Environmental conditions big data management and cloud
computing analytics for sustainable agriculture. World Journal of Computer Ap-
plication and Technology 2,7381 (2017).
16.  Chen, M., Mao, S., Liu, Y. Big Data: A Survey. MONET, 19, 171-209 (2014).
17.  Russakovsky,  O.,  Deng,  J.,  Su,  H.,  Krause,  J.,  Satheesh,  S.,  Ma,  S.,  Huang,  Z.,
Karpathy, A., Khosla, A., Bernstein, M.S., Berg, A.C., Fei-Fei, L. ImageNet Large
Scale  Visual  Recognition  Challenge.  International  Journal  of  Computer  Vision,
115, 211-252 (2015).
18.  Liang, M., Hu, X. (2015). Recurrent convolutional neural network for object recog-
nition. IEEE Conference on Computer Vision and Pattern Recognition (CVPR),
3367-3375 (2015).
19.  Poria, S., Cambria, E., Gelbukh, A.F. Aspect extraction for opinion mining with a
deep convolutional neural network. Knowledge-Based System., 108, 42-49 (2016).
20.  Goodfellow, I.J., Bengio, Y., Courville, A.C. Deep Learning. Nature, 521, 436-444,
(2015).
21.  Bhandare, A., Bhide, M., Gokhale, P., Chandavarkar, R. Applications of Convolu-
tional Neural Networks, (2016).
22.  Schmidhuber J. Deep learning in neural networks: an overview. Neural Networks
61,85117 (2015).
23.  http://image-net.org/challenges/LSVRC/2017, last accessed 2018/09/02.
24.  http://image-net.org/challenges/LSVRC/2012/, last accessed 2018/09/02.
25.  http://image-net.org/challenges/LSVRC/2013/, last accessed 2018/09/02.
26.  ImageNet, http://image-net.org, last accessed 2018/10/21.
27.  Zahangir M.A, Tarek M. Taha1, Chris Yakopcic, Stefan Westberg, Paheding Sidike,
Mst  Shamima  Nasrin,  Brian  C  Van  Essen,  Abdul  A  S.  Awwal,  and  Vijayan  K.
Asari. The History Began from AlexNet: A Comprehensive Survey on Deep Learn-
ing Approaches.https://arxiv.org/pdf/1803.01164
28.  Kamilaris, Andreas and Francesc X. Prenafeta-Boldu. Deep learning in agriculture:
A survey. Computers and Electronics in Agriculture 147: 70-90 (2018).

Modern CNNs for IoT Based Farms11
29.  Zhang, C., Yue, P., Liping, D., Zhaoyan, W,. Automatic Identification of Center
Pivot Irrigation Systems from Landsat Images Using Convolutional Neural Net-
works. Agriculture (2018).
30.  Chebet, E., Yujian, l., Njuki, S., Yingchun, L., A comparative study of fine-tuning
deep learning models for plant disease identification. Computers and Electronics
in Agriculture. https://doi.org/10.1016/j.compag.2018.03.032
31.  Andri, R., Cavigelli, L., Rossi, D., Benini, L. Hyperdrive: A Systolically Scalable
Binary-Weight CNN Inference Engine for mW IoT End-Nodes. 2018 IEEE Com-
puter Society Annual Symposium on VLSI (ISVLSI), 509-515 (2018).
32.  Canziani,  A.,  Paszke,  A.,  Culurciello,  E.  An  Analysis  of  Deep  Neural  Network
Models for Practical Applications. CoRR, abs/1605.07678 (2016).
33.  HasanPour,  S.H.,  Rouhani,  M.,  Fayyaz,  M.,  Sabokrou,  M.,  Adeli,  E.  Towards
Principled Design of Deep Convolutional Networks: Introducing SimpNet. CoRR,
abs/1802.06205 (2018).
34.  LeCun, Y., Bottou, L., Bengio, Y. Gradient-Based Learning Applied to Document
Recognition. Proceedings of the IEEE, 86(11):22782324 (1998).
35.  Krizhevsky, A., Sutskever, I., Hinton, G.E. ImageNet Classification with Deep Con-
volutional Neural Networks. Commun. ACM, 60, 84-90. (2012).
36.  Lin, M., Chen, Q., Yan, S. Network In Network. CoRR, abs/1312.4400 (2013).
37.  Paszke, A., Chaurasia, A., Kim, S., Culurciello, E. ENet: A Deep Neural Network
Architecture for Real-Time Semantic Segmentation. CoRR, abs/1606.02147 (2016).
38.  Zeiler, M.D., Fergus, R. Visualizing and understanding convolutional networks. In
European conference on computer vision, pages 818833. Springer (2014).
39.  Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S.E., Anguelov, D., Erhan, D.,
Vanhoucke, V., Rabinovich, A. Going deeper with convolutions. IEEE Conference
on Computer Vision and Pattern Recognition (CVPR), 1-9 (2015).
40.  Simonyan, K., Zisserman, A. Very Deep Convolutional Networks for Large-Scale
Image Recognition. CoRR, abs/1409.1556 (2014).
41.  Szegedy,  C.,  Vanhoucke,  V.,  Ioffe,  S.,  Shlens,  J.,  Wojna,  Z.  (2016).  Rethinking
the Inception Architecture for Computer Vision. IEEE Conference on Computer
Vision and Pattern Recognition (CVPR), 2818-2826 (2016).
42.  He, K., Zhang, X., Ren, S., Sun, J. Deep Residual Learning for Image Recognition.
2016  IEEE  Conference  on  Computer  Vision  and  Pattern  Recognition  (CVPR),
770-778 (2015).
43.  Huang, G., Liu, Z., Maaten, L.V., Weinberger, K.Q. Densely Connected Convolu-
tional Networks. 2017 IEEE Conference on Computer Vision and Pattern Recog-
nition (CVPR), 2261-2269 (2017).
44.  Szegedy, C., Ioffe, S., Vanhoucke, V. Inception-v4, Inception-ResNet and the Im-
pact of Residual Connections on Learning. AAAI (2017).
45.  He, K., Zhang, X., Ren, S., Sun, J. Identity Mappings in Deep Residual Networks.
ECCV (2016).
46.  Bargoti, S., Underwood, J.P. Deep fruit detection in orchards. 2017 IEEE Interna-
tional Conference on Robotics and Automation (ICRA), 3626-3633 (2017).
47.  Sa, I., Ge, Z., Dayoub, F., Upcroft, B., Perez, T., McCool, C. DeepFruits: A Fruit
Detection System Using Deep Neural Networks. Sensors (2016).
48.  Lee, S.H., Chan, C.S., Wilkin, P., Remagnino, P. Deep-plant: Plant identification
with convolutional neural networks. 2015 IEEE International Conference on Image
Processing (ICIP), 452-456 (2015).
49.  Reyes, A.K., Caicedo, J.C., Camargo, J.E. Fine-tuning Deep Convolutional Net-
works for Plant Recognition CLEF (2015).

12Gikunda and Jouandeau.
50.  Steen, K.A., Christiansen, P., Karstoft, H., Jrgensen, R.N. Using Deep Learning
to Challenge Safety Standard for Highly Autonomous Machines in Agriculture. J.
Imaging, 2, 6 (2016).
51.  Christiansen,  P.,  Nielsen,  L.N.,  Steen,  K.A.,  Jrgensen,  R.N.,  Karstoft,  H.  Deep-
Anomaly:  Combining  Background  Subtraction and  Deep  Learning for  Detecting
Obstacles and Anomalies in an Agricultural Field. Sensors (2016).
52.  Srensen, R. A., Rasmussen, J., Nielsen, J., Jrgensen, R. N. Thistle Detection using
Convolutional Neural Networks. In EFITA WCCA 2017 Conference, Montpellier
Supagro, Montpellier, France, July 26 (2017).
53.  Rahnemoonfar,  M.,  Sheppard,  C.  Deep  Count:  Fruit  Counting  Based  on  Deep
Simulated Learning. Sensors (2017).
54.  Amara, J., Bouaziz, B., Algergawy, A. A Deep Learning-based Approach for Ba-
nana Leaf Diseases Classification. BTW (2017).
55.  Hansen, M.F., Smith, M.L., Smith, L.N., Salter, M.G., Baxter, E.M., Farish, M.,
Grieve, B. Towards on-farm pig face recognition using convolutional neural net-
works. Computers in Industry, 98, 145-152 (2018).
56.  Dyrmann,  M.,  Karstoft,  H.,  Midtiby.,  H.  Plant  species  classification  using  deep
convolutional neural network. Biosystems Engineering 151,7280 (2016).
57.  Hyun, J., Ibrahim. H., Irfan, M., Minh, L., Suhyeon, I. UAV based wilt detection
system via convolutional neural networks. Sustainable Computing: Informatics and
Systems. https://doi.org/10.1016/j.suscom.2018.05.010
58.  Picona,  A.,  Alvarez,  A.,  Seitz,  M.,  Ortiz,  O.,  Echazarra,  J.,  Johannes,  A.  Deep
convolutional neural networks for mobile capture device-based crop disease classi-
fication in the wild. Computers and Electronics in Agriculture.https://doi.org/10.
1016/j.compag.2018.04.002
59.  Jia, Y., Shelhamer, E., Donahue, J., Karayev, S., Long, J., Girshick, R.B., Guadar-
rama, S., Darrell, T. Caffe: Convolutional Architecture for Fast Feature Embed-
ding. ACM Multimedia (2014).
60.  Ioffe, S., Szegedy, C. Batch Normalization: Accelerating Deep Network Training
by Reducing Internal Covariate Shift. ICML (2015).
61.  He, K., Zhang, X., Ren, S., Sun, J. Delving Deep into Rectifiers: Surpassing Human-
Level Performance on ImageNet Classification. 2015 IEEE International Confer-
ence on Computer Vision (ICCV), 1026-1034 (2015). 

A feasibility study of deep neural networks for the
recognition of banknotes regarding central bank
requirements
Julia Schulte
CI Tech Sensors AG
Email: julia.schulte@citechsensors.com
Daniel Staps
Mittweida University
of Applied Science
Email: dstaps@hs-mittweida.de
Alexander Lampe
Mittweida University
of Applied Science
Email: lampe@hs-mittweida.de
Abstract—This paper contains a feasibility study of deep neural
networks  for  the  classification  of  Euro  banknotes  with  respect
to  requirements  of  central  banks  on  the  ATM  and  high  speed
sorting industry. Instead of concentrating on the accuracy for a
large number of classes as in the famous ImageNet Challenge we
focus  thus  on  conditions  with  few  classes  and  the  requirement
of rejection of images belonging clearly to neither of the trained
classes  (i.e.  classification  in  a  so-called  0-class).  These  special
requirements  are  part  of  frameworks  defined  by  central  banks
as  the  European  Central  Bank  and  are  met  by  current  ATMs
and high speed sorting machines. We also consider training and
classification time on state of the art GPU hardware. The study
concentrates on the banknote recognition whereas banknote class
dependent  authenticity  and  fitness  checks  are  a  topic  of  its  own
which  is  not  considered  in  this  work.
I.  INTRODUCTION
An important step in the recirculation of banknotes is their
recognition in high-speed sorting machines and cash-recycling
ATMs which is followed by banknote class dependent authen-
ticity and fitness checks. Central banks ensure the integrity of
the cash cycle by formulating requirements and testing relevant
banknote  handling  machines  see  e.g.  [1].  On  the  other  hand
in  the  last  decade  deep  learning  has  outperformed  classical
algorithms  in  disciplines  like  natural  language  processing,
speech recognition or image recognition see [2].
In  the  current  paper  we  use  a  deep  learning  approach  for
the recognition of Euro banknotes which seems to be a simple
challenge  at  first  glance  but  in  fact  it  turns  out  to  be  tricky
when  central  bank  requirements  with  respect  to  rejection  of
objects  not  belonging  to  a  trained  banknote  class  are  taken
into consideration.
The success of deep learning is mainly driven by challenges
like the ImageNet Large Scale Visual Recognition Challenge
(ILSVRC)   with   1000   classes   including   keyboard,   mouse,
pencil, and many animals and more than one million images,
see  [3].  A  milestone  in  the  history  of  deep  learning  was  the
success of Alexnet [4], the first convolutional neural network
(CNN),  winning  the  ILSVRC  challenge  by  reduction  of  the
top-5  error  rate  from  26.1%  to  15.3%.  The  achievements  of
deep  learning  are  made  possible  by  advances  in  available
computing  power  and  larger  training  data  sets  allowing  for
deeper  models  with  millions  of  parameters.  Following  the
popularity of deep learning in academia it is now available to
the industry and general public via open source frameworks as
e.g.  Tensorflow  [5]  or  Matlab’s  deep  learning  toolbox.  Since
in most applications massive amounts of training data are not
available a popular approach consists of transfer learning, i.e.
the  finetuning  of  some  layers  of  the  pretrained  network  for
a  specific  task,  where  the  pretraining  is  done  on  a  similar
but  sufficiently  large  data  set,  see  [6],  [7].  An  example  is
the  pretraining  on  Imagenet  and  the  fine  tuning  on  a  smaller
data set for the classification of plants [8] or medical images
[9],  [10].  The  problem  of  recognition  with  a  reject  class  is
often  referred  to  as  open  set  recognition.  A  sophisticated
probabilistic approach accompanied by an experimental study
on the ImageNet database is contained in [11].
The current paper is structured as follows. In Section II we in-
troduce the necessary background on banknote categories and
the  recycling  framework  introduced  by  the  European  Central
Bank. Subsequently we summarize some background on image
classification using deep neural networks and transfer learning
in a mathematically rigorous way. In Section III we introduce
the  0-class  module,  i.e.  we  propose  an  architecture  modifi-
cation  of  the  classical  deep  neural  network  image  classifier
which  allows  the  mapping  of  images  to  a  reject  class.  Then,
we  introduce  the  Inception-v3  neural  network  which  will  be
applied  for  transfer  learning.  In  Section  IV  we  present  the
results  of  our  experimental  study  which  contains  a  statistical
analysis  of  classification  results  for  genuine  banknotes  under
different training conditions and on 3 data sets with different
resolutions and with or without application of skew correction.
We  study  classification  results  for  a  deep  neural  network
classifier with additional 0-class module also regarding reject
rates on genuine banknotes as well as on images not belonging
to  a  trained  banknote  class,  where  rejection  is  desired  for
the  latter.  Furthermore,  we  study  training  and  test  times.  A
summary of the results is contained in Section V.
arXiv:1907.07890v1  [cs.CV]  18 Jul 2019

II.  BACKGROUND
A.  Banknote categories and banknote recycling framework by
the European Central Bank
Ensuring  the  integrity  of  the  banknote  cycle  is  a  major
task of the European Central Bank (ECB). For this reason the
recirculation as well as the authenticity and fitness checking is
regulated in the decisions [1], [12] which apply to bank note
handling  machines  like  cash-recycling  ATMs  and  high-speed
sorting machines used e.g. in banks and cash-centers. The ECB
distinguishes between 4 categories of inputs to banknote han-
dling machines. Category 1 consists of objects not recognized
as Euro banknotes e.g. because of a wrong image or format,
transportation  errors,  large  folded  corners,  missing  parts  or
non-Euro currency, compare Figure 3. Category 1 objects have
to  be  rejected  to  the  customer  or  operating  staff.  Category
2  consists  of  suspect  counterfeit  Euro  notes  where  image
and  format  are  correct  but  one  ore  more  security  features
are  clearly  missing  or  out  of  tolerance.  Category  2  shall
be  withdrawn  from  circulation,  handed  over  to  the  national
authorities  within  20  working  days  for  further  investigation
and not be credited to the account holder. Category 3 consists
of banknotes with correct image and format but some security
features which cannot clearly be authenticated possibly due to
tolerance deviations or bad quality of the banknote. Category 3
is treated in the same way as category 2 but may be credited to
the account holder. Category 4 consists of genuine banknotes
where  all  authenticity  checks  are  positive.  Furthermore  it  is
differed  between  Category  4a  where  also  all  fitness  checks
have  a  positive  results  and  category  4b  where  at  least  some
fitness  criteria  has  a  negative  result.  Category  4  is  credited
to  the  account  holder  but  only  category  4a  shall  be  used
for  recirculation  whereas  category  4b  shall  be  returned  to
a  national  central  bank.  The  ECB  tests  banknote  handling
machines and publishes a list of successfully tested machines
on  their  website  [13],  [14].  The  current  test  procedure  (see
[15])  contains  a  counterfeit  test  (at  least  90%  of  a  given
counterfeit  test  deck  shall  be  sorted  in  category  2  or  3  and
none  in  category  4)  and  a  fitness  test  (not  more  than  5%  of
a  given  test  deck  of  unfit  notes  shall  be  sorted  to  category
4a). Furthermore at least 90% of a given test deck of fit and
genuine notes shall be classified as category 4a and not more
than 1% of the fit and genuine notes as category 1, 2 or 3.
B.  Image classification and deep neural networks
An image classifier is a function
f: [a, b]
w×h×c
→{1, . . . , N},
whereh, w, c∈Nare the width and height of the input image
in pixels,c∈Nis the number of input channels (usually 3 for
red, green and blue) and[a, b]is the range of the pixel values.
FurthermoreN∈Ndenotes the number of image classes. Let
P V(N) ={(y
1
, . . . , y
N
)∈[0,1]
N
withy
1
+. . .+y
N
= 1}
denote  the  space  of  probability  vectors  of  lengthN.  A  deep
neural net is a function
f
DNN
(·; Θ) : [a, b]
w×h×c
→P V(N),
whereΘ∈R
m
is  the  vector  of  trainable  parameters  with
m >10
6
not  being  unusual.  A  deep  neural  net  can  be  used
as image classifier of the form
f=g◦f
DNN
(·; Θ),
where
g(y) = arg max(y),   y∈P V(N).
Training  a  neural  net  means  that  the  parameter  vectorΘ
is  repeatedly  updated  in  so-called  training  episodes  where  a
chosen  stochastic  optimization  algorithm  is  used  to  optimize
the  parameters  for  the  classification  of  a  randomly  chosen
batch  of  training  images.  Batch  sizes  of  several  hundred  and
training episode numbers of more than 1000 are not unusual.
C.  Transfer learning
Let a deep neural netf
DNN
mapping toP V(N)be given.
Usuallyf
DNN
has a decomposition of the form
f
DNN
=f
class
(·;
 ̃
Θ)◦f
feat
(·; Θ),
where
f
feat
(·; Θ) : [a, b]
w×h×c
→R
l
with  trainable  parametersΘ∈R
m
is  the  mapping  to  the  so
called feature space and
f
class
(·;
 ̃
Θ) :R
l
→P V(N)
with  trainable  parameters
 ̃
Θ∈R
k
consists  of  the  last  two
layers of the deep neural network which are a fully connected
layer followed by a softmax layer. By concatenating the feature
mapf
feat
of  a  given  deep  neural  net  with  a  suitablef
class
mapping toP V(n)instead ofP V(N)we can obtain a deep
neural network for the classification ofnimage classes instead
ofN.
By transfer learning we mean the training of a classifier
f=g◦f
class
(·;
 ̃
Θ)◦f
feat
(·; Θ)
with  fixed  parametersΘ∈R
m
for  the  classification  of
ndifferent  image  classes  by  updating  only  the  parameter
vector
 ̃
Θ∈R
k
.  Usuallykis  much  smaller  thanm.  Thus
transfer  learning  has  a  significantly  reduced  training  time  in
comparison to training from scratch.
III.  PROPOSEDMETHOD
A.  The 0-class module
We introduce a reject class or 0-class which contains images
belonging  to  neither  of  the  trained  classes.  For  this  purpose
we introduce the so called 0-class module
f
0-class
(·;T) :P V(n)→{0,···, n}
defined by
f
0-class
(y;T) =
{
0,max(y)≤T,
arg max(y),max(y)> T,

fory∈P V(n)with  parameterT∈[0,1]which  can  be
either trained or chosen by hand. Thus the deep neural network
classifier with 0-class module is of the form
f=f
0-class
◦f
class
◦f
feat
: [a, b]
w×h×c
→{0, . . . , n},
wheref(x) = 0means a reject of imagexandf(x) =ifor
i∈ {1, . . . , n}means  that  the  imagexis  mapped  to  theith
trained class.
B.  Google’s inception-v3 CNN
As  deep  neural  net  we  choose  in  the  following  Google’s
Inception-v3  architecture  proposed  in  [16],  which  achieves  a
3.45%  top-5  error  rate  on  the  ILSVRC2012  benchmark  data
set. The inception-v3 has a feature map of the form
f
feat
(·; Θ) : [−1,1]
299×299×3
→R
2048
,
with trainable parameter vectorΘ∈R
m
withm= 23885392.
The  inception  architecture  consists  of  48  different  network
layers,  compare  Figure  1,  which  are  mostly  convolutional,
pooling  or  inception  layers  and  have  the  ability  to  detect
edges, corners, contours and objects. It is available for transfer
learning,  see  [17],  with  parameters  pretrained  on  more  than
one million images from the ImageNet database [3].
Fig. 1.   Architecture of the Inception-v3 neural network.
IV.  EXPERIMENTALSTUDY
A.  The hardware
To assess the potential of the described approach for appli-
cation in the ATM industry we made an experimental study on
a work station with the state of the art GPU NVIDIA GeForce
GTX  1080  Ti  with  11  GB  graphics  storage  and  a  price  of
759e.  The  transfer  learning  for  the  inception-v3  net  and  our
architecture modifications were done in Google’s open source
framework  Tensorflow  [5]  building  on  the  pretrained  model
available as open source repository, see [17].
B.  The data sets
We  compare  results  for  three  different  data  sets  of  Euro
banknotes  which  are  provided  by  Diebold  Nixdorf  AG  and
consist  of  field  data  recorded  with  a  high-speed  line  camera
used  in  Diebold  Nixdorf  cash  recycling  ATMs,  see  [18],
with   integrated   sensor   module   and   recognition   software
by  CI  Tech  Sensors  AG,  see  [19].  The  first  aim  of  the
experimental  study  conducted  in  2018  under  non-disclosure
agreement   with   Mittweida   University   of   Applied   Science
was  to  asses  the  potential  for  industrial  application.  This
explains  why  the  data  is  not  made  publicly  available.  Still
the  authors  promote  publication  of  the  results  for  the  sake
of   public   interest   in   a   balanced   view   on   deep   learning
methods.  All  data  sets  consist  of  images  with  three  color
channels  with  the  specialty  that  red  and  green  are  recorded
in   transmitted   illumination   whereas   blue   is   recorded   in
reflected  illumination.  The  resolution  is25dpi  for  data  sets
1and2and8dpi  for  data  set3.  The  difference  between
data  set1and2is  that  for  data  set1banknotes  have  a
skew  up  to20
◦
.  See  Figure  2  for  example  images.  All  data
(a) Example image from data set 1 of class EUR005a1.
(b)  Example  image  from  data  set  2  of
class EUR
020b4.
(c)  Example  image  from  data
set 3 of class EUR
500a4.
Fig. 2.   Example images for data set 1, 2 and 3.
sets  contain  40  different  banknote  classes  consisting  of  the
four  orientations  of  EUR
005a,  EUR005b,  EUR010a,
EUR010b,EUR020a,EUR020b,EUR050a,
EUR100a,  EUR200a  and  EUR500a  where  a  and  b
denote the first and second series of the Euro banknotes. The
different  orientations  are  treated  as  different  classes  denoted
e.g.   for   EUR005a   by   EUR005a1,   EUR005a2,
EUR
005a3  and  EUR005a4  meaning  front  side,  front
side  upside  down,  back  side  and  back  side  upside  down.
Furthermore  category  1  images  are  provided  which  belong
to  neither  of  the  trained  banknote  classes  or  are  genuine
Euro  notes  not  recognized  by  the  classical  algorithm  used
in  the  field  which  is  usually  due  to  large  folded  corners.
The  number  of  images  per  class  varies  from  291  in  case  of
EUR
200a2  to  54091  in  case  of  EUR050a3  which  is
due  to  different  ratios  of  the  denominations  in  the  field.  Per
data set more than 400000 banknote images of category 4 are
provided.  The  images  contain  recordings  of  banknotes  from
the field which have different fitness quality.
C.  Comparison of different training conditions
We  fix  the  validation  and  test  set  ratio  at10%per  class,
the training batch size at300and use the Adam algorithm as
optimizer. As parameters for the Adam optimizer we use the
default  values  suggested  in  [2,  Section  8.5.3],  i.e.  a  learning
rate of0.001, an exponential decay rate for the first and second
moment estimate of0.9and0.999respectively and a numerical
stabilization constant of10
−8
. We compare the accuracy, i.e.

the  ratio  of  correctly  classified  images  from  the  test  set  for
the  different  data  sets  and  different  training  conditions  with
varying  number  of  training  images  and  training  epochs  see
Table  I.  For  all  three  data  sets  the  results  show  clearly  that
a  higher  number  of  epochs  and  a  larger  training  set  lead  to
an  improvement  of  the  accuracy.  For  a  smaller  training  set
and  a  smaller  number  of  epochs  data  set  2  achieves  the  best
results  followed  by  data  set  1  and  data  set  3.  For  a  larger
number of epochs and a larger training set all data sets achieve
an  accuracy  of100%.  It  should  be  mentioned  that  we  only
consider results on notes which were recognized correctly by
the  currently  used  classifier  in  the  field.  In  Subsection  IV-D
we  will  also  compare  results  for  Euro  notes  rejected  by  the
currently used classifier.
TABLE I
RATIO OF CORRECTLY CLASSIFIED TEST SET IMAGES(ACCURACY)FOR
DATA  SETS1-3UNDER DIFFERENT TRAINING CONDITIONS.
epochs
Data set11000300010000
5099.814%99.842%99.852%
Training images
per class
up to300099.983%99.995%99.993%
all available99.983%99.993%100.00%
epochs
Data set21000300010000
5099.873%99.947%99.967%
Training images
per class
up to300099.983%99.990%99.998%
all available99.995%99.998%100.00%
epochs
Data set31000300010000
5099.771%99.766%99.842%
Training images
per class
up to300099.969%99.993%100.00%
all available99.967%99.995%100.00%
D.  Results for category 1 input
For  the  study  of  the  classification  of  category  1  input  we
concentrate  on  data  set  2.  This  data  set  consists  of  25dpi
images  without  skew  and  achieves  the  best  accuracy  results
on  images  from  the  40  considered  banknote  classes  among
the  three  data  sets.  In  the  following  we  turn  to  the  problem
of classification of category 1 input. By the ECB decision [1]
input images which are obviously not banknotes because of a
wrong image or format have to be rejected. Typical examples
are double notes (images of two overlapping notes), transport
errors  (mostly  because  of  jam),  other  currencies,  cheques  or
genuine Euro notes with large folded corners.
In Figure 3 we show examples for 5 different types. For the
last type of ’rejected genuine Euro notes’ it can be desirable to
obtain a higher acceptance rate and a category 4b classification
whereas a category 2 or 3 classification should be avoided.
It should be noted that a reject rate for genuine notes below
1% is needed to pass the ECB test procedure, see [15]. So this
should be the aim for a deep learning based recognition. On the
(a)  Rejected  input  of  type  ’double
note’.
(b) Rejected input of type ’transport
error’.
(c)  Rejected  input  of  type  ’other
currency’.
(d) Rejected input of type ’cheque’.
(e)  Rejected  input  of  type  ’rejected
genuine Euro note’.
Fig. 3.   Examples for different types of category 1 input rejected in the field.
other hand non-genuine category 1 images which are mapped
to one of the 40 banknote classes will be considered as fake
notes (category 2 or 3) in the subsequent authenticity checks.
Category  2  or  3  notes  have  to  be  investigated  by  national
central bank authorities and it is therefore not desirable that a
large ratio of category 1 is sorted to category 2 or 3. Thus, a
convenient thresholdTfor the mapping to the0-class should
not  lead  to  a  higher  reject  rate  of  genuine  banknotes  and
should not lead to an increased amount of category 1 images
mapped to a banknote class. In Table II we compare the reject
rates for the inception-v3 net combined with a 0-class module
with  different  thresholds  (C1-C4).  As  test  set  we  use  10%
of the genuine notes accepted plus 10% of the genuine notes
rejected  by  the  classical  algorithm.  The  thresholds  for  the  0-
class  module  are  motivated  by  the  quantiles  of  the  maximal
class probabilities in the set of genuine notes rejected by the
classical algorithm but recognized correctly by the inception-
v3 classifier see Figure 4. As shown in Table II reject rates of
0.51% and lower can be obtained which meet the central bank
requirement of a reject rate below 1%. However, if the reject
rate is reduced further by choosing a lower threshold for the
0-class  module  at  some  point  we  start  to  observe  banknotes
being sorted to the wrong banknote class (C4).
E.  Run time measurements
We  distinguish  between  training  time  and  test  time.  The
training time consists of the time for feature extraction, i.e. for
the application of the pretrained inception-v3 net to the image

TABLE II
COMPARISON OF SORTING RESULTS FOR DIFFERENT CLASSIFIERSC1-C4.
Nr.
Classifier
reject rate
on genuine
BNs (%)
# Non Euro
category 1
images
sorted
in BN class
# accepted
genuine BNs
in wrong
BN class
C1
Inception-v3+
0-Class module
with T=0.9986
0.5100
C2
Inception-v3+
0-Class module
with T=0.9972
0.2610
C3
Inception-v3+
0-Class module
with T=0.9932
0.1220
C4
Inception-v3+
0-Class module
with T=0.9803
0.0453
which is displayed in Table III and of the time for retraining of
the last layer displayed in Table IV. Under a practical view the
time for retraining is neglectable whereas the feature extraction
time for all images can be more than 2h. Still this is a minor
problem since this time has to be expended only once. The test
time is much more critical since in practice we are facing strict
real  time  requirements  in  the  contemplated  application.  The
test time is the sum of the feature extraction time for 1 image
(about 20ms by column 1 of Table III) and the test time of the
resulting feature vector which is in average 0.59ms. Thus we
obtain  a  complete  test  time  of  about  20ms  for  images  of  all
three  data  sets.  Here  we  should  mention  that  the  test  time  is
measured on the same workstation as the training time which
is equipped with a rather expensive graphical processing unit.
TABLE III
FEATURE EXTRACTION TIME FOR DIFFERENT AMOUNTS OF IMAGES FROM
DATA SETS1-3.
Number of images
12000120000400000
data set120.04ms40.08s40min48s136min
data set219.73ms39.46s39min28s131min33s
data set319.49ms38.98s38min59s130min27s
TABLE IV
TIME FOR  RETRAINING  DEPENDING ON THE NUMBER  OF EPOCHS AND
THE BATCH SIZE.
epochs
1000300010000
3032.46s83.89s264.69s
batch size10066.98s180.60s585.16s
300153.76s444.54s1471.91s
V.  CONCLUSION
In  this  paper  we  studied  the  feasibility  of  recognition  of
Euro banknotes by deep learning. We focused on requirements
(a) Ecdfs with x-axis ranging from 0 to 1.
(b) Ecdfs with zoom to high x-values ranging from 0.97 to 1.
Fig.  4.   Empirical  cumulated  distribution  function  (ecdf)  for  maximal  class
probability  in  feature  vector  for  different  types  of  images  rejected  by  the
classical  algorithm  as  well  as  for  genuine  notes  accepted  by  the  classical
algorithm (cat 4 Euro notes). For genuine Euro notes rejected by the classical
algorithm we differ between Euro notes mapped to the correct banknote class
(recognized  EUR  BNs)  and  Euro  notes  mapped  to  a  wrong  banknote  class
(not-recognized EUR BNs) by the inception-v3-classifier.
from  central  banks  including  in  particular  the  rejection  of
objects  with  wrong  image  or  format.  Thus,  we  introduce  a
0-class module which can be concatenated to every classifier
with a probability vector for the trained classes as output and
allows  the  rejection  i.e.  sorting  to  a  0-class  depending  on  a
chosen threshold. In our experimental study we observed that
the largest considered number of training images and epochs
achieves  100%  accuracy  on  all  three  considered  data  sets
(25dpi  without  skew  correction,  25dpi  with  skew  correction
and  8dpi  with  skew  correction).  For  a  smaller  number  of
training images (50 per class) and epochs (1000) we observe
that data set 2 achieves the best accuracy (99.873%), followed
by data set 1 (99.814%) and data set 3 (99.771%). The study
of sorting results using the 0-class module for rejection shows
that  reject  rates  of  0.51%  and  lower  can  be  obtained,  which
meets central bank requirements. However, if the reject rate is
reduced further by choosing a lower threshold for the 0-class

module at some point we observe banknotes being sorted to the
wrong banknote class. Run time measurements show that test
time is approximately 20ms on a work station equipped with
a  state  of  the  art  GPU.  This  is  acceptable  for  the  considered
real-time application. In summary, the deep learning approach
with additional 0-class module offers the possibility for a low
reject rate of genuine Euro banknotes, though it is subject of
further investigation if a higher acceptance rate leads only to
a  higher  category  4b  rate  or  also  to  a  higher  category  3  rate
where the latter is undesirable.
ACKNOWLEDGMENT
The authors would like to thank Michael Flack and Armin
St
 ̈
ockli from CI Tech Sensors AG for supporting the presented
feasibility study and the publication of the results. Furthermore
the  authors  would  like  to  express  their  gratitude  to  Rainer
Stute  from  Diebold  Nixdorf  AG  for  the  collection  of  the
field  data,  to  Peter  Zemp  from  CI  Tech  Sensors  AG  for  the
preprocessing  of  the  field  data  and  to  Armin  St
 ̈
ockli  for  his
valuable  comments  and  active  support  concerning  the  results
on  the  classification  of  the  category  1  images.  Last  but  not
least, we would like to express our special thanks to Markus
S
 ̈
uß  from  Mittweida  University  of  Applied  Science  for  his
advice concerning Python and the Tensorflow framework.
REFERENCES
[1]  European  Central  Bank,  “Decision  of  the  European  central  bank  of  7
September  2012  amending  Decision  ECB/2010/14  on  the  authenticity
and  fitness  checking  and  recirculation  of  euro  banknotes.”Official
Journal of the European Union, vol. L253/19, 2012.
[2]  I. Goodfellow, Y. Bengio, and A. Courville,Deep Learning.   MIT Press,
2016, http://www.deeplearningbook.org.
[3]  O.  Russakovsky,  J.  Deng,  H.  Su,  J.  Krause,  S.  Satheesh,  S.  Ma,
Z. Huang, A. Karpathy, A. Khosla, M. Bernsteinet al., “Imagenet large
scale visual recognition challenge,”IJCV, vol. 115, no. 3, pp. 211–252,
2015.
[4]  A. Krizhevsky, I. Sutskever, and G. E. Hinton, “Imagenet classification
with deep convolutional neural networks,” inAdvances in neural infor-
mation processing systems, 2012, pp. 1097–1105.
[5]  M. Abadi, P. Barham, J. Chen, Z. Chen, A. Davis, J. Dean, M. Devin,
S.  Ghemawat,  G.  Irving,  M.  Isardet  al.,  “Tensorflow:  A  system  for
large-scale machine learning,” in12th USENIX Symposium on Operating
Systems Design and Implementation (OSDI 16), 2016, pp. 265–283.
[6]  J. Yosinski, J. Clune, Y. Bengio, and H. Lipson, “How transferable are
features in deep neural networks?” inNIPS, 2014, pp. 3320–3328.
[7]  J.  Donahue,  Y.  Jia,  O.  Vinyals,  J.  Hoffman,  N.  Zhang,  E.  Tzeng,  and
T.  Darrell,  “Decaf:  A  deep  convolutional  activation  feature  for  generic
visual  recognition,”  inInternational  conference  on  machine  learning,
2014, pp. 647–655.
[8]  A.  K.  Reyes,  J.  C.  Caicedo,  and  J.  E.  Camargo,  “Fine-tuning  deep
convolutional  networks  for  plant  recognition.”CLEF  (Working  Notes),
vol. 1391, 2015.
[9]  H.-C.  Shin,  H.  R.  Roth,  M.  Gao,  L.  Lu,  Z.  Xu,  I.  Nogues,  J.  Yao,
D. Mollura, and R. M. Summers, “Deep convolutional neural networks
for  computer-aided  detection:  Cnn  architectures,  dataset  characteristics
and transfer learning,”IEEE transactions on medical imaging, vol. 35,
no. 5, pp. 1285–1298, 2016.
[10]  M.  Hon  and  N.  M.  Khan,  “Towards  alzheimer’s  disease  classification
through  transfer  learning,”  in2017  IEEE  International  Conference  on
Bioinformatics and Biomedicine (BIBM).    IEEE, 2017, pp. 1166–1169.
[11]  A.  Bendale  and  T.  E.  Boult,  “Towards  open  set  deep  networks,”  in
Proceedings  of  the  IEEE  conference  on  computer  vision  and  pattern
recognition, 2016, pp. 1563–1572.
[12]  European Central Bank, “Decision of the European central bank of 16
September 2010 on the authenticity and fitness checking and recircula-
tion  of  euro  banknotes.”Official  Journal  of  the  European  Union,  vol.
L267/1, 2010.
[13]  ——.(2019)Successfullytestedtypesofbanknotehan-
dling    machine    -    customer-operated    machines.    [Online].    Avail-
able:   https://www.ecb.europa.eu/euro/cashprof/cashhand/generatedPdfs/
Customer
OperatedMachines2019-07-05.en.pdf
[14]  ——.(2019)Successfullytestedtypesofbanknotehan-
dlingmachine-staff-operatedmachines.[Online].Avail-
able:   https://www.ecb.europa.eu/euro/cashprof/cashhand/generatedPdfs/
StaffOperatedMachines2019-07-05.en.pdf
[15]  European   Central   Bank.   (2019)   Procedures   for   testing   banknote
handling  machine  types.  [Online].  Available:  https://www.ecb.europa.
eu/euro/cashprof/cashhand/recycling/html/proctest.en.html#procedure
[16]  C. Szegedy, V. Vanhoucke, S. Ioffe, J. Shlens, and Z. Wojna, “Rethinking
the inception architecture for computer vision,” inCVPR, 2016.
[17]  Google.  (2019)  Tensorflow  implementation  of  pretrained  inception-v3.
[Online].   Available:   https://github.com/tensorflow/models/tree/master/
research/inception
[18]  Diebold   Nixdorf.   (2019)   CS4060   cash   recycling   ATM.   [Online].
Available:   https://www.dieboldnixdorf.com/en-us/financial-institutions/
systems/cash-recyclers/cs%204060
[19]  CI Tech Sensors AG. (2019) Our technology - your security. [Online].
Available: https://www.citechsensors.com/en/technology.html 

optimalFlow: Optimal-transport approach to
flow cytometry gating and population matching
∗
Eustasio del Barrio
1
, Hristo Inouzhe
2
, Jean-Michel Loubes
3
, Carlos Matr ́an
4
, and
Agust ́ın Mayo-
 ́
Iscar
5
1,2,4,5
Departamento de Estad ́ıstica e Investigaci ́on Operativa and IMUVA, Universidad
de Valladolid, Spain.
3
Universit ́e de Toulouse, Institut de Math ́ematiques de Toulouse, France.
Abstract
Data used in Flow Cytometry present pronounced variability due to biological and tech-
nical  reasons.   Biological  variability  is  a  well  known  phenomenon  produced  by  measure-
ments on different individuals, with different characteristics such as age, sex, etc...  The use
of  different  settings  for  measurement,  the  variation  of  the  conditions  during  experiments
or  the  different  types  of  flow  cytometers  are  some  of  the  technical  sources  of  variability.
This  high  variability  makes  difficult  the  use  of  supervised  machine  learning  for  identifi-
cation  of  cell  populations.   We  proposeoptimalFlowTemplates,  based  on  asimilarity  dis-
tanceandWasserstein  barycenters,  which  clusterizes  cytometries  and  produces  prototype
cytometries  for  the  different  groups.   We  show  that  supervised  learning  restricted  to  the
new groups performs better than the same techniques applied to the whole collection.  We
also presentoptimalFlowClassification, which uses a database of gated cytometries and op-
timalFlowTemplates to assign cell types to a new cytometry.  We show that this procedure
can  outperform  state  of  the  art  techniques  in  the  proposed  datasets.   Our  code  and  data
are  freely  available  as  R  packages  at  https://github.com/HristoInouzhe/optimalFlow  and
https://github.com/HristoInouzhe/optimalFlowData.
1    Introduction
Flow cytometry (FC) works with ‘high-dimensional quantitative measurement of light scatter
and fluorescence emission properties of hundreds of thousands of individual cells in each analysed
sample’ (see [1]).  These quantitative measurements allow to analyze and classify individual cells
providing diverse applications.  For example,  as mentioned in [29],  ‘flow cytometry is used to
identify  and  quantify  populations  of  immune  cells’  in  order  to  monitor  the  immune  state  of
patients or to detect relevant biomarkers by comparing flow cytometries from different patient
groups.
A main component in FC is gating,  the assignment of individual cells (data records) into
discrete  cell  types.   Manual  gating,  i.e.,  an  expert  assigning  cell  types  (labels)  to  individual
cells, using a set of rules on one or two-dimensional projections, has been the prevalent option.
However, this manual approach has some shortcomings.  First, it is subjective since it depends
∗
Research  partially  supported  by  FEDER,  Spanish  Ministerio  de  Econom ́ıa  y  Competitividad,   grant
MTM2017-86061-C2-1-P  and  Junta  de  Castilla  y  Le ́on,  grants  VA005P17  and  VA002G18.   Research  partially
supported by ANITI program and DEEL IRT.
1
arXiv:1907.08006v1  [stat.ML]  18 Jul 2019

on the expertise of the user,  on the sequence of markers (measured variables) used to do the
projections and on the locations of the gates on those projections.  Second, it can be very time
consuming  because  it  is  ‘roughly  quadratic  in  the  number  of  markers’  (see  [23]).   Third,  the
recent increase in the number of markers and number of cells per cytometry makes human error
a relevant factor.
In order to avoid some of the difficulties related to manual gating there have been different
approaches to automated gating.  Some are unsupervised, therefore, there is no use of previously
gated cytometries.  Hence, gating is done through a clustering procedure.  We present a small
selection of such unsupervised automated gating procedures. FLOCK [28], which dose grid-based
density estimation (with merging) and then k-means; FLAME [27], which performs skewtmodel
based clustering and flowClust [24, 25], which does robust based clustering throughtmixture
models with Box-Cox transformation.  Other related clustering procedures are:  flowPeaks [19]
performs Gaussian mixture model based clustering (with modified covariances) and merging and
flowMeans [2] does k-means with initialization via mode detection through kernel density based
estimation.  More information about state of the art methods can be found in [1, 29].
Accuracy of cell type assignation can be improved using supervised machine learning where
historical  information  is  contained  in  previously  gated  cytometries  (manually  or  otherwise).
Recently, some methods have been produced addressing this problem.  In [23], DeepCyTOF was
introduced, essentially combining de-noising, deep-learning algorithms and domain adaptation.
In  [26],  flowLearn  was  introduced,  combining  density  features  of  the  data,  manually  selected
gating thresholds and derivative-based density alignments.  We stress that other more classical
approaches for supervised learning are also available.  For example, random forest algorithms,
support  vector  machines  or  quadratic  discriminant  analysis  can  be  used  when  learning  from
some previously gated cytometry.  Supervised machine learning is a well documented topic and
for more detailed explanations we refer to [3].
There  are  two  main  set-ups  for  using  supervised  learning.   First,  the  classical  one,  where
there is an available data base of historical information.  In the FC context, this means that a
collection of gated flow cytometries is available and we want to use this information in order
to  gate a  new cytometry.  Second,  an alternative  one,  where  we  have a  collection of  ungated
cytometries and it is possible to gate some of them and use these gated cytometries to classify
the rest of the cytometries in the collection.
In  both  set-ups  there  is  a  fundamental  problem  intrinsic  to  FC.  That  is,  flow  cytometry
data has considerable technical and biological variability.  Biological variability appears due to
intrinsic  differences  between  individuals  such  as  illness,  age,  sex,  etc...   Technical  variability
can appear due to the use of different settings for the measurements, due to the variations of
the conditions during the experiments or due to the use of different types of flow cytometers.
Precisely this high variability makes the use of supervised methods a hard task.
In  this  work  we  provide  novel  methods  for  grouping  (clustering)  gated  cytometries.   By
clustering a set of cytometries we are producing groups (clusters) of cytometries that have lower
variability than the whole collection.  This in turn allows to improve greatly the performance of
any supervised learning procedure.  We provide evidence of this below.  Once we have a partition
(clustering) of a collection of cytometries, we provide several methods for obtaining an artificial
cytometry (prototype, template) that represents in some optimal way the cytometries in each
respective group.  These prototypes can be used, among other things, for matching populations
between  different  cytometries  as  suggested  in  [7, 20].   Even  more,  a  procedure  able  to  group
similar cytometries could help to detect individuals with a common particular condition.
optimalFlowTemplatesis our procedure for clustering cytometries and obtaining templates.
It is based on recent developments in the field of optimal transport such as asimilarity distance
between  clusterings,  introduced  in  [12],  and  abarycenter(Frechet  mean,  see  [10, 22])  andk-
2

barycenters(see [4, 5, 8]) of probability distributions.
We introduce a supervised classification tool,optimalFlowClassification, for the case when
a database of gated cytometries is available.  The procedure uses the prototypes obtained by
optimalFlowTemplates on the database.  These are used to initialisetclust, a robust extension
of k-means that allows for non-spherical shapes, for gating a new cytometry (see [18], not to be
confused with TCLUST, [14]).  By using a similarity distance between the best clustering ob-
tained by tclust and the artificial cytometries provided by optimalFlowTemplates we can assign
the new cytometry to the most similar template (and the respective group of cytometries).  We
provide several options of how to assign cell types to the new cytometry using the most relevant
information, represented by the assigned template and the respective cluster of cytometries.
2    Methods
We start with the mathematical treatment of flow cytometry data.  We can view a gated flow
cytometry, sayX
i
, as a collection ofn
i
multidimensional points with their associated labels (cell
types or group labels) forming a setL
i
={L
i
k
}
k
i
k=1
ofk
i
different labels. Hence, a gated cytometry
can be described asX
i
={(X
i
j
,Y
i
j
)}
n
i
j=1
whereX
i
j
∈R
d
andY
i
j
∈L
i
.  Alternatively we could
describe it as a partition (clustering) of allX
i
j
into groups (clusters) formed by points sharing the
same labels.  That is,C
i
={(C
i
k
,p
i
k
)}
k
i
k=1
whereC
i
k
={X
i
j
: 1≤j≤n
i
,Y
i
j
=L
i
k
}is a cluster and
p
i
k
is a weight associated with labelL
i
k
.  A third useful description is to view a gated cytometry
as a clustering but coming from a mixture of location-scatter multivariate distributions.  With
some  abuse  of  notationC
i
={(m
i
k
,S
i
k
,p
i
k
)}
k
i
k=1
wherem
i
k
,S
i
k
are  the  multivariate  mean  and
covariance of the points in clusterC
i
k
.
2.1    optimalFlowTemplates
Due  to  the  the  high  variability  in  flow  cytometry  data  we  should  expect  that  learning  form
different elements in a database should produce significantly different results on the classification
of a new cytometryX
T
={X
T
1
,...,X
T
n
T
}⊂R
d
. Our approach is to search for clusters of existing
cytometries in the database.  In this way we pursuit for a notable reduction of variability thus
allowing a good representation of the cytometries in each of these groups through prototypic
cytometries.  Therefore, using a prototype of a group for learning should produce a similar result
for classifyingX
T
to the one obtained when using any other cytometry in the same group.
2.1.1  Clustering cytometries
Since  gated  cytometries  can  be  viewed  as  partitions  (clusterings)  and  we  want  to  clusterize
cytometries in order to reduce variability, we want to do clustering of clusterings, also known
as  metaclustering.   The  methodology  we  will  develop  in  this  work  is  to  use  some  meaningful
distance  between  partitions  and  then  apply  hierarchical  clustering  methods.   As  a  distance
between  clusterings  we  propose  to  use  thesimilarity  distanceintroduced  in  [12].   It  is  based
on two auxiliary distances.  The optimal transport distance between two partitionsC
i
andC
j
,
defined as
d
OT
(C
i
,C
j
) =
k=k
i
∑
k=1
l=k
j
∑
l=1
w
∗
kl
d(C
i
k
,C
j
l
),
3

whered(C
i
k
,C
j
l
) is a distance between clustersC
i
k
andC
j
l
.  (w
∗
kl
) are the solutions of the optimal
transport linear program
minimize
∑
k=k
i
k=1
∑
l=k
j
l=1
w
kl
d(C
i
k
,C
j
l
)
subject tow
kl
≥0,1≤k≤k
i
,1≤l≤k
j
∑
l=k
j
l=1
w
kl
=p
i
k
,1≤k≤k
i
∑
k=k
i
k=1
w
kl
=p
j
l
,1≤l≤k
j
∑
k=k
i
k=1
∑
l=k
j
l=1
w
kl
= 1.
(1)
d
OT
measures the cost of the optimal way of transforming one partition into the other.  For more
detailed explanations on optimal transport see Supplementary Material Section A. The other
auxiliary distance is the naive transport distance, defined as
d
NT
(C
i
,C
j
) =
k
i
∑
k=1
k
j
∑
l=1
p
i
k
p
j
l
d(C
i
k
,C
j
l
).
It measures the cost of naively transforming one partition into the other.
Thesimilarity distanceis defined as the quotient
d
S
(C
i
,C
j
) =
d
OT
(C
i
,C
j
)
d
NT
(C
i
,C
j
)
.(2)
We recall that 0≤d
S
≤1, whered
S
= 0 means that partitionsC
i
,C
j
are represented by the
same clusters with the same weights andd
S
= 1 means that every cluster inC
i
is transported
proportionally to every cluster inC
j
.  Therefore, values ofd
S
close to 0 can be interpreted as high
similarity between clusterings, and values ofd
S
close to 1 can be interpreted as very dissimilar
clusterings.  In order to completely defined
S
, we need to specify a distance between clusters.
Our choice is to use the well known Wasserstein distance (see Supplementary Material Section
A) so
d(C
i
k
,C
j
l
) =W
2
(N(m
i
k
,S
i
k
),N(m
j
l
,S
j
l
)).(3)
In essence, we are treating clusters as multivariate normal distributions,N(m
i
k
,S
i
k
) andN(m
j
l
,S
j
l
),
with means and covariances calculated from the clusters.  Our choice of the Wasserstein distance
is based on the desire to account for the spatial shapes of the clusters and to obtain templates
for the groups of cytometries.  We stress that all results in this work are also valid when un-
derstanding clusters as members of a location-scatter family.  Another interesting measure for
cluster difference is,W
γ
(C
i
k
,C
j
l
), the (entropy) regularized Wasserstein distance (see Supplemen-
tary material Section A) where clusters are understood as empirical distributions.
However, any other dissimilarity measure can be used, for example the symmetric Kullback-
Leibler was used in [7] or Friedman-Rafsky test statistic was used in [20], in the context of cluster
comparison in flow cytometry.  When we see clusters as collections of points, the Adjusted Rand
Index,  the  Jaccard  distance  or  other  similar  can  be  used,  at  the  expense  of  loosing  spatial
information.
The clustering of cytometries is presented in lines 1-17 in Algorithm 1, resulting in a partition
T.  Lines 12-16 are concerned with the obtention of a distances matrixSthat in line 17 is used
to  perform  hierarchical  clustering.   Classical  agglomerative  algorithms  can  be  used,  but  also
density based algorithms as DBSCAN and HDBSCAN.
4

Algorithm 1optimalFlowTemplates
Input:X
1
,...,X
N
,equal.weights
1:fori≤Ndo
2:whilek≤k
i
and|C
i
k
|enough for covariance estimationdo
3:m
i
k
←meanC
i
k
;S
i
k
←covC
i
k
4:ifequal.weights=Truethen
5:p
i
k
←1/k
i
6:else
7:p
i
k
←|C
i
k
|/
∑
k
i
k=1
|C
i
k
|
8:end if
9:C
i
k
←(m
i
k
,S
i
k
,p
i
k
)
10:end while
11:end for
12:fori≤Ndo
13:fori < j≤Ndo
14:S
ij
←d
S
(C
i
,C
j
)
15:end for
16:end for
17:T←hierarchical clustering withS
18:fori≤|T|do
19:T
i
←template obtention on cytometries inT
i
20:end for
21:T={T
i
,...,T
|T|
}
Output:T,T
5

2.1.2  Template obtention through consensus clustering
Once  we  have  a  partition,T,  of  the  collection  of  cytometries{C
j
}
N
j=1
,  we  want  to  obtain  a
prototype cytometry,T
i
,  for every group of cytometries,i,  in the partitionT(lines 18-21 in
Algorithm 1).  To address this goal we resort to k-barycenters using Wasserstein distance, which
provide a suitable tool for consensus on probability distributions (see Supplementary Material
Section A for more details).  We propose three different methods on how to obtain a template
cytometry from a group of cytometries. That is, on how to do consensus (ensemble) clustering on
flow cytometries.  More on this topic can be found in Section B in the Supplementary material.
Pooling:   Suppose  that{L
i
}
N
i=1
⊂L={L
1
,...,L
K
}.   This  is  the  case  for  a  set  of  gated
cytometries with identified cell populations.
Input:C
1
,...,C
N
,T
1:forj≤Kdo
2:C
ij
←set of all clusters associated with labelL
j
for the cytometries in groupi.
3:if|C
ij
|>0then
4:T
i
j
←take 1-barycenter of the clusters inC
ij
viewed as multivariate normals.
5:else
6:T
i
j
is empty
7:end if
8:end for
9:T
i
←{T
i
1
,...,T
i
K
}
Output:T
i
Density based hierarchical clustering:
Input:C
1
,...,C
N
,T
1:C
i
←set formed by every cluster of every cytometry in groupi.
2:forj,k≤|C
i
|do
3:W
jk
←W
2
(N(m
i
j
,S
i
j
),N(m
i
k
,S
i
k
))
4:end for
5:T←density based hierarchical clustering based onW.
6:forj≤|T|do
7:T
i
j
←barycenter of elements with labeljinT.
8:end for
9:T
i
←{T
i
1
,...,T
i
|T|
}
Output:T
i
k-barycenter:
Input:C
1
,...,C
N
,T,K
1:C
i
←set formed by every cluster of every cytometry in groupi.
2:T
i
←K-barycenter of the elements inC
i
.
Output:T
i
The intuition behind pooling, once we have groups of similar cytometries and cell types are
known, is the following.  A prototype of a cell type is the 1-barycenter (barycenter), a consensus
representation, of the clusters (multivariate distributions) representing the same cell type in the
cytometries that are members of the same group inT.  A prototype cytometry is the collection
of prototypes of each cell type.
6

However, our templates could be obtained even when we have gated cytometries but without
cell type identification between them.  Density based hierarchical clustering and k-barycenter
are based on the idea that clusters that are close in Wasserstein distance should be understood
as  representing  the  same  cell  type,  although  we  may  not  know  which  cell  type.   When  using
k-barycenters  we  have  to specify  the number  of cell  types,K,  that  we  want  for the  artificial
cytometry.  However, when using density based hierarchical clustering as HDBSCAN (see [11])
or DBSCAN (see [15]) the selection of the number of cell types for the prototype cytometry is
automatic.  Recall that both k-barycenters, through trimming, and density based hierarchical
clustering are robust clustering procedures.
2.2    optimalFlowClassification
Our goal is to do supervised classification, i.e., assign cell types to a new cytometryX
T
, using the
information given in a database of gated cytometries{C
i
}
N
i=1
.  The different sources of variability,
mainly those of technical nature and those which are properly due to different cohorts present
in the database, advise to search for different cytometric structures.  Hence, we should assign
X
T
to the group of cytometries that is more similar to it and then use supervised techniques.
Indeed, this is the purpose of optimalFlowClassification, as shown in Algorithm 2.  As an input
we apply optimalFlowTemplates to the database{C
i
}
N
i=1
in order to obtain the partitionTand
the templatesT.
Algorithm 2optimalFlowClassification
Input:X
T
={X
T
1
,...,X
T
n
T
},T,T
1:fori≤|T|do
2:C
i,u
←tclust onX
T
initialized withT
i
3:end for
4:C
u
←arg max of tclust objective function over allC
i,u
5:fori≤|T|do
6:S
i
←d
S
(C
u
,T
i
)
7:end for
8:T
∗
←T
arg minS
i
;T
∗
←T
arg minS
i
9:C
T
←labelling ofX
T
using transfer labelling or supervised classification based onT
∗
orT
∗
.
Output:C
T
Lines  1-4  in  Algorithm  2  are  dedicated  to  finding  an  unsupervised  partition  of  the  new
cytometryX
T
using as initialization for tclust the prototypes of the database.  We favour the
use of tclust over k-means since it allows for non-spherical clusters and for trimming, making
partitions more robust to outliers. Additional information about tclust is given in Supplementary
Material Section C. Initializing with the database entries attempts to use optimally the available
information.   Hence,  ifX
T
is  similar  to  some  of  the  cytometries  in  the  database,  supervised
initialization should be advantageous.  However, some other suitable unsupervised initializations
can be used, as the ones proposed in FLOCK, flowPeaks or flowMeans.  We need to clusterX
T
in order to compare it with the template cytometries.
In lines 5-8 we look to assignX
T
, using the clusteringC
u
, produced in the previous step, to
the template that is closest in similarity distance toC
u
.  With this we hope to use only the most
relevant information of the database, summarized inT
∗
andT
∗
.
The last step in algorithm 2, line 9, is concerned with assigning cell types toX
T
.  To do this
we have several options.  We can try to relabelC
u
in an optimal way usingT
∗
orT
∗
, i.e, do label
transfer.  Alternatively, we can useT
∗
to do Quadratic Discriminant Analysis (QDA) or we can
7

find the most similar partition in similarity distance (2) fromT
∗
toC
u
and use it to do QDA or
random forest classification.  In short, we can do label transfer or supervised classification.
For supervised classification we use standard tools, random forest and QDA, however, other
methods can be used in a straightforward fashion.  We remark that when using QDA andT
∗
,
we are using non-linear multidimensional gating regions obtained fromT
∗
in order to classify
X
T
.   This  can  be  taught  as  an  extension  of  the  method  presented  in  [26]  where  only  linear
one-dimensional regions are used.  Another interesting fact is that the use ofd
S
allows us to
select the most similar real cytometry toC
u
, hence supervised tools should be more effective.
The problem of relabelling a clusteringC
j
with respect to another clusteringC
i
is usually
stated  as  a  weighted  bipartite  matching  problem,  where  weights  are  related  to  the  similarity
between clusters in the two partitions. This problem can be solved by the hungarian method [21].
Generalized edge cover is another possible solution to relabelling (see [7]).
Additionally we introduce an approach to obtain a fuzzy relabelling based on solving the
optimal transport linear program (1).  The solution, (w
∗
kl
), is the base for this fuzzy relabelling.
We define the score of clusterlinC
j
to come from clusterkinC
i
ass
l
k
=w
∗
kl
/p
j
l
.  In words,
s
l
k
is  the  proportion  of  probability  coming  from  clusterk,  with  respect  to  the  probability  in
clusterl, that arrives at clusterl.  Clearly, 0≤s
l
k
≤1, and the closer to 1 the score is the more
evidence we have that clusterkandlrepresent the same cluster.  A fuzzy relabelling for cluster
linC
j
is the collection of all the scoress
l
={s
l
1
,...,s
l
|C
i
|
}.  A variation of the previous score is
 ̃s
l
k
=s
l
k
∗w
∗
kl
/p
i
k
, where we are weighting by the proportion of clusterkthat goes to clusterl,
with respect to the probability contained in clusterk.  In this way we down-weight the effect of
a small proportion of a big cluster with respect to a big proportion of a small cluster arriving
tol.  From these fuzzy relabellings a hard relabelling can be easily obtained.
Again, a suitable distance between clusters can be the Wasserstein distance as in (3).  How-
ever, another possibility is to use
d(C
i
k
,C
j
l
) =
1
|C
i
k
||C
j
l
|
∑
x∈C
i
k
∑
y∈C
j
l
‖x−y‖
2
.(4)
(3) is computationally very efficient but does not allow to label very small clusters inC
j
.(4) does
allow labelling small clusters inC
j
, at the price of using sub-sampling to compare bigger clusters
(for example more than 10000 points).
3    Results
In this section we present several experiments and comparisons of our methods with other state
of  the  art  procedures  on  a  real  database.   In  Figure  1  we  provide  visual  intuition  of  what  a
cytometry looks like when understood as a mixture of normal distributions.  We also provide an
example of a prototype cytometry.  In Figure 2 we provide comparisons between the result of
optimalFlowTemplates, flowMatch and what can be considered a ground truth.  In Table 1 we
provide comparisons between state of the art unsupervised gating as given by flowMeans and
our proposal for initializing tclust with supervised information.  We also provide comparisons
between the state of the art supervised method deepCyTOF and our own supervised procedure
optimalFlowClassification.
3.1    Data
Our database is formed by 21 gated flow cytometries,{X
i
}
21
i=1
, obtained following the Euroflow
protocols, kindly provided by Centro de Investigaci ́on del Cancer (CIC) in Salamanca, Spain.
8

All 21 cytometries have been obtained in a BD FACSCanto flow cytometer but in three different
centres.  The size of the cytometry datasets vary from 50,000 cells to 254,450 cells.  The samples
are from adult male and female individuals, with a varied range of ages, that have been diagnosed
as healthy.  More information about the data set can be found in Table 2 in the Supplementary
material.
Clearly, there is biological variability, since there are different individuals with different ages
and other different characteristics. Moreover, we have technical variability since we have different
centres, different dates of measurement and different incubation times.  However, we remark that
all individuals belong to the same class of healthy people.
3.2    Measures of performance
We need appropriate measures of the performance of the different automated gating procedures
that appear in this work.  We recall that we use both unsupervised and supervised methods.  In
this set-up an appropriate tool is theF-measurestatistic which has been used in [1, 2, 19, 23].
With our notation we have
F(C
i
,C
j
) =
∑
k=1,...,|C
i
|
|C
i
k
|
M
max
l=1,...,|C
j
|
F(C
i
k
,C
j
l
),
F(C
i
k
,C
j
l
) = 2
R(C
i
k
,C
j
l
)P(C
i
k
,C
j
l
)
R(C
i
k
,C
j
l
) +P(C
i
k
,C
j
l
)
,
R(C
i
k
,C
j
l
) =
|C
i
k
∩C
j
l
|
|C
i
k
|
andP(C
i
k
,C
j
l
) =
|C
i
k
∩C
j
l
|
|C
j
l
|
withM=
∑
k=1,...,|C
i
|
|C
i
k
|=
∑
l=1,...,|C
j
|
|C
j
l
|.  We make the conventionR(∅,C
j
l
) =P(C
i
k
,∅) = 1
andR(C
i
k
,∅) =P(∅,C
j
l
) = 0.  Another appealing measure is themedian F-measureused in [26]
specifically for supervised learning.  The formal definition is
 ̃
F(C
i
,C
j
) = median
{
{F(C
i
k
,C
j
k∗
) :ksuch thatL
i
k
=L
j
k
∗
∈L
i
∩L
j
},{0}×|L
i
4L
k
|
}
whereC
i
is the considered ground truth, in our case a manual gating, andC
j
is another classi-
fication of the same data.
To measure how similar are two cytometries, i.e., how well we do when learning from one
to classify the other and how well we do when learning with the later to classify the former we
introduce the following distance.
d
learning
(X
i
,X
j
) = 1−
F(C
j
,
 ̃
C
j
) +F(C
i
,
 ̃
C
i
)
2
where
 ̃
C
j
is  the  partition  resulting  from  the  classification  of  the  data  inX
j
using  a  random
forest learned inX
i
.
 ̃
C
i
is the partition resulting from the classification of the data inX
i
using
a random forest learned inX
j
.  This measure gives us a notion of how close in terms of being
good predictors for one another are two cytometries.  We have that 0≤d
learning
≤1, and two
cytometries are interchangeable for learning ifd
learning
is close to 0.  A variation of this measure
is
 ̃
d
learning
(X
i
,X
j
) = 1−
 ̃
F(C
j
,
 ̃
C
j
) +
 ̃
F(C
i
,
 ̃
C
i
)
2
.
9

Figure 1:  Representation of five cell types.  Top-left:C
7
as a collection of points.  Top-right:C
7
as a mixture of gaussians.  Bottom-left:  Pooling ofC
7
,C
8
andC
16
.  Bottom-right:  barycenters of
the cell types in the pooling.
10

1
1
0
9
78
1
4
1
3
1
5
2
1
1
4
3
5
6
1
2
0
.
0
0
.
1
0
.
2
0
.
3
0
.
4
0
20
40
60
6
15
978213
11
4
10
5
141213
7
89
2
1
1
1
1
0
4
3
1
2
56
1
4
1
3
1
5
0
.
0
0
0
.
0
4
0
.
0
8
0
.
1
2
9
78
3
4
2
1
1
5
6
1
2
1
4
1
3
1
5
1
1
0
0
.
0
0
0
.
0
2
0
.
0
4
0
.
0
6
0
.
0
8
Figure  2:  Hierarchical  trees  for  the  databaseDB.   Top-left:  result  of  optimalFlowTemplates.
Top-right:  result  of  flowMatch  with  Mahalanobis  distance.   Bottom-left:  single  linkage  with
 ̃
d
learning
.  Bottom-right:  single linkage withd
learning
.
3.3    Clustering cytometries and template obtention
We start with a visual example to grasp the intuition behind our approach to flow cytometry. Top
left in Figure 1 we have a three dimensional projection of five cell types present inC
7
:  Basophils
(black), CD4+CD8- (red), Eosinophils (green), Monocyts (Blue), Neutrophils (Cyan).  From the
picture we can view each cell type as a cluster, hence havingC
7
={C
7
1
,...,C
7
5
}, omitting weight
information for simplicity, whereC
7
1
corresponds to Basophils,C
7
2
to CD4+CD8- and so on...On
the  other  hand,  top  right  in  Figure  1  we  have  a  representation  of  the  same  groups  when  we
understand them as multivariate normals, that isC
7
={(m
7
1
,S
7
1
),...,(m
7
5
,S
7
5
)}where (m
7
1
,S
7
1
)
are the multivariate mean and covariance of the points gated as Basophils, (m
7
2
,S
7
2
) of points
gated as CD4+CD8-...  It becomes apparent that the  multivariate geometrical information is
a  reasonable  representation  of  the  cytometry,  even  more,  it  allows  to  obtain  templates  in  a
computationally efficient way.
Suppose  that  we  have  a  database,  which  is  a  subset  of  15  cytometries,  given  byDB=
{C
2
,C
3
,C
4
,C
5
,C
7
,C
8
,C
9
,C
12
,C
13
,C
14
,C
15
,C
16
,C
17
,C
19
,C
21
}.    We  also  have  a  partition  of  the
dabase,T,  where  one  group  isT
3
={C
7
,C
8
,C
16
}.   If  we  plot  together  the  five  cell  types  for
all three cytometries inT
3
we get the representation bottom left in Figure 1.  A prototypeT
3
for clusterT
3
, obtained by pooling as indicated in Section 2.1.2, is represented bottom right in
Figure 1.  We see that the artificial cytometry (template, prototype) gives a nice representation
of the information contained in bottom left of Figure 1.  Even more, this artificial cytometry is
quite similar to any of the original cytometries inT
3
.
Once  we  have  seen  the  intuitive  meaning  of  clustering  cytometries  and  the  obtention  of
templates,  we  want  to  compare  different  methods  to  cluster  the  databaseDB.   We  use  for  a
ground truth the simple linkage hierarchical clusterings obtained usingd
learning
, bottom right
11

C
i
t
o
m
e
t
r
y
 
2
C
i
t
o
m
e
t
r
y
 
1
C
i
t
o
m
e
t
r
y
 
1
4
C
i
t
o
m
e
t
r
y
 
1
8
C
i
t
o
m
e
t
r
y
 
2
1
C
i
t
o
m
e
t
r
y
 
1
7
C
i
t
o
m
e
t
r
y
 
2
0
C
i
t
o
m
e
t
r
y
 
5
C
i
t
o
m
e
t
r
y
 
7
0
.
3
0
0
.
3
5
0
.
4
0
0
.
4
5
0
.
5
0
0
.
5
5
0
.
6
0
Figure 3:  Result of optimalFlowTemplates on the databseSafter gating each cytometry with
flowMeans.
of Figure 2, and using
 ̃
d
learning
, bottom left of Figure 2.  For a state of the art comparison, we
use flowMatch, described in [7], using Mahalanobis distance, depicted top right in Figure 2.  The
clustering obtained by optimalFlowTemplates when using single linkage hierarchical clustering
is shown top left in Figure 2.  More comparisons can be seen in Figure 4 in the Supplementary
material.  At a first glance it is clear that the results form optimalFlowTemplates are much more
similar  to  the  ground  truth  than  those  of  flowMatch.   This  should  be  interpreted  as  the  fact
that  optimalFlowTemlates  captures  more  accurately  the  similarity  between  cytometries  than
flowMatch.  Two additional facts should be stated:  first, the similarity distance is independent
of parameters,  something that is not the case for the generalized edge cover distance used in
flowMatch.   Second,  optimalFlowTemplates  produces  templates  only  at  one  stage,  once  the
number  of  clusters  is  determined,  while  flowMatch  produces  templates  at  every  stage  of  the
hierarchical clustering procedure.
3.4    Gating and classification
We will apply optimalFlowTemplates+optimalFlowClassification to the databaseDBintroduced
in the previous section. We will use as a test setTS={C
1
,C
6
,C
10
,C
11
,C
18
,C
20
}. For the cytome-
tries inTS, we also perform and unsupervised gating given by flowMeans and an unsupervised
procedure given by tclust initialized with the templates obtained by optimalFlowTemplates.
Results  can  be  seen  in  columns  3-5  of  Table  1.   In  Table  3  and  4  in  the  Supplementary
material we have a full description of the results of optimalFlowClassification.  We see that tclust
initialized  with  optimalFlowTemplates  is  competitive  with  flowMeans,  but  more  importantly,
optimalFlowTemplates+optimalFlowClassification is superior in every of the test cytometries,
12

DeepCyTOFDeepCyTOF 2flowMeanstclustoptimalFlowC
Citometry 10.96410.98570.95010.95040.9740
Citometry 20.94200.95850.8988
Citometry 50.87280.87200.8977
Citometry 60.91950.93350.9522
Citometry 70.87630.80620.9508
Citometry 100.86100.81410.9595
Citometry 110.86530.91700.9256
Citometry 140.98250.92950.9004
Citometry 170.69820.98160.8978
Citometry 180.68400.97970.90030.87160.9853
Citometry 200.68840.97600.92230.86610.9834
Citometry 210.69420.96990.9269
Table 1:  Table of F-measure statistics.  DeepCyTOF: results of deepCyTOF onS.  DeepCyTOF
2:  results of deepCyTOF onS
1
andS
2
.  flowMeans:  results of flowMeans.  tclust:  results of opti-
malFlowTemplates initialized tclust onTS.  optimalFlowC: results ot optimalFlowClassification
onTS.
giving  5  form  6  F-measures  higher  than  0.95  and  the  other  higher  than  0.92.   Clearly  our
supervised procedure is working well and, as expected, is giving better performance than state
of the art unsupervised alternatives.
However,  we  also  want  to  compare  with  a  state  of  the  art  supervised  procedure.   In  this
case we will use deepCyTOF, with some bug corrections and some adaptations to our setting
of the github version,  implemented in Python withtensorflow0.12 andkeras1.2.2.  In order
to  use  deepCyTOF  we  need  cytometries  with  the  same  number  and  type  of  cell  types  so  we
use a data setS={
 ̃
C
1
,
 ̃
C
2
,
 ̃
C
5
,
 ̃
C
7
,
 ̃
C
14
,
 ̃
C
17
,
 ̃
C
18
,
 ̃
C
20
,
 ̃
C
21
},  where we have eliminated one group
from each cytometry.  We recall that deepCyTOF only uses the supervised information of one
of the cytometries inSto classify all other members.  We see the results of deepCyTOF, with
domain adaptation and without de-noising, since all entries are classified, in column 1 of Table
1.   DeepCyTOF’s  performance  is  rather  poor,  achieving  worst  F-measure  than  flowMeans  in
6 of the 9 cases and also for all applicable cases (cytometries 1,18,20) than optimalFlowTem-
plates+optimalFlowClassification.
However, these poor results are due to the high variability of the cytometries that can not
be accommodated by the domain adaptation procedure of deepCyTOF. Hence if we were able
to reduce this variability, deepCyTOF should give better results.  Indeed, if we use flowMeans
to  gate  the  cytometries  inS,  and  then  we  use  optimalFlowTemplates,  we  obtain  the  hierar-
chical  three  presented  in  Figure  3.   It  suggests  to  splitSintoS
1
={C
1
,C
2
,C
14
}andS
2
=
{C
5
,C
7
,C
17
,C
18
,C
20
,C
21
}.  We recall that until now we have not used supervised information.
Applying deepCyTOF toS
1
andS
2
we obtain the results in column 2 of Table 1.  Now deep-
CyTOF  performs  better  than  flowMeans  in  7  of  the  9  cases,  however  it  is  better  than  op-
timalFlowTemplates+optimalFlowClassification  only  for  Cytometry  1,  which  is  the  one  that
deepCyTOF uses for learning inS
1
.
13

Supplementary material
A    Notions on optimal transport
Following [33], let us takeP(Ω), the space of probability distributions on Ω.  Forμ,νinP(Ω),
let us define Π(μ,ν) the set of all probability measuresπon Ω×Ω with first marginalμand
second marginalν.  The optimal transport cost between the two measures is defined as
C(μ,ν) =inf
π∈Π(μ,ν)
∫
c(x,y)dπ(x,y)(5)
wherec(x,y) is  the cost of  transporting  one unit of  mass fromxtoy.  A  probabilityπthat
achieves the minimum in (5) is called an optimal coupling, with an associated random variable
(X,Y)  that  has  joint  distributionπ.   Whenμandνare  discrete,  i.e.,μ=
∑
n
i=1
p
i
δ
x
i
and
ν=
∑
m
j=1
q
i
δ
y
i
, withx
i
,y
j
∈R
d
, the optimal transport problem can be solved as the folowing
linear program (see [9])
C(μ,ν) =
n
∑
i=1
m
∑
j=1
w
∗
ij
c(x
i
,y
j
),
(w
∗
ij
) are the solutions of the optimal transport linear program
minimize
∑
n
i=1
∑
m
j=1
w
ij
c(x
i
,y
j
)
subject tow
ij
≥0,1≤i≤n,1≤j≤m
∑
m
j=1
w
ij
=p
i
,1≤i≤n
∑
n
i=1
w
ij
=q
j
,1≤j≤m
∑
n
i=1
∑
m
j=1
w
ij
= 1.
For (Ω,d) a Polish metric space andp∈[1,∞), thep−Wasserstein distance betweenμand
νis defined as
W
2
p
(μ,ν) =inf
π∈Π(μ,ν)
∫
d
p
(x,y)dπ(x,y) = inf{Ed
p
(X,Y),L(X) =μ,L(Y) =ν},
whereL(X) refers to the law ofX.
We  present  the  entropy  regularized  Wasserstein  distance,  since  it  is  strictly  convex  and
there are efficient solutions based on the Sinkhorn algorithm (see [13]).  For a fixedγ >0 the
regularized Wasserstein distance is defined as
W
γ
(μ,ν) =
n
∑
i=1
m
∑
j=1
w
∗
ij
‖x
i
−y
j
‖
2
+γ
n
∑
i=1
m
∑
j=1
w
∗
ij
logw
∗
ij
,
where (w
∗
ij
) are the solutions of the optimal transport linear program
minimize
∑
n
i=1
∑
m
j=1
w
ij
‖x
i
−y
j
‖
2
+γ
∑
m
i=1
∑
m
j=1
w
ij
logw
ij
subject tow
ij
≥0,1≤i≤n,1≤j≤m
∑
m
j=1
w
ij
=p
i
,1≤i≤n
∑
n
i=1
w
ij
=q
j
,1≤j≤m
∑
n
i=1
∑
m
j=1
w
ij
= 1.
Let us denoteP
2
(R
d
) the set of probability measures onR
d
with finite second moment and
let us taked
p
(x,y) =‖x−y‖
p
forx,y∈R
d
.  In [8] the notions ofk-barycenter and trimmed
14

k-barycenter  were  introduced,  building  on  the  concept  of  Wasserstein  barycenter  introduced
in [10, 22].  Ak-barycenter of probabilities{μ
1
,...,μ
n
}inP
2
(R
d
) with weightsλ
1
,...,λ
n
is any
k-set{ ̄μ
1
,..., ̄μ
k
}inP
2
(R
d
) such that for any{ν
i
,...,ν
k
}⊂P
2
(R
d
) we have that
n
∑
i=1
λ
i
min
j∈{1,...,k}
W
2
2
(μ
i
, ̄μ
j
)≤
n
∑
i=1
λ
i
min
j∈{1,...,k}
W
2
2
(μ
i
,ν
j
).(6)
Anα-trimmedk-barycenter of{μ
1
,...,μ
n
}with weights as before is any k-set{ ̄μ
1
,..., ̄μ
k
}with
weights
 ̄
λ= (
 ̄
λ
1
,...,
 ̄
λ
n
)∈Λ
α
(λ) such that
n
∑
i=1
 ̄
λ
i
min
j∈{1,...,k}
W
2
2
(μ
i
, ̄μ
j
) =min
{ν
1
,...,ν
k
}⊂P
2
(R
d
),λ
∗
∈Λ
α
(λ)
n
∑
i=1
λ
∗
i
min
j∈{1,...,k}
W
2
2
(μ
i
,ν
j
),(7)
where Λ
α
(λ) ={λ
∗
= (λ
∗
1
,...,λ
∗
n
) : 0≤λ
∗
i
≤λ
i
/(1−α),
∑
n
i=1
λ
∗
i
= 1}.
Broadly speaking k-barycenters can be thought of as an extension of k-means to the space
of probabilities with finite second order, since we can rewrite (6) as
min
S
k
∑
j=1
∑
μ
i
∈S
j
λ
i
W
2
2
(μ
i
, ̄μ
j
)(8)
whereS={S
1
,...,S
k
}is a partition of{μ
1
,...,μ
n
}and  ̄μ
j
is the barycenter of the elements in
S
j
.  Therefore, trimmed k-barycenters may be matched to trimmed k-means.  As stated in [8],
efficient  computations  can  be  done  when  dealing  with  location-scatter  families  of  absolutely
continuous distributions inP
2
(R
d
). A notable example being the family of multivariate Gaussian
distributions.
B    Consensus clustering
Consensus clustering is the problem of combining different partitions.  These partitions (cluster-
ings), can come from different clustering algorithms applied to the same data, the same algorithm
looking for different number of clusters or with a different initialization or a combination of the
previous.  A possible approach to the problem is to use some type of relabelling of the original
partitions and an optimization procedure to extract a consensus clustering that is the closest
in some sense to the relabelled partitions [6, 32].  Other alternatives comprising cluster-based
similarity partitioning algorithm, hypergraph partitioning algorithm and meta-clustering algo-
rithm (clustering of partitions) were proposed in [31].  Consensus clustering results in a gain in
robustness and in the possibility of parallelization and reuse of information.
A shortcoming of the previous procedures is the difficulty to handle a combination of clus-
terings of different data.  This shortcoming can be addressed when clusters in a partition can be
viewed as a distribution.  This is the case when mixture models are used for clustering.  Also,
in many cases we can represent clusters, obtained by some clustering procedure, by their means
and  covariance  matrices.   Even  more,  some  fields  work  with  data  represented  as  probability
distributions.
In this setting,  we would have several partitions,  coming from the same or  from  different
data,C
1
,...,C
N
whereC
1
={μ
1,1
,...,μ
k
1
,1
},...,C
N
={μ
1,N
,...,μ
k
N
,N
}are  subsets  of  some
space of probability measures.  A natural idea is to pool together all the distributions, obtaining
the data set{μ
1
,...,μ
n
}withn=k
1
+···+k
N
, and to do clustering in the abstract space of
probabilities.  The resulting partition of{μ
1
,...,μ
n
}can be used to obtain a set of distributions
S={ ̄μ
1
,..., ̄μ
k
}that will represent the consensus clustering.
15

Let us fix that{μ
1
,...,μ
n
}⊂P
2
(R
d
).  A particular implementation of the previous strategy
was presented in [8] where the consensus clusterSis taken to be the (trimmed)k-barycenter as in
((7))(8). Here we present some alternative but related strategies to obtain a consensus clustering.
We  can  define  then×ndistance  matrixW,  whereW
i,j
=W
2
(μ
i
,μ
j
),  and  use  hierarchical
clustering to obtain a partition{S
1
,...,S
k
}of{μ
1
,...,μ
n
}.  Then taking the barycenter (1-
barycenter)  of  the  elements  in  eachS
i
we  obtain  the  consensus  clusteringS={ ̄μ
1
,..., ̄μ
k
}.
With hierarchical clustering we mean single linkage,  complete linkage or average linkage,  but
also density based hierarchical clustering as DBSCAN [15] or HDBSCAN [11].  The former are
able to select automatically the appropriate number of clusters, which can be seen as a desirable
quality, even more, they are also robust as the trimmedk-barycenter.
C    Initializing an unsupervised procedure
The unsupervised clustering procedure we have selected istclust, introduced in [18], which is a
robust model based clustering procedure that allows for non spherical clusters.  Nontheless, it is
possible to use any other unsupervised procedure that allows an initialization with a clustering
defined by probability distributions.  For example, this is the case for the popularmclust[16,30],
a finite Gaussian mixture model based clustering solved by an EM-algorithm.
tclustsearches for a partition{C
0
,...,C
k
}ofX={X
1
,...,X
n
}, with|C
0
|=dnαe, vectors
m
j
, positive definite matricesS
j
and weightsp
j
∈[0,1] that approximately maximize the pseudo-
likelihood
k
∑
j=1
∑
i∈C
j
log
(
p
j
φ
m
j
,S
j
(X
i
)
)
,(9)
under restrictions over the scatter matricesS
j
.  Byφ
m,S
we denote the density function of the
multivariate normalN(m,S).C
0
is the cluster of trimmed observations,  where the trimming
level isα.
The details of the algorithm can be found in [17].  For us it is relevant to recall only the
initialization step, i.e, to provide an initialθ
0
= (p
0
1
,...,p
0
k
,m
0
1
,...,m
0
k
,S
0
1
,...,S
0
k
).  Hence, to
initializetclustwe only need a set of weights with corresponding means and covariances.
16

Participant
Final diagnosis
Type of tested sample
Type of coagulant (preservation)
Sex
Age (years)
Incubation period
Type of Flow Cytometer
Centre 1
HD
PB
EDTA
M
53
30 min
BD FACSCanto
Centre 1
HD
PB
EDTA
M
50
30 min
BD FACSCanto
Centre 1
HD
PB
EDTA
M
61
30 min
BD FACSCanto
Centre 2
HD
PB
Heparin
M
29
30 min
BD FACSCanto
Centre 2
HD
PB
Heparin
M
38
30 min
BD FACSCanto
Centre 2
HD
PB
Heparin
F
27
30 min
BD FACSCanto
Centre 2
HD
PB
Heparin
F
NA
30 min
BD FACSCanto
Centre 2
HD
PB
Heparin
M
NA
30 min
BD FACSCanto
Centre 2
HD
PB
Heparin
F
NA
30 min
BD FACSCanto
Centre 2
HD
PB
Heparin
F
NA
30 min
BD FACSCanto
Centre 3
HD
PB
NA
M
34
15 min
BD FACSCanto
Centre 3
HD
PB
NA
F
33
15 min
BD FACSCanto
Centre 3
HD
PB
NA
M
32
15 min
BD FACSCanto
Centre 3
HD
PB
NA
M
33
15 min
BD FACSCanto
Centre 3
HD
PB
NA
F
35
15 min
BD FACSCanto
Centre 3
HD
PB
EDTA
NA
Adult
15 min
BD FACSCanto
Centre 3
HD
PB
EDTA
NA
Adult
15 min
BD FACSCanto
Centre 3
HD
PB
EDTA
NA
Adult
15 min
BD FACSCanto
Centre 3
HD
PB
EDTA
NA
Adult
15 min
BD FACSCanto
Centre 3
HD
PB
EDTA
NA
Adult
15 min
BD FACSCanto
Table 2:  Detailed information about the participants and the measurments for 20 of the 21 cytometries.
17

5
6
1
2
2
1
1
34
1
1
0
1
4
1
3
1
5
9
78
0
.
0
0
.
1
0
.
2
0
.
3
0
.
4
0
.
5
0
100
200
300
400
500
6
15
789
12
5
14
213
1310
4
11
7
89
1
1
0
1
4
1
3
1
5
4
1
2
56
3
2
1
1
0
.
0
0
.
1
0
.
2
0
.
3
0
.
4
0
.
5
0
.
6
9
78
1
1
0
1
4
1
3
1
5
5
6
1
2
3
4
2
1
1
0
.
0
0
0
.
1
0
0
.
2
0
0
.
3
0
Figure  4:  Hierarchical  trees  for  the  databaseDB.   Top-left:  result  of  optimalFlowTemplates.
Top-right:  result of flowMatch with symmetric Kulback-Leibler divergence.  Bottom-left:  com-
plete linkage with
 ̃
d
learning
.  Bottom-right:  complete linkage withd
learning
.
18

Cytometry 1
Cytometries clustering
Templates formation
Method 1
Method 2
Method 3
Method 4
Method 5
complete, k = 5
pooling
0.9064
0.9339
0.8992
0.9196
0.8521
HDBSCAN
pooling
0.9064
0.9323
0.8992
0.9196
0.8521
complete, k = 5
HDBSCAN
0.0000
0.9398
0.8825
0.3542
0.7429
HDBSCAN
HDBSCAN
0.0000
0.9111
0.7235
0.5263
0.9186
complete, k = 5
37-barycenter, alpha = 0.05
0.0000
0.9498
0.9512
0.2298
0.8707
HDBSCAN
37-barycenter, alpha = 0.05
0.0000
0.9485
0.7755
0.6846
0.5988
Ctometry 6
Cytometries clustering
Templates formation
Method 1
Method 2
Method 3
Method 4
Method 5
complete, k = 5
pooling
0.7692
0.8524
0.7613
0.8373
0.8373
HDBSCAN
pooling
0.8787
0.8571
0.7762
0.8427
0.8427
complete, k = 5
HDBSCAN
0.7212
0.9265
0.8398
0.0653
0.8163
HDBSCAN
HDBSCAN
0.8270
0.9276
0.8399
0.7924
0.8034
complete, k = 5
37-barycenter, alpha = 0.05
0.0000
0.9184
0.8399
0.8110
0.7572
HDBSCAN
37-barycenter, alpha = 0.05
0.1468
0.9112
0.7849
0.6314
0.6314
Citometry 10
Cytometries clustering
Templates formation
Method 1
Method 2
Method 3
Method 4
Method 5
complete, k = 5
pooling
0.9525
0.9431
0.9440
0.9306
0.9306
HDBSCAN
pooling
0.9525
0.9421
0.9440
0.9306
0.9306
complete, k = 5
HDBSCAN
0.9009
0.9451
0.9445
0.0739
0.8181
HDBSCAN
HDBSCAN
0.9009
0.9423
0.9445
0.0739
0.8181
complete, k = 5
37-barycenter, alpha = 0.05
0.0000
0.9345
0.9407
0.9358
0.1163
HDBSCAN
37-barycenter, alpha = 0.05
0.0000
0.6694
0.6325
0.7901
0.1610
Table 3:  Median
F
-measure for
C
1
,
C
6
and
C
10
for different combinations of our procedures.
Cytometries  clustering
indicates the method
used for clustering in optimalFlowTemplates.
Templates  formation
indicates the method used for obtaining templates for the clusters of
cytometries.  Method 1 refers to using the best template and QDA. Method 2 refers to using random forest with the cytometry closest insimilarity distance in the assigned group.  Method 3 is like Method 2 but using QDA. Method 4 is label matching between the best templateand the best
tclust
result.  Method 5 is label matching through a vote between label matchings of every cytometry in the best group.
19

Citometry 11
Cytometries clustering
Templates formation
Method 1
Method 2
Method 3
Method 4
Method 5
complete, k = 5
pooling
0.9069
0.9506
0.9336
0.9378
0.9363
HDBSCAN
pooling
0.9069
0.9496
0.9336
0.9378
0.9363
complete, k = 5
HDBSCAN
0.4304
0.7500
0.6864
0.1264
0.5928
HDBSCAN
HDBSCAN
0.4304
0.7556
0.6864
0.1264
0.5928
complete, k = 5
37-barycenter, alpha = 0.05
0.6319
0.9383
0.9116
0.6206
0.9095
HDBSCAN
37-barycenter, alpha = 0.05
0.0000
0.9494
0.9116
0.7151
0.8975
Citometry 18
Cytometries clustering
Templates formation
Method 1
Method 2
Method 3
Method 4
Method 5
complete, k = 5
pooling
0.9088
0.9611
0.9038
0.6433
0.3232
HDBSCAN
pooling
0.8465
0.8585
0.7045
0.7901
0.4740
complete, k = 5
HDBSCAN
0.9043
0.9618
0.9171
0.6415
0.7912
HDBSCAN
HDBSCAN
0.9043
0.9617
0.9171
0.2133
0.6214
complete, k = 5
37-barycenter, alpha = 0.05
0.0000
0.9617
0.9171
0.7879
0.7895
HDBSCAN
37-barycenter, alpha = 0.05
0.0000
0.8501
0.9171
0.8468
0.7911
Citometry 20
Cytometries clustering
Templates formation
Method 1
Method 2
Method 3
Method 4
Method 5
complete, k = 5
pooling
0.9140
0.9557
0.9046
0.7517
0.4447
HDBSCAN
pooling
0.9140
0.9537
0.9046
0.7517
0.4447
complete, k = 5
HDBSCAN
0.9140
0.9587
0.9231
0.6020
0.4346
HDBSCAN
HDBSCAN
0.9140
0.9589
0.9231
0.6308
0.7542
complete, k = 5
37-barycenter, alpha = 0.05
0.2538
0.9587
0.9231
0.6865
0.6198
HDBSCAN
37-barycenter, alpha = 0.05
0.0000
0.9621
0.9231
0.6354
0.4060
Table 4:  Same as Table 3 but for cytometries
C
11
,
C
18
and
C
20
.
20

References
[1]  Aghaeepour, N. Finak, G. Hoos, H. Mosmann, TR. Brinkman, R. Gottardo, R. and Scheuer-
mann,  RH.  (2013)  Critical  assessment  of  automated  flow  cytometry  data  analysis  tech-
niques.Nature Methods.
[2]  Aghaeepour, N. Nikolic, R. Hoos, HH. and Brinkman, RR. (2011) Rapid Cell Population
Identification in Flow Cytometry Data.Cytometry A.
[3]  Alpaydin, E. (2014)Introduction to Machine Learning. MIT Press.
[4]
 ́
Alvarez-Esteban,  P. del Barrio,  E. Cuesta-Albertos,  JA. and Matr ́an,  C. (2016) A fixed-
point approach to barycenters in Wasserstein space.Journal of Mathematical Analysis and
Applications.
[5]
 ́
Alvarez-Esteban,  P.  del  Barrio,  E.  Cuesta-Albertos,  JA.  and  Matr ́an,  C.  (2018)  Wide
Consensus aggregation in the Wasserstein Space. Application to location-scatter families.
Bernoulli.
[6]  Ayad, H. and Kamel, M. (2010) On voting-based consensus of cluster ensembles.Pattern
Recognition.
[7]  Azad, A. Pyne, S. and Pothen, A. (2012) Matching phosphorylation response patterns of
antigen-receptor-stimulated T cells via flow cytometry.BMC Bioinformatics.
[8]  del Barrio, E. Cuesta-Albertos, JA. Matr ́an, C. and Mayo-
 ́
Iscar, A. (2017) Robust clustering
tools based on optimal transportation.Statistics and Computing.
[9]  Bertsimas, D. and Tsitsiklis, J. (1997)Introduction to Linear Optimization..
[10]  Boissard, E. Le Gouic, T. and Loubes, J-M. et al. (2015) Distribution’s template estimate
with Wasserstein metrics.Bernoulli.
[11]  Campello, R. Moulavi, D. and Sander, J. (2013) Density-Based Clustering Based on Hier-
archical Density Estimates.Advances in Knowledge Discovery and Data Mining.
[12]  Coen, MH. Hidayath Ansari, M. and Filmore, N. (2010) Comparing Clusterings in Space.
ICML.
[13]  Cuturi, M. and Doucet, A. (2014) Fast Computation of Wasserstein Barycenters.Interna-
tional Conference on Machine Learning
[14]  Dost,  B.  Wu,  C.  Su,  A.  and  Bafna,  V.  (2011)  TCLUST:  a  fast  method  for  clustering
genome-scale expression data.IEEE/ACM Trans Comput Biol Bioinform.
[15]  Ester,  M.  Kriegel,  H-P.  Sander,  J.  and  Xu,  X.  (1996)  A  Density-Based  Algorithm  for
Discovering Clusters in Large Spatial Databases with Noise.AAAI.
[16]  Fraley,  C.  and  Raftery,  A.  (2002)  Model-Based  Clustering,  Discriminant  Analysis,  and
Density Estimation.Journal of the American Statistical Association
[17]  Fritz,  H.  Garc ́ıa-Escudero,  LA.  and  Mayo-
 ́
Iscar,  A.  (2013)  A  fast  algorithm  for  robust
constrained clustering.Computational statistics and data anlysis.
21

[18]  Garc ́ıa-Escudero, LA. Gordaliza, A. Matr ́an, C and Mayo-
 ́
Iscar, A. (2008) A general trim-
ming approach to robust cluster analysis.Annals of Statistics.
[19]  Ge, Y. and Sealfon, SC. (2012) flowPeaks: a fast unsupervised clustering for flow cytometry
data via K-means and density peak finding.Bioinformatics.
[20]  Hsiao, C. Liu, M. Stanton, R. McGee, M. Qian, Y. and Scheuermann, RH.(2016) Mapping
cell populations in flow cytometry data for cross-sample comparison using the Friedman-
Rafsky test statistic as a distance measure.Cytometry A.
[21]  Kuhn, H. (1955) The Hungarian method for the assignment problem.Naval  Research  Lo-
gistic Quarterly.
[22]  Le Gouic, T. and Loubes, JM. (2017) Existence and consistency of Wasserstein barycenters.
Probability Theory and Related Fields.
[23]  Li, H. Shaham, U. Stanton, K. Yao, Y. Montgomery, R. and Kluger, Y. (2017) Gating Mass
Cytometry Data by Deep Learning.Bioinformatics.
[24]  Lo, K. Brinkman, R. and Gottardo, R. (2008) Automated Gating of Flow Cytometry Data
via Robust Model-Based Clustering.Cytometry A
[25]  Lo, K. Hahne, F. Brinkman, R. and Gottardo, R. (2009) flowClust: a Bioconductor package
for automated gating of flow cytometry data.BMC Bioinformatics
[26]  Lux, M. Brinkman, RR. Chauve, C. Laing, A. Lorenc, A. Abeler-D ̈orner, L. and Hammer,
B. (2018) flowLearn:  fast and precise identification and quality checking of cell populations
in flow cytometry.Bioinformatics.
[27]  Pyne, S. Hu, X. Wang, K. Rossin, E. Lin, TI. Maier, L. Baecher-Allan, C. McLachlan, G.
Tamayo,  P. Hafler,  D. De Jager,  P. and Mesirov,  J. (2009) Automated high-dimensional
flow cytometric data analysis.Proceedings of the National Academy of Sciences.
[28]  Qian, Y. Wei, C. Eun-Hyung Lee, F. Campbell, J. Halliley, J. Lee, JA. Cai, J. Kong, YM.
Sadat, E. Thomson, E. Dunn, P. Seegmiller, AC. Karandikar, NJ. Tipton, CM. Mosmann,
T. Sanz, I. and Scheuermann, RH. (2010) Elucidation of Seventeen Human Peripheral Blood
B cell Subsets and Quantification of the Tetanus Response Using a Density-Based Method
for the Automated Identification of Cell Populations in Multidimensional Flow Cytometry
Data.Cytometry B Clin Cytom.
[29]  Saeys, Y.Van Gassen, S. Lambrecht, BN. (2016) Computational flow cytometry:  helping to
make sense of high-dimensional immunology data.Nature Reviews Immunology.
[30]  Scrucca, L. Fop, M. Murphy, TB. and Raftery, AE. (2016) mclust 5:  Clustering, Classifi-
cation and Density Estimation Using Gaussian Finite Mixture Models.The R Journal.
[31]  Strehl, A. and Ghosh, J. (2002) Cluster Ensembles – A Knowledge Reuse Framework for
Combining Multiple Partitions.Journal of Machine Learning Research.
[32]  Topchy, A. Jain, A. (2005) Clustering Ensembles:  Models of Consensus and Weak Parti-
tions.IEEE Transactions on Pattern Analysis and Machine Intelligence.
[33]  Villani, C. (2009)Optimal Transport:  Old and New.
22 

Least Angle Regression in Tangent Space and
LASSO for Generalized Linear Model
∗
Yoshihiro Hirose
†
Hokkaido University, Japan
Abstract
We propose sparse estimation methods for the generalized linear mod-
els, which run Least Angle Regression (LARS) and Least Absolute Shrink-
age and Selection Operator (LASSO) in the tangent space of the manifold
of  the  statistical  model.   Our  approach  is  to  roughly  approximate  the
statistical model and to subsequently use exact calculations.  LARS was
proposed as an efficient algorithm for parameter estimation and variable
selection for the normal linear model.  The LARS algorithm is described
in  terms  of  Euclidean  geometry  with  regarding  correlation  as  metric  of
the space.  Since the LARS algorithm only works in Euclidean space, we
transform  a  manifold  of  the  statistical  model  into  the  tangent  space  at
the origin.  In the generalized linear regression, this transformation allows
us to run the original LARS algorithm for the generalized linear models.
The  proposed  methods  are  efficient  and  perform  well.   Real-data  anal-
ysis  shows  that  the  proposed  methods  output  similar  results  as  that  of
thel
1
-penalized  maximum  likelihood  estimation  for  the  generalized  lin-
ear  models.   Numerical  experiments  show  that  our  methods  work  well
and they can be better than thel
1
-penalization for the generalized linear
models in generalization, parameter estimation, and model selection.
Keywords:  Exponential family, Generalized linear regression, Information
geometry, Sparse modelling
1  Introduction
We introduce sparse estimation methods for the generalized linear models (GLM).
One of the proposed methods is based on Least Angle Regression (LARS) Efron
et al. (2004) and is described in terms of Riemannian geometry.  The main fea-
tures of our approach are i) we use an approximation of a statistical model and
do  not  use  the  statistical  model  itself,  and  ii)  the  proposed  methods  are  cal-
culated exactly,  which allows us to compute the estimators efficiently.  In the
∗
This work was partly supported by JSPS KAKENHI Grant Number JP18K18008 and
JST CREST Grant Number JPMJCR1763.
†
hirose@ist.hokudai.ac.jp
1
arXiv:1907.08100v1  [stat.ML]  18 Jul 2019

literature, a few extensions of LARS have been proposed which are based on Rie-
mannian geometry (/information geometry/differential geometry): for example,
Hirose and Komaki (2010) and Augugliaro et al. (2013).  The existing methods
take advantage of a dual structure of the model manifolds, which requires com-
putational costs.  Our method utilizes a part of the dual structure and uses the
original LARS algorithm in the tangent space.  The proposed method enables us
to compute the estimator easily.  Furthermore, we show Least Absolute Shrink-
age and Selection Operator (LASSO) Tibshirani (1996) for the normal linear
model is also available in the tangent space.
In this two decades, sparse modelling is extensively investigated.  LASSO is
a representative method and motivated many researchers in machine learning,
statistics, and other fields.  LASSO was proposed as an estimation and variable-
selection method for the normal linear model.  LASSO minimizes the penalized
least square with a tuning parameter.  Various generalizations have been pro-
posed for other problems.  For example, Park and Hastie (2007) and Yuan and
Lin (2007) treat the generalized linear regression and Gaussian graphical mod-
els, respectively.  See also Hastie et al. (2009).
LARS was proposed for the same problem as LASSO. The LARS algorithm
is very efficient, and it can also compute the LASSO estimator if a minor change
is added.  The LARS algorithm uses only correlation coefficients between the
response  and  explanatory  variables.   Therefore,  the  algorithm  is  described  in
terms of Euclidean geometry.
Information geometry is a Riemannian-geometrical framework for statistics
and other fields Amari (1985); Amari and Nagaoka (2000); Amari (2016); Ay
et al. (2017).  In this framework, we treat a statistical model as a Riemannian
manifold and take advantage of its geometrical properties for estimation, test,
and  other  tasks.   Each  probability  distribution  is  treated  as  a  point  in  the
manifold.  For example, estimation problem for the generalized linear regression
can be described in terms of the geometry.  The GLM is treated as a manifold
and  an  estimator  assigns  a  point  in  the  manifold  to  an  observed  data.   The
maximum likelihood estimator (MLE) uses a kind of projection.
Some extensions of LARS have been proposed based on the information ge-
ometry of the exponential family of distributions.  Hirose and Komaki (2010)
and Augugliaro et al. (2013) proposed different extensions of LARS, which take
advantage of the dual structure of the model manifold.  Their works are theoret-
ically natural.  However, these methods needs many iterations of approximation
computation,  which  is  inevitable  for  treating  more  complicated  objects  than
Euclidean  space.   Note  again  that  our  approach  is  different  from  that  of  the
existing methods.  We roughly approximate the model manifold by the tangent
space and use the exact computation of LARS in the tangent space.  The use-
fulness of our idea is validated by numerical experiments.  Our approach will
enables us to apply many tools for LARS to the GLM.
In Section 2, we introduce our problem and the related works.  In Section 3,
we propose a sparse estimation method based on LARS. Furthermore, LASSO-
type estimators are also proposed.  In Section 4, we compare our methods with
thel
1
-penalization for the GLM by performing numerical experiments.  Section
2

5 is our conclusion.  Lemmas are given and proved in Appendix A.
2  Problem and Related Method
In  subsection  2.1,  we  formulate  the  problem  and  introduce  our  notation.   In
subsections 2.2 and 2.3, we briefly describe the LARS algorithm and the LASSO
estimators, respectively.
2.1  Problem and Notation
In this paper, we consider the generalized linear regression, which is an estima-
tion problem of the GLM. In the generalized linear regression, a responseyis
represented by a linear combination of explanatory variablesx
1
,x
2
,...,x
d
as
h(y
a
) =
d
∑
i=1
x
a
i
θ
i
,(a= 1,2,...,n),
whereh:R→Ris called a link function,nis the sample size,dis the number
of explanatory variables,  andθ= (θ
i
) is the parameter to be estimated.  Let
X= (x
a
i
) be the design matrix, which is an (n×d)-matrix.  Lety= (y
a
) be the
response vector, which is a column vector of lengthn.
In terms of probability distributions, the problem above corresponds to es-
timation for an exponential family of distributions, that is, the GLM,
M={p(·|θ)|θ∈R
d
}, p(y|θ) =p(y|X,θ) = exp
{
y
>
Xθ−ψ(θ)
}
,
whereψ:R
d
→Ris called a potential function.  As a special case, the normal
linear regression uses the link functionh(y) =yand a quadratic function as the
potential function.  Another example is the logistic regression,  where the link
function ish(y) =y/(1−y) and the potential function isψ(θ) =
∑
n
a=1
log{1 +
exp(
∑
d
i=
x
a
i
θ
i
)}.
Through the paper, we assume that the design matrixXis normalized, that
is, each column vector has the mean zero and thel
2
-norm one:
∑
n
a=1
x
a
i
= 0
and
∑
n
a=1
(x
a
i
)
2
= 1 fori= 1,2,...,d.  Furthermore, we assume that column
vectors ofXare linearly independent.
2.2  LARS
We briefly describe the LARS algorithm.  In subsection 3.2, we use the LARS
algorithm for proposing an estimation method.  The detail and more discussions
on LARS can be found in,  for example,  Efron et al. (2004) and Hastie et al.
(2009).
LARS was proposed as an algorithm for parameter estimation and variable
selection in the normal linear regression.  In the LARS algorithm, the estimator
moves from the origin to the maximum likelihood estimate (MLE)
ˆ
θ
MLE
of the
3

Data:the design matrixXand the response vectory
Result:the sequence of the LARS estimates (
ˆ
θ
(k)
)
k=0,1,...,d
Initialization:k:= 1,
ˆ
θ
(0)
:= 0,
ˆ
θ
(d)
:=
ˆ
θ
MLE
,r
(0)
:=
ˆ
θ
(d)
−
ˆ
θ
(0)
=
ˆ
θ
MLE
whilek < ddo
Calculate the correlations
ˆ
c
(k)
and the active setI
(k)
of the indices:
ˆ
c
(k)
:=X
>
Xr
(k−1)
,
ˆ
C
(k)
:= max
j
{|ˆc
(k),i
|}, I
(k)
:={i||ˆc
(k),i
|=
ˆ
C
(k)
}.
Usings
i
= sign{ˆc
(k),i
}(i∈I
(k)
), define a bisector of an anglew
(k)
and others:
X
(k)
:= (...s
i
x
i
...)
i∈I
(k)
, G
(k)
:=X
>
(k)
X
(k)
, A
(k)
:= (1
>
k
G
−1
(k)
1
k
)
−1/2
,
w
(k)
:=A
(k)
G
−1
(k)
1
k
,a
(k)
:=X
>
X
(k)
w
(k)
.
Define the next estimate
ˆ
θ
(k)
as
{
(
ˆ
θ
i
(k)
)
i∈I
(k)
:= (
ˆ
θ
i
(k−1)
)
i∈I
(k)
+γdiag(s
i
)
i∈I
(k)
w
(k)
,
(
ˆ
θ
i
(k)
)
i∈I
c
(k)
:= 0
with
ˆγ:=  min
j∈I
c
(k)
+
{
ˆ
C
(k)
−ˆc
(k),j
A
(k)
−a
(k),j
,
ˆ
C
(k)
+ ˆc
(k),j
A
(k)
+a
(k),j
}
>0,
where min
+
{a
1
,...,a
N
}:= min{a
i
|a
i
>0 (i= 1,...,N)}.
Setr
(k)
:=
ˆ
θ
(d)
−
ˆ
θ
(k)
andk:=k+ 1.
end
Algorithm 1:The Least Angle Regression (LARS) algorithm
full model.  The full model means the linear model including all the explana-
tory variables.  The MLE
ˆ
θ
MLE
is determined by the design matrixXand the
responsey.  The detailed algorithm of LARS is showed in Algorithm 1, where
ˆ
θ
(k)
isk-th estimate the algorithm outputs.  After iterations, LARS outputs a
sequence of the estimates
ˆ
θ
(0)
,
ˆ
θ
(1)
,...,
ˆ
θ
(d)
.
The idea of the LARS algorithm is showed by Figure 1.  The figure indicates
the estimator’s move in the parameter spaceR
d
whend= 2.  The estimator a)
selects a parameter (or parameters) which makes a least angle between
ˆ
θ
MLE
−
ˆ
θ
(k)
andθ
i
-axis, and b) uses it as a trajectory in the form of the bisector of an
angle.  The LARS algorithm is described in terms of Euclidean geometry and
can be computed efficiently.  Furthermore,X
>
Xplays an important role in the
LARS algorithm,  which is one of our motivations for considering the tangent
space of a statistical model.
4

Figure 1:   The LARS algorithm when there are two explanatory variables.  The
parameter space isR
2
.
ˆ
θ
MLE
is the MLE of the full model.  In this example,θ
1
is selected at first iteration,I
0
={1}.  The first estimate is
ˆ
θ
(1)
and its second
element is zero.  The second estimate is
ˆ
θ
(2)
=
ˆ
θ
MLE
=
ˆ
θ
(1)
+ ˆγw
(2)
.  In the
left figure, the estimator moves along the bisector of an angle from
ˆ
θ
(1)
to the
second  estimate
ˆ
θ
(2)
.   The right  figure  is  another interpretation  of  the LARS
algorithm.  The residualr(θ) =
ˆ
θ
MLE
−θmoves from
ˆ
θ
MLE
to 0.
2.3  LASSO
LASSO is an optimization problem for parameter estimation and variable selec-
tion in the normal linear regression.  LASSO solves the minimization problem
min
θ∈R
d
{
‖y−Xθ‖
2
2
+λ‖θ‖
1
}
,
whereλ≥0 is a tuning parameter.  The path of the LASSO estimator whenλ
varies can be made by the LARS algorithm with a minor modification.
LASSO can be applied to the GLM as thel
1
-penalized MLE, which is the
minimization problem
min
θ∈R
d
{
−y
>
Xθ+ψ(θ) +λ‖θ‖
1
}
.(1)
For example, see Park and Hastie (2007).
3  The Proposed Methods
Our main idea is to run the LARS algorithm in the tangent space of the model
manifold.  This idea is very simple.  However, it works well as Sections 3 and 4
show.
In subsection 3.1, we introduce information geometry we use in this paper.
In  subsection  3.2,  we  propose  LARS  in  tangent  space,  which  is  an  extension
of  the  original  LARS  to  the  GLM.  The  proposed  method  is  identical  to  the
original  LARS  when  applied  to  the  normal  linear  model.   Subsection  3.3  is  a
remark  on  the  matrixX
>
X.   In  subsection  3.4,  we  propose  other  methods
which are related with LASSO. Subsection 3.5 explains the difference between
the proposed methods and the existing methods.
5

3.1  Information Geometry
We introduce some tools from information geometry/Riemannian geometry, in-
cluding model manifold, tangent space, and exponential map (Figure 2).  This is
a brief introduction.  For details, see Amari (1985); Amari and Nagaoka (2000);
Amari (2016); Ay et al. (2017).
In the generalized linear regression, we need to select one distribution from
the GLM. A model manifold is a manifold consisting of probability distributions
of interest.  That is, the model manifold isM={p(·|θ)|θ∈R
d
}, wherep(·|θ)
indicates  the  probability  distribution  with  the  regression  coefficientθ.   The
parameterθworks as a coordinate system inM.
The  tangent  spaceT
p
Mat  a  pointp∈ Mis  a  linear  space  consisting
of  directional  derivatives,  that  is,T
p
M={v=
∑
d
i=1
v
i
∂
i
|v
i
∈R},  where
∂
i
:=∂/∂θ
i
.  We consider the tangent spaceT
p(·|0)
Matp(·|0).  For simplicity,
we callp(·|0) andT
p(·|0)
M, the origin and the tangent spaceT
0
Mat the origin,
respectively.
Any pair of two vectors inT
0
Mhas its inner product.  The inner product is
determined by the Fisher information matrixG=G(0) = (g
ij
(0)):
g
ij
(θ) = E [∂
i
l(θ)∂
j
l(θ)],
wherel(θ) = logp(y|θ) is the log-likelihood.  Using the Fisher metricG,  the
inner product ofv
1
=
∑
d
i=1
v
i
1
∂
i
andv
2
=
∑
d
i=1
v
j
2
∂
j
is given by
〈v
1
,v
2
〉=
d
∑
i=1
d
∑
j=1
v
i
1
v
j
2
〈∂
i
,∂
j
〉=
d
∑
i=1
d
∑
j=1
v
i
1
v
j
2
g
ij
.
In the generalized linear regression, the Fisher metricGatT
0
Mis propor-
tional  to  the  correlation  matrixX
>
Xof  the  explanatory  variables.   That  is,
G=cX
>
Xfor somec >0.  For details, see Lemma 2 in subsection A.1.
A point in the tangent spaceT
0
Mcan be identified with a point inMvia
an exponential map.  We introduce the e-exponential map Exp
0
:T
0
M → M
defined as follows.  Forv=
∑
v
i
∂
i
∈T
0
M, let Exp
0
(v) =p(·|v)∈Mwithv=
(v
i
).  Our problem in this paper is estimation for the GLM and the parameter
is  a  regression  coefficient  vectorθ∈R
d
.   Therefore,  we  can  avoid  technical
difficulties of an exponential map.  The map Exp
0
is a bijection fromT
0
Mto
M.  For details, see subsection A.3.
For readers familiar with information geometry, we make an additional re-
mark.  The model manifoldMof the GLM is e-flat and the regression coefficient
θis an e-affine coordinate system ofM.{∂
i
}is the natural basis ofT
0
Mwith
respect to the coordinate systemθ.  Each coordinate axis ofθ
i
inMcorresponds
to∂
i
-axis inT
0
Mvia the e-exponential map.
In the following, we also use another representation ofT
0
M.  This represen-
tation is useful for our purpose:T
0
M={Xθ|θ∈R
d
}.∂
i
is corresponding to
i-th column vector of the design matrixX.  In our notation,Xθalso indicates
∑
θ
i
∂
i
in the tangent spaceT
0
M, not only a pointp(·|θ)∈ M.  However, we
6

Figure 2:  A statistical manifoldMand the tangent spaceT
0
Mat the origin.
The white surface isMand the gray plane isT
0
M.  A point inMis corre-
sponding to a point inT
0
Mthrough the e-exponential map, and vice versa.  For
example, a curve (an e-geodesic, strictly) inMcorresponds to a line inT
0
M.
believe that it is not confusing because a vector in the tangent space and a point
inMare identified through the exponential map.
3.2  LARS in Tangent Space
The main idea of the proposed method is to run LARS in the tangent space
T
0
Mat  the  origin.   First,  we  correspond  the  model  manifold  to  the  tangent
spaceT
0
Mby the e-exponential map.  After mapping, our computation is done
by the original LARS algorithm. However, we do not use the responseydirectly.
We introduce a virtual response
ˆ
y.  The LARS algorithm outputs a sequence of
parameter estimates, whose length is the same as the number of the parameter.
Finally, the estimates are mapped to the model manifold.
Before  running  the  original  LARS  algorithm,  we  introduce  the  virtual  re-
sponse
ˆ
y.  The virtual response
ˆ
yis defined using the design matrixXand the
MLE
ˆ
θ
MLE
of the full model:
ˆ
y=X
ˆ
θ
MLE
.  Note that LARS used only correla-
tion coefficients between the responseyand the explanatory variablesXin the
form ofy
>
Xθ, which is identical with
ˆ
θ
>
MLE
X
>
Xθ.  Therefore, introducing the
appropriate representation of the response
ˆ
y=X
ˆ
θ
MLE
, we need onlyX
>
Xas
ˆ
y
>
Xθ=
ˆ
θ
>
MLE
X
>
Xθ.
In the estimation step of the proposed method, we run the original LARS
algorithm in the tangent spaceT
0
Mas if the response is
ˆ
y.  LARS outputs a
sequence{
ˆ
θ
(0)
,
ˆ
θ
(1)
,...,
ˆ
θ
(d)
}of the model parameter.  As is shown in Figure 1,
the LARS estimator
ˆ
θcan be regarded as moving from the origin to the MLE
ˆ
θ
MLE
of the full model.r(
ˆ
θ) :=
ˆ
θ
MLE
−
ˆ
θof the estimator
ˆ
θis moving from
the MLE
ˆ
θ
MLE
to the origin (Figure 1).  The latter is useful for our method
because it allows us to fix the estimator’s tangent space to the origin.  Note that
the LARS algorithm in subsection 2.2 is described from the latter perspective.
7

LARS in Tangent space (TLARS)LARS in Tangent space (TLARS) is
given as follows:
1.  Calculate the MLE
ˆ
θ
MLE
of the full model.
2.  Run the LARS algorithm for the design matrixXand the response
ˆ
y=
X
ˆ
θ
MLE
.
3.  Using the sequence{
ˆ
θ
(0)
,
ˆ
θ
(1)
,...,
ˆ
θ
(d)
}made by LARS, the result is the
sequence{p(·|
ˆ
θ
(0)
),p(·|
ˆ
θ
(1)
),...,p(·|
ˆ
θ
(d)
)}.
As  a  special  cese,  the  proposed  method  coincides  with  the  original  LARS
when we consider the normal linear regression.  Note that TLARS is as compu-
tationally efficient as LARS although TLARS solves the estimation problem of
the GLM.
3.3  KL Divergence and Correlation
The KullbackLeibler divergence (KL divergence) is a key quantity in information
geometry, which is also important in machine learning, statistics and informa-
tion theory.  For the GLM, the KL divergenceDis given by
D(θ,θ
′
) =ψ(θ
′
)−ψ(θ)−η
>
(θ
′
−θ),
whereη=  E
θ
[X
>
y]  is  the  expectation  parameter  of  the  exponential  family.
The KL divergence is approximated up to second order as
D(θ,θ+ dθ) =D(θ+ dθ,θ) =
1
2
d
∑
i,j=1
g
ij
dθ
i
dθ
j
,
where dθ= (dθ
i
).
In generalized linear regression, the Fisher metricG= (g
ij
) is proportional to
the correlation matrixX
>
X, that is,G=cX
>
Xfor somec >0. (See Appendix
A.1.)  The KL divergence is approximately related with the correlation matrix
as
D(θ,θ+ dθ) =D(θ+ dθ,θ) =
c
2
dθ
>
X
>
Xdθ.(2)
In the proposed method, we used
(
ˆ
θ
MLE
−
ˆ
θ
(k)
)
>
X
>
X(θ−
ˆ
θ
(k)
).(3)
Eq  (2)  implies  that  the  correlation  (3)  is  interpreted  as  the  inner  product  of
two vectorsθ−
ˆ
θ
(k)
and
ˆ
θ
MLE
−
ˆ
θ
(k)
inT
0
Mand that they are approximately
corresponding to a triangle inM, where the square of the length is measured
by the KL divergence.
3.4  LASSO in Tangent Space
We propose two estimation methods.  One is LASSO modification of TLARS.
The other is an approximation of thel
1
-penalization for the GLM (1).
8

LASSO in Tangent space 1 (TLASSO1)By modifying the LARS algo-
rithm so that the algorithm outputs the LASSO estimator Efron et al. (2004),
we  can  use  LASSO  in  the  tangent  spaceT
0
M.    LASSO  in  Tangent  space
(TLASSO1) is formally defined as a minimization problem
min
θ∈R
d
{
‖X
ˆ
θ
MLE
−Xθ‖
2
2
+λ‖θ‖
1
}
,(4)
which implies that we use the design matrixXand the responseX
ˆ
θ
MLE
in the
ordinary LASSO. This is corresponding to the LASSO modification of TLARS.
As is shown in subsection 3.3, the correlation matrix is regarded as an ap-
proximation of the KL divergence, on which the MLE is based.  TLASSO1 is
also an approximation of thel
1
-penalization for the GLM.
LASSO in Tangent space 2 (TLASSO2)Another LASSO-type method
is a direct approximation of (1).  TLASSO2 is defined as
min
θ∈R
d
{
‖αX
 ̃
θ−Xθ‖
2
2
+λ‖θ‖
1
}
,(5)
whereα= 1/(h
−1
)
′
(0) and
 ̃
θsatisfiesX
>
X
 ̃
θ=X
>
y.  Since the column vectors
of the design matrixXare assumed to be linearly independent,
 ̃
θuniquely exists.
Problem (5) is in a form of the normal linear regression with the design matrix
Xand the responseαX
 ̃
θ.  TLASSO2 (5) is an approximation of  (1).  In fact,
using
 ̃
θandα, the log-likelihood is approximated as follows (see subsection A.2):
logp(y|θ)≈−
1
2α
(θ−α
 ̃
θ)
>
X
>
X(θ−α
 ̃
θ) +
α
2
 ̃
θ
>
 ̃
θ−ψ(0).
Note thatα
 ̃
θis an approximation of the MLE
ˆ
θ.
3.5  Remarks on Other Information-Geometrical Methods
We  briefly  compare  TLARS  with  two  existing  methods  which  are  extensions
of  LARS  based  on  information  geometry.   One  is  Bisector  Regression  (BR)
by  Hirose  and  Komaki  (2010)  and  the  other  is  Differential-Geometric  LARS
(DGLARS) by Augugliaro et al. (2013).  Our concern here is about algorithm
itself.
First, the BR algorithm is very different from TLARS. BR takes advantage
of the dually flat structure of the GLM and tries to make an equiangular curve
using the KL divergence.  Furthermore, the BR estimator moves from the MLE
of the full model to the origin while, in our method, the residual moves from
ˆ
θ
MLE
to the origin.
DGLARS is also different from TLARS. It uses tangent spaces, where the
equiangular vector is considered, and exponential maps. However, the DGLARS
estimator  actually  moves  fromp(·|0)  top(·|
ˆ
θ
MLE
)  inM.   Accordingly,  the
tangent space at the current estimator moves, which makes us treat the tangent
spaces at many points inM.  DGLARS treats the model manifold directly, but
9

it  requires  many  iterations  of  approximation  computation  for  the  algorithm.
Note  that  the  update  of  the  TLARS  estimator  is  described  fully  in  terms  of
only the tangent spaceT
0
M, that is, Figure 1 inT
0
Minstead ofR
d
.
4  Numerical Example
We show results of numerical examples and compare our methods with a related
method.  In detail, we compare four methods in the logistic regression setting:
LARS in Tangent Space (TLARS), LASSO in Tangent Space (TLASSO1 and
2), and thel
1
-penalized maximum likelihood estimation for the GLM (L1).
Our  methods  do  not  require  an  extra  implementation  because  the  LARS
algorithm  has  already  been  implemented  inlarspackage  of  the  software  R.
Since  we  used  R,  we  only  neededglm()for  calculating  the  MLE  andlars
package for the proposed methods.  For the computation ofL
1
-penalization, we
usedglmnetpackage Friedman et al. (2008).
4.1  Real Data
We applied the proposed methods and the L1 method to a real data.  The data
is the South Africa heart disease (SAheart) data included byElemStatLearn
package of R. This data contains nine explanatory variables of 462 samples.  The
response is a binary variable.
We show the results by the four methods.  The top left of Figure 3 and the
top right are the paths by TLARS and TLASSO1, respectively.  In this example,
they are the same.  The bottom left is the TLASSO2 path, and the bottom right
is the L1 path.  The paths by TLARS, TLASSO1, and TLASSO2 are made by
lars()function of R, and that of L1 byglmnet().
The four paths are very similar while the proposed methods are based only
on  the  tangent  space,  not  on  the  model  manifold.   These  results  imply  that
the approximation of the model does not require deterioration of result in our
methods, especially, TLARS and TLASSO1.
4.2  Numerical Experiments
We performed numerical experiments.  The topic is three-fold:  generalization,
parameter  estimation,  and  model  selection.   The  result  is  shown  in  Table  1.
Bold values are the best and better values.
The procedure of the experiments is as follows.  We fixed the number of the
parameterd,  the true value of the parameterθ
0
,  and the sample sizen.  For
each ofmtrials, we made the responseyand the design matrixXbyrnorm()
function in R. The four methods were applied to (y,X).
For  selecting  one  model  and  one  estimate  from  a  sequence  of  parameter
10

******
*
*
*
*
0.00.20.40.60.81.0
−5
0
5
10
|beta|/max|beta|
Standardized Coefficients
**
*
*
*
*
*
*
*
*
****
*
*
*
*
*
*
********
*
*
***
*
*
*
*
*
*
*
*****
*
*
*
*
*
*******
*
*
*
*********
*
*
*
*
*
*
*
*
*
*
*
LAR
7
8
4
6
9
01345679
******
*
*
*
*
0.00.20.40.60.81.0
−5
0
5
10
|beta|/max|beta|
Standardized Coefficients
**
*
*
*
*
*
*
*
*
****
*
*
*
*
*
*
********
*
*
***
*
*
*
*
*
*
*
*****
*
*
*
*
*
*******
*
*
*
*********
*
*
*
*
*
*
*
*
*
*
*
LASSO
7
8
4
6
9
01345679
******
*
*
*
*
0.00.20.40.60.81.0
−4
0
2
4
6
8
|beta|/max|beta|
Standardized Coefficients
***
*
*
*
*
*
*
*
****
*
*
*
*
*
*
********
*
*
**
*
*
*
*
*
*
*
*
*****
*
*
*
*
*
*******
*
*
*
*********
*
*
*
*
*
*
*
*
*
*
*
LASSO
7
8
4
6
5
0145679
01020304050
−5
0
5
10
L1 Norm
Coefficients
045679
Figure  3:The  resulted  paths  by  TLARS  (top  left),  TLASSO1  (top  right),
TLASSO2  (bottom  left),  and  L1  (bottom  right).   They  are  very  similar.   In
this  example,  the  paths  by  TLARS  and  TLASSO1  are  the  same.   The  paths
by TLARS, TLASSO1, and TLASSO2 are made bylars()function of R, and
that of L1 byglmnet().
estimates, we used AIC and BIC:
AIC =−2 logp(y|
ˆ
θ) + 2d
′
,(6)
BIC =−2 logp(y|
ˆ
θ) +d
′
logn,(7)
whered
′
is the number of the parameter of the model under consideration.  For
a  sequence  (
ˆ
θ
(k)
)  made  by  each  of  the  four  methods,  letI
(k)
={i|
ˆ
θ
i
(k)
6=  0}
and
ˆ
θ
(k)
MLE
the MLE of the modelM
(k)
={p(·|θ)|θ
j
= 0 (j6∈I
(k)
)}.  We call
(6)  with
ˆ
θ=
ˆ
θ
(k)
MLE
AIC1,  and  (6)  with
ˆ
θ=
ˆ
θ
(k)
AIC2.   Similarly,  (7)  with
ˆ
θ=
ˆ
θ
(k)
MLE
is BIC1, and (7) with
ˆ
θ=
ˆ
θ
(k)
is BIC2.
For evaluating the generalization error of the four methods, we newly made
mobservations{(y
l
1
,X
l
1
),...,(y
l
m
,X
l
m
)}inl-th  trial  (l=  1,2,...,m).   We
computed the difference between (y
l
1
,...,y
l
m
) andmpredictions by each of the
methods.  The “generalization” columns of Table 1 show the average prediction
error overmtrials.  Smaller value is better.
11

The  “model  selection”  columns  show  the  number  of  the  trials  (amongm
trials) where the methods selected the true model.  The “Seq” column indicates
the  number  of  the  trials  where  each  sequence  of  estimates  included  the  true
model.  Larger value is better.
In  the  “parameter  estimation”  columns,  each  value  means  the  average  of
‖
ˆ
θ−θ
0
‖
2
2
of the selected estimate
ˆ
θ.
In  Table  1,  we  report  the  results  of  three  cases.   We  usedm=  10,000
for  all  cases  but  case  C2  wherem=  1,000.   In  case  A,  we  setd=  10  and
θ
0
= (10,10,10,−10,−10,−10,0,0,0,0)
>
.  We usedn= 100 for case A1 and
n= 1,000 for A2.  In generalization, three methods (TLARS, TLASSO1, and
L1) with AIC2 were much better than the other combinations of method and
information  criterion.   In  model  selection,  the  four  methods  with  BIC1  were
much  better  regardless  of  the  sample  size.   In  parameter  estimation,  TLARS
and TLASSO1 with AIC1 and BIC2 were better in the small sample setting.
However, in the larger sample setting, the four methods with AIC2 were better.
These tendencies were observed in other cases, for example,θ
0
= (10,10,−10,−10,0,0,0,0,0,0)
>
.
Case B is the case ofd= 10 andθ
0
= (10,10,0,0,0,0,0,0,0,0)
>
with the
relationx
3
=x
2
+, wherex
2
andx
3
are the second and third columns of the
design matrixX, respectively, andis distributed according to a multivariate
normal distribution.  We setn= 100 andn= 1,000 for cases B1 and B2, respec-
tively.  In generalization, TLARS and TLASSO1 with AIC1, BIC1, and BIC2
were better than the others in Case B1.  Three methods (TLARS, TLASSO1,
and L1) with AIC1 and BIC2 were better for the larger sample setting.  In Case
B, our interest is mainly in generalization because estimation of the true model
and the parameter value are not very meaningful.  However, the four methods
with BIC1 were better in model selection.
In case C, we usedd= 50 and, asθ
0
, the vector of the length 50 with ten
10s, ten−10s, and thirty 0s.  In generalization and parameter estimation, three
methods (TLARS, TLASSO1, and L1) with AIC2 were better than the others
regardless of the sample size.  In model selection, the four methods with BIC1
were much better than the others.
In  summary,  the  proposed  methods  worked  very  well.   Of  course,  the  L1
method sometimes performs better than our methods.  However, the proposed
methods, especially TLARS and TLASSO1, are better than L1 in many situ-
ations.  Furthermore,  TLARS and TLASSO1 output the same results in very
many trials.
5  Conclusion
We proposed the sparse estimation methods as an extension of LARS for the
GLM. The methods take advantage of the tangent space at the origin,  which
is  a  rough  approximation  of  the  model  manifold.   The  proposed  methods  are
computationally efficient because the problem is approximated by the normal
linear regression.  The numerical experiments showed that our idea worked well
by comparison with thel
1
-penalization for the GLM. One of our future works
12

Table 1:  The results of the numerical experiments.
Case
Method
generalization  (
×
10
−
2
)
model selection
parameter estimation
AIC1
AIC2
BIC1
BIC2
Seq
AIC1
AIC2
BIC1
BIC2
AIC1
AIC2
BIC1
BIC2
A1
TLARS
10.70
9.80
12.97
10.72
0.7246
0.3969
0.1838
0.4973
0.3672
168.3
178.7
195.5
167.4
TLASSO1
10.70
9.80
12.97
10.72
0.7247
0.3968
0.1838
0.4974
0.3784
168.3
178.7
195.5
167.4
TLASSO2
15.73
12.49
18.35
15.04
0.7086
0.4062
0.0662
0.4865
0.2769
249.3
171.4
310.2
232.4
L1
18.81
9.74
22.60
10.46
0.6897
0.3996
0.0301
0.4824
0.1548
315.7
183.5
404.5
169.1
A2
TLARS
4.04
3.60
5.14
3.96
0.9785
0.4955
0.1252
0.8573
0.4988
58.7
45.6
99.6
56.4
TLASSO1
4.04
3.58
5.14
3.96
0.9785
0.4955
0.1252
0.8573
0.4988
58.7
45.6
99.6
56.4
TLASSO2
4.73
3.69
5.91
4.40
0.9787
0.4959
0.0561
0.8575
0.4022
79.6
47.2
126.9
69.0
L1
8.20
3.59
10.57
4.05
0.9732
0.4968
0.0721
0.8570
0.3810
234.3
45.4
352.9
58.7
B1
TLARS
13.52
13.89
13.42  13.16
0.5500
1799
0.1455
0.4293
0.3369
146.7
221.6
104.9
106.5
TLASSO1
13.33
13.67
13.28  13.00
0.5643
0.1784
0.1508
0.4316
0.3474
144.0
214.2
102.8  102.1
TLASSO2
14.05
13.94
14.81
14.23
0.5666
0.1820
0.1152
0.4366
0.3257
105.0
133.8
106.2
100.0
L1
15.98
14.43
19.16
13.59
0.5560
0.1814
0.0785
0.4342
0.2671
131.4
334.1
155.9
101.4
B2
TLARS
4.95
5.20
5.16
4.95
0.5848
0.1926
0.1127
0.5402
0.4157
96.8
140.6
89.9
84.8
TLASSO1
4.95
5.20
5.16
4.94
0.5852
0.1918
0.1127
0.
5400
0.4159
96.8
140.6
89.9
84.8
TLASSO2
5.00
5.31
5.29
5.05
0.5850
0.1926
0.0978
0.5400
0.4104
95.0
143.7
90.8
85.1
L1
5.90
5.10
7.62
4.90
0.5793
0.1925
0.0935
0.5367
0.3946
109.1
132.2
158.8
82.0
C1
TLARS
10.18
9.27
14.71
10.97
0.1479
0.0087
0.0009
0.0787
0.0237
373.3  324.8
751.4
435.9
TLASSO1
10.18
9.27
14.71
10.97
0.1479
0.0087
0.0009
0.0787
0.0237
373.3  324.8
751.4
435.9
TLASSO2
14.78
11.65
19.09
15.72
0.1399
0.0098
0.0000
0.0742
0.0147
811.9
537.0
1183.8
895.2
L1
13.48
9.48
19.48
12.05
0.1137
0.0088
0.0000
0.0706
0.0050
690.5
351.6
1215.4
566.4
C2
TLARS
3.98
3.36
6.22
4.17
0.773
0.014
0.000
0.486
0.077
247.4
172.1
608.9
274.2
TLASSO1
3.98
3.36
6.22
4.17
0.773
0.014
0.000
0.486
0.077
247.4
172.1
608.9
274.2
TLASSO2
4.45
3.53
6.64
4.57
0.779
0.014
0.000
0.486
0.068
311.6
190.4
687.7
329.0
L1
4.58
3.40
8.08
4.34
0.736
0.015
0.000
0.486
0.046
330.8
176.0
982.7
297.9
13

is to evaluate TLARS theoretically.  Furthermore, we will apply tools developed
for  LARS  and  LASSO  to  TLARS  and  TLASSO,  for  example,  screening  and
post-selection inference.
References
Shun-ichi Amari.Differential-Geometrical  Methods  in  Statistics, volume 28 of
Lecture Notes in Statistics.  Springer, 1985.
Shun-ichi Amari.Information Geometry and Its Applications.  Springer, 2016.
Shun-ichi Amari and Nagaoka.Methods of Information Geometry, volume 191
ofTranslations of Mathematical Monographs.  Oxford University Press, 2000.
Luigi Augugliaro,  Angelo M. Mineo,  and Ernst C. Wit.  dglars:  a differential
geometric approach to sparse generalized linear models.Journal of the Royal
Statistical Society, Series B, 75:471–498, 2013.
Nihat Ay, Jurgen Jost, Hong Van Le, and Lorenz Schwachhofer.Information
Geometry.  Springer, 2017.
Bradley  Efron,  Trevor  Hastie,  Ian  Johnstone,  and  Robert  Tibshirani.   Least
angle regression.Annals of Statistics, 32:407–499, 2004.
Jerome Friedman, Trevor Hastie, and Robert Tibshirani.  Regularization paths
for  generalized  linear  models  via  coordinate  descent.Journal  of  Statistical
Software, 33:1–22, 2008.
Trevor Hastie, Robert Tibshirani, and Jerome Friedman.The Elements of Sta-
tistical Learning (2nd Edition).  Springer, 2009.
Yoshihiro Hirose and Fumiyasu Komaki.  An extension of least angle regression
based on the information geometry of dually flat spaces.Journal of Compu-
tational and Graphical Statistics, 19:1007–1023, 2010.
Mee Young Park and Trevor Hastie.l
1
-regularization path algorithm for gen-
eralized linear models.Journal of the Royal Statistical Society, Series B, 69:
659–677, 2007.
Robert Tibshirani.  Regression shrinkage and selection via the lasso.Journal of
the Royal Statistical Society, Series B, 58:267–288, 1996.
Ming Yuan and Yi Lin. Model selection and estimation in the gaussian graphical
model.Biometrika, 94:19–35, 2007.
14

A  Lemmas and Remarks
We  show  some  lemmas  and  make  remarks.   Well-known  facts  in  information
geometry are used. See Amari (1985); Amari and Nagaoka (2000); Amari (2016);
Ay et al. (2017).
As introduced in subsection 3.4,
 ̃
θsatisfiesX
>
X
 ̃
θ=X
>
yandα= 1/
 ̃
h(0),
wherehis the link function and
 ̃
h(0) = (h
−1
)
′
(0).  As in subsection 3.3,η
j
isj-
th element ofη(θ) = E
θ
[X
>
y].  Lettingμ(θ) = E
θ
[y], it holdsη(θ) =X
>
μ(θ).
Furthermore, we haveμ
a
(θ) =h
−1
(
∑
d
i=1
x
a
i
θ
i
) (a= 1,2,...,n).
A.1  Metric at Tangent Space and Correlation Between
Explanatory Variables
We show that the Fisher metricG= (g
ij
) at the tangent spaceT
0
Mis propor-
tional to the correlation matrixX
>
Xof the explanatory variables (Lemma 2).
To avoid confusion, in this subsection, we useG(0) = (g
ij
(0)) for the metric in
T
0
MandG(θ) = (g
ij
(θ)) for the metric in the tangent space atp(·|θ).
Lemma 1.It holds that
∂ψ
∂θ
i
=
n
∑
a=1
x
a
i
h
−1
(
d
∑
j=1
x
a
j
θ
j
)
>
.
Proof.Since it is known thatη
i
=∂ψ/∂θ
i
,
(
∂ψ
∂θ
1
,
∂ψ
∂θ
2
,...,
∂ψ
∂θ
d
)
= (η
1
,η
2
,...,η
d
) =μ(θ)
>
X
=
(
h
−1
(
d
∑
i=1
x
1
i
θ
i
)
,h
−1
(
d
∑
i=1
x
2
i
θ
i
)
,...,h
−1
(
d
∑
i=1
x
n
i
θ
i
))
X.
Lemma 2.G(0) =cX
>
Xfor somec >0.
Proof.It is known that the metricg
ij
is derived from the potential functionψ:
g
ij
(θ) =∂
i
∂
j
ψ(θ).  Therefore, it holds
g
ij
(θ) =∂
i
∂
j
ψ(θ) =∂
i
η
j
(θ)
=
n
∑
a=1
x
a
i
∂
j
μ
a
(θ) =
n
∑
a=1
x
a
i
∂
j
h
−1
(
d
∑
k=1
x
a
k
θ
k
)
=
n
∑
a=1
x
a
i
x
a
j
 ̃
h
(
d
∑
k=1
x
a
k
θ
k
)
,
where
 ̃
his the derivative ofh
−1
.  Lettingθ= 0 andc=
 ̃
h(0), we haveG(0) =
cX
>
X.   Since  bothG(0)  andX
>
Xare  known  to  be  positive  definite,cis  a
positive constant.
15

Note thatcis common to alli,jandain the proof.  This is why the tangent
space at the originθ= 0 is selected as the space where LARS runs.
A.2  Approximations of the Likelihood and MLE
We approximate the log-likelihood and the MLE for the GLM.
Lemma 3.The log-likelihood is expanded as
logp(y|θ) =−
1
2α
(θ−α
 ̃
θ)
>
X
>
X(θ−α
 ̃
θ) +
α
2
 ̃
θ
>
 ̃
θ−ψ(0) +O(‖θ‖
3
).
Proof.Usingα=  1/
 ̃
h(0)  and  Lemmas  1  and  2,  the  potential  functionψis
expanded as follows:
ψ(θ) =ψ(0) +
(
∂ψ
∂θ
1
(0),
∂ψ
∂θ
2
(0),...,
∂ψ
∂θ
d
(0)
)
θ+
1
2
θ
>
G(0)θ+O(‖θ‖
3
)
=ψ(0) +h
−1
(0)1
>
Xθ+
1
2α
θ
>
X
>
Xθ+O(‖θ‖
3
)
=ψ(0) +
1
2α
θ
>
X
>
Xθ+O(‖θ‖
3
).
At the last equal sign, we used1
>
X= 0 because each column vector ofXis
normalized.  Therefore,
logp(y|θ) =y
>
Xθ−ψ(θ)
=
 ̃
θ
>
X
>
Xθ−ψ(θ)
=
 ̃
θ
>
X
>
Xθ−
{
ψ(0) +
1
2α
θ
>
X
>
Xθ+O(‖θ‖
3
)
}
=−
1
2α
(θ−α
 ̃
θ)
>
X
>
X(θ−α
 ̃
θ) +
α
2
 ̃
θ
>
 ̃
θ−ψ(0) +O(‖θ‖
3
).
Lemma 3 implies thatα
 ̃
θis an approximation of the MLE
ˆ
θ
A.3  e-Exponential Map
In Riemannian geometry, a point in a tangent space is mapped to a manifold
via an exponential map.  An exponential map is defined using a geodesic.  A
geodesic in a manifold corresponds to a straight line in Euclidean space.  When
we consider an exponential map, we need to introduce not only metric but also
a connection.  A connection determines flatness and straightness in a manifold.
In Section 3, we implicitly introduced the e-connection.  From the viewpoint of
the e-connection, each curve ofθ
i
-axis is an e-geodesic.
For a manifoldMand a pointp∈M, an exponential mapfatpis formally
defined  as  follows.   First,  we  consider  the  geodesicγ
v
(t)  forv∈T
p
Mwhich
16

satisfiesγ
v
(0) =pandγ
′
v
(0) =v.  Here the parametertmoves in a subset of
R.  Note that, given a connection, the geodesicγ
v
locally exists and is uniquely
determined.  The exponential mapfisf:T
p
M → Mandf(v) =γ
v
(1) for
v∈D⊂T
p
M, whereD={v∈T
p
M|γ
v
(1) exists}.
In general, an exponential map is not necessarily easy to treat.  For example,
the domainDof an exponential map is called a star-shaped domain and does
not coincide with a whole tangent space.  However, our exponential map Exp
0
:
T
0
M→Mhas a useful property.  The domain of Exp
0
is a wholeT
0
Mand the
range is a wholeM.
Lemma 4.The  mapExp
0
:T
0
M →Mdefined  in  subsection  3.1  is  the  e-
exponential  map  for  a  manifold  of  the  GLM.  Furthermore,Exp
0
is  a  bijection
from the tangent spaceT
0
Mto the manifoldM.
Proof.Forv=
∑
d
i=1
v
i
∂
i
∈T
0
M,  the value of the map is Exp
0
(v) =p(·|v),
wherev= (v
i
).  It is known that the e-geodesicγ(t) satisfyingγ(0) =p(·|v)
and  dγ(t)/dt|
t=0
=vis  represented  asγ(t)  =tvin  the  e-affine  coordinate
system.   Therefore,  Exp
0
(v)  =p(·|v)  =γ(1),  which  means  that  Exp
0
is  the
e-exponential map.
SinceM={p(·|θ)|θ∈R
d
}, the e-exponential map is defined on a whole
T
0
M.  Forθ∈R
d
,w=
∑
d
i=1
θ
i
∂
i
∈T
0
Mand Exp
0
(w) =p(·|θ), which imply
that  the  e-exponential  map  is  a  surjection.   Furthermore,  ifv,w∈T
0
Mare
different, Exp
0
(v)6= Exp
0
(w) because the column vectors ofXare assumed to
be linearly independent.
17 

On the relation between
Loss Functions and T-Norms
? ??
Francesco Giannini
1
, Giuseppe Marra
1,2
, Michelangelo Diligenti
1
,
Marco Maggini
1
, and Marco Gori
1
1
Department of Information Engineering and Mathematical Sciences,
University of Siena, ITALY
{fgiannini,diligmic,maggini,marco}@diism.unisi.it
2
Department of Information Engineering,
University of Florence, ITALY
g.marra@unifi.it
Abstract.Deep learning has been shown to achieve impressive results
in several domains like computer vision and natural language process-
ing. A key element of this success has been the development of new loss
functions, like the popular cross-entropy loss, which has been shown to
provide faster convergence and to reduce the vanishing gradient problem
in very deep structures. While the cross-entropy loss is usually justified
from  a  probabilistic  perspective,  this  paper  shows  an  alternative  and
more direct interpretation of this loss in terms of t-norms and their as-
sociated generator functions, and derives a general relation between loss
functions and t-norms. In particular, the presented work shows intrigu-
ing results leading to the development of a novel class of loss functions.
These losses can be exploited in any supervised learning task and which
could lead to faster convergence rates that the commonly employed cross-
entropy loss.
Keywords:Loss functions·Learning from constraints·T-Norms.
1  Introduction
A careful choice of the loss function has been pivotal into the success of deep
learning. In particular, thecross-entropy loss, or log loss, measures the perfor-
mance of a classifier and increases when the predicted probability of an assign-
ment diverges from the actual label [7]. In supervised learning, the cross-entropy
loss has a clear interpretation as it attempts at minimizing the distribution of
the predicted and given pattern labels. From a practical standpoint, the main
advantage of this loss is to limit the vanishing gradient issue for networks with
sigmoidal or softmax output activations.
?
This project has received funding from the European Union’s Horizon 2020 research
and innovation program under grant agreement No 825619.
??
To appear in 29th International Conference on Inductive Logic Programming, Plov-
div, Bulgaria on 3-5 Sep 2019.
c
©
ILP2019
arXiv:1907.07904v1  [cs.LG]  18 Jul 2019

2F. Giannini et al.
Recent advancements in Statistical Relational Learning (SRL) [16] allow to
inject prior knowledge, often expressed using a logic formalism, into a learner.
One of the most popular lines of research in this community attempts at defin-
ing  frameworks  for  performing  logic  inference  in  the  presence  of  uncertainty.
For example, Markov Logic Networks [18] and Probabilistic Soft Logic [1] inte-
grate First Order Logic (FOL) and graphical models. More recently, many at-
tempts have been focusing on integrating reasoning with uncertainty with deep
learning [20]. A common solution, followed by approaches like Semantic Based
Regularization [4] and Logic Tensor Networks [5], relies on using deep networks
to  approximate  the  FOL  predicates,  and  the  overall  architecture  is  optimized
end-to-end by relaxing the FOL into a differentiable form, which translates into
a set of constraints. For the sake of overall consistency, one question that can
naturally arise in this context is how the fitting of the supervised examples can
be expressed using logic formalism. Following this starting point, this paper fol-
lows an orthogonal approach for the definition of a loss function, by studying
the relation between the translation of the prior knowledge using t-norms and
the resulting loss function. In particular, the notion of t-normgeneratorplays
a fundamental role in the behavior of the corresponding loss. Remarkably, the
cross-entropy loss can be naturally derived within this framework. However, the
presented theoretical results suggest that there is a larger class of loss functions
that correspond to the different possible translations of logic using t-norms, and
some loss functions are potentially more effective than the cross-entropy to limit
the vanishing gradient issue, therefore proving a faster convergence rate.
The paper is organized as follows: Section 2 presents the basic concepts about
t-norms, generators and aggregator functions. Section 3 introduces the learning
frameworks used to represent supervised learning in terms of logic rules, while
Section 4 presents the experimental results and, finally, Section 5 draws some
conclusions.
2  Fuzzy Aggregation Functions
The aggregation takes place on a set of values typically representing preferences
or  satisfaction  degrees  restricted  to  the  unit  interval  [0,1]  to  be  aggregated.
There are several ways to aggregate them into a single value expressing an overall
combined score, according to what is expected from such mappings. The purpose
of aggregation functions is to combine inputs that are typically interpreted as
degrees of membership in fuzzy sets, degrees of preference or strength of evidence.
Aggregation functions have been studied by several authors in the literature [2,3],
and they are successfully used in many practical applications, for instance see
[8,19]. Please note that the fuzzy aggregation functions that will be covered in
this section can be directly applied to the output of a multi-task classifier, when
implemented via a neural network with sigmoidal or softmax output units.
Basic  Definitions.Aggregation  functions  are  defined  for  inputs  of  any  car-
dinality,  however  for  simplicity  the  main  definitions  are  provided  only  for  the

On the relation between Loss Functions and T-Norms3
G ̈odelLukasiewiczProduct
T
M
(x, y) = min{x, y}T
L
(x, y) = max{0, x+y−1}T
Π
(x, y) =x·y
Table 1: Fundamental t-norms.
binary  case.  A  (binary)  aggregation  function  is  a  non-decreasing  functionA:
[0,1]
2
→[0,1],  such  that:A(0,0)  =  0,A(1,1)  =  1.  An  aggregation  function
Acan be categorized according to the pointwise order in Equation 1 as:con-
junctivewhenA≤min,disjunctivewhen max≤A,averaging(amean) when
min< A <max andhybridotherwise; where min and max are the aggregation
functions for theminimumandmaximumrespectively.
A
1
≤A
2
iffA
1
(x,y)≤A
2
(x,y),for allx,y∈[0,1].(1)
Conjunctive and disjunctive type functions combine values as if they were
related by a logical AND and OR operations, respectively. On the other hand,
averaging type functions have the property that low values can be compensated
by  high  values.  Mean  computation  is  the  most  common  way  to  combine  the
inputs,  since  it  assumed  the  total  score  cannot  be  above  or  below  any  of  the
inputs, but it depends on all the inputs.
2.1    Archimedean T-Norms
Despite averaging functions have nice properties to aggregate fuzzy values, they
are  not  suitable  to  represent  neither  a  conjunction  nor  a  disjunction,  because
they do not generalize their boolean counterpart. This is a reason why, we focus
on t-norms and t-conorms  [11,14], that areassociative, commutativeaggregation
functions with 1 and 0 asneutral  element, respectively. Table 1 reports G ̈odel,
Lukasiewicz and Product t-norms, which are referred as the fundamental t-norms
because all the continuous t-norms can be obtained as ordinal sums of the two
fundamental t-norms [10]. A simple example of a t-norm that is not continuous
is given by the Drastic t-normT
D
, that is always returning a zero value, except
forT
D
(1,1) = 1.Archimedeant-norms [13] are a class of t-norms that can be
constructed by means of unary monotone functions, calledgenerators.
Definition 1.A  t-normTis  said  to  beArchimedeanif  for  everyx∈(0,1),
T(x,x)< x.  In  addition,Tis  saidstrictif  for  allx∈(0,1),0< T(x,x)< x
otherwise is saidnilpotent.
For instance, the Lukasiewicz t-normT
L
is nilpotent, the Product t-normT
Π
is strict, while the G ̈odel oneT
M
is not archimedean, indeedT
M
(x,x) =x, for
allx∈[0,1]. The Lukasiewicz and Product t-norms are enough to represent the
whole classes of nilpotent and strict Archimedean t-norms [14].
A fundamental result for the construction of t-norms byadditivegenerators
is based on the following theorem [12]:

4F. Giannini et al.
Theorem 1.Letg:  [0,1]→[0,+∞]be  a  strictly  decreasing  function  with
g(1)  =  0andg(x) +g(y)∈Range(g)∪[g(0
+
),+∞]for  allx,yin[0,1],  and
g
(−1)
its pseudo-inverse. Then the functionT: [0,1]→[0,1]defined as
T(x,y) =g
−1
(
min{g(0
+
),g(x) +g(y)}
)
.(2)
is a t-norm andgis said anadditive generatorforT.
Any t-normTwith an additive generatorgis Archimedean, ifgis continuous
thenTis  continuous,Tis  strict  if  and  only  ifg(0)  =  +∞,  otherwise  it  is
nilpotent.
Example 1.If we takeg(x) = 1−x, then alsog
−1
(y) = 1−yand we getT
L
:
T(x,y) = 1−min{1,1−x+ 1−y}= max{0,x+y−1}.
Example 2.Takingg(x) =−log(x), we haveg
−1
(y) =e
−y
and we getT
Π
:
T(x,y) =e
−(min{+∞,−log(x)−log(y)})
=x·y .
Eq. (2) allows to derive the other fuzzy connectives as function of the generator:
residuum :x⇒y=g
−1
(max{0,g(y)−g(x)})
bi-residuum :x⇔y=g
−1
(|g(x)−g(y)|)
(3)
Ifgis expressed as a parametric function, it is possible to define families of
t-norms, which can be constructed by the generator obtained when setting the
parameters to specific values. Several parametric families of t-norms have been
introduced  [2].  The  experimental  section  of  this  paper  employs  the  family  of
Schweizer–Sklar and Frank t-norms, depending on a parameterλ∈(−∞,+∞)
andλ∈[0,+∞] respectively, and whose generators are defined as:
g
SS
λ
(x) =
{
−log(x)    ifλ= 0
1−x
λ
λ
otherwise
andg
F
λ
(x) =







−log(x)ifλ= 1
1−xifλ= +∞
log
(
λ−1
λ
x
−1
)
otherwise
(4)
3  From Formulas to Loss Functions
A learning process can be thought of as a constraint satisfaction problem, where
the constraints represent the knowledge about the functions to be learned. In par-
ticular, multi-task learning can be expressed via a set of constraints expressing
the fitting of the supervised examples, plus any additional abstract knowledge.
Let us consider a set of unknown task functionsP={p
1
,...,p
J
}defined on
R
n
, all collected in the vectorp= (p
1
,...,p
J
) and a set of known functions or
predicatesS. Given the setX ⊆R
n
of available data, a learning problem can be
generally formulated as min
p
L(X,S,p) whereLis a positive-valued functional
denoting  a  certain  loss  function.  Each  predicate  is  approximated  by  a  neural

On the relation between Loss Functions and T-Norms5
network providing an output value in [0,1]. The available knowledge about the
task functions consists in a set of FOL formulasKB={φ
1
,...,φ
H
}and the
learning process aims at finding a good approximation of each unknown element,
so that the estimated values will satisfy the formulas for the input samples. Since
any formula is true if it evaluates to 1, in order to satisfy the constraints we may
minimize the following loss function:
L(X,S,p) =
H
∑
h=1
λ
h
L
(
f
h
(X,S,p)
)
(5)
where  anyλ
h
is  the  weight  for  theh-th  logical  constraint,  which  can  be  se-
lected  via  cross-validation  or  jointly  learned  [15,21],f
h
is  the  truth-function
corresponding to the formulaφ
h
according to a certain t-norm fuzzy logic and
Lis a decreasing function denoting the penalty associated to the distance from
satisfaction of formulas, so thatL(1) = 0. In the following, we will study dif-
ferent  forms  for  theLcost  function  and  how  it  depends  on  the  choice  of  the
t-norm generator. In particular, at-norm  fuzzy  logicgeneralizes Boolean logic
to variables assuming values in [0,1] and is defined by its t-norm modeling the
logical AND [9]. The connectives can be treated using the fuzzy generalization
of  first–order  logic  that  was  first  proposed  by  Novak  [17].  Theuniversaland
existential  quantifiersoccurring in the formulas inKBallows the aggregation
of different evaluations (groundings) of the formulas on the available data. For
instance, given a formulaφ(x
i
) depending on a certain variablex
i
∈ X
i
, where
X
i
denotes the available samples for thei-th argument of one of the involved
predicates inφ, we may convert the quantifiers as the minimum and maximum
operations that are common to any t-norm fuzzy logic:
∀x
i
φ(x
i
) =⇒f
φ
(X
i
,S,p) =  min
x
i
∈X
i
f
φ
(x
i
,S,p)
∃x
i
φ(x
i
) =⇒f
φ
(X
i
,S,p) =  max
x
i
∈X
i
f
φ
(x
i
,S,p)
3.1    Loss Functions by T-Norms Generators
A quantifier can be seen as a way to aggregate all the possible groundings of a
predicate variable that, in turn, are [0,1]-values. Different aggregation functions
have also been considered, for example in [5], the authors consider a mean op-
erator to convert the universal quantifier. However this has the drawback that
also the existential quantifier has the same semantics conversion and then it is
determined by the authors via Skolemization. Even if this choice may yield some
learning benefits, it has no direct justification inside a logic theory. Moreover it
does not suggest how to map the functional translation of the formula into a con-
straint. In the following, we investigate the mapping of formulas into constraints
by means of generated t-norm fuzzy logics, and we exploited the same additive
generator of the t-norm to map the formula into the functional constraints to be
minimized, i.e.L=g.

6F. Giannini et al.
Given a certain formulaφ(x) depending on a variablexthat ranges in the
setXand its corresponding functional representationf
φ
(x,p) evaluated on each
x∈X, the conversion of universal and existential quantifiers should have seman-
tics equivalent to the AND and OR of the evaluation of the formula over the
groundings, respectively. This can be realized by directly applying the t-norm
or t-conorms over the groundings. For instance, for the universal quantifier:
∀xφ(x)≡
∧
x
φ(x)=⇒g
−1
(
min
{
g(0
+
),
∑
x∈X
g
(
f
φ
(x,S,p)
)
})
,(6)
wheregis an additive generator of the t-normTcorresponding to the universal
quantifier. Since any generator function is decreasing, in order to maximize the
satisfaction of∀xφ(x) we can minimizegapplied to Equation 6, namely:
min{g(0
+
),
∑
x∈X
g(f
φ
(x,S,p))}ifTis nilpotent(7)
∑
x∈X
g(f
φ
(x,S,p))ifTis strict(8)
As a consequence, with respect to the convexity of the expressions in Equa-
tions 7-8, we get the following result, that is an immediate consequence of how
the convexity is preserved by function composition.
Proposition 1.Ifgis a linear function andf
φ
is concave, Equation 7 is convex.
Ifgis a convex function andf
φ
is linear, Equation 8 is convex.
Example 3.Ifg(x) = 1−x(Lukasiewicz t-norm) from Equation 7 we get:
min(1,
∑
x∈X
(1−(f
φ
(x,S,p))).
Hence, in casef
φ
is concave (see [6] for a characterization of the concave fragment
of Lukasiewicz logic), this function is convex.
Ifg=−log (Product t-norm) from Equation 8 we get the cross-entropy:
−
∑
x∈X
log(f
φ
(x,S,p)).
As we already pointed out in Section 2, ifgis an additive generator for a
t-normT, then the residual implication and the biresidum with respect toTare
given by Equation 3. In particular, ifp
1
,p
2
are two unary predicates functions
sharing the same input domainX, andS=∅the following formulas yield the

On the relation between Loss Functions and T-Norms7
following penalty terms:
∀xp
1
(x) =⇒min
{
g(0
+
),
∑
x∈X
g(p
1
(x))
}
∀xp
1
(x)⇒p
2
(x) =⇒min
{
g(0
+
),
∑
x∈X
max(0,g(p
2
(x))−g(p
1
(x))
}
∀xp
1
(x)⇔p
2
(x) =⇒min
{
g(0
+
),
∑
x∈X
|g(p
1
(x))−g(p
2
(x))|
}
.
3.2    Redefinition of supervised Learning with Logic
In this section, we study the case of supervised learning w.r.t. the choice of a
certain  additive  generator.  Let  us  consider  a  multi-task  classification  problem
with  predicatesp
j
,j=  1,...,Jdefined  over  the  same  input  domain  with  a
supervised training setT={(x
i
,y
i
)}where eachy
i
∈{1,2,...,J}is the output
class for the patternx
i
andXis the overall set of supervised patterns. Finally, the
known predicateS
j
is defined for each predicate such thatS
j
(x
i
) = 1 iffy
i
=j,
and we indicate asX
j
={x
i
∈ X:S
j
(x
i
) = 1}the set of positive examples for
thej-th predicate. Then, we can enforce the supervision constraints forp
j
as:
∀xS
j
(x)⇔p
j
(x)=⇒ L(X,S,p
j
) =
∑
x∈X
|g(S
j
(x))−g(p
j
(x))|
In  the  special  case  of  the  predicates  implemented  by  neural  networks  and
exclusive multi-task classification, where each pattern should be assigned to one
and only one class, the exclusivity can be enforced using a softmax output ac-
tivation. Typically, in this scenario, only the positive supervisions are explicitly
listed, and since it holds thatg(S
j
(x)) = 0,∀x∈X
j
, yields:
L
+
(X,S,p
j
) =
∑
x∈X
j
g(p
j
(x)),(9)
For instance, in the case of Lukasiewicz and Product logic, we have, respectively:
L
+
L
(X
j
,p
j
) =
∑
x∈X
j
(1−p
j
(x)),L
+
Π
(X
j
,p
j
) =−
∑
x∈X
j
log (p
j
(x))
corresponding to theL
1
and cross entropy losses, respectively.
4  Experimental Results
The proposed framework allows to recover well-known loss functions by express-
ing  the  fitting  of  the  supervision  using  logic  and  then  carefully  selecting  the

8F. Giannini et al.
01000020000300004000050000
0.4
0.5
0.6
0.7
0.8
0.9
1.0
=1.5
=1.0
= 0  (T  )
= 1  (T )
(a) The Schweizer–Sklar t-norms
01000020000300004000050000
0.4
0.5
0.6
0.7
0.8
0.9
1.0
= 1  (T  )
= 100.0
= 10000
= + Inf  (T )
(b) The Frank t-norms
Fig. 1:  Convergence  speed  of  multiple  generated  loss  functions  on  the  MNIST
classification task for different values of the parameterλof equation 4. The well-
known cross-entropy loss is equivalent to the loss obtained by theT
Π
generator.
t-norm  used  to  translate  the  resulting  formulas.  However,  a  main  strength  of
the proposed theory is that it becomes possible to derive new principled losses
starting from any family of parametric t-norms. Driven by the huge impact that
cross-entropy gained w.r.t. to classical loss functions in improving convergence
speed  and  generalization  capabilities,  we  designed  a  set  of  experiments  to  in-
vestigate  how  the  choice  of  a  t-norm  can  lead  to  a  loss  function  with  better
performances than the cross-entropy loss. The Schweizer–Sklar and the Frank
parametric t-norms defined in Section 2.1 have been selected for this experimen-
tal  evaluation,  given  the  large  spectrum  of  t-norms  that  can  be  generated  by
varying theirλparameter. The well known MNIST dataset is used as bench-
mark for all the presented experiments. In order to have a fair comparison, the
same neural network architecture is used during all the runs: a 1-hidden layer
neural network with 50 hidden ReLU units and 10 softmax output units. The
softmax  activation  function  allows  to  express  only  positive  supervisions,  like
commonly done in mutually exclusive classification using the cross-entropy loss.
Optimization is carried on using Vanilla gradient descent with a fixed learning
rate of 0.01.
Results are shown in Figure 1, that reports the accuracy on the test set of a
neural network trained on the MNIST dataset. Specific choices of the parameter
λrecover classical loss functions, like the cross-entropy loss, which is equivalent
to the loss obtained usingT
Π
. The results confirm that the cross-entropy loss
converges faster than theL
1
obtained when usingT
L
. However, there is a wide
range of possible choices for the parameterλthat brings an even faster conver-
gence and better generalization than the widely adopted used cross-entropy.

On the relation between Loss Functions and T-Norms9
5  Conclusions
This paper presents a framework to embed prior knowledge expressed as logic
statements  into  a  learning  task,  showning  how  the  choice  of  the  t-norm  used
to convert the logic into a differentiable form defines the resulting loss function
used during learning. When restricting the attention to supervised learning, the
framework recovers popular loss functions like the cross-entropy loss, and allows
to define new loss functions corresponding to the choice of the parameters of t-
norm parametric forms. The experimental results show that some newly defined
losses provide a faster convergence rate that the commonly used cross-entropy
loss.  Future  work  will  focus  on  testing  the  loss  functions  in  more  structured
learning  tasks,  like  the  one  commonly  addressed  with  Logic  Tensor  Networks
and Semantic based Regularization. The parametric form of the loss functions
allows to define joint learning tasks, where the loss parameters are co-optimized
during learning, for example using maximum likelihood estimators.
References
1.  Bach, S.H., Broecheler, M., Huang, B., Getoor, L.: Hinge-loss markov random fields
and probabilistic soft logic. Journal of Machine Learning Research18, 1–67 (2017)
2.  Beliakov, G., Pradera, A., Calvo, T.: Aggregation functions: A guide for practi-
tioners, vol. 221. Springer (2007)
3.  Calvo, T., Koles ́arov ́a, A., Komorn ́ıkov ́a, M., Mesiar, R.: Aggregation operators:
properties, classes and construction methods. In: Aggregation operators, pp. 3–104.
Springer (2002)
4.  Diligenti, M., Gori, M., Sacca, C.: Semantic-based regularization for learning and
inference. Artificial Intelligence244, 143–165 (2017)
5.  Donadello, I., Serafini, L., d’Avila Garcez, A.: Logic tensor networks for seman-
tic  image  interpretation.  In:  IJCAI  International  Joint  Conference  on  Artificial
Intelligence. pp. 1596–1602 (2017)
6.  Giannini, F., Diligenti, M., Gori, M., Maggini, M.: On a convex logic fragment for
learning and reasoning. IEEE Transactions on Fuzzy Systems (2018)
7.  Goodfellow, I., Bengio, Y., Courville, A., Bengio, Y.: Deep learning, vol. 1. MIT
press Cambridge (2016)
8.  Grabisch, M., Marichal, J.L., Mesiar, R., Pap, E.: Aggregation functions: means.
Information Sciences181(1), 1–22 (2011)
9.  H ́ajek,  P.:  Metamathematics  of  fuzzy  logic,  vol.  4.  Springer  Science  &  Business
Media (2013)
10.  Jenei, S.: A note on the ordinal sum theorem and its consequence for the construc-
tion of triangular norms. Fuzzy Sets and Systems126(2), 199–205 (2002)
11.  Klement, E.P., Mesiar, R., Pap, E.: Triangular norms. position paper i: basic ana-
lytical and algebraic properties. Fuzzy Sets and Systems143(1), 5–26 (2004)
12.  Klement, E.P., Mesiar, R., Pap, E.: Triangular norms. position paper ii: general
constructions and parameterized families. Fuzzy Sets and Systems145(3), 411–438
(2004)
13.  Klement, E.P., Mesiar, R., Pap, E.: Triangular norms. position paper iii: continuous
t-norms. Fuzzy Sets and Systems145(3), 439–454 (2004)

10F. Giannini et al.
14.  Klement, E.P., Mesiar, R., Pap, E.: Triangular norms, vol. 8. Springer Science &
Business Media (2013)
15.  Kolb, S., Teso, S., Passerini, A., De Raedt, L.: Learning smt (lra) constraints using
smt solvers. In: IJCAI. pp. 2333–2340 (2018)
16.  Koller,  D.,  Friedman,  N.,  Dˇzeroski,  S.,  Sutton,  C.,  McCallum,  A.,  Pfeffer,  A.,
Abbeel,  P.,  Wong,  M.F.,  Heckerman,  D.,  Meek,  C.,  et  al.:  Introduction  to  sta-
tistical relational learning. MIT press (2007)
17.  Nov ́ak,  V.,  Perfilieva,  I.,  Mockor,  J.:  Mathematical  principles  of  fuzzy  logic,
vol. 517. Springer Science & Business Media (2012)
18.  Richardson,  M.,  Domingos,  P.:  Markov  logic  networks.  Machine  learning62(1),
107–136 (2006)
19.  Torra, V., Narukawa, Y.: Modeling decisions: information fusion and aggregation
operators. Springer Science & Business Media (2007)
20.  Xu, J., Zhang, Z., Friedman, T., Liang, Y., Broeck, G.V.d.: A semantic loss function
for deep learning with symbolic knowledge. arXiv preprint arXiv:1711.11157 (2017)
21.  Yang, F., Yang, Z., Cohen, W.W.: Differentiable learning of logical rules for knowl-
edge base reasoning. In: Advances in Neural Information Processing Systems. pp.
2319–2328 (2017) 

Amortized Monte Carlo Integration
Adam Goli
 ́
nski
* 1 2
Frank Wood
3
Tom Rainforth
* 1
Abstract
Current  approaches  to  amortizing  Bayesian  in-
ference focus solely on approximating the pos-
terior  distribution.    Typically,  this  approxima-
tion is, in turn, used to calculate expectations for
one  or  more  target  functions—a  computational
pipeline which is inefficient when the target func-
tion(s) are known upfront.  In this paper, we ad-
dress  this  inefficiency  by  introducing  AMCI,  a
method foramortizing Monte Carlo integration
directly.  AMCI operates similarly to amortized
inference  but  produces  three  distinct  amortized
proposals, each tailored to a different component
of  the  overall  expectation  calculation.   At  run-
time, samples are produced separately from each
amortized proposal, before being combined to an
overall estimate of the expectation. We show that
while existing approaches are fundamentally lim-
ited  in  the  level  of  accuracy  they  can  achieve,
AMCI can theoretically produce arbitrarily small
errors  for  any  integrable  target  function  using
only a single sample from each proposal at run-
time.   We further show that it is able to empir-
ically outperform the theoretically optimal self-
normalized importance sampler on a number of
example problems.  Furthermore,  AMCI allows
not  only  for  amortizing  over  datasets  but  also
amortizing over target functions.
1. Introduction
At  its  core,  Bayesian  modeling  is  rooted  in  the  calcula-
tion of expectations:  the eventual aim of modeling is typ-
ically  to  make  a  decision  or  to  construct  predictions  for
unseen  data,  both  of  which  take  the  form  of  an  expec-
tation  under  the  posterior  (Robert,  2007).   This  aim  can
*
Equal contribution
1
Department of Statistics,  University of
Oxford,  United Kingdom
2
Department of Engineering Science,
University of Oxford, United Kingdom
3
Department of Computer
Science,  University  of  British  Columbia,  Vancouver,  Canada.
Correspondence to: Adam Goli
 ́
nski<adamg@robots.ox.ac.uk>.
Proceedings  of  the36
th
International  Conference  on  Machine
Learning, Long Beach, California, PMLR 97, 2019.  Copyright
2019 by the author(s).
thus be summarized in the form of one or more expecta-
tionsE
p(x|y)
[
f(x)
]
,  wheref(x)is  a  target  function  and
p(x|y)is the posterior distribution onxfor some datay,
which we typically only know up to a normalizing constant
p(y). More generally, expectations with respect to distribu-
tions with unknown normalization constant are ubiquitous
throughout the sciences (Robert & Casella, 2013).
Sometimesf(x)is not known up front. Here it is typically
convenient to first approximatep(x|y), e.g.  in the form of
Monte Carlo (MC) samples, and then later use this approx-
imation to calculate estimates,  rather than addressing the
target expectations directly.
However,  it is often the case in practice that a particular
target function, or class of target functions, is known a pri-
ori. For example, in decision-based settingsf(x)takes the
form of a loss function, while any posterior predictive dis-
tribution  constitutes  a  set  of  expectations  with  respect  to
the posterior, parameterized by the new input.  Though of-
ten overlooked,  it is well established that in suchtarget-
awaresettings the aforementioned pipeline of first approx-
imatingp(x|y)and then using this as a basis for calculat-
ingE
p(x|y)
[
f(x)
]
is suboptimal as it ignores relevant in-
formation inf(x)(Hesterberg, 1988; Wolpert, 1991; Oh &
Berger, 1992; Evans & Swartz, 1995; Meng & Wong, 1996;
Chen  &  Shao,  1997;  Gelman  &  Meng,  1998;  Lacoste-
Julien et al., 2011; Owen, 2013; Rainforth et al., 2018b).
As we will later show, the potential gains in such scenarios
can be arbitrarily large.
In  this  paper,  we  extend  these  ideas  toamortizedinfer-
ence settings (Stuhlm
 ̈
uller et al., 2013; Kingma & Welling,
2014; Ritchie et al., 2016; Paige & Wood, 2016; Le et al.,
2017;  2018a;  Webb  et  al.,  2018),  wherein  one  looks  to
amortize  the  cost  of  inference  across  different  possible
datasets  by  learning  an  artifact  that  assists  the  inference
process at runtime for a given dataset. Existing approaches
do not operate in a target-aware fashion, such that even if
the inference network learns proposals that perfectly match
the true posterior for every possible dataset, the resulting
estimator is still sub-optimal.
To  address  this,  we  introduce  AMCI,  a  framework  for
performingAmortized  Monte Carlo  Integration.   Though
still  based  on  learning  amortized  proposals  distributions,
AMCI   varies   from   standard   amortized   inference   ap-
arXiv:1907.08082v1  [stat.ML]  18 Jul 2019

Amortized Monte Carlo Integration
proaches  in  three  respects.   First,  it  operates  in  a  target-
aware fashion, incorporating information aboutf(x)into
the  amortization  artifacts.Second,   rather  than  using
self-normalization,  AMCI  employs  three  distinct  propos-
als for separately estimatingE
p(x)
[
p(y|x) max(f(x),0)
]
,
E
p(x)
[
−p(y|x) min(f(x),0)
]
, andE
p(x)
[
p(y|x)
]
, before
combining these into an overall estimate.  This breakdown
allows for arbitrary performance improvements compared
to self-normalized importance sampling (SNIS). Finally, to
account for cases in which multiple possible target func-
tions may be of interest, AMCI also allows for amortization
over parametrized functionsf(x;θ).
Remarkably,  AMCI  is  able  to  achieve  an  arbitrarily  low
error  at  run-time  using  only  a  single  sample  from  each
proposal given sufficiently powerful amortization artifacts,
contrary to the fundamental limitations on the accuracy of
conventional amortization approaches. This ability is based
around its novel breakdown of the target expectation into
separate components,  the subsequent utility of which ex-
tends beyond the amortized setting we consider here.
2. Background
2.1. Importance Sampling
Importance  Sampling  (IS),  in  its  most  basic  form,  is  a
method  for  approximating  an  expectationE
π(x)
[
f(x)
]
when it is either not possible to sample fromπ(x)directly,
or when the simple MC estimate,
1
N
∑
N
n=1
f(x
n
)where
x
n
∼π(x), has problematically high variance (Hesterberg,
1988; Wolpert, 1991).  Given a proposalq(x)from which
we can sample and for which we can evaluate the data, it
forms the following estimate
μ
:
=E
π(x)
[
f(x)
]
=
∫
f(x)
π(x)
q(x)
q(x)dx(1)
≈ˆμ
:
=
1
N
∑
N
n=1
f(x
n
)w
n
(2)
wherex
n
∼q(x)andw
n
:
=π(x
n
)/q(x
n
)is known as the
importance weight of samplex
n
.
In practice, one often does not have access to the normal-
ized form ofπ(x). For example, in Bayesian inference set-
tings, we typically haveπ(x)  =p(x|y)∝p(x,y).  Here
we can use our samples to both approximate the normal-
ization  constant  and  the  unnormalized  integral.   Thus  if
π(x)∝γ(x), we have
E
π(x)
[f(x)] =
∫
f(x)γ(x)
q(x)
q(x)dx
∫
γ(x)
q(x)
q(x)dx
≈
∑
N
n=1
f(x
n
)w
n
∑
N
n=1
w
n
(3)
wherex
n
∼q(x),  andw
n
:
=γ(x
n
)/q(x
n
).   This  ap-
proach is known as self-normalized importance sampling
(SNIS). Conveniently, we can also construct the SNIS esti-
mate lazily by calculating the empirical measure, i.e.  stor-
ing weighted samples,
π(x)≈
∑
N
n=1
w
n
δ
x
n
(x)
/
∑
N
n=1
w
n
(4)
and then using this to construct the estimate in (3) when
f(x)becomes  available.   As  such,  we  can  also  think  of
SNIS  as  a  method  for  Bayesian  inference  as,  informally
speaking, the empirical measure produced can be thought
of as an approximation of the posterior.
For a general unknown target, the optimal proposal, i.e. the
proposal  which  results  in  estimator  having  lowest  possi-
ble  variance,  is  the  target  distributionq(x)  =π(x)(see
e.g. (Rainforth, 2017,  5.3.2.2)).   However,  this no longer
holds  if  we  have  some  information  aboutf(x).   In  this
target-aware scenario, the optimal behavior turns out to de-
pend on whether we are self-normalizing or not.
For the non-self-normalized case, the optimal proposal can
be shown to beq
∗
(x)∝π(x)|f(x)|(Owen, 2013). Interest-
ingly, in the case wheref(x)≥0∀x, this leads to an exact
estimator, i.e.ˆμ=μ(withˆμas per (2)). To see this, notice
that the normalizing constant forq
∗
(x)is
∫
π(x)f(x) dx=
μand henceq
∗
(x) =π(x)f(x)/μ.  Therefore, even when
N= 1, any possible value of the resulting samplex
1
yields
anˆμsatisfyingˆμ=f(x
1
)π(x
1
)/q
∗
(x
1
) =μ.
In the self-normalized case,  the optimal proposal instead
transpires to beq
∗
(x)∝π(x)|f(x)−μ|(Hesterberg, 1988).
In this case, one can no longer achieve a zero variance es-
timator  for  finiteNand  nonconstantf(x).   Instead,  the
achievable error is lower bounded by (Owen, 2013)
E[(ˆμ−μ)
2
]≥
1
N
(
E
π(x)
[|f(x)−μ|]
)
2
,(5)
creating a fundamental limit on the performance of SNIS,
even when information aboutf(x)is incorporated.
Given that these optimal proposals make use of the true ex-
pectationμ, we will clearly not have access to them in prac-
tice. However, they provide a guide for the desirable prop-
erties of a proposal and can be used as targets for adaptive
IS methods (see (Bugallo et al., 2017) for a recent review).
2.2. Inference Amortization
Inference  amortization  involves  learning  anamortization
artifactthat takes in datasets and produces proposals tai-
lored to the corresponding inference problems. This amor-
tization artifact typically takes the form of a parametrized
proposal,q(x;φ(y;η)), which takes in datayand produces
proposal  parameters  using  aninference  networkφ(y;η),
which itself has parametersη.  When clear from the con-
text, we will use the shorthandq(x;y,η)for this proposal.
Though the exact process varies with context, the inference
network  is  usually  trained  either  by  drawing  latent-data
sample pairs from the jointp(x,y)(Paige & Wood, 2016;

Amortized Monte Carlo Integration
Le et al., 2017; 2018b), or by drawing mini-batches from
a  large  dataset  using  stochastic  variational  inference  ap-
proaches (Hoffman et al., 2013; Kingma & Welling, 2014;
Rezende et al., 2014; Ritchie et al., 2016).  Once trained,
it provides an efficient means of approximately sampling
from the posterior of a particular dataset, e.g. using SNIS.
Out  of  several  variants,  we  focus  on  the  method  intro-
duced by Paige & Wood (2016), as this is the one AMCI
builds upon. In their approach,ηis trained to minimize the
expectation  ofD
KL
[
p(x|y)||q(x;y,η)
]
across  possible
datasetsy, giving the objective
J(η) =E
p(y)
[
D
KL
[
p(x|y)||q(x;y,η)
]
]
=E
p(x,y)
[
−logq(x;y,η)
]
+const wrtη(6)
We note that the distributionp(y)over which we are taking
the expectation is actually chosen somewhat arbitrarily:  it
simply dictates how much the network prioritizes a good
amortization for one dataset over another; different choices
are equally valid and imply different loss functions.
This  objective  requires  us  to  be  able  to  sample  from  the
joint distributionp(x,y)and it can be optimized using gra-
dient methods since the gradient can be easily evaluated:
∇
η
J(η) =E
p(x,y)
[
−∇
η
logq(x;y,η)
]
.(7)
3. AMCI
Amortized  Monte  Carlo  integration  (AMCI)  is  a  frame-
work  for  amortizing  the  cost  of  calculating  expectations
μ(y,θ)
:
=E
π(x;y)
[f(x;θ)].   Hereyrepresents  change-
able aspects of the reference distributionπ(x;y)(e.g.  the
dataset) andθrepresents changeable parameters of the tar-
get functionf(x;θ). The reference distribution is typically
known only up to a normalization constant, i.e.π(x;y) =
γ(x;y)/Zwhereγ(x;y)can be evaluated pointwise,  but
Zis unknown.  AMCI can still be useful in settings where
Zis known, but here we can simply use its known value
rather than constructing a separate estimator.
Amortization can be performed acrossyand/orθ.  When
amortizing overy, the function does not need to be explic-
itly parameterized;  we just need to be able to evaluate it
pointwise.   Similarly,  when  amortizing  overθ,  the  refer-
ence distribution can be fixed.  In fact, AMCI can be used
for  a  parameterized  set  of  conventional  integration  prob-
lems
∫
x∈X
f(x;θ)dxby exploiting the fact that
∫
x∈X
f(x;θ)dx=E
π(x)
[f(x;θ)/π(x)](8)
for anyπ(x)whereπ(x)6= 0∀x∈Xfor whichf(x)6= 0.
For  consistency  of  notation  with  the  amortized  inference
literature, we will presume a Bayesian setting in the rest of
this section, i.e.π(x;y) =p(x|y)andγ(x;y) =p(x,y).
3.1. Estimator
Existing  amortized  inference methods  implicitly  evaluate
expectations  using  SNIS  (or  some  other  form  of  self-
normalized  estimator  (Paige  &  Wood,  2016;  Le  et  al.,
2018a)),  targeting  the  posterior  as  the  optimal  proposal
q
∗
(x;y)≈p(x|y).  Not only is this proposal suboptimal
when  information  about  the  target  function  is  available,
there is a lower bound on the accuracy the SNIS approach
itself can achieve as shown in (5).
AMCI overcomes these limitations by breaking down the
overall  expectation  into  separate  components  and  con-
structing separate estimates for each.   We can first break
down  the  target  expectation  into  the  ratio  of  the  “unnor-
malized expectation” and the normalization constant:
μ(y,θ)
:
=E
p(x|y)
[
f(x;θ)
]
=
E
p(x|y)
[
f(x;θ)p(y)
]
E
p(x)
[
p(y|x)
]
=
E
q
1
(x;y,θ)
[
f(x;θ)p(x,y)
q
1
(x;y,θ)
]
E
q
2
(x;y)
[
p(x,y)
q
2
(x;y)
]
=
:
E
1
E
2
(9)
whereq
1
(x;y,θ)andq
2
(x;y)are two separate proposals,
used respectively for each of the two expectationsE
1
and
E
2
.  We note that the proposalq
1
(x;y,θ)may depend not
only on the observed datasety, but also on the parameters
of the target functionθ.
We can now generate separate MC estimates forE
1
and
E
2
, and take their ratio to estimate the overall expectation:
μ(y,θ)≈ˆμ(y,θ)
:
=
ˆ
E
1
/
ˆ
E
2
where
ˆ
E
1
:
=
1
N
N
∑
n=1
f(x
′
n
;θ)p(x
′
n
,y)
q
1
(x
′
n
;y,θ)
x
′
n
∼q
1
(x;y,θ)
ˆ
E
2
:
=
1
M
M
∑
m=1
p(x
m
,y)
q
2
(x
m
;y)
x
m
∼q
2
(x;y).
(10)
The key idea behind AMCI is that we can nowseparately
train each of these proposals to be good estimators for
their respective expectation, rather than rely on a single
proposal to estimate both, as is implicitly the case for SNIS.
Consider,  for  example,  the  case  wheref(x;θ)≥0.   If
q
1
(x;y,θ)∝f(x;θ)p(x|y)andq
2
(x;y)∝p(x|y)then
both
ˆ
E
1
and
ˆ
E
2
will  form  exact  estimators  (as  per  Sec-
tion 2.1), even ifN=M= 1. Consequently, we achieve an
exact  estimator  forμ(y,θ),  allowing  for  arbitrarily  large
improvements  over  any  SNIS  estimator,  because  SNIS
forcesq
1
(x;y,θ)andq
2
(x;y)to be the same distribution.
More  generally,  the  optimal  proposal  forE
1
andE
2
are
q
1
(x;y,θ)∝|f(x;θ)|p(x|y)andq
2
(x;y)∝p(x|y)respec-
tively, with the latter always resulting in an exact estimator
forE
2
.  Thus the more|f(x;θ)|p(x|y)varies fromp(x|y),
the  worse  the  conventional  approach  of  only  amortizing

Amortized Monte Carlo Integration
the posterior will perform, while the harder it becomes to
construct  a  reasonable  SNIS  estimator  even  when  infor-
mation aboutf(x;θ)is incorporated.  Separately learning
q
1
(x;y,θ)andq
2
(x;y)means that each will become a bet-
ter individual proposal and the overall estimator improves.
It turns out that we do not actually require the previous as-
sumption off(x;θ)≥0∀x,θto achieve a zero variance
estimator. Specifically, if we let
1
f
+
(x;θ) = max(f(x;θ),0)and(11)
f
−
(x;θ) =−min(f(x;θ),0)(12)
denote  truncations  of  the  target  function  into  its  positive
and negative components (as per the concept of posiviti-
sation (Owen, 2013,  9.13)),  then we can break down the
overall expectation as follows
μ(y,θ)
=
E
q
+
1
(x;y,θ)
[
f
+
(x;θ)p(x,y)
q
+
1
(x;y,θ)
]
−E
q
−
1
(x;y,θ)
[
f
−
(x;θ)p(x,y)
q
−
1
(x;y,θ)
]
E
q
2
(x;y)
[
p(x,y)
q
2
(x;y)
]
=
:
E
+
1
−E
−
1
E
2
(13)
where we now have three expectations and three proposals.
Analogously to (10), we can construct estimates for each
expectation separately and then combine them:
μ(y,θ)≈ˆμ(y,θ)
:
= (
ˆ
E
+
1
−
ˆ
E
−
1
)/
ˆ
E
2
where
ˆ
E
+
1
:
=
1
N
N
∑
n=1
f
+
(x
+
n
;θ)p(x
+
n
,y)
q
+
1
(x
+
n
;y,θ)
x
+
n
∼q
+
1
(x;y,θ)
ˆ
E
−
1
:
=
1
K
K
∑
k=1
f
−
(x
−
k
;θ)p(x
−
k
,y)
q
−
1
(x
−
k
;y,θ)
x
−
k
∼q
−
1
(x;y,θ)
ˆ
E
2
:
=
1
M
M
∑
m=1
p(x
m
,y)
q
2
(x
m
;y)
x
m
∼q
2
(x;y),(14)
which forms the AMCI estimator. The theoretical capabil-
ity of this estimator is summarized in the following result,
the proof for which is given in Appendix B.
Theorem 1.If the following hold for a givenθandy,
E
p(x)
[
f
+
(x;θ)p(y|x)
]
<∞(15)
E
p(x)
[
f
−
(x;θ)p(y|x)
]
<∞(16)
E
p(x)
[
p(y|x)
]
<∞(17)
and   we   use   the   corresponding   set   of   optimal   pro-
posalsq
+
1
(x;y,θ)∝f
+
(x;θ)p(x,y),q
−
1
(x;y,θ)∝
f
−
(x;θ)p(x,y),  andq
2
(x;y)∝p(x,y),  then the AMCI
1
Practically,  it  may  sometimes  be  beneficial  to  truncate  the
proposal  about  another  point,c,  by  instead  usingf
+
(x;θ) =
max(f(x;θ)−c,0)andf
−
(x;θ) =−min(f(x;θ)−c,0), then
addingconto our final estimate.
estimator defined in(14)satisfies
E
[
ˆμ(y,θ)
]
=μ(y,θ),Var
[
ˆμ(y,θ)
]
= 0(18)
for anyN≥1,K≥1, andM≥1, such that it forms an
exact estimator for thatθ,ypair.
Though our primary motivation for developing the AMCI
estimator is its attractive properties in an amortization set-
ting, we note that it may still be of use in static expectation
calculation settings. Namely, the fact that it can achieve an
arbitrarily low mean squared error for a given number of
samples  means  it  forms  an  attractive  alternative  to  SNIS
more  generally,  particularly  when  we  are  well-placed  to
hand-craft highly effective proposals and in adaptive im-
portance sampling settings.
We note that individual elements of this estimator have pre-
viously appeared in the literature. For example, the general
concept of using multiple proposals has been established
in  the  context  of  multiple  importance  sampling  (Veach
&  Guibas,  1995).The  use  of  two  separate  proposals
for the unnormalized target and the normalizing constant
(i.e. (10)), on the other hand, was recently independently
suggested by Lamberti et al. (2018) in a non-amortized set-
ting.  However,  we believe that the complete form of the
AMCI estimator in (14) has not previously been suggested,
nor its theoretical benefits or amortization considered.
3.2. Amortization
To evaluate (14), we need to learn three amortized propos-
alsq
+
1
(x;y,θ),q
−
1
(x;y,θ), andq
2
(x;y).
Learningq
2
(x;y)is  equivalent  to  the  standard  inference
amortization problem and so we will just use the objective
given by (6), as described in section 2.2.
The approaches for learningq
+
1
(x;y,θ)andq
−
1
(x;y,θ)are
equivalent, other than the function that is used in the esti-
mators. Therefore, for simplicity, we introduce our amorti-
zation procedure in the case wheref(x;θ)≥0∀x,θ, such
that we can need only learn a single proposal,q
1
(x;y,θ),
for the numerator as per (10).  This trivially extends to the
full AMCI setup by separately repeating the same training
procedure forq
+
1
(x;y,θ)andq
−
1
(x;y,θ).
3.2.1. FIXED FUNCTIONf(x)
We first consider the scenario wheref(x)is fixed (i.e.  we
are not amortizing over function parametersθ) and hence
in this section we drop the dependence ofq
1
onθ.
To learn the parametersηfor the first amortized proposal
q
1
(x;y,η),  we  need  to  adjust  the  target  in  (6)  to  incor-
porate  the  effect  of  the  target  function.    LetE
1
(y)
:
=
E
p(x)
[
f(x)p(y|x)
]
andg(x|y)
:
=
f(x)p(x,y)
E
1
(y)
, i.e. the nor-
malized  optimal  proposal  forq
1
.    Naively  adjusting  (6)

Amortized Monte Carlo Integration
leads to a double intractable objective
J
′
1
(η) =E
p(y)
[D
KL
(
g(x|y)||q
1
(x;y,η)
)
]
=E
p(y)
[
−
∫
X
f(x)p(x,y)
E
1
(y)
logq
1
(x;y,η) dx
]
+const wrtη.
(19)
Here the double intractability comes from the fact we do
not knowE
1
(y)and, at least at the beginning of the training
process, we cannot estimate it efficiently either.
To address this, we use our previous observation that the
expectation  overp(y)in  the  above  objective  is  chosen
somewhat arbitrarily.  Namely, it dictates the relative pri-
ority of different datasetsyduring training and not the op-
timal proposal for each individual datapoint; disregarding
the finite capacity of the network,  the global optimum is
still alwaysD
KL
[
g(x|y)||q
1
(x;y,η)
]
= 0,∀y.   We thus
maintain a well-defined objective if we choose a different
reference distribution over datasets. In particular, if we take
the expectation with respect toh(y)∝p(y)E
1
(y), we get
J
1
(η) =E
h(y)
[
D
KL
(
g(x|y)||q
1
(x;y,η)
)
]
=c
−1
E
p(x,y)
[
−f(x) logq
1
(x;y,η)
]
+const wrtη
(20)
wherec=E
p(y)
[
E
1
(y)
]
>0is a positive constant that
does  not  affect  the  optimization—it  is  the  normalization
constant for the distributionh(y)—and can thus be ignored.
Each term in this expectation can now be evaluated directly,
meaning we can again run stochastic gradient descent algo-
rithms to optimize it. Note that this does not require evalua-
tion of the densityp(x,y), only the ability to draw samples.
Interestingly, this choice ofh(y)can be interpreted as giv-
ing larger importance to the values ofywhich yield larger
E
1
(y).  Informally, we could think about this choice as at-
tempting to minimizing the L1 errors of our estimates, that
isE
p(y)
[|E
1
(y)−
ˆ
E
1
(y)|], presuming that the error in our
estimation scales as the magnitude of the true valueE
1
(y).
More generally,  if we chooseh(y)∝p(y)E
1
(y)λ(y)for
some positive evaluable functionλ
:
Y →R
+
, we get a
tractable objective of the form
J
1
(η;λ) =E
p(x,y)
[
−
f(x)
λ(y)
logq
1
(x;y,η)
]
up to a constant scaling factor and offset.  We can thus use
this trick to adjust the relative preference given to different
datasets, while ensuring the objective is tractable.
3.2.2. PARAMETERIZED FUNCTIONf(x;θ)
As previously mentioned, AMCI also allows for amortiza-
tion  over  parametrized  functions,  to  account  for  cases  in
which multiple possible target functions may be of inter-
est. We can incorporate this by usingpseudo priorp(θ)to
generate example parameters during our training.
Analogously toh(y),  the choice ofp(θ)determines how
much importance we assign to different possible functions
that  we  would  like  to  amortize  over.   Since,  in  practice,
perfect  performance  is  unattainable  over  the  entire  space
ofθ,  the  choice  ofp(θ)is  important  and  it  will  have  an
important effect on the performance of the system.
Incorporatingp(θ)is  straightforward:   we  take  the  ex-
pectation  of  the  fixed  target  function  training  objective
overθ.    In  this  setting,  our  inference  networkφneeds
to  takeθas  input  when  determining  the  parameters  of
q
1
and  hence  we  letq
1
(x;y,θ,η)
:
=q
1
(x;φ(y,θ;η)).
IfE
1
(y,θ)
:
=E
p(x)
[
f(x;θ)p(y|x)
]
,g(x|y;θ)
:
=
f(x;θ)p(x,y)/E
1
(y,θ), andh(y,θ)∝p(y)p(θ)E
1
(y,θ),
we get an objective which is analogous to (20):
J
1
(η) =E
h(y,θ)
[
D
KL
(
g(x|y;θ)||q
1
(x;y,θ,η)
)
]
=c
−1
·E
p(x,y)p(θ)
[
−f(x;θ) logq
1
(x;y,θ,η)
]
+const wrtη
(21)
wherec=E
p(y)p(θ)
[
E
1
(y,θ)
]
>0is again a positive con-
stant that does not affect the optimization.
3.3. Efficient Training
Iff(x;θ)andp(x)p(θ)are mismatched, i.e.f(x;θ)is large
in regions wherep(x)p(θ)is low, training by na
 ̈
ıvely sam-
pling fromp(x)p(θ)can be inefficient. Instead, it is prefer-
able  to  try  and  sample  fromg(θ,x)∝p(x)p(θ)f(x;θ).
Though this is itself an intractable distribution, it represents
a standard, rather than an amortized, inference problem and
so it is much more manageable than the overall training.
Namely, as the samples do not depend on the proposal we
are learning or the datasets, we can carry out this inference
process as a pre-training step that is substantially less costly
than the problem of training the inference networks itself.
One approach is to construct an MCMC sampler targeting
g(θ,x)to generate the samples, which can be done upfront
before training. Another is to use an importance sampler
J
1
(η) =const wrtη(22)
+c
−1
E
q
′
(θ,x)p(y|x)
[
−
p(θ)p(x)f(x;θ)
q
′
(θ,x)
logq
1
(x;y,θ,η)
]
whereq
′
(θ,x)is a proposal as close tog(θ,x)as possible.
In the case of non-parameterized functionsf(x), there is
no need to take an expectation overp(θ), and we instead
desire to sample fromg(x)∝p(x)f(x).
4. Experiments
Even though AMCI is theoretically able to achieve exact
estimators with a finite number of samples, this will rarely
be the case for practical problems, for which learning per-

Amortized Monte Carlo Integration
10
1
10
2
10
3
10
4
Number of samplesN
10
−4
10
−1
10
2
10
5
ReMSE
AMCI
SNISq
2
SNISq
m
SNIS bound
(a) One-dimensional tail integral
10
1
10
2
10
3
10
4
Number of samplesN
10
−3
10
−1
10
1
ReMSE
(b) Five-dimensional tail integral
Figure 1:  Relative mean squared errors (as per (25)) for [left] the one-dimensional and [right] the five-dimensional tail
integral example.  The solid lines for each estimator indicate the median ofδ(y,θ)estimated using a common set of100
samples fromy,θ∼p(y)p(θ), with the correspondingδ(y,θ)then each separately estimated using100samples of the
respective
ˆ
δ(y,θ).  The shading instead shows the estimates from replacingδ(y,θ)with the25%and75%quantiles of
ˆ
δ(y,θ)for a givenyandθ.  The median ofδ(y,θ)is at times outside of this shaded region asδ(y,θ)is often dominated
by a few large outliers. The dashed line shows the median ofδ(y,θ)with theδ(y,θ)corresponding to the ReMSE optimal
SNIS estimator, namely(E
p(x|y)
[|f(x;θ)−μ(y,θ)|])
2
/Nas per (5), which is itself estimated (with only nominal error)
using10
6
samples.  We note that the error for SNIS withq
2
proposal is to a large extent flat because there is not a single
sample in the estimator for whichf(x;θ)>0, such that they returnˆμ(y,θ) = 0and hence giveδ(y,θ) = 1.  In Figure
(b) the SNISq
m
line reaches the ReMSE value of10
18
atN=2and the y-axis limits have been readjusted to allow clear
comparison at higherN. This effect is caused by the bias of SNIS: these extremely high errors for SNISq
m
arise when all
Nsamples happen to be drawn from distributionq
1
, for further explanation and the full picture see Figure 5 in Appendix A.
fect proposals is not typically realistic, particularly in amor-
tized contexts (Cremer et al., 2018).  It is therefore neces-
sary to test its empirical performance to assert that gains are
possible with inexact proposals. To this end, we investigate
AMCI’s performance on two illustrative examples.
Our primary baseline is the SNIS approach implicitly used
by most existing inference amortization methods, namely
the  SNIS  estimator  with  proposalq
2
(x;y).   Though  this
effectively represents the previous state-of-the-art in amor-
tized expectation calculation, it turns out to be a very weak
baseline. We, therefore, introduce another simple approach
one could hypothetically consider using:  training separate
proposals as per AMCI, but then using this to form a mix-
ture distribution proposal for an SNIS estimator. For exam-
ple, in the scenario wheref(x;θ)≥0∀x,θ(such that we
only need to learn two proposals), we can use
q
m
(x;y,θ) =
1
2
q
1
(x;y,θ) +
1
2
q
2
(x;y)(23)
as an SNIS proposal that takes into account the needs of
bothE
1
andE
2
.  We refer to this method as themixture
SNIS  estimator  and  emphasize  that  it  represents  a  novel
amortization approach in its own right.
We also compare AMCI to the theoretically optimal SNIS
estimator,  i.e.   the error bound given by (5).   As we will
show,  AMCI is often able to empirically outperform this
bound,  thereby  giving  better  performance  thananyap-
proach based on SNIS, whether that approach is amortized
or not. This is an important result and, it particular, it high-
lights that the potential significance of the AMCI estimator
extends beyond the amortized setting we consider here.
We further consider using SNIS with proposalq
1
(x;y,θ).
However,   this  transpires  to  perform  extremely  poorly
throughout (far worse thanq
2
(x;y)) and so we omit its re-
sults from the main paper, giving them in Appendix A.
In all experiments, we use the same number of sample from
each proposal to form the estimate (i.e.N=M=K).
An implementation for AMCI and our experiments is avail-
able at  http://github.com/talesa/amci.
4.1. Tail Integral Calculation
We start with the conceptually simple problem of calculat-
ing tail integrals for Gaussian distributions, namely
p(x) =N(x; 0,Σ
1
)p(y|x) =N(y;x,Σ
2
)(24)
f(x;θ) =
∏
D
i=1
1
x
i
>θ
i
p(θ) =UNIFORM(θ; [0,u
D
]
D
)
whereDis the dimensionality, we setΣ
2
=I, andΣ
1
is a
fixed covariance matrix (for details see Appendix C).
This  problem  was  chosen  because  it  permits  easy  calcu-
lation  of  the  ground  truth  expectations  by  exploiting  an-
alytic  simplifications,  while  remaining  numerically  chal-
lenging for values ofθfar away from the mean when we
do  not  use  these  simplifications.   We  performed  one  and

Amortized Monte Carlo Integration
five-dimensional variants of the experiment.
We use normalizing flows (Rezende & Mohamed, 2015) to
construct our proposals, providing a flexible and powerful
means of representing the target distributions.  Details are
given in Appendix C. Training was done by using impor-
tance sampling to generate the values ofθandxas per (22)
withq
′
(θ,x) =p(θ)·HALFNORMAL(x;θ,diag(Σ
2
)).
To  evaluate  AMCI  and  our  baselines  we  use  the  relative
mean squared error (ReMSE)δ(y,θ) =E
[
ˆ
δ(y,θ)
]
, where
ˆ
δ(y,θ) =
(
μ(y,θ)−ˆμ(y,θ)
)
2
μ(y,θ)
2
(25)
andˆμ(y,θ)is our estimate forμ(y,θ).  We then consider
summary statistics across different{y,θ}, such as its me-
dian wheny,θ∼p(y)p(θ).
2
In calculating this,δ(y,θ)was
separately estimated for each value ofyandθusing100
samples of
ˆ
δ(y,θ)(i.e.100realizations of the estimator).
As  shown  in  Figure  1,   AMCI  outperformed  SNIS  in
both  the  one-  and  five-dimensional  cases.   For  the  one-
dimensional example, AMCI significantly outperformed all
of SNISq
2
, SNISq
m
, and the theoretically optimal SNIS
estimator.  SNISq
2
, the approach implicitly taken by ex-
isting  inference  amortization  methods,  typically  failed  to
place even a single sample in the tail of the distribution,
even for largeN.  Interestingly, SNISq
m
closely matched
the theoretical SNIS bound, suggesting that this amortized
proposal  is  very  close  to  the  theoretically  optimal  one.
However,  this still constituted significantly worse perfor-
mance  than  AMCI—taking  about10
3
more  samples  to
achieve the same relative error—demonstrating the ability
of AMCI to outperform the best possible SNIS estimator.
For  the  five-dimensional  example,  AMCI  again  signifi-
cantly outperformed our main baseline SNISq
2
.  Though
it still also outperformed SNISq
m
, its advantage was less
than in one-dimensional case, and it did not outperform the
SNIS theoretical bound.  SNISq
m
itself did not match the
bound as closely as in the one-dimensional example either,
suggesting that the proposals learned were worse than in
the one-dimensional case.  Further comparisons based on
using the mean squared error (instead of ReMSE) are given
in Appendix A and show qualitatively similar behavior.
4.2. Planning Cancer Treatment
To demonstrate how AMCI might be used in a more real-
world  scenario,  we  now  consider  an  illustrative  example
relating to cancer diagnostic decisions. Imagine that an on-
cologist is trying to decide whether to administer a treat-
ment to a cancer patient.  Because the treatment is highly
invasive, they only want to administer it if there is a realis-
2
Variability inδ(y,θ)between different instances of{y,θ}is
considered in Figures 7 and 8 in Appendix A.
10
1
10
2
10
3
10
4
Number of samplesN
10
−4
10
−2
10
0
10
2
ReMSE
AMCI
SNISq
2
SNISq
m
SNIS bound
Figure 2:  Relative mean squared errors for the cancer ex-
ample. Conventions as per Figure 1. It is worth noting that
it took about10
4
more samples for the SNISq
2
estimator to
achieve the same level of accuracy as the AMCI estimator.
tic chance of it being successful, i.e. that the tumor shrinks
sufficiently  to  allow  a  future  operation  to  be  carried  out.
However,  they  are  only  able  to  make  noisy  observations
about the current size of the tumor, and there are various
unknown parameters pertaining to its growth, such as the
patients predisposition to the treatment.  To aid in the on-
cologists decision, the clinic provides a simulator of tumor
evolution,  a  model  of  the  latent  factors  required  for  this
simulator, and a loss function for administering the treat-
ment given the final tumor size.  We wish to construct an
amortization of this simulator, so that we can quickly and
directly predict the expected loss function for administering
the treatment from a pair of noisy observations of the tumor
size taken at separate points in time. A detailed description
of the model and proposal setup is in the Appendix C.3.
To  evaluate  the  learned  proposals  we  followed  the  same
procedure as for the tail integral example.  Results are pre-
sented in Figure 2. AMCI again significantly outperformed
the literature baseline of SNISq
2
—it took aboutN= 10
4
samples for SNISq
2
to achieve the level of relative error
of AMCI forN= 2.  AMCI further maintained an advan-
tage over SNISq
m
, which itself again closely matched the
optimal SNIS estimator.  Further comparisons are given in
Appendix A and show qualitatively similar behavior.
5. Discussion
In all experiments AMCI performed better than SNIS with
eitherq
2
orq
m
for its proposal.  Moreover, it is clear that
AMCI is indeed able to break the theoretical bound on the
achievable performance of SNIS estimators: in some cases
AMCI  is  outperforming  the  best  achievable  error  by  any
SNIS estimator, regardless of the proposal the latter uses.
Interestingly, the mixture SNIS estimator we also introduce
proved to be a strong baseline as it closely matched the the-
oretical baseline in both experiments.   However,  such an
effective mixture proposal is only possible thanks learning
the  multiple  inference  artifacts  we  suggest  as  part  of  the

Amortized Monte Carlo Integration
AMCI framework,  while its performance was still gener-
ally inferior to AMCI itself.
We now consider the question of when we expect AMCI to
work particularly well compared to SNIS, and the scenar-
ios where it is less beneficial, or potentially even harmful.
We  first  note  that  scaling  with  increasing  dimensionality
is  a  challenge  for  both  because  the  importance  sampling
upon which they rely suffers from the curse of dimension-
ality.  However, the scaling of AMCI should be no worse
than existing amortization approaches as each of the amor-
tized proposals is trained in isolation and corresponds to a
conventional inference amortization.
We  can  gain  more  insights  into  the  relative  performance
of the two approaches in different settings using an infor-
mal asymptotic analysis in the limit of a large number of
samples. Assumingf(x;θ)≥0∀x,θfor simplicity,
3
then
both AMCI and SNIS can be expressed in the form of (10),
where for SNIS we setq
1
(x;y,θ) =q
2
(x;y),N=M, and
share samples between the estimators. Separately applying
the central limit theorem to
ˆ
E
1
and
ˆ
E
2
yields
ˆμ(y,θ) =
ˆ
E
1
ˆ
E
2
→
E
1
+σ
1
ξ
1
E
2
+σ
2
ξ
2
,asN,M→∞(26)
whereξ
1
,ξ
2
∼N(0,1)and
σ
1
:
=
1
N
Var
q
1
(x;y,θ)
[
f(x;θ)p(x,y)
q
1
(x;y,θ)
]
,(27)
σ
2
:
=
1
M
Var
q
2
(x;y)
[
p(x,y)
q
2
(x;y)
]
.(28)
Asymptotically, the mean squared error ofˆμ(y,θ)is dom-
inated by its variance.  Thus, by taking a first order Taylor
expansion of Var[ˆμ(y,θ)]about1/E
2
, we get, for largeM,
E
[
(
ˆμ(y,θ)−μ(y,θ)
)
2
]
≈
1
E
2
2
(
σ
2
1
+σ
2
2
μ(y,θ)
2
−2μ(y,θ)σ
1
σ
2
Corr[ξ
1
,ξ
2
]
)
=
σ
2
2
E
2
2
(
(κ−Corr[ξ
1
,ξ
2
])
2
+ 1−Corr[ξ
1
,ξ
2
]
2
)
(29)
where  the  approximation  from  the  Taylor  expansion  be-
comes exact in the limitM→∞andκ
:
=σ
1
/(μ(y,θ)σ
2
)
is a measure of the relative accuracy of the two estimators.
See (43) in Appendix D.1 for a more verbose derivation.
For a given value ofσ
2
, the value ofκfor SNIS is com-
pleted dictated by the problem:  in general, the larger the
mismatch betweenf(x;θ)p(x,y)andp(x,y), the largerκ
will be.  This yields the expected result that the errors for
SNIS become large in this setting. For AMCI, we can con-
trolκthrough ensuring a good proposal for both
ˆ
E
1
and
ˆ
E
2
,  and,  if desired,  by adjustingMandN(relative to a
3
The results trivially generalize to generalf(x)with suitable
adjustment of the definition ofσ
1
.
Test
f(x;θ)p(x|y)
p(x|y)
θ
q
1
(x;y,θ)
q
2
(x;y)
10
−4
10
−1
10
2
Test
AMCI
SNISq
2
10
−3
10
−1
10
1
Test
−5.0−2.50.02.55.0
x
10
1
10
2
10
3
10
4
Number of samplesN
10
−4
10
−1
10
2
0.000.250.500.751.00
α
10
−3
10
−1
10
1
Density
ReMSE
AMCI ReMSE
Figure  3:   Results  for  the  one-dimensional  tail  integral
model  in  a  setting  with  large  mismatch  [top]  and  low
mismatch  [bottom],  with(y,θ),  respectively(1,3)and
(3,0.1).  The left column illustrates the shape of the pro-
posalq
1
and the achievable quality of fit tof(x;θ)p(x|y),
we see that AMCI is able to learn very accurate proposals
in both cases. The right column compares the performance
of the AMCI and the SNIS estimators where we see that the
gain for AMCI is much larger when the mismatch is large.
Uncertainty bands in column two are estimated over a 1000
runs and are almost imperceptibly small.
fixed budgetM+N). Consequently, we can achieve better
errors than SNIS by drivingκdown.
On the other hand,  asf(x;θ)p(x,y)andp(x,y)become
increasingly well matched,  thenκ→1and we find that
AMCI  has  little  to  gain  over  SNIS.  In  fact,  we  see  that
AMCI can potentially be worse than SNIS in this setting:
whenf(x;θ)p(x,y)andp(x,y)are closely matched,  we
also  have  Corr[ξ
1
,ξ
2
]
2
≈1for  SNIS,  such  that  we  ob-
serve a canceling effect, potentially leading to very low er-
rors. Achieving Corr[ξ
1
,ξ
2
]
2
≈1can be more difficult for
AMCI, potentially giving rise to a higher error.  However,
it could be possible to mitigate this by correlating the esti-
mates, e.g. through common random numbers.
To assess if this theory manifests in practice, we revisit our
tail integral example, comparing large and small mismatch
scenarios. The results, shown in Figure 3, agree with these
theoretical  findings.   In  Appendix  D  we  further  showing
that the reusing of samples for both
ˆ
E
1
and
ˆ
E
2
in AMCI
can be beneficial when the targets are well matched.
More generally, as Theorem 1 tells us that the AMCI es-
timator can achieve an arbitrarily low error for any given
target function,  while SNIS cannot,  we know that its po-
tential  gains  are  larger  the  more  accurate  we  are  able  to
make  our  proposals.   As  such,  as  advances  elsewhere  in
the field allow us to produce increasingly effective amor-
tized proposals,  e.g.   through advanced normalizing flow
approaches (Grathwohl et al., 2019; Kingma & Dhariwal,
2018), the larger the potential gains are from using AMCI.

Amortized Monte Carlo Integration
Acknowledgments
We would like to thank Yee Whye Teh for providing help-
ful discussions at the early stages of the project. AG is sup-
ported by the UK EPSRC CDT in Autonomous Intelligent
Machines and Systems. FW is supported by DARPA D3M,
under  Cooperative  Agreement  FA8750-17-2-0093,  Intel
under its LBNL NERSC Big Data Center, and an NSERC
Discovery  grant.   TR  is  supported  by  the  European  Re-
search Council under the European Unions Seventh Frame-
work Programme (FP7/20072013) / ERC grant agreement
no.  617071.  His research leading to these results also re-
ceived funding from EPSRC under grant EP/P026753/1.
References
Bugallo,   M.  F.,   Elvira,   V.,   Martino,   L.,   Luengo,   D.,
Miguez, J., and Djuric, P. M. Adaptive importance sam-
pling: the past, the present, and the future.IEEE Signal
Processing Magazine, 34(4):60–79, 2017.
Chen, M.-H. and Shao, Q.-M. On Monte Carlo methods for
estimating ratios of normalizing constants.The Annals
of Statistics, 25(4):1563–1594, 08 1997.
Cremer, C., Li, X., and Duvenaud, D.  Inference subopti-
mality in variational autoencoders.Proceedings of the
International Conference on Machine Learning (ICML),
2018.
Enderling, H. and Chaplain, M. A. Mathematical modeling
of tumor growth and treatment.Current pharmaceutical
design, 20–30:4934–40, 2014.
Evans, M. and Swartz, T.  Methods for approximating in-
tegrals  in  statistics  with  special  emphasis  on  Bayesian
integration problems.Statistical science, pp. 254–272,
1995.
Gelman, A. and Meng, X.-L.  Simulating normalizing con-
stants: from importance sampling to bridge sampling to
path  sampling.Statistical  Science,  13(2):163–185,  05
1998.
Grathwohl, W., Chen, R. T. Q., Bettencourt, J., Sutskever,
I.,  and  Duvenaud,  D.FFJORD:  free-form  continu-
ous dynamics for scalable reversible generative models.
International  Conference  on  Learning  Representations
(ICLR), 2019.
Hahnfeldt,  P.,  Panigrahy,  D.,  Folkman,  J.,  and Hlatky,  L.
Tumor development under angiogenic signaling.Cancer
Research, 59(19):4770–4775, 1999.
Hesterberg, T. C.Advances in importance sampling.  PhD
thesis, Stanford University, 1988.
Hoffman,  M.  D.,  Blei,  D.  M.,  Wang,  C.,  and  Paisley,  J.
Stochastic  variational  inference.Journal  of  Machine
Learning Research (JMLR), 2013.
Kingma, D. P. and Ba, J.   Adam:  A method for stochas-
tic optimization.International Conference on Learning
Representations (ICLR), 2015.
Kingma,  D.  P.  and  Dhariwal,  P.   Glow:  Generative  flow
with  invertible  1x1  convolutions.Advances  in  Neural
Information Processing Systems (NIPS), 2018.
Kingma, D. P. and Welling, M.  Auto-encoding variational
Bayes.International Conference on Learning Represen-
tations (ICLR), 2014.
Lacoste-Julien, S., Husz
 ́
ar, F., and Ghahramani, Z. Approx-
imate inference for the loss-calibrated Bayesian.Pro-
ceedings of the International Conference on Artificial In-
telligence and Statistics (AISTATS), 2011.
Lamberti, R., Petetin, Y., Septier, F., and Desbouvries, F.
A double proposal normalized importance sampling es-
timator.2018 IEEE Statistical Signal Processing Work-
shop (SSP), pp. 238–242, 2018.
Le, T. A., Baydin, A. G., and Wood, F.  Inference compila-
tion and universal probabilistic programming.Proceed-
ings of the International Conference on Artificial Intelli-
gence and Statistics (AISTATS), 2017.
Le, T. A., Igl, M., Jin, T., Rainforth, T., and Wood, F. Auto-
encoding sequential Monte Carlo.International Confer-
ence on Learning Representations (ICLR), 2018a.
Le,  T.  A.,  Kosiorek,  A.  R.,  Siddharth,  N.,  Teh,  Y.  W.,
and   Wood,   F.Revisiting   reweighted   wake-sleep.
arXiv:1805.10469, 2018b.
Meng, X.-L. and Wong, W. H.   Simulating ratios of nor-
malizing constants via a simple identity:  A theoretical
exploration.Statistica Sinica, 6:831–860, 1996.
Oh, M.-S. and Berger, J. O. Adaptive importance sampling
in Monte Carlo integration.Journal of Statistical Com-
putation and Simulation, 41(3-4):143–168, 1992.
Owen, A. B.Monte Carlo theory, methods and examples.
2013.
Paige, B. and Wood, F.  Inference networks for sequential
Monte  Carlo  in  graphical  models.Proceedings  of  the
International Conference on Machine Learning (ICML),
2016.
Papamakarios,  G.,  Pavlakou,  T.,  and Murray,  I.   Masked
autoregressive flow for density estimation.Advances in
Neural Information Processing Systems (NIPS), 2017.

Amortized Monte Carlo Integration
Rainforth, T.Automating inference, learning, and design
using probabilistic programming. PhD thesis, 2017.
Rainforth, T., Cornish, R., Yang, H., Warrington, A., and
Wood, F. On Nesting Monte Carlo Estimators.Proceed-
ings of the International Conference on Machine Learn-
ing (ICML), 2018a.
Rainforth,  T.,  Zhou,  Y.,  Lu,  X.,  Teh,  Y.  W.,  Wood,  F.,
Yang,  H.,  and  van  de  Meent,  J.-W.Inference  trees:
Adaptive  inference  with  exploration.arXiv  preprint
arXiv:1806.09550, 2018b.
Rezende, D. and Mohamed, S.  Variational inference with
normalizing  flows.Proceedings  of  the  International
Conference on Machine Learning (ICML), 2015.
Rezende, D. J., Mohamed, S., and Wierstra, D.  Stochastic
backpropagation and approximate inference in deep gen-
erative models.Proceedings of the International Confer-
ence on Machine Learning (ICML), 2014.
Ritchie,D.,Horsfall,P.,and    Goodman,N.    D.
Deep  amortized  inference  for  probabilistic  programs.
arXiv:1610.05735, 2016.
Robert, C.The Bayesian choice:  from decision-theoretic
foundations to computational implementation.  Springer
Science & Business Media, 2007.
Robert, C. and Casella, G.Monte Carlo statistical methods.
Springer Science & Business Media, 2013.
Stuhlm
 ̈
uller,  A.,  Taylor,  J.,  and  Goodman,  N.   Learning
stochastic  inverses.Advances  in  Neural  Information
Processing Systems (NIPS), 2013.
Veach, E. and Guibas, L. J. Optimally combining sampling
techniques for Monte Carlo rendering.Proceedings of
the 22nd annual conference on Computer graphics and
interactive techniques, pp. 419–428, 1995.
Webb,  S.,  Goli
 ́
nski,  A.,  Zinkov,  R.,  Siddharth,  N.,  Rain-
forth,  T.,  Teh,  Y.  W.,  and  Wood,  F.Faithful  inver-
sion of generative models for effective amortized infer-
ence.Advances in Neural Information Processing Sys-
tems (NIPS), 2018.
Wolpert, R. L. Monte Carlo integration in Bayesian statisti-
cal analysis.Contemporary Mathematics, 115:101–116,
1991.

Appendices for Amortized Monte Carlo Integration
Adam Goli
 ́
nski*Frank WoodTom Rainforth*
A. Additional Experimental Results
10
1
10
2
10
3
10
4
Number of samplesN
10
−5
10
−2
10
1
10
4
10
7
ReMSE
10
1
10
2
10
3
10
4
Number of samplesN
10
−13
10
−10
10
−7
10
−4
10
−1
MSE
AMCI
SNISq
2
SNISq
1
SNISq
m
SNIS bound
Figure 4: Additional results for one-dimensional tail integral example as per Figure 1a. [left] Relative mean squared errors
(as per (25)).  [right] Mean squared errorE[(μ(y,θ)−ˆμ(y,θ)
2
].  Conventions as per Figure 1.  The results for SNISq
1
indicate that it severely underestimatesE
2
leading to very large errors, especially when the mismatch betweenp(x|y)and
f(x;θ)is as significant as in the tail integral case.
10
1
10
2
10
3
10
4
Number of samplesN
10
−1
10
4
10
9
10
14
10
19
ReMSE
10
1
10
2
10
3
10
4
Number of samplesN
10
−23
10
−21
10
−19
10
−17
MSE
AMCI
SNISq
2
SNISq
1
SNISq
m
SNIS bound
Figure 5: Additional results for five-dimensional tail integral example as per Figure 1b. [left] Relative mean squared errors
(as per (25)).  [right] Mean squared errorE[(μ(y,θ)−ˆμ(y,θ)
2
].  Conventions as per Figure 1.  The y-axis limits for the
MSE have been readjusted to allow clear comparison at higherN.  Note that the SNISq
m
yields MSE of10
−1
atN= 2,
while the SNISq
1
MSE is far away from the range of the plot for allN, giving a MSE of10
−0.9
atN= 2and10
−1.2
at
N= 10
4
, with a shape very similar to the ReMSE for SNISq
1
as per the left plot. The extremely high errors for SNISq
m
at
low values ofNarise in the situation when allNsamples drawn happen to come from distributionq
1
. We believe that the
results presented forq
m
underestimate the value ofδ(y,θ)between aroundN= 6andN= 100, due to the fact that the
estimation process forδ(y,θ), though unbiased, can have a very large skew. ForN≤6there is a good chance of at least
one of the100trials we perform having allNsamples originating from distributionq
1
, such that we generate reasonable
estimates for the very high errors this can induce. ForN≥100the chances of this event occurring drop to below10
−30
,
such that it does not substantially influence the true error.  For6≤N≤100, the chance the event will occur in our100
trials is small, but the influence it has on the overall error is still significantly, meaning it is likely we will underestimate the
error. This effect could be alleviated by Rao-Blackwellizing the choice of the mixture component, but this would induce a
stratified sampling estimate, thereby moving beyond the SNIS framework.

Amortized Monte Carlo Integration
10
1
10
2
10
3
10
4
Number of samplesN
10
−4
10
−2
10
0
10
2
10
4
ReMSE
10
1
10
2
10
3
10
4
Number of samplesN
10
−8
10
−6
10
−4
10
−2
10
0
MSE
AMCI
SNISq
2
SNISq
1
SNISq
m
SNIS bound
Figure 6:  Additional results for cancer example as per Figure 2.  [left] Relative mean squared errors (as per (25)).  [right]
Mean squared errorE[(μ(y,θ)−ˆμ(y,θ)
2
]. Conventions as per Figure 1. Here, the SNISq
1
performs much better than in
the tail integral example because of smaller mismatch betweenp(x|y)andf(x;θ), meaning the estimates forE
2
are more
reasonable. Nonetheless, we see that SNISq
1
still performs worse that even SNISq
2
.
10
1
10
2
10
3
10
4
Number of samplesN
10
−5
10
−3
10
−1
10
1
ReMSE
AMCI
SNISq
2
SNISq
m
SNIS bound
(a) One-dimensional
10
1
10
2
10
3
10
4
Number of samplesN
10
−3
10
−2
10
−1
10
0
10
1
ReMSE
AMCI
SNISq
2
SNISq
m
SNIS bound
(b) Five-dimensional
Figure 7:  Investigation of the variability of the results across datapointsy,θfor [left] the one-dimensional and [right]
the five-dimensional tail integral example.  Unlike previous figures, the shading shows the estimates of the25%and75%
quantiles ofδ(y,θ)estimated using a common set of100samples fromy,θ∼p(y)p(θ), with the correspondingδ(y,θ)
then each separately estimated using100samples of the respective
ˆ
δ(y,θ).  The solid lines for each estimator and the
dashed line remain the same as in previous figures – they indicate the median ofδ(y,θ).  Now the dashed line also has a
shaded area associated with it reflecting the variability in the SNIS bound across datapoints.
10
1
10
2
10
3
10
4
Number of samplesN
10
−4
10
−3
10
−2
10
−1
10
0
10
1
ReMSE
AMCI
SNISq
2
SNISq
m
SNIS bound
Figure 8:  Investigation of the variability of the results across datapointsy,θfor cancer example.   Conventions as per
Figure 7. The fact that the upper quantile of the AMCI error is larger than the upper quantile of the SNISq
m
error suggests
that there are datapoints for which AMCI yields higher mean squared error than SNISq
m
. However, AMCI is still always
better than the standard baseline, i.e. SNISq
2
.

Amortized Monte Carlo Integration
B. Proof of Theorem 1
Theorem 1.If the following hold for a givenθandy,
E
p(x)
[
f
+
(x;θ)p(y|x)
]
<∞(15)
E
p(x)
[
f
−
(x;θ)p(y|x)
]
<∞(16)
E
p(x)
[
p(y|x)
]
<∞(17)
and we use the corresponding set of optimal proposalsq
+
1
(x;y,θ)∝f
+
(x;θ)p(x,y),q
−
1
(x;y,θ)∝f
−
(x;θ)p(x,y), and
q
2
(x;y)∝p(x,y), then the AMCI estimator defined in(14)satisfies
E
[
ˆμ(y,θ)
]
=μ(y,θ),Var
[
ˆμ(y,θ)
]
= 0(18)
for anyN≥1,K≥1, andM≥1, such that it forms an exact estimator for thatθ,ypair.
Proof.The  result  follows  straightforwardly  from  considering  each  estimator  in  isolation.   Note  that  the  normalization
constants  for  distributionsq
+
1
,q
−
1
,q
2
areE
+
1
,E
−
1
,E
2
,  respectively,  e.g.
∫
f
+
(x
+
;θ)p(x
+
,y) dx
+
=E
+
1
.   Therefore,
starting with
ˆ
E
2
, we have
ˆ
E
2
=
1
M
M
∑
m=1
p(x
m
,y)
q
2
(x
m
;y)
=
1
M
M
∑
m=1
p(x
m
,y)
p(x
m
,y)/E
2
=E
2
(30)
for all possible values ofx
m
. Similarly, for
ˆ
E
+
1
ˆ
E
+
1
=
1
N
N
∑
n=1
p(x
+
n
,y)f
+
(x
+
n
;θ)
q
1
(x
+
n
;y,θ)
=
1
N
N
∑
n=1
p(x
+
n
,y)f
+
(x
+
n
;θ)
p(x
+
n
,y)f
+
(x
+
n
;θ)/E
+
1
=E
+
1
(31)
for all possible values ofx
+
n
. Analogously, we have
ˆ
E
−
1
=E
−
1
for all possible values ofx
−
k
. Combining all of the above,
the result now follows.
C. Experimental details
C.1. One-dimensional tail integral
Let us recall the model from (24),
p(x) =N(x; 0,Σ
1
)p(y|x) =N(y;x,Σ
2
)f(x;θ) =
∏
D
i=1
1
x
i
>θ
i
p(θ) =UNIFORM(θ; [0,u
D
]
D
)
where for the one-dimensional exampleD= 1we usedu
1
= 5andΣ
1
= Σ
2
= 1.
For our parameterized proposalsq
1
(x;y,θ)andq
2
(x;y)we used a normalizing flow consisting of10radial flow layers
(Rezende & Mohamed, 2015) with a standard normal base distribution.  The parameters of each flow were determined by
a neural network taking in the values ofyandθas input, and returning the parameters defining the flow transformations.
Each network comprised of 3 fully connected layers with 1000 hidden units each layer, with relu activation functions.
Training was done by using importance sampling to generate the values ofθandxas per (22) with
q
′
(θ,x) =p(θ)·HALFNORMAL(x;μ=θ,σ= Σ
2
).
and a learning rate of10
−2
with the Adam optimizer Kingma & Ba (2015).
The ground truth values ofμ(y,θ)were determined analytically usingμ(y,θ) =E
p(x|y)
[
f(x;θ)
]
= 1−Φ(θ), whereΦ(·)
is the standard normal cumulative distribution function.
C.2. Five-dimensional tail integral
In the context of the model definition in (24), for the five-dimensional example we usedu
5
= 3,Σ
2
=Iand
Σ
1
=






1.2449    0.2068    0.1635    0.1148    0.0604
0.2068    1.2087    0.1650    0.1158    0.0609
0.1635    0.1650    1.1665    0.1169    0.0615
0.1148    0.1158    0.1169    1.1179    0.0620
0.0604    0.0609    0.0615    0.0620    1.0625






.

Amortized Monte Carlo Integration
In this case, we used a conditional masked autoregressive flow (MAF) (Papamakarios et al., 2017) with standard normal
base distribution as the parameterization of our proposalsq
1
(x;y,θ)andq
2
(x;y). Here the normalizing flows consisted of
16 flow layers with single 1024 hidden units layer within each flow and we used tanh rather than relu activation functions
as we found this made a significant difference in terms of training stability for the distributionq
1
.  We did not find batch
normalization to help the performance or stability significantly, and hence we have not used it.  We used the conditional
MAF implementation from http://github.com/ikostrikov/pytorch-flows.
Training was done using importance sampling to generate the values ofθandxas per (22) with
q
′
(θ,x) =p(θ)·HALFNORMAL(x;μ=θ,σ=diag(Σ
2
)).
We used a learning rate of10
−4
an the Adam optimizer.
The estimates of the ground truth valuesμ(y,θ)were determined numerically using an SNIS estimator with10
10
samples
and the proposalq(x;θ) =HALFNORMAL(x;μ=θ,σ=diag(Σ
2
)).
C.3. Planning Cancer Treatment
As explained in the main paper, this experiment revolves around an oncologist is trying to decide whether to administer
a treatment to a cancer patient.   They have access to two noisy measurements of the tumor size,  a simulator of tumor
evolution,  a model of the latent factors required for this simulator,  and a loss function for administering the treatment
given the final tumor size.  We note that this is problem for which the target functionf(x)does not have any changeable
parameters (i.e.θ=∅).
The size of the tumor is measured at the time of admissiont= 0and five days later (t= 5), yielding observationsc
′
0
andc
′
5
.
These are noisy measurements of the true sizesc
0
andc
5
. The loss function`(c
100
)is based only on the size of the tumor
aftert= 100days of treatment. The simulator for the development of the tumor takes the form of an ordinary differential
equation (ODE) and is taken from (Hahnfeldt et al., 1999; Enderling & Chaplain, 2014; Rainforth et al., 2018a).
The ODE itself is defined on two variables, the size of the tumor at timet,c
t
, and corresponding carrying capacity,K
t
,
where we takeK
0
= 700. In addition to the initial tumor sizec
0
, the key parameter of the ODE, and the only one we model
as varying across patients, is∈[0,1], a coefficient determining the patient’s response to the anti-tumor treatment.  The
ODE now take the form
dc
dt
=−λclog
(
c
K
)
−c
dK
dt
=φc−ψKc
2/3
(32)
where the values of the parametersφ= 5.85, ψ= 0.00873, λ= 0.1923are based on those recommended in Hahnfeldt et al.
(1999). We use the notation
c
t
=ω(K
0
,c
0
,,t)(33)
to denote the deterministic process of running an ODE solver on (32) with given inputs,  up to timet,  and assume the
following statistical model
c
0
∼GAMMA(k= 25,θ= 20)
∼BETA(α= 5.0,β= 10.0)
c
′
t
∼GAMMA
(
k=
c
2
t
10000
,θ=
c
t
10000
)
.
To summarize and relate the model to the notation from Section 3:x={c
0
,},y={c
′
0
,c
′
1
}.  The function in this case is
fixed to the loss function for administering the treatment given the final tumor size provided to us by the clinic
f(x) =`(ω(700,c
0
,,t= 100))(34)
`(c) =
1−2×10
−8
2
(
tanh
(
−
c−300
150
)
+1
)
+10
−8
.(35)
AmortizationIn this case, the amortization is performed using parametric distributions as proposals:  a Gamma distri-
bution forc
0
and a Beta distribution for, both parameterized by a multilayer perceptron with 16 layers with 5000 hidden
units each.  Since we do not face an overwhelming mismatch betweenf(x)andp(x), unlike in the tail integral example,

Amortized Monte Carlo Integration
the training was done by generating the values ofxfrom the priorp(x)as per (21). We used a learning rate of10
−4
with
the Adam optimizer.
Similarly to the case of five-dimensional tail integral example, the estimates serving as ground truth valuesμ(y)have been
determined numerically using an SNIS estimator with10
9
samples and the proposal set to the priorq(x) =p(x).
C.4. Mini-batching Procedure
AMCI operates in a slightly unusual setting for neural network training because instead of having a fixed dataset, we are
instead training on samples from our modelp(x,y).  The typical way to perform batch stochastic gradient optimization
involves many epochs over the training dataset,  stopping once the error increases on the validation set.  Each epoch is
itself broken down into multiple iterations, wherein one takes a random mini-batch (subsample) from the dataset (without
replacement) and updates the parameters based on a stochastic gradient step using these samples, with the epoch finishing
once the full dataset has been used.
However, there are different ways the training can proceed when we have the ability to generate an infinite amount of data
from our modelp(x,y)and we now no longer fave the risk of overfitting.  There are two extremes approaches one could
take. The first one would be sampling two large but fixed-size datasets (training and validation) before the time of training
and then following the standard training procedure for the finite datasets outlined above.  The other extreme would be to
completely surrender the idea of dataset or epoch, and sample each batch of data presented to the optimizer directly from
p(x,y). In this case, we would not need a validation dataset as we would never be at risk of overfitting—we would finish
the training once we are satisfied with the convergence of the loss value.
Paige  & Wood  (2016)  found  that the  method  which  empirically performed  best  in similar  amortized  inference  setting
was one in the middle between the two extremes outlined above.  They suggest a method which decides when to sample
new synthetic (training and validation) datasets, based on performance on the validation data set.  They draw fixed-sized
training and validation datasets and optimize the model using the standard finite data procedure on the training dataset
until the validation error increases.  When that happens they sample new training and validation datasets and repeat the
procedure.  This continues until empirical convergence of the loss value.  In practice, they allow a few missteps (steps
of increasing value) for the validation loss before they sample new synthetic datasets, and limit the maximum number of
optimization epochs performed on a single dataset.
We use the above method throughout all of our experiments.  We allowed a maximum of 2 missteps w.r.t.  the validation
dataset and maximum of 30 epochs on a single dataset before sampling new datasets.
Note that the way training and validation datasets are generated is modified slightly when using the importance sampling
approach for generatingxandθdetailed in Section 3.3.  Whenever we use the objective in (22), instead of sampling the
training and validation datasets from the priorp(x,y)we will sample them from the distributionq
′
(θ,x)·p(y|x)whereq
′
is a proposal chosen to be as close top(x)p(θ)f(x;θ)as possible.
We note that while training was robust to the number of missteps allowed, adopting the general scheme of Paige & Wood
(2016) was very important in achieving effective training: we initially tried generating every batch directly from the model
p(x,y)and we found that the proposals often converged to the local minimum of just sampling from the prior.
D. Reusing samples
The AMCI estimator in (14) requires takingT=N+K+Msamples,  but onlyN,K,  orMare used to evaluate
each of the individual estimators.  Given that, in practice, we do not have access to the perfectly optimal proposals, it can
sometimes be more efficient to reuse samples in the calculation of multiple components of the expectation, particularly if
the target function is cheap to evaluate relative to the proposal.  Care is required though to ensure that this is only done
when a proposal remains valid (i.e. has finite variance) for the different expectation.
To give a concrete example, in the case wheref(x;θ)≥0∀x,θ, such that we can use a single proposal for the numerator
as per (10), we could use the following estimator
μ(y,θ)≈
α
ˆ
E
1
(q
1
) + (1−α)
ˆ
E
1
(q
2
)
β
ˆ
E
2
(q
1
) + (1−β)
ˆ
E
2
(q
2
)
(36)
where
ˆ
E
i
(q
j
)indicates the estimate forE
i
using the samples fromq
j
. The level of interpolation is set by parametersα,β

Amortized Monte Carlo Integration
Test
f(x;θ)p(x|y)
p(x|y)
θ
q
1
(x;y,θ)
q
2
(x;y)
10
−4
10
−1
10
2
Test
AMCI
SNISq
2
10
−3
10
−1
10
1
Test
−5.0−2.50.02.55.0
x
10
1
10
2
10
3
10
4
Number of samplesN
10
−4
10
−1
10
2
0.000.250.500.751.00
α
10
−3
10
−1
10
1
Density
ReMSE
AMCI ReMSE
Figure 9: Extension of Figure 3. Column three presents the effects of reusing samples by varying the parameterαin (36)
(β= 0, number of samples is fixed toN=M= 64), where we see that this sample re-usage provides small gains for the
low mismatch case, but no gains in the high mismatch case.  Uncertainty bands in columns two and three are estimated
over a 1000 runs and are very small.
which vary between 0 and 1. If we had direct access to the optimal proposals, it would naturally be preferable to setα= 1
andβ= 0, leading to a zero-variance estimator.  However, for imperfect proposals, the optimal values vary slightly from
this (see Appendix D.1).
In relation to our discussion in Section 5, the third column of Figure 9 shows how whenf(x;θ)p(x,y)andp(x,y)are
closely matched we can decrease the error of our AMCI estimator by reusing samples through settingα <1.
Note that while it is possible to setβ >0for negligible extra computational cost as
ˆ
E
2
(q
1
)depends only on weights
needed for calculating
ˆ
E
1
(q
1
), settingα <1requires additional evaluations of the target function and so will likely only
be beneficial when this is cheap relative to sampling from or evaluating the proposal.
D.1. Derivation of the optimal parameter values forαandβ
In this section,  we derive the optimal values ofαandβin terms of minimizing the mean squared error (MSE) of the
estimator in (36). We assume that we are allocated a total sample budget ofTsamples, such thatM=T−N.
Let the true values of the expectations in the numerator and denominator be denoted asE
1
andE
2
, respectively.  We also
define the following shorthands for the unbiased importance sampling estimators with respect to proposalsq
1
andq
2
in
(36)a
1
=
1
N
∑
N
n
f(x
n
;θ)p(x
n
,y)
q
1
(x
n
;y,θ)
,b
1
=
1
M
∑
M
m
f(x
∗
m
;θ)p(x
∗
m
,y)
q
2
(x
∗
m
;y)
,a
2
=
1
N
∑
N
n
p(x
n
,y)
q
1
(x
n
;y,θ)
,b
2
=
1
M
∑
M
m
p(x
∗
m
,y)
q
2
(x
∗
m
;y)
, where
x
n
∼q
1
(x;y,θ)andx
∗
m
∼q
2
(x;y).
We start by considering the estimator according to (36)
μ
:
=
E
1
E
2
≈ˆμ
:
=
ˆ
E
1
ˆ
E
2
:
=
αa
1
+ (1−α)b
1
βa
2
+ (1−β)b
2
.(37)
Using the central limit theorem separately for
ˆ
E
1
and
ˆ
E
2
, then we thus have, asN,M→∞,
ˆμ→
E
1
+σ
1
ξ
1
E
2
+σ
2
ξ
2
,(38)
whereξ
1
,ξ
2
∼ N(0,1)are correlated standard normal random variables andσ
1
andσ
2
are the standard deviation of the
estimators for the numerator and the denominator, respectively. Specifically we have
σ
2
1
=Var[αa
1
+ (1−α)b
1
]
=α
2
Var
q
1
[a
1
] + (1−α)
2
Var
q
2
[b
1
],

Amortized Monte Carlo Integration
which by the weak law of large numbers
=
α
2
N
Var
q
1
[f(x
1
)w
1
] +
(1−α)
2
M
Var
q
2
[f(x
∗
1
)w
∗
1
](39)
wherew
1
=p(x
1
,y)/q
1
(x
1
;y,θ),w
∗
1
=p(x
∗
1
,y)/q
2
(x
∗
1
;y),x
1
∼q
1
(x;y,θ), andx
∗
1
∼q
2
(x;y). Analogously,
σ
2
2
=
β
2
N
Var
q
1
[w
1
] +
(1−β)
2
M
Var
q
2
[w
∗
1
].(40)
Now going back to (38) and using Taylor’s Theorem on1/(E
2
+σ
2
ξ
2
)about1/E
2
gives
ˆμ=
E
1
+σ
1
ξ
1
E
2
(
1−
σ
2
ξ
2
E
2
)
+O()
=
E
1
E
2
+
σ
1
ξ
1
E
2
−
E
1
σ
2
ξ
2
E
2
2
−
σ
1
σ
2
ξ
1
ξ
2
E
2
2
+O()
whereO()represents asymptotically dominated terms. Note here the importance of using Taylor’s theorem, instead of just
a Taylor expansion, to confirm that these terms are indeed asymptotically dominated. We can further drop theσ
1
σ
2
ξ
1
ξ
2
/E
2
2
term as this will be of orderO(1/
√
MN)and will thus be asymptotically dominated, giving
=
E
1
E
2
+
σ
1
ξ
1
E
2
−
E
1
σ
2
ξ
2
E
2
2
+O().(41)
To calculate the MSE ofˆμ, we start with the standard bias variance decomposition
E
[
(
ˆμ−
E
1
E
2
)
2
]
= Var [ˆμ] +
(
E
[
ˆμ−
E
1
E
2
]
)
2
.(42)
Considering first the bias squared term, we see that this depends only on the higher order termsO(), while the variance
does not. It straightforwardly follows that the variance term will be asymptotically dominant, so we see that optimizing for
the variance is asymptotically equivalent to optimizing for the MSE.
Now using the standard relationshipVar[X+Y] = Var[X]+Var[Y]+2 Cov[X,Y]yields
Var[ˆμ] = Var
[
E
1
E
2
]
+ Var
[
σ
1
ξ
1
E
2
]
+ Var
[
E
1
σ
2
ξ
2
E
2
2
]
+ 2 Cov
[
σ
1
ξ
1
E
2
,−
E
1
σ
2
ξ
2
E
2
2
]
+O()
≈0 +
σ
2
1
E
2
2
+
E
2
1
σ
2
2
E
4
2
−2
E
1
σ
1
σ
2
E
3
2
Cov[ξ
1
,ξ
2
]
=
1
E
2
2
(
σ
2
1
+σ
2
2
μ
2
−2μσ
1
σ
2
Corr[ξ
1
,ξ
2
]
)
(43)
sinceVar[ξ
1
] = Var[ξ
2
] = 1  =⇒Cov[ξ
1
,ξ
2
] =Corr[ξ
1
,ξ
2
],
=
α
2
NE
2
2
Var
q
1
[f(x
1
)w
1
] +
(1−α)
2
ME
2
2
Var
q
2
[f(x
∗
1
)w
∗
1
] +
E
2
1
β
2
NE
4
2
Var
q
1
[w
1
] +
E
2
1
(1−β)
2
ME
4
2
Var
q
2
[w
∗
1
]
−2
E
1
E
3
2
Corr[ξ
1
,ξ
2
]
(
α
2
N
Var
q
1
[f(x
1
)w
1
] +
(1−α)
2
M
Var
q
2
[f(x
∗
1
)w
∗
1
]
)(
β
2
N
Var
q
1
[w
1
] +
(1−β)
2
M
Var
q
2
[w
∗
1
]
)
To assist in the subsequent analysis, we assume that there is no correlation, Corr[ξ
1
,ξ
2
] = 0.  Though this assumption is
unlikely to be exactly true, there are two reasons we believe it is reasonable.  Firstly, because we expect to setα≈1and
β≈0, the correlation should generally be small in practice as the two estimators rely predominantly on independent sets
of samples. Secondly, we believe this is generally a relatively conservative assumption: if one were to presume a particular
correlation, there are adversarial cases with the opposite correlation where this assumption is damaging.

Amortized Monte Carlo Integration
Given this assumption it is now straightforward to optimize forαandβby finding where the gradient is zero as follows
∇
α
(Var[ˆμ]E
2
2
) =
2αVar
q
1
[f(x
1
)w
1
]
N
−
2(1−α)Var
q
2
[f(x
∗
1
)w
∗
1
]
T−N
= 0
⇒α
∗
=N·
(
(T−N)
Var
q
1
[f(x
1
)w
1
]
Var
q
2
[f(x
∗
1
)w
∗
1
]
+N
)
−1
(44)
noting that
∇
2
α
(Var[ˆμ]E
2
2
) =
Var
q
1
[f(x
1
)w
1
]
N
+
Var
q
2
[f(x
∗
1
)w
∗
1
]
T−N
>0
and hence it’s a local minimum. Analogously
β
∗
=N·
(
(T−N)
Var
q
1
[w
1
]
Var
q
2
[w
∗
1
]
+N
)
−1
.(45)
We note that it is possible to estimate all the required variances here using previous samples. It should therefore be possible
to adaptively setαandβby using these equations along with empirical estimates for these variances. 

Multi-Purposing Domain Adaptation Discriminators for Pseudo
Labeling Confidence
Garrett Wilson
garrett.wilson@wsu.edu
Washington State University
Pullman, WA
Diane J. Cook
djcook@wsu.edu
Washington State University
Pullman, WA
ABSTRACT
Often domain adaptation is performed using a discriminator (do-
main classifier) to learn domain-invariant feature representations
so that a classifier trained on labeled source data will generalize
well to unlabeled target data. A line of research stemming from
semi-supervised learning uses pseudo labeling to directly generate
“pseudo labels” for the unlabeled target data and trains a classifier
on the now-labeled target data, where the samples are selected
or weighted based on some measure of confidence. In this paper,
we propose multi-purposing the discriminator to not only aid in
producing domain-invariant representations but also to provide
pseudo labeling confidence.
CCS CONCEPTS
•Computing methodologies→Transfer learning;Unsuper-
vised learning;Neural networks;•Theory of computation
→Adversarial learning.
KEYWORDS
domain adaptation, pseudo labeling, instance weighting, domain-
invariant features
ACM Reference Format:
Garrett Wilson and Diane J. Cook. . Multi-Purposing Domain Adaptation
Discriminators for Pseudo Labeling Confidence. InProceedings of AdvML’19:
Workshop on Adversarial Learning Methods for Machine Learning and Data
Mining at KDD.ACM, New York, NY, USA, 6 pages.
1  INTRODUCTION
Unsupervised domain adaptation is a problem consisting of two
domains: a source domain and a target domain. Labeled source data
and unlabeled target data are available for use during training, and
the goal is to learn a model that performs well on data from the
target domain [15,17,36]. As a result, this can be used to reduce
the need for costly labeled data in the target domain.
A common approach for domain adaptation is to learn a domain-
invariant feature representation, which in deep learning methods
is typically a feature extractor neural network. Intuitively, if a clas-
sifier trained on these domain-invariant features of the labeled
source data performs well, then the classifier may generalize to
the unlabeled target data since the feature distributions for both
domains will be highly similar. (Though, performance on the target
data depends on how similar the domains are, and this method may
actually increase the error if the domains are too different [4,58].)
Numerous methods proposed for achieving this goal have yielded
AdvML’19: Workshop on Adversarial Learning Methods for Machine Learning and Data
Mining at KDD, August 5th, 2019, Anchorage, Alaska, USA
.
promising results, and many of these methods use adversarial train-
ing [56].
One such adversarial domain-invariant feature learning method
is the domain-adversarial neural network (DANN) [14, 15], which
is a typical baseline for other variants. This method consists of a fea-
ture extractor network followed by two additional networks: a task
classifier and a domain classifier (Figure 1). The network is updated
by two competing objectives: (1) the feature extractor followed by
the task classifier learns to correctly classify the labeled source data
while the domain classifier learns to correctly predict whether the
features originated from source or target data, and (2) the feature
extractor learns to make the domain classifier predict the domain
incorrectly. To this end, they propose a gradient reversal layer be-
tween the feature extractor and domain classifier so that during
backpropagation, the gradient is negated when updating the feature
extractor weights. More recently, Shu et al. [47] found replacing the
gradient reversal layer with adversarial alternating updates from
generative adversarial networks (GANs) [18] to perform better.
Pseudo labeling is a technique from semi-supervised learning
that is also sometimes included in domain-invariant feature learning
methods for domain adaptation [11,41,45,60]. In pseudo labeling,
a source classifier trained on the labeled source data is first used
to label the unlabeled target data, generating “pseudo” labels that
may not all be correct. Next, a target classifier can be trained in a
supervised manner on the now-labeled target data. Often there is a
selection criterion to utilize only pseudo-labeled data that are more-
likely correct (i.e., the model is more confident on those samples).
Typically the selection is based on whether the softmax output
prediction entropy is low enough [11,35,60]. The softmax output
can be viewed as a probability distribution over the possible labels,
so a uniform distribution over these predictions indicates the model
has no idea what label to predict whereas a very high prediction
probability for one class (low entropy) indicates the model has high
confidence in a prediction. Other measures of confidence include
ensemble agreement (combined with softmax confidence) [41] or
k-nearest neighbor agreement [45].
In this paper, we propose another selection criterion for pseudo
labeling: the discriminator’s confidence. Methods such as DANN
already have a discriminator, allowing it to be easily multi-purposed
to not only aid in producing domain-invariant representations but
also to provide pseudo labeling confidence. The domain discrim-
inator learns to classify feature representations as either source
domain or target domain, but in unsupervised domain adaptation
this can also be interpreted as known label vs. unknown label, or
rather, accurate vs. possibly inaccurate, assuming the task classifier
performs well on the source data. Thus, we could view samples as
arXiv:1907.07802v1  [cs.LG]  17 Jul 2019

AdvML’19: Workshop on Adversarial Learning Methods for Machine Learning and Data Mining at KDD, August 5th, 2019, Anchorage,
Alaska, USAGarrett Wilson and Diane J. Cook
(labeled)
source
data
(unlabeled)
target
data
Feature
Extractor
Feature
Extractor
Task
Classifier
Domain
Classifier
class
label
“source”
or
“target”
Shared
Weights
(a) Training
(unlabeled)
target
data
Feature
Extractor
Task
Classifier
class
label
(b) Testing
Figure 1: Network setup for DANN that learns a domain-
invariant feature representation – the basis for our proposed
method.
“confident” if the discriminator incorrectly classifies the target sam-
ples’ feature representations as originating from the source domain.
Intuitively, this process may select samples that are pseudo labeled
correctly since the feature representation was close to that of data
with known labels. However, our proposed approach assumes (1)
the task classifier does perform well on the labeled source data and
(2) there exists sufficient similarity between domains. The first as-
sumption is easy to verify during training. The second assumption
is harder to quantify, but empirically we obtain high target domain
performance.
To explain our proposed method, we first discuss the relationship
with existing methods. Second, we describe our method in detail.
Finally, we perform experiments on a variety of image datasets
commonly used for domain adaptation.
2  RELATED WORK
Numerous domain-invariant feature learning methods have been
proposed. Some do this by minimizing a divergence such as maxi-
mum mean discrepancy [27,29,38], second-order statistics [32,33,
49,54,57], or contrastive domain discrepancy [20]. Others use op-
timal transport [9,10], graph matching [11], or reconstruction [16].
Still others learn domain-invariant features adversarially with a
domain classifier [1,14,15,28,37,46,51,52] or a GAN [43,44]. The
method in this paper is based on DANN, an adversarial approach.
Several domain-invariant adaptation methods also incorporate
pseudo labeling to further improve performance. Some select confi-
dent samples that have low entropy [11,60]. Others use an ensemble
of networks that make independent predictions and select confi-
dent samples based on a combination of the ensemble agreement
and verifying that at least one of the ensemble predictions has low
entropy [41]. One method classifies withk-nearest neighbors and
thus bases its confidence on agreement of thekpredictions [45]. In
this paper, we propose using the DANN discriminator to provide a
measure of confidence for pseudo labeling.
Pseudo labeling can be viewed as conditional entropy regulariza-
tion [19,25], which while proposed for semi-supervised learning
has also been applied in domain adaptation methods [21,47]. En-
tropy regularization and pseudo labeling are based upon the cluster
assumption: data are clustered by class/label and separated by low-
density regions. If this is true, then decision boundaries should lie
in these low-density regions [7, 25]. Entropy regularization is one
way to move decision boundaries away from regions with higher
density. However, this assumes that the decisions do not drastically
change when approaching data points, i.e., that the model is locally
Lipschitz [47]. This can be enforced with virtual adversarial train-
ing [30], which thus is typically also used when applying entropy
regularization to domain adaptation [21,47]. Alternative methods
have also been proposed with the same effect of moving decision
boundaries into lower-density regions based on GANs [55], adver-
sarial dropout [42], and self-ensembling [13,22,50]. We base our
method on pseudo labeling rather than entropy regularization or
the alternative methods.
Pseudo labeling is related to self-training and expectation max-
imization. In self-training, a classifier is trained on labeled data,
predicts labels of unlabeled data, and is re-trained on the previously-
unlabeled data. This process is then repeated [59]. Self-training can
be shown to be equivalent to a particular classification expectation
maximization algorithm [2,19]. Pseudo labeling is almost the same,
except that it is trained simultaneously on labeled and unlabeled
data [25]. In domain adaptation, we have two separate domains, so
we may instead wish to use the pseudo-labeled target data to train
a separate target classifier [41]. This could be done in either one or
two steps (similar to pseudo labeling or self-training, respectively).
Pseudo labeling is also related to co-training. Co-training is
similar to self-training but utilizes two classifiers for two separate
views of the data. Pseudo-labeled samples are selected in which
exactly one of the classifiers is confident, which are then added to
the labeled training set for training in subsequent iterations [8].
When only one view is available as is common in domain adaptation
problems, Chen et al. [8] propose feature splits to artificially create
two views.
Finally, the proposed method of using a discriminator or domain
classifier to select which samples to use for adaptation is related
to selection adaptation, a type of instance weighting [3,12]. In
selection adaptation, a domain classifier learns to predict which
domain the samples are from. The labeled source data weighted by
a function of these domain predictions are used to train a target
classifier [12]. While related, this differs from our proposed method
in several ways. First, we do not weight the source data but rather
pseudo label and weight the target data. Second, our discriminator
operates at a feature level rather than a sample level. Third, our
discriminator is trained jointly rather than in stages (more common
in deep methods).
3  METHOD
We compare several alternative approaches for domain adaptation.
In the first approach, no adaptation is performed. In the second
method, we use DANN to learn a domain-invariant feature repre-
sentation. The third approach employs pseudo labeling and weights

Multi-Purposing Domain Adaptation Discriminators for Pseudo Labeling Confidence
AdvML’19: Workshop on Adversarial Learning Methods for Machine Learning and Data Mining at KDD, August 5th, 2019, Anchorage,
Alaska, USA
instances either by the task classifier’s softmax confidence or by a
discriminator’s confidence (our proposed method).
3.1  No adaptation
We train a feature extractor followed by a task classifier on the
labeled source data only. Then we evaluate this model on the target
data to see how well it generalizes without performing any domain
adaptation. We expect this method to perform poorly when large
differences exist between domains.
3.2  DANN
We train a feature extractor, softmax task classifier, and binary do-
main classifier as shown in Figure 1. The training consists of three
weight updates at each iteration: (1) the feature extractor and task
classifier together are trained to correctly classify labeled source
data (e.g., with categorical cross entropy loss), (2) the domain clas-
sifier is trained to correctly label from which domain’s data the
feature representation originated, and (3) the feature extractor is
trained to fool the domain classifier. Through this process, the fea-
ture extractor learns to produce domain-invariant representations.
Rather than using a gradient reversal layer [15] for steps (2) and
(3), we choose to perform a GAN-like update as used by Shu et al.
[47]. For a discriminatorD, a feature extractorF, source domain
dataD
s
, and target domain dataD
t
, these two updates can be
performed by minimizing:
min
D
−E
x∼D
s
[
logD(F(x))
]
−E
x∼D
t
[
log(1−D(F(x)))
]
(1)
min
F
−E
x∼D
t
[
logD(F(x))
]
−E
x∼D
s
[
log(1−D(F(x)))
]
(2)
Step (2) becomes Equation 1, updating the discriminator to cor-
rectly classify the feature representations of source and target data
as “source” and “target”. Step (3) becomes Equation 2, updating the
feature extractor to fool the discriminator by classifying source
data as “target” and target data as “source”. The losses for these two
updates can be computed with binary cross entropy.
3.3  Pseudo labeling
Pseudo labeling can be added to DANN using the following steps.
First, perform updates to the feature extractor, task classifier, and
domain classifier on a batch of source and target data as in DANN
(Figure 1a). Second, pseudo label a batch of target data using the
task classifierand record the domain classifier predictions without
updating the model (Figure 2a). Third, train atarget classifieron
this pseudo-labeled target data but weighted by the probability
that the feature representations were generated from source data
(Figure 2b). If the domain classifier is a binary classifier where 0
is “source” and 1 is “target”, this probability can be calculated as
1−D(F(x)). This contrasts with weighting by the task classifier’s
max softmax output probability as a measure of confidence. Both
methods of weighting are evaluated in the experiments.
3.4  Instance weighting
Alternatively, we can replace pseudo labeling with instance weight-
ing. In this case we train the target classifier on source data weighted
by how target-like the feature representation appears, given by
(unlabeled)
target
data
Feature
Extractor
Task
Classifier
Domain
Classifier
pseudo
label
“source”
or
“target”
(a) Training: pseudo label step (no weight update)
(unlabeled)
target
data
Feature
Extractor
Target
Classifier
(pseudo-
labeled)
class label
(b) Training: update target classifier step
(unlabeled)
target
data
Feature
Extractor
Target
Classifier
class
label
(c) Testing
Figure 2: After each DANN training step (Figure 1a), target
data is (a) pseudo labeled, and then (b) a target classifier is
trained on those pseudo labels but weighted by the discrimi-
nator’s predictions from (a), representing the probability the
feature representation was generated fromsourcedata (i.e.,
the discriminator was fooled). All feature extractors share
weights. At test time, the feature extractor and target classi-
fier are used for making predictions. Note that DANN uses
atask classifierwhereas the abovetarget classifieris a sep-
arate classifier and is only trained on pseudo-labeled target
data.
D(F(x)). As in pseudo labeling, this weighting contrasts with weight-
ing by the task classifier’s softmax confidence. At test time, as in
pseudo labeling, we can use the feature extractor followed by the
target classifier for predictions. Note that this method is essentially
selection adaptation [12] but trained jointly and performed at a
feature-level representation rather than the sample level.
4  EXPERIMENTS
We evaluate the method variations of no adaptation, DANN, in-
stance weighting evaluated on the task or target classifiers (Instance-
TaskC and Instance), pseudo labeling without the adversarial step
that produces a domain-invariant feature representation (Pseudo-
NoAdv), and pseudo labeling evaluated on the task and target clas-
sifiers (Pseudo-TaskC and Pseudo). Each instance weighting and
pseudo labeling method is trained and evaluated both for weight-
ing by the task classifier’s softmax confidence (task) and by the
discriminators confidence (domain).
We train these methods on popular computer vision datasets:
MNIST [23], USPS [24], SVHN [34], MNIST-M [15], SynNumbers
[15], SynSigns [31], and GTSRB [48]. For MNIST↔USPS, we upscale
USPS to 28x28 pixels to match MNIST using bilinear interpolation.

AdvML’19: Workshop on Adversarial Learning Methods for Machine Learning and Data Mining at KDD, August 5th, 2019, Anchorage,
Alaska, USAGarrett Wilson and Diane J. Cook
Table 1: Classification accuracy (source→target) of the methods on benchmark computer vision datasets: MNIST, USPS, SVHN,
MNIST-M, SynNumbers, SynSigns, and GTSRB. The strongest task vs. domain confidence on each dataset for each method is
highlighted in bold (if not the same). The best-performing method in each column is underlined. The last method (italicized)
is the one we propose in this paper. This method performs best on average.
MethodMN→USUS→MNSV→MNMN→MN-MSyn
N
→SVSyn
S
→GTSRBAverage
No Adaptation0.8880.8690.7970.2460.8270.9540.764
DANN0.9610.9650.8550.9490.8810.9320.924
Instance (task)0.9600.9640.8310.9430.8760.9360.918
Instance (domain)0.9370.9580.8640.9390.8800.9150.916
Pseudo-NoAdv (task)0.9680.9650.7410.7890.9090.9720.891
Pseudo-NoAdv (domain)0.970
0.9600.8690.7210.9010.9630.897
Pseudo-TaskC (task)0.9620.9700.8610.9860.8910.9190.931
Pseudo-TaskC (domain)0.9540.9780.8980.9830.8810.9050.933
Pseudo (task)0.9520.9720.8730.9850.8980.9340.936
Pseudo (domain)0.9500.979
0.9100.9850.8940.9240.940
For MNIST→MNIST-M, we pad MNIST with zeros (before normal-
ization) to be 32x32 pixels and convert to RGB to match MNIST-M.
For SVHN→MNIST, we pad MNIST to 32x32 and convert to RGB
to match SVHN. The other datasets already have matching image
sizes and depths.
For all experiments, we use the small CNN model used by Shu et
al. [47] and for pseudo labeling use the task classifier architecture for
the target classifier. We train each model 80,000 steps with Adam
using a learning rate of 0.001 [47], a batch size of 128 [15], the
adversarial learning rate schedule from DANN [15], and a learning
rate of 0.0005 for the target classifier. Target and source domain
data is fed through the model in separate batches allowing for
domain-specific batch statistics [13,26]. For model selection, we use
1000 labeled target samples from the training datasets as a holdout
validation set. The reported accuracies are for the evaluation of
each model (the target classifier for pseudo labeling and instance
weighting methods, otherwise task classifier) on the testing sets
that performed best on the holdout validation set. Thus, since in
truly “unsupervised” domain adaptation situations we would not
have any labeled target data, these results can be interpreted as an
upper bound for how well these methods can perform [53]. Using
some labeled target examples in this way is a common approach
for tuning domain adaptation methods [5, 6, 21, 39, 47, 53, 55].
The results are summarized in Table 1. As indicated in these
results, the proposed method of pseudo labeling with domain confi-
dence performs the best. We can see that in all cases at least one of
the adaptation methods improves over no adaptation, at least one of
the pseudo labeling methods improves over instance weighting, and
at least one of the pseudo labeling methods improves over DANN.
On half of the datasets and on average, using adversarial training
with pseudo labeling improves results. Typically, evaluating pseudo
labeling on the target classifier is more effective than on the task
classifier; though interestingly Pseudo-TaskC almost always out-
performs DANN despite the task classifier never being updated by
the pseudo labeling process. This indicates that pseudo labeling can
improve the feature representation for the target domain. Finally,
our primary goal was to determine if using a discriminator’s confi-
dence is more effective than a task classifier’s softmax confidence,
which is true on average for each of the pseudo labeling methods
though not for instance weighting. Thus, these experiments appear
to provide evidence that pseudo labeling with a domain discrimina-
tor’s confidence may yield an improvement over a task classifier’s
softmax confidence.
5  CONCLUSION
In this paper, we investigated how to weight samples for pseudo
labeling. We proposed using a discriminator’s confidence rather
than a task classifier’s softmax confidence. The results of testing
these methods on computer vision datasets provides insight into
the possible benefit of using a discriminator not only for producing
a domain-invariant feature representation but also for weighting
samples for pseudo labeling.
Future work includes hyperparameter tuning either on the hold-
out set or with a method that does not require any labeled target
data such as reverse validation [15]. This method should be tested
on additional datasets such as Office-31 [40] and on a greater va-
riety of domain adaptation tasks. Additionally, we can determine
whether confidence thresholding [13] improves over confidence
weighting. Finally, we can investigate theory behind selecting or
weighting samples for pseudo labeling or instance weighting that
may indicate why or when this method will work in addition to
possible tweaks to yield improvements, such as possibly using a
function of the discriminator’s output rather than the probability
directly, as is done in selection adaptation [12].
REFERENCES
[1]
Hana  Ajakan,  Pascal  Germain,  Hugo  Larochelle,  François  Laviolette,  and
Mario Marchand. 2014.  Domain-adversarial neural networks.arXiv preprint
arXiv:1412.4446(2014).
[2]
Massih-Reza Amini and Patrick Gallinari. 2002. Semi-supervised logistic regres-
sion. InECAI. 390–394.

Multi-Purposing Domain Adaptation Discriminators for Pseudo Labeling Confidence
AdvML’19: Workshop on Adversarial Learning Methods for Machine Learning and Data Mining at KDD, August 5th, 2019, Anchorage,
Alaska, USA
[3]
Oscar Beijbom. 2012. Domain adaptations for computer vision applications.arXiv
preprint arXiv:1211.4860(2012).
[4]Shai Ben-David, John Blitzer, Koby Crammer, Alex Kulesza, Fernando Pereira, and
Jennifer Wortman Vaughan. 2010. A theory of learning from different domains.
Machine Learning79, 1 (01 May 2010), 151–175.   https://doi.org/10.1007/s10994-
009-5152-4
[5]Konstantinos Bousmalis, George Trigeorgis, Nathan Silberman, Dilip Krishnan,
and Dumitru Erhan. 2016. Domain Separation Networks. InAdvances in Neural
Information Processing Systems 29, D. D. Lee, M. Sugiyama, U. V. Luxburg, I. Guyon,
and R. Garnett (Eds.). Curran Associates, Inc., 343–351.   http://papers.nips.cc/
paper/6254-domain-separation-networks.pdf
[6]Fabio Maria Carlucci, Lorenzo Porzi, Barbara Caputo, Elisa Ricci, and Samuel Rota
Bulò. 2017. Autodial: Automatic domain alignment layers. In2017 IEEE Interna-
tional Conference on Computer Vision (ICCV). IEEE, 5077–5085.
[7]
Olivier Chapelle and Alexander Zien. 2005.  Semi-supervised classification by
low density separation.. InAISTATS, Vol. 2005. Citeseer, 57–64.
[8]Minmin Chen, Kilian Q Weinberger, and John Blitzer. 2011.  Co-Training for
Domain Adaptation.  InAdvances in Neural Information Processing Systems 24,
J. Shawe-Taylor, R. S. Zemel, P. L. Bartlett, F. Pereira, and K. Q. Weinberger
(Eds.). Curran Associates, Inc., 2456–2464.  http://papers.nips.cc/paper/4433-co-
training-for-domain-adaptation.pdf
[9]Nicolas Courty, Rémi Flamary, Amaury Habrard, and Alain Rakotomamonjy. 2017.
Joint distribution optimal transportation for domain adaptation.  InAdvances
in Neural Information Processing Systems 30, I. Guyon, U. V. Luxburg, S. Bengio,
H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett (Eds.). Curran Associates,
Inc., 3730–3739.   http://papers.nips.cc/paper/6963-joint-distribution-optimal-
transportation-for-domain-adaptation.pdf
[10]
Bharath Bhushan Damodaran, Benjamin Kellenberger, Rémi Flamary, Devis Tuia,
and Nicolas Courty. 2018. DeepJDOT: Deep Joint Distribution Optimal Transport
for Unsupervised Domain Adaptation. InComputer Vision – ECCV 2018, Vittorio
Ferrari, Martial Hebert, Cristian Sminchisescu, and Yair Weiss (Eds.). Springer
International Publishing, Cham, 467–483.
[11]Debasmit Das and C. S. George Lee. 2018.  Graph Matching and Pseudo-Label
Guided Deep Unsupervised Domain Adaptation. InArtificial Neural Networks and
Machine Learning – ICANN 2018, Věra Kůrková, Yannis Manolopoulos, Barbara
Hammer, Lazaros Iliadis, and Ilias Maglogiannis (Eds.). Springer International
Publishing, Cham, 342–352.
[12]Hal Daumé III. 2012. A course in machine learning.Publisher, ciml. info5 (2012),
69.
[13]Geoff French, Michal Mackiewicz, and Mark Fisher. 2018.  Self-ensembling for
visual domain adaptation. InInternational Conference on Learning Representations.
https://openreview.net/forum?id=rkpoTaxA-
[14]Yaroslav Ganin and Victor Lempitsky. 2015. Unsupervised Domain Adaptation by
Backpropagation. InProceedings of the 32nd International Conference on Machine
Learning (Proceedings of Machine Learning Research), Francis Bach and David Blei
(Eds.), Vol. 37. PMLR, 1180–1189.  http://proceedings.mlr.press/v37/ganin15.html
[15]Yaroslav  Ganin,  Evgeniya  Ustinova,  Hana  Ajakan,  Pascal  Germain,  Hugo
Larochelle, François Laviolette, Mario Marchand, and Victor Lempitsky. 2016.
Domain-Adversarial Training of Neural Networks.Journal of Machine Learning
Research17, 59 (2016), 1–35.  http://jmlr.org/papers/v17/15-239.html
[16]
Muhammad Ghifary, W. Bastiaan Kleijn, Mengjie Zhang, David Balduzzi, and
Wen Li. 2016. Deep Reconstruction-Classification Networks for Unsupervised
Domain Adaptation. InComputer Vision – ECCV 2016, Bastian Leibe, Jiri Matas,
Nicu Sebe, and Max Welling (Eds.). Springer International Publishing, Cham,
597–613.
[17]
Ian Goodfellow, Yoshua Bengio, and Aaron Courville. 2016.Deep learning. MIT
press.
[18]Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley,
Sherjil Ozair, Aaron Courville, and Yoshua Bengio. 2014. Generative Adversarial
Nets. InAdvances in Neural Information Processing Systems 27, Z. Ghahramani,
M. Welling, C. Cortes, N. D. Lawrence, and K. Q. Weinberger (Eds.). Curran Asso-
ciates, Inc., 2672–2680.   http://papers.nips.cc/paper/5423-generative-adversarial-
nets.pdf
[19]Yves Grandvalet and Yoshua Bengio. 2005. Semi-supervised Learning by Entropy
Minimization. InAdvances in Neural Information Processing Systems 17, L. K. Saul,
Y. Weiss, and L. Bottou (Eds.). MIT Press, 529–536.  http://papers.nips.cc/paper/
2740-semi-supervised-learning-by-entropy-minimization.pdf
[20]Guoliang Kang, Lu Jiang, Yi Yang, and Alexander G Hauptmann. 2019.  Con-
trastive Adaptation Network for Unsupervised Domain Adaptation.arXiv preprint
arXiv:1901.00976(2019).
[21]Abhishek Kumar, Prasanna Sattigeri, Kahini Wadhawan, Leonid Karlinsky, Roge-
rio Feris, Bill Freeman, and Gregory Wornell. 2018. Co-regularized Alignment for
Unsupervised Domain Adaptation. InAdvances in Neural Information Processing
Systems 31, S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and
R. Garnett (Eds.). Curran Associates, Inc., 9345–9356.  http://papers.nips.cc/paper/
8146-co-regularized-alignment-for-unsupervised-domain-adaptation.pdf
[22]
Samuli Laine and Timo Aila. 2017. Temporal Ensembling for Semi-Supervised
Learning.  InInternational Conference on Learning Representations.https:
//openreview.net/forum?id=BJ6oOfqge
[23]
Yann LeCun, Corinna Cortes, and Christopher J.C. Burges. 1998.  The MNIST
database of handwritten digits.    Retrieved August 16, 2018 from http://yann.
lecun.com/exdb/mnist/
[24]Y. LeCun, O. Matan, B. Boser, J. S. Denker, D. Henderson, R. E. Howard, W.
Hubbard, L. D. Jacket, and H. S. Baird. 1990. Handwritten zip code recognition
with multilayer networks. In[1990] Proceedings. 10th International Conference on
Pattern Recognition, Vol. ii. 35–40 vol.2.  https://doi.org/10.1109/ICPR.1990.119325
[25]Dong-Hyun Lee. 2013. Pseudo-label: The simple and efficient semi-supervised
learning method for deep neural networks. InWorkshop on Challenges in Repre-
sentation Learning, ICML, Vol. 3. 2.
[26]Yanghao Li, Naiyan Wang, Jianping Shi, Xiaodi Hou, and Jiaying Liu. 2018. Adap-
tive Batch Normalization for practical domain adaptation.Pattern Recognition80
(2018), 109 – 117.   https://doi.org/10.1016/j.patcog.2018.03.005
[27]
Mingsheng Long, Yue Cao, Jianmin Wang, and Michael Jordan. 2015. Learning
Transferable Features with Deep Adaptation Networks. InProceedings of the 32nd
International Conference on Machine Learning (Proceedings of Machine Learning
Research), Francis Bach and David Blei (Eds.), Vol. 37. PMLR, 97–105.http:
//proceedings.mlr.press/v37/long15.html
[28]
Mingsheng Long, Zhangjie Cao, Jianmin Wang, and Michael I Jordan. 2018.
Conditional Adversarial Domain Adaptation. InAdvances in Neural Information
Processing Systems 31, S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-
Bianchi, and R. Garnett (Eds.). Curran Associates, Inc., 1640–1650.  http://papers.
nips.cc/paper/7436-conditional-adversarial-domain-adaptation.pdf
[29]
Mingsheng Long, Han Zhu, Jianmin Wang, and Michael I. Jordan. 2017.  Deep
Transfer Learning with Joint Adaptation Networks. InProceedings of the 34th
International Conference on Machine Learning (Proceedings of Machine Learning
Research), Doina Precup and Yee Whye Teh (Eds.), Vol. 70. PMLR, International
Convention Centre, Sydney, Australia, 2208–2217.  http://proceedings.mlr.press/
v70/long17a.html
[30]T. Miyato, S. Maeda, S. Ishii, and M. Koyama. 2018. Virtual Adversarial Training:
A Regularization Method for Supervised and Semi-Supervised Learning.IEEE
Transactions on Pattern Analysis and Machine Intelligence(2018), 1–1.    https:
//doi.org/10.1109/TPAMI.2018.2858821
[31]Boris Moiseev, Artem Konev, Alexander Chigorin, and Anton Konushin. 2013.
Evaluation of Traffic Sign Recognition Methods Trained on Synthetically Gener-
ated Data. InAdvanced Concepts for Intelligent Vision Systems, Jacques Blanc-Talon,
Andrzej Kasinski, Wilfried Philips, Dan Popescu, and Paul Scheunders (Eds.).
Springer International Publishing, Cham, 576–583.
[32]Pietro Morerio, Jacopo Cavazza, and Vittorio Murino. 2018.  Minimal-Entropy
Correlation Alignment for Unsupervised Deep Domain Adaptation. InInterna-
tional Conference on Learning Representations.  https://openreview.net/forum?id=
rJWechg0Z
[33]
Pietro Morerio and Vittorio Murino. 2017. Correlation Alignment by Riemannian
Metric for Domain Adaptation.arXiv preprint arXiv:1705.08180(2017).
[34]Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo Wu, and An-
drew Y Ng. 2011.  Reading digits in natural images with unsupervised feature
learning. InNIPS workshop on deep learning and unsupervised feature learning,
Vol. 2011. 5.
[35]Avital Oliver, Augustus Odena, Colin A Raffel, Ekin Dogus Cubuk, and Ian Good-
fellow. 2018. Realistic Evaluation of Deep Semi-Supervised Learning Algorithms.
InAdvances in Neural Information Processing Systems 31, S. Bengio, H. Wallach,
H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett (Eds.). Curran Asso-
ciates, Inc., 3235–3246.   http://papers.nips.cc/paper/7585-realistic-evaluation-of-
deep-semi-supervised-learning-algorithms.pdf
[36]
Sinno Jialin Pan and Qiang Yang. 2010.  A Survey on Transfer Learning.IEEE
Transactions on Knowledge and Data Engineering22, 10 (Oct 2010), 1345–1359.
https://doi.org/10.1109/TKDE.2009.191
[37]Sanjay Purushotham, Wilka Carvalho, Tanachat Nilanon, and Yan Liu. 2017. Vari-
ational adversarial deep domain adaptation for health care time series analysis.
InInternational Conference on Learning Representations.  https://openreview.net/
forum?id=rk9eAFcxg
[38]
A. Rozantsev, M. Salzmann, and P. Fua. 2019.   Beyond Sharing Weights for
Deep Domain Adaptation.IEEE Transactions on Pattern Analysis and Machine
Intelligence41, 4 (April 2019), 801–814.    https://doi.org/10.1109/TPAMI.2018.
2814042
[39]Paolo Russo, Fabio M. Carlucci, Tatiana Tommasi, and Barbara Caputo. 2018.
From Source to Target and Back: Symmetric Bi-Directional Adaptive GAN. In
The IEEE Conference on Computer Vision and Pattern Recognition (CVPR).
[40]Kate Saenko, Brian Kulis, Mario Fritz, and Trevor Darrell. 2010. Adapting Visual
Category Models to New Domains. InComputer Vision – ECCV 2010, Kostas
Daniilidis, Petros Maragos, and Nikos Paragios (Eds.). Springer Berlin Heidelberg,
Berlin, Heidelberg, 213–226.
[41]Kuniaki Saito, Yoshitaka Ushiku, and Tatsuya Harada. 2017.  Asymmetric Tri-
training for Unsupervised Domain Adaptation. InProceedings of the 34th In-
ternational Conference on Machine Learning (Proceedings of Machine Learning
Research), Doina Precup and Yee Whye Teh (Eds.), Vol. 70. PMLR, 2988–2997.
http://proceedings.mlr.press/v70/saito17a.html

AdvML’19: Workshop on Adversarial Learning Methods for Machine Learning and Data Mining at KDD, August 5th, 2019, Anchorage,
Alaska, USAGarrett Wilson and Diane J. Cook
[42]
Kuniaki Saito, Yoshitaka Ushiku, Tatsuya Harada, and Kate Saenko. 2018. Adver-
sarial Dropout Regularization. InInternational Conference on Learning Represen-
tations.  https://openreview.net/forum?id=HJIoJWZCZ
[43]Swami Sankaranarayanan, Yogesh Balaji, Carlos D. Castillo, and Rama Chel-
lappa. 2018. Generate to Adapt: Aligning Domains Using Generative Adversarial
Networks. InThe IEEE Conference on Computer Vision and Pattern Recognition
(CVPR).
[44]Swami Sankaranarayanan, Yogesh Balaji, Arpit Jain, Ser Nam Lim, and Rama
Chellappa. 2018.  Learning From Synthetic Data: Addressing Domain Shift for
Semantic Segmentation. InThe IEEE Conference on Computer Vision and Pattern
Recognition (CVPR).
[45]Ozan Sener, Hyun Oh Song, Ashutosh Saxena, and Silvio Savarese. 2016. Learn-
ing Transferrable Representations for Unsupervised Domain Adaptation.   In
Advances in Neural Information Processing Systems 29, D. D. Lee, M. Sugiyama,
U. V. Luxburg, I. Guyon, and R. Garnett (Eds.). Curran Associates, Inc., 2110–
2118.  http://papers.nips.cc/paper/6360-learning-transferrable-representations-
for-unsupervised-domain-adaptation.pdf
[46]
Jian Shen, Yanru Qu, Weinan Zhang, and Yong Yu. 2018. Wasserstein Distance
Guided Representation Learning for Domain Adaptation. InThirty-Second AAAI
Conference on Artificial Intelligence.
[47]Rui Shu, Hung Bui, Hirokazu Narui, and Stefano Ermon. 2018.  A DIRT-T Ap-
proach to Unsupervised Domain Adaptation. InInternational Conference on Learn-
ing Representations.  https://openreview.net/forum?id=H1q-TM-AW
[48]
J. Stallkamp, M. Schlipsing, J. Salmen, and C. Igel. 2011. The German Traffic Sign
Recognition Benchmark: A multi-class classification competition. InThe 2011
International Joint Conference on Neural Networks. 1453–1460.   https://doi.org/10.
1109/IJCNN.2011.6033395
[49]
Baochen Sun and Kate Saenko. 2016. Deep CORAL: Correlation Alignment for
Deep Domain Adaptation. InComputer Vision – ECCV 2016 Workshops, Gang
Hua and Hervé Jégou (Eds.). Springer International Publishing, Cham, 443–450.
[50]Antti Tarvainen and Harri Valpola. 2017. Mean teachers are better role models:
Weight-averaged consistency targets improve semi-supervised deep learning
results. InAdvances in Neural Information Processing Systems 30, I. Guyon, U. V.
Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett
(Eds.). Curran Associates, Inc., 1195–1204.    http://papers.nips.cc/paper/6719-
mean-teachers-are-better-role-models-weight-averaged-consistency-targets-
improve-semi-supervised-deep-learning-results.pdf
[51]
Eric Tzeng, Judy Hoffman, Trevor Darrell, and Kate Saenko. 2015. Simultaneous
Deep Transfer Across Domains and Tasks. InThe IEEE International Conference
on Computer Vision (ICCV).
[52]Eric Tzeng, Judy Hoffman, Kate Saenko, and Trevor Darrell. 2017. Adversarial
Discriminative Domain Adaptation. InThe IEEE Conference on Computer Vision
and Pattern Recognition (CVPR).
[53]Jiawei Wang, Zhaoshui He, Chengjian Feng, Zhouping Zhu, Qinzhuang Lin,
Jun Lv, and Shengli Xie. 2018.   Domain Confusion with Self Ensembling for
Unsupervised Adaptation.arXiv preprint arXiv:1810.04472(2018).
[54]
Yifei Wang, Wen Li, Dengxin Dai, and Luc Van Gool. 2017. Deep Domain Adap-
tation by Geodesic Distance Minimization. InThe IEEE International Conference
on Computer Vision (ICCV) Workshops.
[55]Kai-Ya Wei and Chiou-Ting Hsu. 2018. Generative Adversarial Guided Learning
for Domain Adaptation.British Machine Vision Conference(2018).
[56]
Garrett Wilson and Diane J. Cook. 2019. A Survey of Unsupervised Deep Domain
Adaptation.arXiv preprint arXiv:1812.02849(2019).
[57]Y. Zhang, N. Wang, S. Cai, and L. Song. 2018. Unsupervised Domain Adaptation
by Mapped Correlation Alignment.IEEE Access6 (2018), 44698–44706.   https:
//doi.org/10.1109/ACCESS.2018.2865249
[58]
Han Zhao, Remi Tachet des Combes, Kun Zhang, and Geoffrey J Gordon. 2019.
On Learning Invariant Representation for Domain Adaptation.arXiv preprint
arXiv:1901.09453(2019).
[59]
Xiaojin Jerry Zhu. 2005.Semi-supervised learning literature survey.  Technical
Report. University of Wisconsin-Madison Department of Computer Sciences.
[60]
Yang Zou, Zhiding Yu, B.V.K. Vijaya Kumar, and Jinsong Wang. 2018.  Unsu-
pervised Domain Adaptation for Semantic Segmentation via Class-Balanced
Self-Training. InThe European Conference on Computer Vision (ECCV). 

A Novel Approach for Detection and Ranking of Trendy and Emerging
Cyber Threat Events in Twitter Streams
Avishek Bose, Vahid Behzadan, Carlos Aguirre, William H. Hsu
abose@ksu.edu, behzadan@ksu.edu, caguirre97@ksu.edu, bhsu@ksu.edu
∗
Department of Computer Science, Kansas State University, Manhattan, Kansas, 66506, USA
Abstract—We  present  a  new  machine  learning  and  text  in-
formation   extraction   approach   to   detection   of   cyber   threat
events  in  Twitter  that  arenovel(previously  non-extant)  and
developing(marked by significance with respect to similarity with
a  previously  detected  event).  While  some  existing  approaches
to  event  detection  measure  novelty  and  trendiness,  typically  as
independent criteria and occasionally as a holistic measure, this
work focuses on detecting both novel and developing events using
an  unsupervised  machine  learning  approach.  Furthermore,  our
proposed  approach  enables  the  ranking  of  cyber  threat  events
based  on  an  importance  score  by  extracting  the  tweet  terms
that are characterized as named entities, keywords, or both. We
also  impute  influence  to  users  in  order  to  assign  a  weighted
score  to  noun  phrases  in  proportion  to  user  influence  and  the
corresponding event scores for named entities and keywords. To
evaluate the performance of our proposed approach, we measure
the efficiency and detection error rate for events over a specified
time  interval,  relative  to  human  annotator  ground  truth.
Index Terms—novelty detection, emerging topics, event detec-
tion, named entity recognition, threat intelligence, user influence,
tweet  analysis
I.  INTRODUCTION
This  paper  presents  a  new  methodology  for  recognizing
potential  cyber  threats  using  passive  filtering  and  ranking
in  social  text  streams,  particularly  Twitter  streams.Passive
monitoring  here  refers  to  collecting  intelligence  and  solu-
tions of different cyber threats from different platforms using
only  text  corpora  and  lists  of  named  entities  or  keywords
(e.g., gazetteers) rather than direct background knowledge of
threats.  Twitter  is  examined  as  a  high-bandwidth  platform
where  both  actors  from  both  sides  of  cyberdefense,  such  as
attackers and security professionals, post cybersecurity-related
messages  [25].  The  overall  goal  of  this  work  is  to  analyze
these  messages  collectively  to  attain  actionable  insights  and
collect intelligence on emergent cyber threat events. Detecting
events  from  social  media  includes  a)novelevent  detection,
including  first  stories  or  tweets  about  previously  non-extant
topics; anddevelopingevents (especially for bursty topics, but
also  for  non-bursty  topics  for  which  volume  and  aggregate
important  build  up  gradually).  In  this  work,  we  treat  novelty
of events from the developing nature of events (emergence) as
orthogonalproperties. This allows novel events that have not
yet attained trending status or viral propagation to be tracked,
while still incorporating traditional trend detection methods.
Recent  research  includes  some  work  on  detecting  both
novel and developing events in Twitter streams (e.g., [2][15]),
especially where emergence is defined as trending. However,
only  a  few  studies  have  further  focused  on  detecting  cyber
threat events in Twitter streams. Furthermore, we propose an
approach to the ranking of events with regards to their signif-
icance.  While  such  a  ranking  generally  depends  on  both  the
application domain and user objectives, the relative importance
to a general community of interest, such as the cybersecurity
community,  can  be  imputed  based  on  pervasiveness,  spread
rate, and novelty. In this study, we also rank the two types of
events  based  on  the  order  of  their  corresponding  importance
score  to  show  how  much  a  particular  event  is  important
compared  to  proximate  events  within  a  user-specified  time
range  of  a  reference  tweet.  In  contrast  with  large  document
corpora,  analyzing  short  documents  such  as  tweets  presents
some  specific  semantic  challenges  towards  extracting  terms,
relationships, patterns, and actionable insights in general. For
example,  terms  mentioned  in  a  short  tweet  lack  context,  and
there is less co-occurrence data in the entire corpus on which
to base expressible relations between named entities or terms.
Our system takes as input a user-specified maximum interval
of detection for related cyber threat events, within an original
tweet  that  is  deemed  relevant.  The  full  text  of  this  tweet,  or
quoted  part  of  a  retweet,  is  captured.  Social  network  param-
eters  such  as  indegree  (number  of  followers)  are  calculated
and  normalized  by  range.  The  text  bodies  of  tweets  are
vectorized  using  term  frequency-inverse  document  frequency
(TFIDF) [23], the resulting TFIDF vectors are clustered using
theDBSCAN[22]  density-based  clustering  algorithm,  noise
points  are  discarded,  and  the  concatenated  text  contents  of
each  cluster  are  ranked  using  theTextRankalgorithm  [20],
to  obtain  representative  keywords  and  named  entities  that
representpotentialevents. We then identify different scenar-
ios:  a)  novel  and  developing  story;  b)  novel  story  only;  c)
developing story only; d) not an event based on heuristics that
are  described  in  Section  IV.  Additionally,  we  also  calculate
an  importance  score  for  each  event  based  on  the  heuristics
presented in Section IV. Finally, we tag each event according
to their descriptive features and provide a rank based on their
importance scores.
Keynovel  contributionsof this work are as follows:
1)  We detect both trendy and novel types of events related
to cybersecurity from Twitter streams.
2)  We provide a method for the ranking of potential cyber
threat events according to their importance score based
on  keywords,  as  well  as  their  named  entity  confidence
and user influence scores.
3)  The proposed method can be tuned to capture important
arXiv:1907.07768v1  [cs.IR]  12 Jul 2019

cybersecurity events based on user-specified parameters.
II.  RELATEDAPPROACHES
This  section  briefly  summarizes  key  methodologies  for
cyber  threat  detection  from  text  corpora,  particularly  social
media.
Dabiri  et  al.[4]  analyzed  traffic  related  tweets  for  detect-
ing  traffic  event  by  applying  deep  learning  models,  includ-
ing  convolutional  and  recurrent  neural  networks  incorporat-
ing  aword2vec-based  word  embedding  layer  to  represent
terms. This approach performs well but is domain-dependent
and  highly  costly  in  terms  of  manual  annotation  for  high-
throughput sources of training data such as Twitter. In contrast,
TwitInfo[3]  incorporates  a  new  streaming  algorithm  that  au-
tomatically discovers peaks of event-related tweets and labels
them  from  the  tweets  texts.  This  approach,  however,  focuses
only burstiness of tweets and ignores both user influence and
novelty with respect to developing events.
Rupinder  et  al.  [9]  also  proposed  a  framework  based  on
deep  learning  for  extracting  cyber  threat  and  security-related
insights from Twitter, categorizing three types of threats (ex-
amples  of  which  are  Distributed  Denial  of  Service  (DDoS)
attacks, data breaches, and account hijacking). From text doc-
uments, events are extracted using a) target domain generation;
b) dynamically-typed query expansion; and c) event extraction.
This  approach  employs  both  syntactic  and  semantic  analysis
using  dependency  tree  graphs  and  convolutional  kernel,  but
is highly computationally intensive due to the cost of autoen-
coder training.
Sceller et al. [13] uses unsupervised learning to detect and
categorize  cybersecurity  events  by  analyzing  cybersecurity-
related Twitter posts based on a set of seed keywords specified
for  each  level  taxonomy.  This  algorithm  is  prone  to  false
negatives  because  it  may  not  detect  potential  cyber  threat
events as events in the first place.
Ranade  et  al.  [5]  propose  a  method  for  processing  threat-
related tweets using the Security Vulnerability Concept Extrac-
tor  (SVCE)  which  generates  tags  about  cybersecurity  threat
or  vulnerabilities  such  as  means  of  an  attack,  consequences
of  an  attack,  affected  software,  hardware,  and  vendors.  This
approach does not generalize to the user communities as it is
personalized for individual users’ system profiles.
Edouard [6] propose a framework that utilizes Named Entity
Recognition (NER) and ontology reasoning (usingDBPedia),
along  with  classification  learning  approaches  such  as  Naive
Bayes,  SVM,  and  a  deep  neural  network  (Long  Short  Term
Memory  /  Recurrent  Neural  Network,  aka  LSTM-RNN),  for
category  tag  imputation.  The  graph  algorithmPageRankis
used to rank candidate items for information retrieval.
The  approach  of  Lee  et  al.  [11]  focuses  on  community
communication and influence to detect cyber threats by group-
ing  highly  contributing  Twitter  users  and  scores  them  as
an  expert  community  to  get  information  to  be  explored  and
then  to  be  efficiently  exploited.  This  framework  incorporates
four  components:  a)  an  interface  to  the  Twitter  social  media
platform;  b)  a  flexible  machine  learning  system  interface  for
document  categorization;  c)  a  mixture-of-experts  weighting
and  extraction  scheme;  d)  a  new  topic  detector.  This  frame-
work is highly dependent on expertise and data quality.
A  method  by  Sapienza  et  al.  [12]  considers  various  web
data  sources  to  generate  indication  of  warnings  for  detecting
upcoming potential cyber threats. While potentially extensible
to named entites discoverable by set expansion, this approach
is  focused  on  detecting  ”novel  words”  and  does  not  yet  in-
corporate a full contextualized topic model, feature weighting
model, or method of user influence.
Finally, the work of Alan et al. [16] is based on a supervised
learning approach to train an extractor for extracting new cat-
egories of cybersecurity events by seeding a small number of
positive event example over a significant amount of unlabeled
data. As with previous approaches, it does not yet incorporate
full NER nor allow for entity set expansion.
III.  BACKGROUND
This section presents a brief review of the key technologies
that  are  adopted  in  our  proposed  framework  for  threat  event
detection in tweets.
A.  Named Entity Recognition (NER)
In general, NER is an information extraction task aimed at
locating and classifying the names of specific entities such as
persons, organizations and locations, based on analysis of text
units such as n-grams and noun phrases. Generic entities such
as  numerical  quantities  are  sometimes  also  included.  In  our
analysis, NER is used to discover the names of entities in re-
ported cyber threats. Key objectives of using machine learning
to  improve  NER  are:  a)  set  expansion  to  broaden  the  set  of
cyber threats based on synonymy and other relationships that
can be inferred by text pattern analysis; b) feature weighting
for relevance or salience; c) relationships that are discoverable
from data; d) confidence scoring.
B.  TextRank
The  TextRank  algorithm  [20]  is  an  extended  version  of
Google   PageRank   [21]   algorithm   that   aims   to   determine
keywords by generating a word graph from a given text doc-
ument unlike determining high ranked webpages that is done
by  the  PageRank  algorithm.  The  TextRank  score  calculates
importance  of  a  word  from  given  a  text  that  is  identical  to
PageRank score works for webpages. The importance however
associated with a vertex is determined based on the votes that
are cast for it, and the vertices’ score casting these votes.
C.  TFIDF
TFIDF   [23]   is   a   information   retrieval   method   used   in
various  purpose  such  as  word  co-occurence  based  document
vectorization,  word  ranking,  document  similarity  calculation,
etc.  In  information  retrieval,  TF  (term  frequency)  refers  to
term  frequency  of  a  particular  word  in  a  document,  while
IDF  (inverse  document  freqency)  refers  to  inverse  document
frequency of a word in the whole corpus of documents.

D.  DBSCAN
DBSCAN[22] is a density-based clustering approach works
by enforcing a minimum number of data points (MinPts) inside
a specified-radius neighborhood (Eps) of a data point to make
adensity-reachablecluster;  this  process  continues  until  no
points on the frontier are density-reachable, then restarts with
a new initial point.
IV.  PROPOSEDMETHOD
Analyzing  Twitter  texts  for  getting  valuable  insights  has
always  been  an  issue  because  of  its  unstructured  way  of
writing and the length of tweets. In this section we go through
some steps described in the subsections below.
A.  Tweet Collection and Early Annotation
In this analysis we used Twitter data collected through four
days  from6
th
September  to9
th
September  in  2018  and  a
small portion of data collected in30
th
and31
th
August, 2018
that  is  stored  in  MongoDB  database.  As  our  main  focus  is
to  getting  insights  of  cybersecurity-related  events  and  rank
their  scores,  we  crawled  Twitter  data  using  the  Twitter  API
based  on  some  security  related  keywords.  Without  applying
security related keywords, the crawled Twitter data would be
generalized to all domains and thus the result would be biased
to detecting general kind of events. This datasets was manually
annotated  whether  the  tweets  are  relevant  to  cyber  security
or  not  by  taking  help  from  four  annotators  for  our  earlier
work  [25].  Although  we  used  security  related  keywords  for
crawling the Twitter data, many of those tweets are irrelevant
or promotional. That is why the annotation plays a crucial role
here  and  the  resulting  dataset  of  this  process  are  available  at
[18]. In this study, we initially have 21368 tweets and working
with the annotated data, we found 11111 tweets are related to
cyber security. We apply our algorithm on those cyber security
related tweets and the whole tweets’ datasets individually. We
took  the  full  text  of  each  tweet  if  the  tweet  is  not  quoted  or
retweeted  from  any  other  users.  If  any  tweet  is  retweeted  or
quoted from any other user, we take the original retweeted or
quoted tweet full text. Then, we let an user to give a numeric
value  input  as  the  number  of  time  intervals  based  on  tweet
occurrence.  This  process  divides  the  whole  time  period  of
tweet  occurrence  into  some  equal  time  chunks  based  on  the
number that we are taking from the user. Thus, for each time
interval a number of tweets are aggregated into a chunk based
on their corresponding occurring time.
B.  Tweet Pre-processing and Cleaning
As  we  stated  earlier  that  tweet  text  is  very  unstructured
that  contains  a  lot  of  misspelled  words  and  sometime  the
text  is  not  a  complete  sentence.  That  is  why  we  apply  a
tool  named  SymSpell  [24]  to  correct  the  misspelled  words.
Then we take only the characters from the tweet text that are
alphanumeric and remove all punctuation characters. Then we
remove  all  the  stopwords  from  the  text  because  these  are  so
frequently  occurred  over  the  whole  data  set  that  may  reduce
the analysis performance. After that we consider cleaning the
tweets’  texts  in  both  cases  either  by  applying  stemming  or
without stemming. We removed all the words or tokens which
lengths are only one.
C.  Influential Twitter user Impact
Influential users tweets are valuable for detecting important
cyber security related events. That is why we keep records of
each Twitter user with their number of followers corresponding
to  their  posted  cyber  security  related  tweets.  As  the  number
of followers represents is directly proportional to the influence
of the  user, their used  words in cyber  security related tweets
are  also  important.  So,  for  each  time  interval,  we  normalize
the values of follower numbers for each user using Min-Max
normalization.  This  normalization  process  normalizes  each
value between 0 and 1. We then assign the normalized value
of users’ follower number to each of their used noun phrases
in  tweets.  Here,  we  used  python  nltk  library  to  extract  noun
phrases from tweets. If similar words are used by several tweet
user,  we  keep  the  highest  normalized  value  of  an  user  for
each  word  used  in  a  tweet.  Now,  for  each  time  interval,  for
all  tweets,  each  noun  phrase  has  a  corresponding  value  that
represents its weight inherited by its user. This value will also
be used to calculate event score.
D.  Determining Algorithm Design Architecture
In  this  study,  we  apply  a  very  popular  word  vectorization
method in NLP domain named tfIdf [23] that is based on word
co-occurrence  in  documents  to  make  word  vector  for  each
tweet from the data set. After doing process mentioned above
for all tweets in a time interval, it generates a tfIdf matrix. We
found this method gives a better performance compared to the
word  semantic  relation  based  approaches  that  are  discussed
later in Section VI. Then, we apply the DBSCAN [22] density
based  clustering  algorithm  using  the  aforementioned  tfIdf
matrix to find cluster of similar meaning tweets. These clusters
can represent the potential events. However, we did not apply
the K-means clustering algorithm because we did want to limit
the  number  of  events  found  in  our  analysis,  for  each  time
interval. For this analysis, we ignore the noise points generated
by applying DBSCAN because in our observation over the data
set we found that the noise points are conveying a very little
impact to find cyber security related events.
E.  Event Detection Heuristics and Scoring
Firsly, we aggregate all tweet texts in a cluster into a single
text.  Then  we  simulate  named  entity  and  keyword  identifi-
cation  process  on  the  aggregated  text  by  applying  TextRazor
[19] online Named Entity recognition API and TextRank [20]
algorithm from Gensim library respectively. Additionally, the
TextRazor provides a Confidence score for each named entity
and TextRank from Gensim [26] also provides a score for each
keyword based on word graph mentioned earlier in Section IV.
We apply two different set rules to determine the type of the
events and and their corresponding score that will be used to
rank  the  cyber  security  related  events.  To  formulate  our  idea

into  implementation,  we  produce  four  different  sets  of  token
set mentioned below.
1)commonSet-refers  the  set  of  words  that  are  common
in  both  named  entity  and  keyword.  Additionally,  we
also  take  some  higher  scored  named  entities  and  key-
words  from  two  setsnamedEntitySetandkeywordSet
mentioned  later  respectively  to  add  the  tokens  to  the
commonSet.
2)keywordSet-refers  the  set  of  words  that  only  appear  in
the keyword set and not common with the named entity
set.
3)namedEntitySet-refers the set of words that only appear
in  the  named  entity  set  and  not  common  with  the
keyword set.
4)unionSet-this set keeps all named entities and keywords.
The  Figure  1  clearly  depicts  the  graphical  illustration  of
four  different  token  sets  mentioned  above.  HerecommonSet,
keywordSet,namedEntitySetandunionSetare  represented  by
k∪(K∩N)∪n,K-N,N-KandK∪(K∩N)∪Nrespectively.
Here,kandnare  the  set  of  highly  scored  keywords  and
named  entities  and  can  be  represented  ask∈Kandn∈N
respectively.
1)  Determine  Event  Novelty:We  store  all  the  tokens  of
the  setnamedEntitySetandcommonSetinto  another  set  of
tokens named asnoveltyCheckerSetfor all clusters generated
for all time intervals. We are storing all these tokens because
we  are  checking  the  similarity  of  the  tokens  from  the  set
of  a  subsequently  generated  cluster  to  the  stored  tokens’  set
noveltyCheckerSetto  determine  whether  the  newly  generated
cluster  has  some  novelty  or  not  based  on  a  cosine  similarity
threshold value determined empirically.
2)  Determining Trendiness:If the similarity score reaches
the defined thresholdcosineThresh, we determine the working
cluster  is  just  trendy  except  the  very  first  cluster  because
this  cluster  would  not  find  any  different  set  to  compare  the
similarity.  We  also  take  a  user  defined  threshold  of  number
of  tweetstweetThreshto  determine  getting  a  trendy  event.
Thus,  if  the  the  number  of  tweets  does  not  reach  to  the
value mentioned by the user, it will be an unnoticeable event.
However, if tweets from a cluster satisfies the cosine similarity
thresholdcosineThreshas well as number of tweets threshold
tweetThresh,  still  it  may  not  represent  a  noticeable  event
because it may be a spamming of banal topic. So, we apply a
different heuristic if the length of thecommonSetset is greater
than the one fifth(0.20) times of thenamedEntitySetset, only
then  the  cluster  will  be  counted  as  trendy.  We  are  checking
this because a big cluster of tweets’ texts will have so many
named entities that will mean a variety of topics but a single
cluster should be biased towards a single topic described in it.
3)  Determining  Novelty:Now,  if  the  cosine  similarity  of
stored  token  set  of  tokensnoveltyCheckerSetand  working
cluster token set is less than the threshold valuecosineThresh,
the working cluster could be a potential novel event. However,
we  set  a  threshold  value  minimum  three  tweets  to  be  in  the
cluster  to  refer  it  as  an  event.  Now,  if  the  number  of  tweets
is  greater  or  equal  than  the  user  defined  threshold  value  of
trendinesstweetThresh, the cluster is addressed as “Novel and
Trendy” but if the number of tweets in the cluster is less than
the number of user defined threshold value, it is addressed as
“Just Novel”. That is how we determine a type of a generated
cluster of tweets as an event type.
4)  Event  Score  Calculation  Process:As  we  mentioned
earlier the ranking of cyber threat related events is also an im-
portant task, we are motivated to calculate score of each event
if an event finds a event type based on our empirically defined
heuristics  mentioned  above.  We  calculate  scores  for  each  of
defined events individually by applying different heuristics. As
the confidence score of a named entity in the TextRazor and
the score of a keyword in the TextRank algorithm are different
in scale, we apply sigmoid function to normalize each scores
of  a  named  entity  and  keyword  respectively.  As  every  token
is stored in a dictionary for each generated cluster, we update
the  score  of  each  token  if  it  considered  both  named  entity
and  keyword  by  adding  two  scores  after  normalizing  by  the
sigmoid function.
5)  Score  Calculation  for  Trendy  Event:Now,  for  a  “Just
Trendy” event firstly we calculate the entity score of the event
by adding the scores of each token included in thecommonSet
and  then  multiplying  the  total  added  value  with  the  value  of
total number of tweets that makes an event as trendy. Secondly,
we added the value of each noun phrases corresponding to the
event’s tweets where the noun phrases are inherited from the
value of influential users’ followers. This score are then added
to the initially calculated entity score mentioned above for the
aggregated tweets’ texts to get the total score. We calculate the
entity score like this mentioned above because, this will assign
a higher score to a trendy event either if tweets in a same topic
appear so many times in a cluster or number of tokens in the
commonSetis  higher.  This  heuristic  assumes  that  even  if  the
event  topic  does  not  appear  so  many  times  in  corresponding
tweets  compared  to  the  other  highly  appeared  event  topics,
because of the number of common tokens in both name entity
and  keywords,  the  heuristic  give  importance  to  those  tokens
as important tokens.
6)  Score  Calculation  for  Trendy  and  Novel  Event:Then
for  a  “Novel  and  Trendy”  event,  we  added  the  values  of  all
the  tokens  of  the  set  being  generated  by  the  union  operation
ofkeywordSetandcommonSet.  Afterwards,  we  multiply  the
added  value  with  the  value  of  total  number  of  tweets  that
represent  the  event  to  calculate  the  entity  score.  Then  we
again added the value of each noun phrases corresponding to
the event’s tweets where the noun phrases are inherited from
the  value  of  influential  users’  followers.  This  score  are  then
added  to  the  entity  score  like  discussed  earlier  in  the  above
paragraph to get the total score. We calculate the entity score
like  this  because  this  event  is  already  proved  to  be  a  novel
event and we need to consider whether it has tokens common
in both named entity and keyword set to check the main topic
discussed  about  in  this  event.  Additionally,  we  also  need  to
consider the keywords appeared in this event to check which
topics are also mentioned in the tweet texts of the novel event.
That  means  a  novel  and  trendy  event  will  get  a  very  higher

score compared to the other events.
7)  Score  Calculation  for  Just  Novel  Event:Now,  for  the
“First  Story”  event,  we  consider  to  keep  a  set  of  tokens
generated  by  differentiatingkeywordSetfromunionSetand
then doing union operation with thecommonSet. This resulting
set  stores  all  the  named  entities  with  the  keywords  which
have  very  high  score.  Then,  we  add  all  the  values  of  the
corresponding  tokens  in  the  resulting  set  and  multiply  the
added value with the user defined threshold valuetweetThresh
for being an event as trendy to get the entity score. Then we
repeat  the  procedure  of  adding  the  value  of  noun  phrases  to
the entity score of the working event. We are calculating the
entity score like this, because if the event is just novel, it will
not appear in so many tweets and that is how it may loose its
importance. So, by means of giving importance to this kind of
events,  we  are  multiplying  the  total  score  of  resulting  set  of
tokens  by  the  value  oftweetThresh.  Thus,  it  can  get  at  least
as importance as any trendy event can acquire. We choose the
aforementioned resulting set because, we need to consider the
novelty of an event that is based on the the confidence score
of the named entity and some high ranked keywords. There is
no mean to consider the whole keyword set right now because
in this case, it seems useless to other trendy topics discussed
except the common ones with named entity set.
8)  Ranking  Scores  of  Events:Our  proposed  approach  re-
peats the above mentioned condition checking for each cluster
whether to determine as an event or not and score calculation
for  each  cluster  that  is  only  considered  as  an  event  for  each
time  interval.  Finally,  we  rank  each  event  by  ordering  their
total  score  for  each  time  interval.  The  flow  chart  of  our
proposed approach is depicted in Figure 2.
F.  Annotation Approach
To evaluate the performance of our proposed approach, we
compared the results of our proposed method with a manually
annotated  list  of  events.  A  subset  of  301  tweets  collected
in  sequence  in  the  window  starting  at  2018-08-30  23:00:08
CST  to  2018-09-02  10:50:19  CST  was  manually  annotated
according  to  i.  impact,  ii.  tweet  count,  and  iii.  worldwide
effect  to  be  considered  as  an  event.  We  also  consider  three
categories whether they are i. first story and novel, ii. trending
or developing, and iii. novel and trending. For validation, we
check the ratio of correctly detected events in that window to
the total number of relevant events, and the ratio of correctly
detected events to the total number of detected events.
V.  EXPERIMENTALRESULTS
A.  Simulation
For  our  analysis,  we  use  scikit  learn  [27]  to  calculate
tfIdf  matrix  [23],  to  apply  DBSCAN  [22]  algorithm  and  to
use cosine similarity. The parameters assignments for making
the  tfIdf  matrix  aremax
df=  0.90,maxfeatures=  200000,
mindf=  0.01  andngramrange=  (1,1).  Then,  parame-
ter  assignments  for  DBSCAN  algorithm  areeps=  1  and
min
samples= 3. Again, we use the cosine similarity threshold
as  0.5  for  similarity  checking  for  trendiness.  Table  I  shows
Fig. 1.   Graphical representation ofcommonSet,keywordSetandnamedEnti-
tySet
TABLE I
Summery Result of five time intervals; NT:Number of Tweets; JT: Just
Trendy; TN: Trendy and Novel; FS: First Story; TE: Total Number of Events
IntervalNTJTTNFSTE
1145011415
2314005050
3812173745
41239091827
529740511
the  result  of  five  time  intervals  collectively  from  2018-08-
30 23:00:08 to 2018-09-02 10:50:19.200000, from 2018-09-02
10:50:19.200000 to 2018-09-04 22:40:30.400000, from 2018-
09-04 22:40:30.400000 to 2018-09-07 10:30:41.600000, from
2018-09-07 10:30:41.600000 to 2018-09-09 22:20:52.800000
and    from    2018-09-09    22:20:52.800000    to    2018-09-12
10:11:04 by Interval 1, 2, 3, 4 and 5 respectively. We keep only
detected  True  Positive  events  and  represent  in  Table  I.  From
Table I we can see for the first interval (2018-08-30 23:00:08
to 2018-09-02 10:50:19.200000) we have total 145 tweets and
total 15 events. Moreover, out of 15 events we got no “Trendy
Event”,  1  “Novel  and  Trendy  Event”  and  14  “Novel  Event”.
This  description  will  be  continued  for  rest  of  the  intervals
similarly. In Table II we show the extracted keywords for each
event  for  the  first  time  interval.  The  keywords  mentioned  in
the  Table  II  are  used  to  detect  cyber  security  related  events
for the first time interval. For better representation, We show
only the plot of the2
nd
time interval in Fig. 3 because of the
paper space limitation. This figure depicts the found events in
x axis, the amount of tweets on left side of figure 3 in y axis
and  the  event  score  on  the  right  side  of  figure  3  in  y  axis.
The red vertical bar represents number of tweets and the blue
vertical bar represents event score for each detected event.
B.  Annotation-Based Validation
1)  Design Selection Approach:There are few decision we
had  to  make  to  formulate  the  design  architecture  of  this
algorithm. Firstly, we thought to analyze the semantic relation
between  the  words  of  each  tweet  text  to  get  the  insights
of  cyber  security  events.  That  is  why  we  previously  applied
doc2Vec  [28]  which  is  an  extended  application  of  word2vec
[30]  for  getting  similar  meaning  tweets  to  find  events  from
the  data  sets  but  we  could  not  get  any  satisfactory  result

Fig. 2.   Flowchart of the proposed approach
Fig. 3.   Event plot of the second time interval proposed approach
because  we  found  that  shallow  neural  network  model  text
domain  tools  like  doc2Vec  [28]  works  based  on  word  vector
embeddings that does not perform well for short and noisy text
data  set.  Embedding  methods  did  not  work  properly  in  short
texts  because  tokens  in  a  short  text  have  a  thin  contextual
relation  between  each  other  and  this  relation  get  worse  due
to  misspelled  and  incomprehensible  tokens.  A  sample  result
of  doc2Vec  applying  hypermeter  valuesvector
size=  300,
mincount= 2 andepochs= 45 respectively is shown in Table
IV  that  exhibits  most  similar  tweet  and  second  most  similar
tweet  of  a  particular  tweet  that  does  not  have  any  noticeable
similarity  with  any  of  those  tweet  document  whereas  a  doc-
ument  must  show  similarity  with  at  least  to  itself.  Similarity
score of each tweet to the particular tweet is represented inside
the  parentheses  in  the  first  column.  Again,  we  thought  in  a
different way to apply LDA [29] to find some topics that may
represent events. Since the tweet text is very short, almost all
of  the  time  a  tweet  does  not  represent  more  that  one  event.
That is why, we decided to apply LDA [29] on the aggregated
tweet texts from corresponding time intervals. This, approach
also fails to show the expected result because of the incoherent
nature  of  tweet  text.  Due  to  the  space  limitation  of  the  we
could not present in this work. Thus, we decided to apply very
popular tfIdf vectorization because we found that words in a
tweet text has a few semantic relation between each other and
word  co-occurrence  is  better  option  to  apply  in  this  domain.
Consequently,  we  found  a  better  performance  by  comparing
the result with the previously applied approaches.

TABLE II
Summery result of time interval 1(’2018-08-30 23:00:08’, ’2018-09-02 10:50:19.200000’)
Event NumberNKeywords
0’security’, ’android (operating system)’, ’android’, ’wi-fi’, ’privacy’
1’microsoft’, ’disclosed’, ’twitter’, ’windows’, ’microsoft windows’, ’hacker discloses’
2’website’, ’catalonia’, ’spain’, ’banking’, ’bank’, ’inf’
3’based’, ’huff’, ’buffer overflow’
4’vulnerability (computing)’, ’security’, ’repository’, ’critical vulnerability’, ’apache’, ’inf’
5’vulnerability’, ’resource consumption’, ’prior’, ’resource’, ’rsa’, ’bleach’
6’task’,’windows’,’patch,’scheduler’
7’security’, ’android (operating system)’, ’android’, ’data’, ’privacy’, ’tracking’
8’cracking ransom’, ’coin’, ’free’, ’ransom’, ’cybersex’, ’net’
9’vulnerability (computing)’, ’patch’, ’spyware’, ’phishing’, ’inf sec cube security’, ’patched’, ’malware’
10’security’, ’website’
11’plus’, ’pump’
12’version’, ’web server’, ’debugger’, ’skype’, ’update’, ’denial service’, ’exploit (computer security)’
13’cisco systems’, ’service’, ’cisco’
14security’, ’photo’,’service’
TABLE III
Summery result of time interval 1(’2018-08-30 23:00:08’, ’2018-09-02 10:50:19.200000’);EN: Event Number;EL: Event Link; TC:Tweets Count
NESR:Normalized Event Score Rank;ET: Event Type; AER: Annotator Event Ranking; DBR: Difference between Rankings; FS: First Story (novel); FST:
First Story and Trendy (developing)
ENTCEvent ScoreNESRETELAERDBR
05167.60845FSlink141
17211.0333FSLink221
221190.59504FSLink331
3355.322610FSNA133
412110.60489FSLink472
54130.41698FSLink580
6317.222514FSLink6104
76145.79387FSLink752
88154.31156FSLink860
95389.70822FSLink997
10440.063913FSNA141
11746.470612FSLink10120
1251391.33911FSTLink1110
13552.890611FSLink12110
14416.934515FSNA150
TABLE IV
Sample result of doc2Vec
TermsTexts
Documentguides   on   fixing   sql   injections   vul-
nerabilities sql injection technique ex-
ploits  security  vulnerability  occurring
database layer application the vulnera-
bility present user input either
MostSimilar
(0.8027611970901489)
free vps server ddos protected hosting
SecondMostSimilar
(0.6457577347755432)
cvnway just ddos server
Median(
0.21316465735435486)
minibb  bbfuncsearchphp  table  sql  in-
jection
Least (-0.4030833840370178)ransomware weapon used cyber attacks
elixir ng news source trust
2)  Validation  of  the  Approach:Table  V  shows  the  perfor-
mance result of our proposed approach according to the eval-
uation methodology described in Section IV-F. The annotators
annotate  301  and  found  total  20  events  and  6  tweet  clusters
that are not events. On the other hand, the our algorithm found
total  16  events.  Now,  15  events  out  of  16  events  are  real
events  (True  Positive)  included  in  20  ground  truth  but  one
event  is  False  positive.  So,  the  True  Positive,  False  Positive,
False  Negative  and  True  Negative  rates  are  75%,  16.67%,
25%  and  83.33%  respectively  and  we  got  a  good  precision
value  that  is  93.75%.  An  interesting  news  is  that  we  can
only  stream  a  very  small  amount  of  tweets  per  millisecond
approximately 1%  of the  total tweet  posted that  is addressed
in  this  web  article  [31].  So,  the  Twitter  data  itself  only  is
not sufficient to detect all of the ongoing cyber security event
and  that  is  why  we  limit  ourself  to  calculate  recall  score  by
keeping  track  published  cyber  security  events  in  online.  In
Table  III,  we  present  the  fifteen  true  positive  events,  along
with  their  tweet  count  and  their  corresponding  scores.  We
order the events by their corresponding scores and match with
the  annotators’  annotations.  The4
th
and  the7
th
column  of
the  Table  III  present  proposed  approach  event  ranking  and
annotators’ ranking respectively and comparing the4
th
and the
7
th
column of the table, we can see the annotators predictions
are quite similar to our approach in case of event detection and

event  ranking.  The  validity  of  the  detection  approach  can  be
checked by clicking the link mentioned in the6
th
column to
see  the  reports  published  in  authentic  blogs  and  newspapers.
The5
th
column represents the type of events detected by our
algorithm. The sum squared error (SSE) of the event ranking
of  our approach  and annotator’s  ranking is  86  by calculating
the difference mentioned in the8
th
column of the table.
TABLE V
Confusion matrix of the algorithm’s generated result
Total PopulationGround Truth positiveGround Truth negative
Derived positiveTrue
Positive=75%
FalsePosi-
tive=16.67%
Derived negativeFalse
Negative=25%
TrueNega-
tive=83.33%
VI.  CONCLUSION
We presented a novel machine learning and text information
extraction method for the detection of cyber threat events from
tweets. We considered two types of such events, those that are
novel,  and  those  that  are  further  developments  of  previously
detected  tweets.  Furthermore,  we  proposed  an  approach  for
the  ranking  of  cyber  threat  events  based  on  an  importance
score computed based on the named entities and keywords in
the text of tweets. We also impute influence to users in order
to  assign  a  weighted  score  to  noun  phrases  in  proportion  to
user  influence  and  the  corresponding  event  scores  for  named
entities  and  keywords.  To  evaluate  the  performance  of  our
proposals, we measure the efficiency and detection error rate
for  events  over  a  specified  time  interval,  relative  to  human
annotator  ground  truth,  and  demonstrate  the  feasibility  of  its
application in detecting cyber threat events from tweets. Future
directions of this research include the extension of our current
method for detection and ranking of sub-events in each cyber
threat event. Moreover, the heuristics applied in this work are
presented as proofs of concept, while leaving room for further
enhancement and customization per user requirements. As fur-
ther venue of future word, the methodology used for influence
measurement of users can be extended via means such as meta-
network  modeling  and  link  extraction  of  the  dynamic  social
network of users that are active in the cybersecurity domain.
REFERENCES
[1]  Q.  Li,  A.  Nourbakhsh,  S.  Shah  and  X.  Liu,  “Real-Time  Novel  Event
Detection from Social Media,”2017 IEEE 33rd International Conference
on Data Engineering (ICDE), San Diego, CA, 2017, pp. 1129-1139. doi:
10.1109/ICDE.2017.157
[2]  Mario Cataldi, Luigi Di Caro, and Claudio Schifanella. 2010. “ Emerging
topic detection on Twitter based on temporal and social terms evaluation”,
In Proceedings of the Tenth International Workshop on Multimedia Data
Mining (MDMKDD ’10). ACM, New York, NY, USA, Article 4, 10 pages.
DOI: https://doi.org/10.1145/1814245.1814249.
[3]  Adam  Marcus,  Michael  S.  Bernstein,  Osama  Badar,  David  R.  Karger,
Samuel   Madden,   and   Robert   C.   Miller.   2011.,“Twitinfo:   aggregat-
ing  and  visualizing  microblogs  for  event  exploration.”,In  Proceed-
ings   of   the   SIGCHI   Conference   on   Human   Factors   in   Computing
Systems   (CHI   ’11).   ACM,   New   York,   NY,   USA,   227-236.   DOI:
https://doi.org/10.1145/1978942.1978975.
[4]  Sina  Dabiri,  Kevin  Heaslip,“Developing  a  Twitter-based  traffic  event
detection   model   using   deep   learning   architectures”,Expert   Systems
with Applications, Volume 118, 2019, Pages 425-439, ISSN 0957-4174,
https://doi.org/10.1016/j.eswa.2018.10.017.
[5]  P. Ranade, S. Mittal, A. Joshi and K. Joshi,“Using Deep Neural Networks
to Translate Multi-lingual Threat Intelligence”,2018 IEEE International
Conference  on  Intelligence  and  Security  Informatics  (ISI),  Miami,  FL,
2018, pp. 238-243. doi: 10.1109/ISI.2018.8587374.
[6]  A.   Edouard,“Event   detection   and   analysis   on   short   text   messages”,
Universit Cte d’Azur, 2017.
[7]  W. Li and Y. Huang,“New Event Detect Based on LDA and Correlation
of Subject Terms”,2011 International Conference on Internet Technology
and Applications, Wuhan, 2011, pp. 1-4. doi: 10.1109/ITAP.2011.6006301
[8]  Lau,  Jey  Han,  Nigel  Collier,  and  Timothy  Baldwin.“On-line  trend  anal-
ysis  with  topic  models:#  twitter  trends  detection  topic  model  online.”,
Proceedings of COLING, 2012 (2012): 1519-1534.
[9]  Rupinder  Paul  Khandpur,  Taoran  Ji,  Steve  Jan,  Gang  Wang,  Chang-
Tien  Lu,  and  Naren  Ramakrishnan.  2017.“Crowdsourcing  Cybersecu-
rity:  Cyber  Attack  Detection  using  Social  Media”,In  Proceedings  of
the  2017  ACM  on  Conference  on  Information  and  Knowledge  Man-
agement  (CIKM  ’17).ACM,  New  York,  NY,  USA,  1049-1057.  DOI:
https://doi.org/10.1145/3132847.3132866
[10]  Wurzer,  Dominik,  Victor  Lavrenko,  and  Miles  Osborne.“Twitter-scale
new   event   detection   via   k-term   hashing.”Proceedings   of   the   2015
Conference on Empirical Methods in Natural Language Processing, pp.
2584-2589.
[11]  K.-C.  Lee,  C.-H.  Hsieh,  L.-J.  Wei,  C.-H.  Mao,  J.-H.  Dai,  and  Y.-
T.  Kuang,“Sec-buzzer:  cyber  security  emerging  topic  mining  with  open
threat intelligence retrieval and timeline event annotation”,Soft Comput-
ing, vol. 21, no. 11, pp. 28832896, 2017.
[12]  Sapienza,  Anna,  Sindhu  Kiranmai  Ernala,  Alessandro  Bessi,  Kristina
Lerman, and Emilio Ferrara. “Discover: Mining online chatter for emerg-
ing cyber threats.”Companion of the The Web Conference 2018 on The
Web  Conference  2018,  pp.  983-990.  International  World  Wide  Web
Conferences Steering Committee, 2018.
[13]  Quentin  Le  Sceller,  ElMouatez  Billah  Karbab,  Mourad  Debbabi,  and
Farkhund  Iqbal.  2017.“SONAR:  Automatic  Detection  of  Cyber  Secu-
rity  Events  over  the  Twitter  Stream.”Proceedings  of  the  12th  Inter-
national   Conference   on   Availability,   Reliability   and   Security   (ARES
’17).   ACM,   New   York,   NY,   USA,   Article   23,   11   pages.   DOI:
https://doi.org/10.1145/3098954.3098992
[14]  Xiaojing   Liao,   Kan   Yuan,   XiaoFeng   Wang,   Zhou   Li,   Luyi   Xing,
and  Raheem  Beyah.  2016.“Acing  the  IOC  Game:  Toward  Automatic
Discovery  and  Analysis  of  Open-Source  Cyber  Threat  Intelligence.”
Proceedings  of  the  2016  ACM  SIGSAC  Conference  on  Computer  and
Communications  Security  (CCS  ’16).  ACM,  New  York,  NY,  USA,  755-
766. DOI: https://doi.org/10.1145/2976749.2978315
[15]  Ifrim,  Georgiana,  Bichen  Shi,  and  Igor  Brigadir.“Event  Detection  in
Twitter  using  Aggressive  Filtering  and  Hierarchical  Tweet  Clustering.”
In SNOW-DC@ WWW, pp. 33-40. 2014.
[16]  Alan   Ritter,   Evan   Wright,   William   Casey,   and   Tom   Mitchell.
2015.“Weakly Supervised Extraction of Computer Security Events from
Twitter.”n  Proceedings  of  the  24th  International  Conference  on  World
Wide  Web  (WWW  ’15).  International  World  Wide  Web  Conferences
Steering Committee, Republic and Canton of Geneva, Switzerland, 896-
905. DOI: https://doi.org/10.1145/2736277.2741083
[17]  Branco,  Eunice  Picareta.“Cyberthreat  discovery  in  open  source  intelli-
gence using deep learning techniques.”PhD dissertation, 2017.
[18]  https://github.com/behzadanksu/cybertweets
[19]  TextRazor-2019;https://www.textrazor.com/
[20]  Mihalcea,  Rada,  and  Paul  Tarau.  “Textrank:  Bringing  order  into  text.”
Proceedings  of  the  2004  conference  on  empirical  methods  in  natural
language processing. 2004.
[21]  Page,  Lawrence,  Sergey  Brin,  Rajeev  Motwani,  and  Terry  Winograd.
“The  PageRank  citation  ranking:  Bringing  order  to  the  web”.Stanford
InfoLab, 1999.
[22]  Ester,  Martin,  Hans-Peter  Kriegel,  Jrg  Sander,  and  Xiaowei  Xu.  “A
density-based algorithm for discovering clusters in large spatial databases
with noise.”Kdd, vol. 96, no. 34, pp. 226-231. 1996.
[23]  H.  Wu  and  R.  Luk  and  K.  Wong  and  K.  Kwok.  “Interpreting  TF-
IDF term weights as making relevance decisions.ACM Transactions on
Information Systems, 26 (3). 2008.
[24]  WolfGarbe¡wolf.garbe@faroo.com¿,“SymSpell6.4”,
https://github.com/wolfgarbe/symspell

[25]  Behzadan,  Vahid,  Carlos  Aguirre,  Avishek  Bose,  and  William  Hsu.
“Corpus  and  Deep  Learning  Classifier  for  Collection  of  Cyber  Threat
Indicators  in  Twitter  Stream”.2018  IEEE  International  Conference  on
Big Data (Big Data), pp. 5002-5007. IEEE, 2018.
[26]  Radim rehurek and Petr Sojka“Software Framework for Topic Modelling
with  Large  Corpora”,Proceedings  of  the  LREC  2010  Workshop  on  New
Challenges  for  NLP  Frameworks,pages  45–50,  May  22,  2010;  DOI:
http://is.muni.cz/publication/884893/en
[27]  Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V. and
Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P. and Weiss,
R. and Dubourg, V. and Vanderplas, J. and Passos, A. and Cournapeau,
D.  and  Brucher,  M.  and  Perrot,  M.  and  Duchesnay,  E.,  “Scikit-learn:
Machine  Learning  in  Python”Journal  of  Machine  Learning  Research,
volume 12, pp 2825–2830, 2011
[28]  Le, Quoc, and Tomas Mikolov. “Distributed representations of sentences
and  documents.”  InInternational  conference  on  machine  learning,  pp.
1188-1196. 2014.
[29]  Blei,  David  M.;  Ng,  Andrew  Y.;  Jordan,  Michael  I  (January  2003).
Lafferty,  John  (ed.).  “Latent  Dirichlet  Allocation”.Journal  of  Machine
Learning Research. 3 (45): pp. 9931022.
[30]  Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean.“Efficient es-
timation of word representations in vector space”.CoRR, abs/1301.3781,
2013.
[31]  Andy Piper, “Potential adjustments to Streaming API sample volumes”,
https://twittercommunity.com/t/potential-adjustments-to-streaming-api-
sample-volumes/31628, Feb 2, 2015. 

OmniNet: A unified architecture for multi-modal
multi-task learning
Subhojeet Pramanik
∗
IBM Watson
email@subho.in
Priyanka Agrawal
IBM Research
pagrawal.ml@gmail.com
Aman Hussain
University of Amsterdam
email@amanhussain.com
Abstract
Transformer is a popularly used neural network architecture, especially for language
understanding. We introduce an extended and unified architecture which can be
used for tasks involving a variety of modalities like image, text, videos, etc. We
propose a spatio-temporal cache mechanism that enables learning spatial dimension
of the input in addition to the hidden states corresponding to the temporal input
sequence.  The proposed architecture further enables a single model to support
tasks with multiple input modalities as well as asynchronous multi-task learning,
thus we refer to it asOmniNet.  For example, a single instance ofOmniNetcan
concurrently learn to perform the tasks of part-of-speech tagging, image captioning,
visual question answering and video activity recognition.  We demonstrate that
training these four tasks together results in about three times compressed model
while retaining the performance in comparison to training them individually. We
also show that using this neural network pre-trained on some modalities assists
in learning an unseen task.   This illustrates the generalization capacity of the
self-attention mechanism on the spatio-temporal cache present inOmniNet.
2
1    Introduction
Transformer [1] is currently one of the best performing models for any sequence transduction tasks,
especially those involving natural language. It is originally designed for a single task at a time. In
fact, most of the generic deep learning architectures [2,3,4] that have been designed and developed
are able to learn, albeit very well, a single task and handle one task specific input domain like image,
text or audio. Furthermore with these models, we often rely on the generalization capability of the
trained network to guarantee performance on unseen examples. Transfer learning [5,6] is another
popular paradigm used to adapt the model to learn a related task with similar input domain.  The
success of neural networks across these challenges is known to be due to their ability in learning
effective representations of the data.  For example, the self-attention mechanism in Transformers
can capture the global temporal dependence in sequential data very well.  Naturally, the question
arises whether we can extend these architectures, like the Transformer, to be able to learn shared
representations from multiple input domains and to be able attend on them representations to perform
a multitude of tasks concurrently.
The research into multi-task models that learn to solve varied tasks across a multitude of input
domains is not new.  Work done in [7] demonstrates an architecture capable of learning a shared
representation across audio and video modalities. Similarly in [8] a convolutional architecture has
been designed to support a variety of NLP tasks. However, most of these architectures are designed
to learn specific set of tasks with known input domains. To the best of our knowledge, there does not
exist a single unified architecture that works out of the box for any combination of multi-modal tasks.
∗
Corresponding author
2
Source code available at:https://github.com/subho406/OmniNet
Preprint. Under review.
arXiv:1907.07804v1  [cs.LG]  17 Jul 2019

To address this gap, we introduce a unified architecture, namelyOmniNet, which enables a single
model to support tasks with multiple input modalities and asynchronous multi-task learning.OmniNet
mimics a computer in terms of input peripherals to support any input modality and a Central Neural
Processor (CNP) that enables multi-task learning. We consider that most real-life data like image,
text, speech, video, etc. is a direct conjunction of spatial and temporal components. Therefore, we
employ a spatio-temporal cache mechanism to learn a shared representation of the input data across
the spatial (space) and temporal (time) dimension. Using a generalizedencode()function,OmniNet
can process and store spatio-temporal representation for each of the input domains and thendecode()
predictions across a multitude of tasks. In our experiments, we train a single compressed instance of
theOmniNetto solve several multi-domain tasks such as part-of-speech tagging, image captioning,
visual question answering and video activity recognition. To make our work reproducible, open to
scrutiny and further development, we have open sourced a demonstration of our system implemented
using Pytorch [9] athttps://github.com/subho406/OmniNet.
2    Related Work
Multi-task learning has been extensively studied in the literature, with applications to a wide set of
problems ranging from natural language processing (NLP) [8,10,11] to speech recognition [12,13]
to vision [14,15,16]. It has also found its use in a combination of diverse tasks like image captioning
and text translation and parsing [17,18]. However, most of these architectures assume the set of tasks
to be known in advance. Similarly, multi-modal learning has been essential for solving a broad range
of interesting problems such as Visual Question Answering [19,20] and Video Question Answering
[21]. Again, the state-of-the-art models are highly specific to the objective in hand and not easily
adaptable to different tasks or domains.
The closest work towards a universal multi-modal multi-task model is the MultiModel [22] architec-
ture which demonstrated for the first time, the ability to learn a multitude of tasks of varying input
domains. However, the MultiModel architecture lacks support for multi-modal tasks with more than
one input domains such as visual question answering. Further, it only attends over the temporal states
of the input data and includes no mechanism to attend over the spatial aspects of the data.  To the
best of our knowledge, our architecture is the first to unify the encoding process on any number of
input domains and includes mechanisms to jointly attend on spatial and temporal representations of
multiple input domains at the same time.
3    Proposed Model
We propose a unified architecture, namelyOmniNet, to enable learning multi-modal tasks with
multiple input domains and support generic multi-tasking for any set of tasks. TheOmniNetarchitec-
ture consists of multiple sub-networks, called peripheral networks, connected to a common central
neural network called the Central Neural Processor (CNP) (Figure1). Each peripheral network is
used to encode the domain specific input into feature representations.  In this work, we describe
image, text and video peripherals (Section3.1). One can add more, say speech peripheral, depending
on the task.  The output representation of a peripheral network is always a spatio-temporal tensor
x∈R
t×s×d
model
, wheret&sare the temporal and spatial dimensions of the input respectively, and
d
model
is the model dimension input to the Central Neural Processor.
The spatio-temporal representations generated by the peripheral networks corresponding to each input
domain are then processed by the Central Neural Processor (CNP). The CNP uses fully attention
based encoder-decoder [23,24,25] model for sequence transduction similar to the Transformer
architecture [1], which is the state-of-the-art for multiple language modeling tasks (Section3.2).
During the encoding stage, the CNP implements a genericencode(x,D)function to first process
and store the spatio-temporal representations of the input, wherex∈R
t×s×d
model
is the spatio-
temporal tensor produced by the peripheral networks andD∈Z: 0≤D < D
len
is the domain
id andD
len
is the max number of domains supported by the CNP. Theencode()function is called
multiple times, once for each multi-modal input from respective peripheral.  During the decoding
stage, adecode(y
shifted
,τ)function is used to decode predictions as softmax probabilities, where
y
shifted
∈Z
N−1
are the target outputs shifted one time-step to the right,Nis the length of the
output sequence;τ∈Z: 0≤τ < τ
len
is task id andτ
len
is the total number of supported tasks. The
2

Figure 1:OmniNetperforming image captioning, visual question answering and POS tagging at once
decoding step is similar to [1], modified to incorporate a two-step attention mechanism over spatial
and temporal cache.
3.1    Peripheral networks
First, we elaborate on how we support multiple input domains using peripheral networks. A peripheral
network can use a pre-trained model from existing literature to ultimately encode a given domain
input to a standardized feature representationx∈R
t×s×d
model
, wheret&sare the temporal and
spatial dimensions of the input respectively, andd
model
is the model dimension input to the Central
Neural Processor. Here we detail text and vision peripherals and one can add more peripherals or
alter the peripheral design depending on the task.
Vision peripheral:
This peripheral uses a convolutional neural network to encode image and video
inputs in the tasks. In our experiments, we use the pre-trainedResNet-152model, a variant of ResNet
[26] consisting of 152 convolutional layers. We removed the final fully connected and avg-pooling
layers to generate spatial feature representations for a given image/video. For an image of dimension
h×w×n
c
,ResNetdown-samples the image intoh
′
×w
′
×n
′
c
, whereh,w,n
c
are the height,
width and number of input channels. For a video, each frame is input to the peripheral to produce
F×h
′
×w
′
×n
′
c
, whereFis the total number of frames in the video.  The encoding vectors are
then projected to dimensiond
model
using a fully connected layer. The output is then reshaped into a
spatio-temporal tensor ofx∈R
t×h
′
w
′
×d
model
, wheretequal to1for an image andFfor a video.
Language peripheral:
The Language peripheral uses byte-pair encoding [27] to generate subwords
for a given input sentence.  The subwords are passed to an embedding layer to generate subword
embeddings of dimensiond
emb
and projected to dimensiond
model
using a fully connected layer.
We used pre-trained subword embeddings withd
emb
= 300andvocab_size= 25000from [28],
which includes pre-trained subword embeddings of over 275 languages, to initialize the weights of
the embedding matrix. The output is then reshaped into a spatio-temporal tensorx∈R
t×1×d
model
,
wheretequal to number of subwords in the input sentence. As we do not have any spatial dimension
in textual data, the spatial dimension ofxfrom a Language peripheral is always 1.
3.2    Central Neural Processor (CNP)
To process the spatio-temporal information in the input data, the CNP implements a spatial cache
C
s
, temporal cacheC
t
and a link arrayL.  The spatial and temporal cache and the link array are
a list of elements, initialized as empty before the encoding process.  During the encoding stage,
an encode() routine takes as input, the tensorxgenerated from the peripheral and corresponding
domain/peripheral idD. This function processes the spatial and temporal information in the inputx
and stores them into the spatial cacheC
s
and the temporal cacheC
t
, respectively and stores their
dimensionst&sin the link array. For a given task, this encode() routine is calledKtimes, whereK
is the number of inputs in the task. Note that these inputs can belong to same or different domains.
The function is defined as follows:
3

Figure 2:left:TemporalEncoderarchitecture;right:OmniNet decode()architecture.
Encode (x,D):
For a given inputx∈R
t×s×d
model
and domain identifierD, theencode()routine
is described in Algorithm1.  Since inputs can come from multiple peripherals, the algorithm first
concatenates the input with the domain embedding to ensure a domain-aware encoding of the input
(Steps 2 to 3). Steps 4 to 7 process the spatial information inxby unrolling the time dimension and
adding these unrolled vectors into the spatial cache. Steps 8 to 10 process the temporal information
inxby averaging the spatial dimension ofxand then passing the averaged tensor to a self-attention
basedTemporalEncoder.  ThisTemporalEncoderis similar to the encoder used in [1] as shown
in Figure2is used to calculate temporal embeddings of the input sequence.  The output from the
TemporalEncoderis appended to the temporal cache.
The above encoding routine keeps appending spatio-temporal information toC
t
&C
s
for each input
x
k
∈R
t
k
×s
k
×d
model
. Note the superscriptkto denote correspondence tok-th input of the task, where
k∈1,...,K. AfterKcalls, we have the temporal cacheC
t
= [T
1
,...,T
R
], whereR=
∑
K
r=1
t
r
;
the spatial cacheC
s
= [S
1
,...,S
P
], whereP={
∑
p
t
p
∗s
p
:p∈1,...,K∧s
p
>1}and the link
arrayL= [(t
1
→s
1
),...,(t
K
→s
K
)]. Note thatC
s
can also be empty in case theencode()is only
called with inputs withs
k
= 1∀k.  Next, we use thedecode()function to generate predictions as
softmax probabilities:
Decode (y
shifted
,τ)
: The architecture of thedecode()function is shown in Figure2. Thedecode()
takes as argument the output labelsy
shifted
shifted one time step to the right, a task idτand generates
predictions by attending from the spatial and temporal cache. Thedecode()function is structured
similar to the decoder used in theTransformerarchitecture [1] and jointly attends on the vectors
stored in the temporal and spatial cache. Similar to [1], the decoding first starts by attending over the
output embeddings using masked multi-head scaled dot product attention. The attention layer for the
temporal cache uses scaled dot-product attention with multiple heads as specified in [1]. The attention
4

Algorithm 1encode(): Encodes spatial and temporal representations into spatial and temporal cache
Require:x∈R
t×s×d
model
,D,C
s
,L,C
t
1:L←L∪(t→s)
2:D
emb
←EmbedLayer(D)
3:x←FC(Concat(x,D
emb
),d
model
)
4:ifs >1then
5:S←Reshape(x,(ts,d
model
)){where, outputS= [S
1
,...,S
ts
]s.t.S
i
∈R
d
model
is a
spatial feature vector.}
6:C
s
←C
s
∪[S
1
,...,S
ts
]{Append spatial representations to spatial cache}
7:end if
8:T←(
∑
s
i=1
x[:,i,:])/s
9:T←TemporalEncoder(T)
{where, outputT= [T
1
,...,T
t
]s.t.T
j
∈R
d
model
is the encoding
of temporal dimension inx.}
10:C
t
←C
t
∪[T
1
,...,T
t
]{Append temporal representations to temporal cache}
layer for the spatial cache, uses gated multi-head attention to attend over the elements of the spatial
cache.  For inputs with both time and space dimension (e.g.  video), we want the spatial attention
layer to attend more on frames which have relatively high attention scores in the temporal cache
attention layer. Therefore, the attention score output from the temporal cache multi-head attention
layerA∈R
n
h
×N×R
, is used to calculate the tensorG∈R
n
h
×N×P
used for gating the attention
score output in the spatial attention layer, wheren
h
is the number of heads in multi-head attention as
described in [1]. The tensorGis calculated usingA&Las detailed in Algorithm 2.
Algorithm 2CalculateGusing output scores from temporal attention and link array
Require:L,A
1:idx←0
2:for eacht, s in Ldo
3:G←[]
4:ifs >0then
5:A
′
←A[:,:,idx:idx+t]
6:A
′
←Expand(A
′
,(n
h
,N,t,s))
{whereExpand(tensor,dimension)expands tensor
according to a given dimension}
7:A
′
←Reshape(A
′
,(n
h
,N,ts))
8:G←G∪A
′
{Append the respective temporal attention scores toG}
9:end if
10:idx←idx+t
11:end for
12:G←Stack(G){Stack the list of tensors to construct tensorGof dimension(n
h
,N,P)}
Given
3
Q: the matrix of queries,K: keys of dimensiond
k
andV: values of dimensiond
v
, the scaled
dot-product attention for the spatial layer is modified as:
Attention(Q,K,V,G) =
(
softmax(
QK
T
√
d
v
)G
)
V(1)
In  order  to  use  the  same  CNP  for  multiple  tasks  with  varying  output  vocabularies,   we
use   multiple   output   embedding   layersOutputEmbedLayer
1
,...,OutputEmbedLayer
τ
len
,
to  generate  the  output  embeddings  for  each  task.At  the  final  layer,   we  use  multiple
(FC+Softmax)
1
,...,(FC+Softmax)
τ
len
classification layers for each task. We also calculate
a task embedding vector usingτand always start decoding using the task embedding vector.
3.3    Multi-task learning
In order to train a single a model simultaneously on mutiple tasks we used the HogWild training
approach as described in [29]. Similar to the approach described in [30], the main process holds a
3
For brevity, we reuse the notations of [1] in this description
5

global copy of the model. We create separate worker processes for each task, where each process
maintains a local copy of a model. At each training iteration, each process starts by synchronizing
its local model with the global copy.  This is done through forward and backward propagation on
its local copy and then copying the locally computed gradients to the global model asynchronously.
Each process then calls the global model optimizer asynchronously to update the weights of the
global model. Instead of storing the model in CPU as in [30] we always store the local copies across
multiple GPUs.
4    Tasks and Setup
We evaluate the effectiveness of our proposed framework for four tasks of different domains (text,
images, video): Image Captioning, Part-of-Speech (POS) tagging, Visual Question Answering (VQA)
and Video-activity Recognition. The hyperparamter values used forn
h
,d
model
,N_Layers,d
k
,d
v
are same as that specified in Transformer base model [1]. For training, we always use cross-entropy
loss with Adam optimizer [31] and schedule the learning rate using Noam scheduler [32] similar to
[1].  In this section, we provide details on datasets used for the experimental analysis.  We further
elaborate on the model setup for each of these tasks.
Part-of-speech Tagging:
To illustrate the task with only temporal modality (t >1&s= 1,
wheretandsare the temporal and spatial dimensions of the input respectively), we consider the
part-of-speech (POS) tagging problem. Given an input sequence of words, the model should produce
a sequence of POS tags corresponding to each word. We use Penn Tree-bank
4
[33] which contains
gold annotations on English WSJ articles by experts. We extract part-of-speech tag labels from the
treebank and use splits 0-18 as training, 19-21 as development and 22-24 as test sets.  During the
encoding stage, each input sentence is passed to the language peripheral to generate a spatio-temporal
tensorx∈R
t×1×d
model
, weretis the sequence length of subwords in the input. The CNPencode()
function is then used to encodexinto the temporal cache. Note that spatial cache is empty for text
inputs, sinces= 1. Thus the decoding stage, is same as that for Transformers to predict the sequence
of POS tags.
Image Captioning:For a task with inputs containing only spatial modality (t= 1&s >1), we
demonstrate the Image Captioning problem. The task requires a model to predict a text caption for a
given image. We use the MSCOCO 2014 dataset [34] for training and present results on the COCO
validation set. During the encoding stage, the input image is resized to dimension224×224and
processed by the vision peripheral containing pre-trained ResNet-152 to produce image embeddings
x∈R
1×49×d
model
.xis then input to theencode()function which populates corresponding spatial
and temporal cache. The decoding stage usesdecode()function with output vocabulary size 25000 to
generate the captions.
Visual Question Answering:For the task with inputs from multiple domain, such that each contains
either spatial or temporal modality (eithert >1&s= 1, ort= 1&s >1for each input),
we choose the task of visual question answering. This task has a question over an image as inputs
and predicts the correct answer label.  We use the recently introduced VQA v2.0 dataset [35] for
this purpose and perform evaluation on the VQA test-dev set. This dataset was used in VQA 2018
challenge and contains over 1.1M question with 11.1M answers relating to images in MSCOCO
dataset. All the images are resized to dimension224×224before training. The encoding stage of this
task utilizes two peripherals: the vision peripheral is used to generate a tensorx
1
∈R
1×49×d
model
for the input image. The language peripheral is used to encode the questions intox
2
∈R
t×1×d
model
,
wheretis equal to the length of the subwords in the question. Theencode()function is the called two
times, first withx
1
and second withx
2
as input. Finally, thedecode()with output vocabulary size
3500 is to generate the answers as softmax probabilities in a single decoding step.
Video Activity Recognition:For tasks which contain both spatial and temporal modality in a single
input (t >1&s >1), we consider the action recognition task on videos. For this purpose, we use
the HMDB dataset [36]. The dataset consists of over 5000 short length clips of real life actions with
51 classes. We present our results on train-test split 1. We use 16 frames per video and resize each of
them to224×224. During the encoding stage, each frame of the video is passed through the vision
peripheral to cumulatively generate a video encodingx∈R
16×49×d
model
which is then used as input
4
https://catalog.ldc.upenn.edu/LDC99T42
6

POSCaptioningVQAHMDB
Acc.BLEU-1OverallY/NNum.OtherAcc.#PARAMS
State-of-the-art97.4477.263.280.342.855.859.4-
Independent95.6170.0455.3174.0935.1746.3555.29450×10
6
Multi-task95.4469.0455.7675.4935.6446.0854.44149×10
6
Table 1:  Performance ofOmniNeton diverse set of tasks when trained individually as well as in
multi-tasking setup.
to theencode()function. Finally, thedecode()with output vocabulary size 51 is to predict the action
as softmax probabilities in a single decoding step.
5    Results and Discussion
We present the evaluation on (a) Tasks of various modalities illustrated in4(b) Multi-tasking setup
for these tasks (Table1) (c) Reuse of the multi-task model for an unseen task (Figure3). In addition,
we also provide some ablation studies on the architecture (Table 2)
Performance of proposed architecture on individual tasks:
We choose a set of four tasks with
diverse input modalities and combinations as described in previous Section4. We train theOmniNet
model independently across each of the above tasks. Each of the tasks demonstrates unique capa-
bilities of this generic architecture.  More specifically, we compare our results with the following
state-of-the-art
5
:- POS tagging: [37]; image captioning & VQA: [16] and HMDB: [38]. The results of
comparison with the state-of-art is shown in Table1. While we do not obtain state-of-art performance
in all the tasks, most of the tasks still attain comparable performance without any hyper-parameter
optimization
6
. We do not focus on optimizing the performance for each of these specific tasks because
our primary objective is to verify whether the model can achieve reasonable performance across all
tasks using a single unified architecture. Although, we do not obtain the state-of-the-art performance
in image captioning, VQA and HMDB, the fact that a single model can be used for tasks with varying
combination of input modalities verifies the wide applicability of the proposed architecture.  We
further believe that, with more computational power, fine tuning the hyperparameters to these tasks
should certainly result in improved performance. Its interesting to note that the model can be easily
extended to new modalities like speech without any modification to the CNP as long as the inputs are
provided in a spatio-temporal form.
Effect of training a diverse set of tasks together:We trained a single joint model on the four
tasks mentioned above. Table1shows that the multi-task model attains similar performance as that
of independent training across various tasks, while resulting in three times reduction in model size.
That is, when a separate model is used for each task, we have a total of over450×10
6
parameters.
Whereas during multi-tasking, the model is much compressed with about149×10
6
parameters,
while achieving similar performance. Interestingly, the model is able to attend on spatio-temporal
components of the inputs from different tasks and concurrently generate predictions across them,
thus demonstrating the generalization capability of our architecture.
Impact  of  individual  architectural  components:In  order  to  support  different  input  domains,
our architecture introduces spatial cache and link array components to the originalTransformer
architecture (which only consists of mechanisms to handle temporal data). We conducted an ablation
study on each of these components to verify their importance across various tasks as shown in Table
2.  The second row ablates the link array from our architecture i.e.  removing the multiplication
ofGin Equation1.  The link array was designed to assist in tasks such as video, containing both
spatial as well as temporal modality in a single input.  The total number of spatial components
becomes very large as number of frames in the video increases, thereby making it difficult to attend
on various spatial regions throughout the video.  Using link array the spatial attention layer can
attend more on specific important frames in the video. Therefore, removal of link array leads to a
huge reduction in performance in HMDB compared to other tasks, because they do not have both
spatio-temporal modalities for any single input.  Removal of spatial cache, on the other hand, has
5
Since most of these tasks are popular challenges, we compare with state-of-the-art which are generically
applicable for the respective task instead of the challenge dataset.
6
We used the exact same hyper-parameters as specified in [1]
7

POSCaptioningVQAHMDB
Acc.BLEU-1OverallAcc.
OmniNetArchitecture95.6170.0455.3155.29
w/o link array95.6170.0454.0545.94
w/o spatial cache95.610.039.8610.91
Table 2: Ablation study on the effect of new architectural components (spatial cache and link array)
introduced in the proposed architecture
significant effect on performance across all tasks containing spatial modality. Since, image captioning
contains only spatial modality and hence the BLEU drops to 0 after ablation.  On the other hand,
VQA leverages both, spatial information from image and temporal information from question, retains
some performance from the use of temporal cache. HMDB also contains spatially averaged frames in
the temporal cache and hence retains some performance. Note that, POS tagging task is not affected
by ablation of any of the components since it only has temporal modality in the input.
Figure 3:  Results of zero-shot video captioning on a model pre-trained on image captioning and
video recognition.
Towards zero-shot learning:  reuse of pre-trained network for unseen task
Sharing represen-
tations across multiple tasks provides the benefit to transfer of useful knowledge across multiple
domains.  Since, image and video are processed by the same vision peripheral, we conducted an
experiment to see whether our model pre-trained on image captioning and video recognition can
perform video captioning without any training on video captioning data (zero-shot learning). The
results of the evaluation on randomly picked instances from the HMDB test split 1 are shown in
Figure3.  Interestingly, the model performs quite well on related actions that were present in the
COCO training; such as captions related to horse riding and baseball. Without training on any video
captioning instance, the model could use the pre-trained information from image captioning to gener-
ate meaningful predictions, hence demonstrating the capability of the model to transfer knowledge
across related multi-modal tasks. However, on concepts that are not present in the MSCOCO dataset,
the model either describes the environment in the video or replaces with alternate known concepts.
This case study, although not comprehensive, shows the capability of the model to learn shared
representations and ability to transfer knowledge across domains. We believe, that adding more tasks
and domains will lead to more interesting zero-shot learning results in future across a wide range of
problems.
6    Conclusions and Future Work
We present a unified neural network architectureOmniNetcapable of learning tasks with multiple
inputs of varying modalities. Further, the architecture can be adopted for multi-task learning across
any set of tasks containing spatio-temporal data. Our architecture attains comparable performance to
the state-of-art on over four diverse tasks. Training these wide array of tasks concurrently provides
a single compressed model while retaining similar performance. We further demonstrate that this
shared model can learn robust representations from various spatio-temporal inputs which are reusable
for unseen tasks.
8

We believe that this proposed architecture has wide applicability to any task with spatio-temporal
inputs. To extend its usability, we would like to introduce new peripherals supporting more domains
such as speech.  We are keen on exploring other aspects to the data beyond temporal and spatial
dimensions such as graphs and relational data.
References
[1]
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez,
Ł ukasz Kaiser, and Illia Polosukhin.  Attention is all you need.  In I. Guyon, U. V. Luxburg,
S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett, editors,Advances in Neural
Information Processing Systems 30, pages 5998–6008. Curran Associates, Inc., 2017.
[2]Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V. Le, Mohammad Norouzi, Wolfgang
Macherey, Maxim Krikun, Yuan Cao, Qin Gao, Klaus Macherey, Jeff Klingner, Apurva Shah,
Melvin Johnson, Xiaobing Liu, Łukasz Kaiser, Stephan Gouws, Yoshikiyo Kato, Taku Kudo,
Hideto Kazawa, Keith Stevens, George Kurian, Nishant Patil, Wei Wang, Cliff Young, Jason
Smith, Jason Riesa, Alex Rudnick, Oriol Vinyals, Greg Corrado, Macduff Hughes, and Jeffrey
Dean.  Google’s neural machine translation system:  Bridging the gap between human and
machine translation.CoRR, abs/1609.08144, 2016.
[3]
Christian Szegedy, Sergey Ioffe, and Vincent Vanhoucke. Inception-v4, inception-resnet and
the impact of residual connections on learning.CoRR, abs/1602.07261, 2016.
[4]Eric Battenberg, Jitong Chen, Rewon Child, Adam Coates, Yashesh Gaur, Yi Li, Hairong Liu,
Sanjeev Satheesh, David Seetapun, Anuroop Sriram, and Zhenyao Zhu.   Exploring neural
transducers for end-to-end speech recognition.CoRR, abs/1707.07413, 2017.
[5]Rui Shu, Hung H. Bui, Hirokazu Narui, and Stefano Ermon. A dirt-t approach to unsupervised
domain adaptation.CoRR, abs/1802.08735, 2018.
[6]Lanqing Hu,  Meina Kan,  Shiguang Shan,  and Xilin Chen.   Duplex generative adversarial
network for unsupervised domain adaptation. InThe IEEE Conference on Computer Vision and
Pattern Recognition (CVPR), June 2018.
[7]
Jiquan Ngiam, Aditya Khosla, Mingyu Kim, Juhan Nam, Honglak Lee, and Andrew Y. Ng.
Multimodal deep learning. InProceedings of the 28th International Conference on International
Conference on Machine Learning, ICML’11, pages 689–696, USA, 2011. Omnipress.
[8]Ronan Collobert and Jason Weston. A unified architecture for natural language processing: Deep
neural networks with multitask learning. InProceedings of the 25th International Conference
on Machine Learning, ICML ’08, pages 160–167, New York, NY, USA, 2008. ACM.
[9]Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang, Zachary DeVito,
Zeming Lin, Alban Desmaison, Luca Antiga, and Adam Lerer.  Automatic differentiation in
PyTorch. InNIPS Autodiff Workshop, 2017.
[10]
Melvin Johnson, Mike Schuster, Quoc V. Le, Maxim Krikun, Yonghui Wu, Zhifeng Chen,
Nikhil Thorat, Fernanda Viégas, Martin Wattenberg, Greg Corrado, Macduff Hughes, and
Jeffrey Dean.  Google’s multilingual neural machine translation system: Enabling zero-shot
translation.Transactions of the Association for Computational Linguistics, 5:339–351, 2017.
[11]Daxiang Dong, Hua Wu, Wei He, Dianhai Yu, and Haifeng Wang.  Multi-task learning for
multiple language translation. InACL, 2015.
[12]M. L. Seltzer and J. Droppo. Multi-task learning in deep neural networks for improved phoneme
recognition. In2013 IEEE International Conference on Acoustics, Speech and Signal Processing,
pages 6965–6969, May 2013.
[13]Kalpesh Krishna, Shubham Toshniwal, and Karen Livescu. Hierarchical multitask learning for
ctc-based speech recognition.CoRR, abs/1807.06234, 2018.
[14]Zhanpeng Zhang, Ping Luo, Chen Change Loy, and Xiaoou Tang. Facial landmark detection by
deep multi-task learning. InIn ECCV. 94–108, 2014.
9

[15]Yaran Chen, Dongbin Zhao, Le Lv, and Qichao Zhang. Multi-task learning for dangerous object
detection in autonomous driving.Information Sciences, 432:559 – 571, 2018.
[16]P. Anderson, X. He, C. Buehler, D. Teney, M. Johnson, S. Gould, and L. Zhang. Bottom-up and
top-down attention for image captioning and visual question answering.  In2018 IEEE/CVF
Conference on Computer Vision and Pattern Recognition, pages 6077–6086, June 2018.
[17]Thang Luong,  Quoc V. Le,  Ilya Sutskever,  Oriol Vinyals,  and Lukasz Kaiser.   Multi-task
sequence to sequence learning. InInternational Conference on Learning Representations, 2016.
[18]Wei Zhao, Benyou Wang, Jianbo Ye, Min Yang, Zhou Zhao, Ruotian Luo, and Yu Qiao. A multi-
task learning approach for image captioning. InProceedings of the Twenty-Seventh International
Joint Conference on Artificial Intelligence, IJCAI-18, pages 1205–1211. International Joint
Conferences on Artificial Intelligence Organization, 7 2018.
[19]Jin-Hwa Kim, Sang-Woo Lee, Donghyun Kwak, Min-Oh Heo, Jeonghee Kim, Jung-Woo Ha,
and Byoung-Tak Zhang. Multimodal residual learning for visual qa. In D. D. Lee, M. Sugiyama,
U. V. Luxburg, I. Guyon, and R. Garnett, editors,Advances in Neural Information Processing
Systems 29, pages 361–369. Curran Associates, Inc., 2016.
[20]
Jin-Hwa Kim, Jaehyun Jun, and Byoung-Tak Zhang. Bilinear attention networks. In S. Bengio,
H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett, editors,Advances in
Neural Information Processing Systems 31, pages 1564–1574. Curran Associates, Inc., 2018.
[21]Jie Lei, Licheng Yu, Mohit Bansal, and Tamara L. Berg. TVQA: localized, compositional video
question answering.CoRR, abs/1809.01696, 2018.
[22]Lukasz Kaiser, Aidan N. Gomez, Noam Shazeer, Ashish Vaswani, Niki Parmar, Llion Jones,
and Jakob Uszkoreit. One model to learn them all.CoRR, abs/1706.05137, 2017.
[23]Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. Neural machine translation by jointly
learning to align and translate. In3rd International Conference on Learning Representations,
ICLR 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings, 2015.
[24]Ilya Sutskever, Oriol Vinyals, and Quoc V Le.  Sequence to sequence learning with neural
networks. In Z. Ghahramani, M. Welling, C. Cortes, N. D. Lawrence, and K. Q. Weinberger,
editors,Advances in Neural Information Processing Systems 27, pages 3104–3112. Curran
Associates, Inc., 2014.
[25]  Kyunghyun Cho, Bart van Merrienboer, Caglar Gulcehre, Dzmitry Bahdanau, Fethi Bougares,
Holger Schwenk, and Yoshua Bengio. Learning phrase representations using RNN encoder–
decoder for statistical machine translation. InProceedings of the 2014 Conference on Empirical
Methods in Natural Language Processing (EMNLP), pages 1724–1734, Doha, Qatar, October
2014. Association for Computational Linguistics.
[26]K. He, X. Zhang, S. Ren, and J. Sun.  Deep residual learning for image recognition.  In2016
IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 770–778, June
2016.
[27]Rico Sennrich,  Barry Haddow,  and Alexandra Birch.   Neural machine translation of rare
words with subword units.   InProceedings of the 54th Annual Meeting of the Association
for Computational Linguistics (Volume 1: Long Papers), pages 1715–1725, Berlin, Germany,
August 2016. Association for Computational Linguistics.
[28]
Benjamin Heinzerling and Michael Strube. BPEmb: Tokenization-free Pre-trained Subword
Embeddings in 275 Languages.  In Nicoletta Calzolari (Conference chair), Khalid Choukri,
Christopher Cieri, Thierry Declerck, Sara Goggi, Koiti Hasida, Hitoshi Isahara, Bente Maegaard,
Joseph Mariani, Hélène Mazo, Asuncion Moreno, Jan Odijk, Stelios Piperidis, and Takenobu
Tokunaga, editors,Proceedings of the Eleventh International Conference on Language Re-
sources and Evaluation (LREC 2018),  Miyazaki,  Japan,  May 7-12,  2018 2018. European
Language Resources Association (ELRA).
10

[29]Benjamin Recht,  Christopher Re,  Stephen Wright,  and Feng Niu.   Hogwild:  A lock-free
approach to parallelizing stochastic gradient descent.  In J. Shawe-Taylor, R. S. Zemel, P. L.
Bartlett, F. Pereira, and K. Q. Weinberger, editors,Advances in Neural Information Processing
Systems 24, pages 693–701. Curran Associates, Inc., 2011.
[30]
Volodymyr Mnih, Adrià Puigdomènech Badia, Mehdi Mirza, Alex Graves, Tim Harley, Tim-
othy P. Lillicrap, David Silver, and Koray Kavukcuoglu.  Asynchronous methods for deep
reinforcement learning. InProceedings of the 33rd International Conference on International
Conference on Machine Learning - Volume 48, ICML’16, pages 1928–1937. JMLR.org, 2016.
[31]Diederik P. Kingma and Jimmy Ba.  Adam:  A method for stochastic optimization.  In3rd
International Conference on Learning Representations, ICLR 2015, San Diego, CA, USA, May
7-9, 2015, Conference Track Proceedings, 2015.
[32]Noam Shazeer and Mitchell Stern. Adafactor: Adaptive learning rates with sublinear memory
cost.CoRR, abs/1804.04235, 2018.
[33]
Mitchell Marcus, Grace Kim, Mary Ann Marcinkiewicz, Robert MacIntyre, Ann Bies, Mark
Ferguson,  Karen Katz,  and Britta Schasberger.   The penn treebank:  Annotating predicate
argument structure. InProceedings of the Workshop on Human Language Technology, HLT ’94,
pages 114–119, Stroudsburg, PA, USA, 1994. Association for Computational Linguistics.
[34]Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan,
Piotr Dollár, and C. Lawrence Zitnick. Microsoft coco: Common objects in context. In David
Fleet, Tomas Pajdla, Bernt Schiele, and Tinne Tuytelaars, editors,Computer Vision – ECCV
2014, pages 740–755, Cham, 2014. Springer International Publishing.
[35]Yash Goyal, Tejas Khot, Douglas Summers-Stay, Dhruv Batra, and Devi Parikh. Making the V
in VQA matter: Elevating the role of image understanding in Visual Question Answering. In
Conference on Computer Vision and Pattern Recognition (CVPR), 2017.
[36]H. Kuehne, H. Jhuang, E. Garrote, T. Poggio, and T. Serre. HMDB: a large video database for
human motion recognition. InProceedings of the International Conference on Computer Vision
(ICCV), 2011.
[37]Drahomíra “johanka” Spoustová, Jan Haji
ˇ
c, Jan Raab, and Miroslav Spousta. Semi-supervised
training for the averaged perceptron POS tagger.  InProceedings of the 12th Conference of
the European Chapter of the ACL (EACL 2009), pages 763–771, Athens, Greece, March 2009.
Association for Computational Linguistics.
[38]Karen  Simonyan  and  Andrew  Zisserman.   Two-stream  convolutional  networks  for  action
recognition in videos.  In Z. Ghahramani, M. Welling, C. Cortes, N. D. Lawrence, and K. Q.
Weinberger, editors,Advances in Neural Information Processing Systems 27, pages 568–576.
Curran Associates, Inc., 2014.
11 

Convolutional Reservoir Computing for World Models
A PREPRINT
Hanten Chang
Graduate school of Systems and
Information Engineering,
University of Tsukuba, Japan
s1820554@s.tsukuba.ac.jp
Katsuya Futagami
Graduate school of Systems and
Information Engineering,
University of Tsukuba, Japan
s1820559@s.tsukuba.ac.jp
July 19, 2019
ABSTRACT
Recently, reinforcement learning models have achieved great success, completing complex tasks such
as mastering Go and other games with higher scores than human players.  Many of these models
collect considerable data on the tasks and improve accuracy by extracting visual and time-series
features using convolutional neural networks (CNNs) and recurrent neural networks, respectively.
However, these networks have very high computational costs because they need to be trained by
repeatedly using a large volume of past playing data.  In this study, we propose a novel practical
approach called reinforcement learning with convolutional reservoir computing (RCRC) model. The
RCRC model has several desirable features: 1. it can extract visual and time-series features very fast
because it uses random fixed-weight CNN and the reservoir computing model; 2. it does not require
the training data to be stored because it extracts features without training and decides action with
evolution strategy. Furthermore, the model achieves state of the art score in the popular reinforcement
learning task. Incredibly, we find the random weight-fixed simple networks like only one dense layer
network can also reach high score in the RL task.
1  Introduction
Recently, reinforcement learning (RL) models have achieved great success, mastering complex tasks such as Go [1, 2]
and other games [3–5] with higher scores than human players. Many of these models use convolutional neural networks
(CNNs) to extract visual features directly from the environment state pixels [6].  Some models use recurrent neural
networks (RNNs) to extract time-series features and achieved higher scores [5, 7].
However, these deep neural network (DNN) based models are very computationally expensive in that they train networks
weights by repeatedly using a large volume of past playing data. Certain techniques can alleviate these costs, such as
the distributed approach [4, 8] which efficiently uses multiple agents, and the prioritized experienced replay [9] which
selects samples that facilitate training. However, the cost of a series of computations, from data collection to action
determination, remains high.
World model [10, 11] can also reduce computational costs by completely separating the training process between the
feature extraction model and the action decision model. World model replaces the feature extraction model training
process with the supervised learning, by using variational auto-encoder (VAE) [12, 13] and mixture density network
combined with an RNN (MDN-RNN) [14, 15]. After extracting the environment state features, it uses an evolution
strategy called the covariance matrix adaptation evolution strategy (CMA-ES) [16, 17] to train an action decision model,
which achieved outstanding scores in popular RL tasks. The separation of these two models results in the stabilization
of feature extraction and omission of parameters to be trained based on task-dependent rewards.
From the success of world model, it is implied that in the RL feature extraction process, it is necessary to extract the
features that express the environment state rather than features trained to solve the tasks. In this study, adopting this
idea, we propose a new method called "reinforcement learning with convolutional reservoir computing (RCRC)". The
RCRC model is inspired by the reservoir computing.
arXiv:1907.08040v1  [cs.LG]  18 Jul 2019

APREPRINT- JULY19, 2019
Figure 1: Reservoir Computing overview for the time-series prediction task.
Reservoir computing [18, 19] is a kind of RNNs, but the model weights are set to random. One of the models of the
reservoir computing model, the echo state network (ESN) [20–22] is used to solve time-series tasks such as future value
prediction. For this, the ESN extracts features for the input based on the dot product between the input and a random
matrix generated without training. Surprisingly, features obtained in this manner are expressive enough to understand
the input signal, and complex tasks such as chaotic time-series prediction can be solved by using them as the input for a
linear model. In addition, the ESN has solved the tasks in multiple fields such as time-series classification [23, 24] and
Q-learning-based RL [25]. Thus, even if the ESN uses random weights, it can extract sufficient expressive features of
the input and can solve the task using the linear model. Similarly, in image classification, the model that uses features
extracted by the CNN with random fixed-weights as the ESN input achieves high accuracy classification with a smaller
number of parameters [26].
Based on the success of the above random fixed-weight models, RCRC extracts the visual features of the environment
state using random fixed-weight CNN and, using these features as the ESN input, extracts time-series features of
the environment state transitions. In the feature extraction process, all features are extracted based on matrices with
random elements. Therefore, no training process is required, and feature extraction can be performed very fast. After
extracting the environment state features, we use CMA-ES [16, 17] to train a linear combination of extracted features
to perform the actions, as in world model. This model architecture results in the omission of the training process of
feature extraction and recuded computational costs; there is also no need to store a large volume of past playing data.
Furthermore, we show that RCRC can achieve state of the art score in popular RL task.
Our contribution in this paper is as follow:
•We developed a novel and highly efficient approach to extract visual and time-series features of an RL
environment state using a fixed random-weight model with no training.
•By combining random weight networks with an evolution strategy method, we eliminated the need to store
any past playing data.
•We showed that a model with these desirable characteristics can achieve state of the art score in popular
continuous RL task.
•
We showed that simple random weight-fixed networks, for example one dense layer network, can also extract
visual features and achieve high score in continuous RL task.
2  Related Work
2.1  Reservoir Computing
Reservoir computing is a promising model that can solve complex tasks, such as chaotic time-series prediction, without
training for the feature extraction process. In this study, we focus on the reservoir computing model, ESN [20–22].
ESN was initially proposed to solve time-series tasks [20] and is regarded as an RNN model [19], it can be applied to
multiple fields.
Let theN-length,D
u
-dimensional input signal beu={u(1),u(2),...,u(t),...,u(N)}∈R
N×D
u
and the signal that
adds input signal to one bias term beU= [u; 1] ={U(1),U(2),...,U(T),...,U(N)} ∈R
N×(D
u
+1)
. [;] is a vector
2

APREPRINT- JULY19, 2019
concatenation. ESN gets features called the reservoir stateX={X(1),,...,X(t),...,X(N)}∈R
N×D
x
as follows:
 ̃
X(t+ 1)  =f(W
in
U(t) +WX(t)))
X(t+ 1)  =  (1−α)X(t) +α
 ̃
X(t+ 1)
where the matricesW
in
∈R
(D
u
+1)×D
x
andW∈R
D
x
×D
x
are random sampled from a probability distribution such
as a Gaussian distribution, andfis the activation function which is applied element-wise. As the activation function,
linearandtanhfunctions are generally used; it is also known that changing the activation function according to the
task improves accuracy [27, 28]. The leakage rateα∈[0,1]is a hyper parameter that tunes the weight between the
current and the previous values, andWhas two major hyper parameters called sparsity which is ratio of 0 elements in
matrixWand the spectral radius that is memory capacity hyper parameter which is calculated by the maximal absolute
eigenvalue ofW.
Finally, ESN estimates the target signaly={y(1),y(2),...,y(t),...,y(N)}∈R
N×D
y
as
y(t) =W
out
[X(t);U(t); 1].
The weight matrixW
out
∈R
D
y
×(D
x
+D
u
+1)
is estimated by a linear model such as ridge regression. An overview of
reservoir computing is shown in Figure1.
The unique feature of the ESN is that the two matricesW
in
andWused to update the reservoir state are randomly
generated from a probability distribution and fixed without training. Therefore, the training process in the ESN consists
only of a linear model to estimateW
out
; therefore, the ESN model has a very low computational cost. In addition, the
reservoir state reflects complex dynamics despite being obtained by random matrix transformation, and it is possible to
use it to predict complex time-series by simple linear transformation [18, 20, 29]. Because of the low computational
cost and high expressiveness of the extracted features, the ESN is also used to solve other tasks such as time-series
classification [23, 24], Q-learning-based RL [25] and image classification [26].
2.2  World models
Recently, most RL models use DNNs to extract features and solved several complex tasks. However, these models have
high computational costs because a large volume of past playing data need to be stored, and network parameters need to
be updated using the back propagation method. There are certain techniques [4, 8, 9] and models that can reduce this
cost; some models [10, 11, 30] separate the training process of the feature extraction and action decision models to more
efficiently train the action decision model.
The world model [10, 11] is one such model, and uses VAE [12, 13] and MDN-RNN [14, 15] as feature extractors.
They are trained using supervised learning with randomly played 10000 episodes data.  As a result, in the feature
extraction process, the task-dependent parameters are omitted, and there remains only one weight parameter to be
trained that decides the action in the model.  Therefore, it becomes possible to use the evolution strategy algorithm
CMA-ES [16, 17] efficiently to train that weight parameter. The process of optimizing weights of action decision model
using CMA-ES can be parallelized. Although the feature extraction model is trained in a task-independent manner,
world model achieved outstanding scores and masterd popular RL taskCarRacing-v0[31].
CMA-ES is one of the evolution strategy methods used to optimize parameters using a multi-candidate search generated
from a multivariate normal distributionN(m,σ
2
C). The parametersm,σ, andCare updated with a formula called the
evolution path. Evolution paths are updated according to the previous evolution paths and evaluation scores. Because
CMA-ES updates parameters using only the evaluation scores calculated by actual playing, it can be used regardless
of whether the actions of the environment are continuous or discrete values [16, 17].  Furthermore, training can be
faster because the calculations can be parallelized by the number of solution candidates. In world model, the action
decision model is simplified to reduce the number of task-dependent parameters, making it possible to use CMA-ES
efficiently [10, 11].
World model improves the computational cost of the action decision model and accelerates the training process by
separating models and applying CMA-ES. However, in world model, it is necessary to independently optimize VAE,
MDN-RNN, and CMA-ES. Further, because the feature extraction model is dependent on the environment, a large
amount of past data must be stored to train the feature extraction model each time the environment changes.
3  Proposal Model
3.1  Basic Concept
World model [10, 11] extracts visual features and time-series features of environment states by using VAE [12, 13]
and MDN-RNN [14, 15] without using environment scores. The models achieve outstanding scores through the linear
3

APREPRINT- JULY19, 2019
Figure 2: RCRC overview to choose the action forCarRacing-v0: the first and second layers are collectively called
the convolutional reservoir computing layer, and both layers’ model weights are sampled from Gaussian distribution
and then fixed.
transformation of these features. This implies that it only requires features that sufficiently express the environment
state, rather than features trained to solve the task.
We thus focus on extracting features that sufficiently express environment state by networks with random fixed-weights.
Using networks whose weights are random and fixed has some advantages, such as having very low computational costs
and no data storage requirements, while being able to sufficiently extract features. For example, a simple CNN with
random fixed-weights can extract visual features and achieve high accuracy [26]. Although the MDN-RNN is fixed in
the world model, it can achieve outstanding scores [32]. In the case of ESN, the model can predict complex time-series
using features extracted by using random matrices transformations [18, 20, 29]. Therefore, it can be considered that CNN
can extract visual features and ESN can extract time-series features, even if their weights are random and fixed. From
this hypothesis, we propose reinforcement learning with the RCRC model, which includes both random fixed-weight
CNN and ESN.
3.2  Proposal model overview
The RCRC model is divided into three model layers. In the first layer, it extracts visual features by using a random
fixed-weight CNN. In the second layer, it uses a series of visual features extracted in the first layer as input to the ESN
to extract the time-series features. In the two layers above, collectively called the convolutional reservoir layer, visual
and time-series features are extracted with no training. In the final layer, the linear combination matrix is trained from
the outputs of the convolutional reservoir layer to the actions. An overview is shown in Figure2.
In the previous study, there is a similar world model–based approach [33] that uses fixed weights in VAE and a memory
component based on recurrent long short-term memory (LSTM) [34]. However, this approach is ineffective in solving
CarRacing-v0.  In the training process, the best average score over 20 randomly created tracks of each generation
were less than 200.  However, as mentioned further on, we achieve an average score above 900 over 100 randomly
created tracks by taking reservoir computing knowledge in the RCRC model.
The characteristics of the RCRC model are as follows:
•The computational cost of this model is very low because visual and time-series features of game states are
extracted using a convolutional reservoir computing layer whose weights are fixed and random.
•In RCRC, only a linear combination in the controller layer needs to be trained because the feature extraction
model (convolutional reservoir computing layer) and the action training model (controller layer) are separated.
4

APREPRINT- JULY19, 2019
•RCRC can take a wide range of actions regardless of continuous or discrete, because of maximizing the scores
that is measured by actually playing.
•Past data storage is not required, as neither the convolutional reservoir computing layer nor the controller layer
need to repeatedly train the past data as in backpropagation.
•The convolutional reservoir computing layer can be applied to other tasks without further training, because the
layer is fixed with task-independent random weights.
3.3  Convolutional Reservoir Computing layer
In the convolutional reservoir computing layer, the visual and time-series features of the environment state image are
extracted by a random fixed-weight CNN and an ESN which has random fixed-weight, respectively. A study using
CNN with fixed random weights for each single-image as input to ESN has been previously conducted, and has shown
its ability to classify MNIST dataset [35] with high accuracy [26]. Based on this study, we developed a novel approach
to perform RL tasks. By taking advantage of the RL characteristic by which the current environment state and action
determine the next state, RCRC updates the reservoir state with current and previous features. This updating process
enables the reservoir state to have time-series features.
More  precisely,  consider  theD
conv
-dimensional  visual  features  extracted  by  fixed  random  weight  CNN  fort-th
environment state pixelsX
conv
(t)∈R
D
conv
and theD
esn
-dimensional reservoir stateX
esn
(t)∈R
D
esn
.  The reservoir
stateX
esn
is time-series features and is updated as follows:
 ̃
X
esn
(t+ 1)  =f(W
in
X
conv
(t) +WX
esn
(t)))
X
esn
(t+ 1)  =  (1−α)X
esn
(t) +α
 ̃
X
esn
(t+ 1).
This updating process has no training requirement, and is very fast, becauseW
in
andWare random matrices sampled
from the probability distribution and fixed.
3.4  Controller layer
The controller layer decides the action by using the output of the convolutional reservoir computing layer,X
conv
andX
esn
.
Lett-th environment state input vector which added one bias term beS(t) = [X
conv
(t);X
esn
(t); 1]∈R
D
conv
+D
esn
+1
).
In the action decision, we suppose that the featureS(t)has sufficient expressive information and it can take action by a
linear combination ofS(t). Therefore, we obtain actionA(t)∈R
N
act
as follows:
 ̃
A(t)  =W
out
S(t)
A(t)  =g(
 ̃
A(t))
where,W
out
∈R
(D
conv
+D
esn
+1)×N
act
is the weight matrix andN
act
is the number of actions in the task environment;gis
applied to each action to put each
 ̃
A(t)in the range of possible values in the task environment.
Because the weights of the convolutional reservoir computing layer are fixed, only the weight parameterW
out
requires
training. We optimizeW
out
by using CMA-ES, as in world model. Therefore, it is possible to parallelize the training
process and handle both discrete and continuous values as actions [16, 17].
The process of optimizingW
out
by CMA-ES are shown as follows:
1.Generatensolution   candidatesW
out
T,i
(i=  1,2,...,n)from   a   multivariate   normal   distribution
N(m(T),σ(T)
2
C(T))
2.  Createnenvironments and agents worker
i
that implement RCRC
3.  SetW
out
i
to the controller layer of worker
i
4.  In each execution environment, each worker
i
playsmepisodes and receivesmscoresG
i,j
(j= 1,2,...,m)
5.  Update evolution paths with the score of eachW
out
i
which isG
i
= 1/m
∑
m
j=1
G
i,j
6.  Updatem,σ,Cusing evolution paths
7.
Generate a newnsolution candidateW
out
(T+1),i
(i= 1,2,...,n)
from the updated multivariate normal distribu-
tionN(m(T+ 1),σ(T+ 1)
2
C(T+ 1))
8.Repeat 2 to 7 until the convergence condition is satisfied or the specified number of repetitions are completed
5

APREPRINT- JULY19, 2019
Figure 3: Example environment state image ofCarRacing-v0and three parameters in the enviroments. The score is
added when the car passes through a tile laid on the course.
In this process,Trepresents an update step of the weight matrixW
out
, andnis the number of solution candidatesW
out
generated at each step. The worker is an agent that implements RCRC, and each worker extracts features, takes the
action and plays in each independent environment to obtain scores. Therefore, it is possible to parallelizenprocesses to
calculate each score.
4  Experiments
4.1  CarRacing-v0
We evaluate the RCRC model in the popular RL taskCarRacing-v0[31] in OpenAI Gym [36]. This is a car racing
game environment that was known as a difficult continuous actions task [10, 11]. The goal of this game is to go around
the course without getting out by operating a car with three continuous parameters: steering wheel[−1,1], accelerator
[0,1], and brake[0,1]. Each frame of the game screen is given by RGB 3 channels and 96×96 pixels. The course is
filled with tiles as shown in Figure3. Each time the car passes a tile on the course,1000/Nis added to the score.Nis
the total number of tiles on the course. The course is randomly generated each time, and the total number of tiles in the
course varies around 300. If all the tiles are passed, the total reward will be 1000, but it is subtracted by 0.1 for each
frame. The episode ends when all the tiles are passed or when 1000 frames are played. If the player can pass all the
tiles without getting out of the course, the reward will be over 900. The definition of "solve" in this game is to get an
average of 900 per 100 consecutive trials.
4.2  Precedure
In the convolutional reservoir computing layer, we set 3 convolution layers and 1 dense layer. The filter sizes in the
convolution layers are 31, 14, and 6, and the strides are all 2. We setD
conv
andD
esn
to 512 to expand the features. In
the reservoir computing layer, we also set the sparsity ofWto 0.8; the spectral radius ofWto 0.95. All activation
functions are set totanh, which is often used in reservoir computing and achieves higher scores.
As in world model, we set three units (
 ̃
A
1
(t),
 ̃
A
2
(t), and
 ̃
A
3
(t)) as output of the controller layer, and each of them
corresponds to an action: steering wheelA
1
(t), acceleratorA
2
(t), and brakeA
3
(t)[10, 11]. Also as in world model,
each actionA(t)is determined by converting each
 ̃
A(t)bygshown as follows [10, 11]:
g(
 ̃
A(t)) =









tanh
(
 ̃
A
1
(t)
)
[tanh
(
 ̃
A
2
(t)
)
+ 1.0]/2.0
clip[tanh
(
 ̃
A
3
(t)
)
,0,1]
.
The functionclip[x,λ
min
,λ
max
]is a function that limits the value ofxin range fromλ
min
toλ
max
by clipping.
6

APREPRINT- JULY19, 2019
Figure 4: The best average score over 8 randomly created tracks among 16 workers atCarRacing-v0.
Table 1:CarRacing-v0scores of various methods.
MethodAverage Score
DQN [37]343±18
DQN + Dropout [38]892±41
A3C (Continuous) [39]591±45
World model with random MDN-RNN [32]870±120
World model (V model) [10]632±251
World model [10]906±21
GA [33]903±73
RCRC model (Visual model)864±79
RCRC model901±20
In the experiment, 16 workers(n= 16)with differentW
out
parameters are prepared for each update step, and each
worker is set to simulate over 8 randomly generated tracks(m= 8), and updateW
out
with an average of these scores.
As the input value, each frame is resized to 3 channels of 64×64 pixels. As in world model [10, 11], we evaluate an
average score over 100 randomly created tracks score as the generalization ability of the models.
To investigate the ability of each network structures, we evaluate three models: full RCRC model, the RCRC model that
removes the reservoir computing layer from convolutional reservoir computing layer (visual model), the RCRC model
that has only one dense layer as feature extractor (dense model). The dense model uses flatten vector of 64×64 with 3
channels image, and weights of all models are random and fixed. The visual model extracts visual features and the
dense model extracts only visual features with no convolutional process. In both the visual model and the dense model,
the inputs to the controller layer are theD
conv
-dimensional outputs from the dense layer shown in Figure2, and one bias
term.
4.3  Result
The best scores among 16 workers are shown in Figure4. Each workers score are evaluated as average score over 8
randomly generated tracks. Although the world model improved score faster than the full RCRC model, the full RCRC
model also reached high score. The full RCRC model reached an average score around 900 at 200 generations and
stable high score after 400 generations, while the world model reached stable high score after 250 generations. This
result shows that the full RCRC model is comparable to world model at the same condition, regardless of no training
7

APREPRINT- JULY19, 2019
process in feature extractions. However, the full RCRC model was slower than the world model to achieve stable high
scores.
Incredibly, the dense model reached an average score above 880 over 8 randomly generated tracks, and the visual model
reached above 890. The dense model’s score transition has higher volatility than the visual model’s score transition.
Furthermore, the visual model’s score is less stable than the full RCRC model’s score. These results shows that only
one dense process can extract visual features even though the weight are random and fixed, and the features extracted
by convolutional process and ESN improved scores.
We also test the ability of single dense network in the MNIST datasets [35] which is benchmark dataset of image
recognition task, including 28×28 gray-scaled handwritten images. The MNIST dataset contains 60000 training data
and 10000 testing data. In experiments, we merged these data, and randomly sampled 60000 data as training data and
10000 data as testing data with no duplication to evaluate model ability by multiple datasets. As input to the dense layer,
we used 784 vector that is flatten representation of 28×28 gray-scaled handwritten images, and set the dense layer has
512 units. Each input vector is divided by 255 to normalize value. The weight of the dense layer is randomly generated
from a Gaussian distributionN(0,0.06
2
)and then fixed. After extracting features by the dense layer, we uses these
features as input to logistic regression with L2 penalty to classify images into 10 classes. As a result of this experiments,
we confirmed the feature extracted by random fixed-weight single dense layer has ability to achieve average accuracy
score91.58±0.27(%)over 20 trials by linear model. Surprisingly, this result shows that only single dense layer with
random fixed-weight has ability to extract visual features.
The generalization ability of the visual model and the full RCRC model that evaluated as average score over 100
randomly generated tracks are shown in Table1. The full RCRC model achieved above 901±20 that is comparable to
state of the art approaches such as the world model approach [10] and GA approach [33]. To achieve over 900 score of
100 randomly generated tracks, the models is only allowed to mistake a few driving. Therefore the full RCRC model
can be regarded as having ability to solveCarRacing-v0.
Although the visual model extracts 512-dimensional visual features with random fixed-weight CNN, it achieves 864±79
which is better than the V model that uses only 32-dimensional features extracted by VAE as input to controller layer in
world model. Furthermore, the time-series features extracted by ESN improves driving.
5  Discussion and Future work
In this study, we focused on extracting features that sufficiently express the environment state, rather than those that are
trained to solve the RL task. To this end, we developed a novel model called RCRC, which, using random fixed-weight
CNN and a novel ESN method, respectively, extracts visual features from environment state pixels and time-series
features from a series of the state pixels.  Therefore, no training process is required, and features can be efficiently
extracted.  In the controller layer, a linear combination of both features and actions is trained using CMA-ES. This
model architecture results in highly practical features that omit the training process and reduce computational costs, and
there is no need to store large volumes of data. We also show that RCRC achieves state of the art scores in a popular
continuous RL task,CarRacing-v0. This result brings us to the conclusion that network structures themselves, such as
CNN and ESN, have the capacity to extract features.
We also found that the single dense network and simple CNN model with random fixed-weight can extract visual
features, and these models achieved high scores. Although VAE has desirable features such as ability to reconstruct
the input and high interpretability of latent space by using reparameterization trick which uses Gaussian noise to use
backpropagation, we consider that large definitive features can also extract expressive enough visual features.
Because of our limited computing resources, we were unable to assign more workers to CMA-ES. There is a possibility
that more efficient and stable training could be performed by assigning more workers. Although RCRC can take wide
range of actions and parallelization by using CMA-ES, it is not suitable for the task that is hard to real simulation
because it has to evaluate parameters by real simulation.
As a further improvement, there is a possibility that the score can be improved and made it more stable by using a
multi-convolutional reservoir computing layer to extract multiple features [40]. The current convolutional reservoir
computing layer uses random weight samples generated from Gaussian distributions. Therefore, it can easily obtain
multiple independent features by using different random seeds.
Our results have the potential to make RL widely available. Recently, many RL models have achieved high accuracy
in various tasks, but most of them have high computational costs and often require significant time for training. This
makes the introduction of RL inaccessible for many. However, by using our RCRC model, anyone can train the model
at a high speed with much lower computational costs, and importantly, anyone can build a highly accurate model.
8

APREPRINT- JULY19, 2019
In addition, RCRC can handle both continuous- and discrete-valued tasks, and even when the environment changes,
training can be performed without any prior learning such as the VAE and MDN-RNN in world model. Therefore, it
can be used easily by anyone in many environments.
In future work, we consider making predictions from previous extracted features and actions to the next ones to be
an important and promising task. Because the ESN was initially proposed to predict complex time-series, it can be
assumed to have capacity to predict future features. If this prediction is achieved with high accuracy, it can self-simulate
RL tasks by making iterative predictions from initial state pixels. This will help to broaden the scope of RL applications.
6  Acknowledgements
The authors are grateful to Takuya Yaguchi for the discussions on reinforcement learning. We also thank Hiroyasu
Ando for helping us to improve the manuscript.
References
[1]David Silver, Aja Huang, Chris J Maddison, Arthur Guez, Laurent Sifre, George Van Den Driessche, Julian
Schrittwieser, Ioannis Antonoglou, Veda Panneershelvam, Marc Lanctot, et al. Mastering the game of go with
deep neural networks and tree search.nature, 529(7587):484, 2016.
[2]David Silver, Julian Schrittwieser, Karen Simonyan, Ioannis Antonoglou, Aja Huang, Arthur Guez, Thomas
Hubert, Lucas Baker, Matthew Lai, Adrian Bolton, et al. Mastering the game of go without human knowledge.
Nature, 550(7676):354, 2017.
[3]
Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Alex Graves, Ioannis Antonoglou, Daan Wierstra, and
Martin A. Riedmiller. Playing atari with deep reinforcement learning.arXiv preprint arXiv:1312.5602, 2013.
[4]
Dan Horgan, John Quan, David Budden, Gabriel Barth-Maron, Matteo Hessel, Hado van Hasselt, and David
Silver. Distributed prioritized experience replay.arXiv preprint arXiv:1803.00933, 2018.
[5]Steven Kapturowski, Georg Ostrovski, Will Dabney, John Quan, and Remi Munos. Recurrent experience replay in
distributed reinforcement learning. InInternational Conference on Learning Representations, 2019.
[6]Kai Arulkumaran, Marc Peter Deisenroth, Miles Brundage, and Anil Anthony Bharath.  Deep reinforcement
learning: A brief survey.IEEE Signal Processing Magazine, 34(6):26–38, 2017.
[7]Matthew Hausknecht and Peter Stone. Deep recurrent q-learning for partially observable mdps. In2015 AAAI
Fall Symposium Series, 2015.
[8]Volodymyr Mnih, Adria Puigdomenech Badia, Mehdi Mirza, Alex Graves, Timothy Lillicrap, Tim Harley, David
Silver, and Koray Kavukcuoglu.   Asynchronous methods for deep reinforcement learning.   InInternational
conference on machine learning, pages 1928–1937, 2016.
[9]Tom Schaul, John Quan, Ioannis Antonoglou, and David Silver.  Prioritized experience replay.arXiv preprint
arXiv:1511.05952, 2015.
[10]  David Ha and Jürgen Schmidhuber. World models.arXiv preprint arXiv:1803.10122, 2018.
[11]
David Ha and Jürgen Schmidhuber. Recurrent world models facilitate policy evolution. In S. Bengio, H. Wallach,
H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett, editors,Advances in Neural Information Processing
Systems 31, pages 2450–2462. Curran Associates, Inc., 2018.
[12]  Diederik P Kingma and Max Welling. Auto-encoding variational bayes.arXiv preprint arXiv:1312.6114, 2013.
[13]
Danilo Jimenez Rezende, Shakir Mohamed, and Daan Wierstra.  Stochastic backpropagation and approximate
inference in deep generative models.arXiv preprint arXiv:1401.4082, 2014.
[14]  Alex Graves. Generating sequences with recurrent neural networks.arXiv preprint arXiv:1308.0850, 2013.
[15]  David Ha. Recurrent neural network tutorial for artists.blog.otoro.net, 2017.
[16]
Nikolaus Hansen and Andreas Ostermeier.  Completely derandomized self-adaptation in evolution strategies.
Evolutionary Computation, 9(2):159–195, 2001.
[17]  Nikolaus Hansen. The CMA evolution strategy: A tutorial.arXiv preprint arXiv:1604.00772, 2016.
[18]David Verstraeten, Benjamin Schrauwen, Michiel d’Haene, and Dirk Stroobandt. An experimental unification of
reservoir computing methods.Neural networks, 20(3):391–403, 2007.
9

APREPRINT- JULY19, 2019
[19]Mantas Lukoševi
ˇ
cius and Herbert Jaeger. Reservoir computing approaches to recurrent neural network training.
Computer Science Review, 3(3):127–149, 2009.
[20]Herbert Jaeger. The “echo state” approach to analysing and training recurrent neural networks-with an erratum
note.Bonn, Germany: German National Research Center for Information Technology GMD Technical Report,
148(34):13, 2001.
[21]Herbert Jaeger and Harald Haas.  Harnessing nonlinearity:  Predicting chaotic systems and saving energy in
wireless communication.science, 304(5667):78–80, 2004.
[22]Mantas Lukoševi
ˇ
cius. A practical guide to applying echo state networks. InNeural networks: Tricks of the trade,
pages 659–686. Springer, 2012.
[23]Pattreeya Tanisaro and Gunther Heidemann. Time series classification using time warping invariant echo state
networks. In2016 15th IEEE International Conference on Machine Learning and Applications (ICMLA), pages
831–836. IEEE, 2016.
[24]Qianli Ma, Lifeng Shen, Weibiao Chen, Jiabin Wang, Jia Wei, and Zhiwen Yu. Functional echo state network for
time series classification.Information Sciences, 373:1–20, 2016.
[25]István Szita, Viktor Gyenes, and András L
 ̋
orincz. Reinforcement learning with echo state networks. InInterna-
tional Conference on Artificial Neural Networks, pages 830–839. Springer, 2006.
[26]Zhiqiang Tong and Gouhei Tanaka. Reservoir computing with untrained convolutional neural networks for image
recognition.  In2018 24th International Conference on Pattern Recognition (ICPR), pages 1289–1294. IEEE,
2018.
[27]Masanobu Inubushi and Kazuyuki Yoshimura.  Reservoir computing beyond memory-nonlinearity trade-off.
Scientific reports, 7(1):10199, 2017.
[28]Hanten Chang, Shinji Nakaoka, and Hiroyasu Ando. Effect of shapes of activation functions on predictability in
the echo state network.arXiv preprint arXiv:1905.09419, 2019.
[29]Alireza Goudarzi, Peter Banda, Matthew R. Lakin, Christof Teuscher, and Darko Stefanovic. A comparative study
of reservoir computing for temporal signal processing.arXiv preprint arXiv:1401.2224, 2014.
[30]Danijar Hafner, Timothy P. Lillicrap, Ian Fischer, Ruben Villegas, David Ha, Honglak Lee, and James Davidson.
Learning latent dynamics for planning from pixels.arXiv preprint arXiv:1811.04551, 2018.
[31]  Oleg Klimov. Carracing-v0.https://gym.openai.com/envs/CarRacing-v0/, 2016.
[32]Corentin Tallec, Léonard Blier, and Diviyan Kalainathan. Reproducing "world models". is training the recurrent
network really needed ?https://ctallec.github.io/world-models/, 2018.
[33]Sebastian Risi and Kenneth O. Stanley.  Deep neuroevolution of recurrent and discrete world models.arXiv
preprint arXiv:1906.08857, 2019.
[34]Sepp Hochreiter and Jürgen Schmidhuber. Long short-term memory.Neural computation, 9(8):1735–1780, 1997.
[35]  Yann LeCun. The mnist database of handwritten digits.http://yann.lecun.com/exdb/mnist/, 1998.
[36]Greg Brockman, Vicki Cheung, Ludwig Pettersson, Jonas Schneider, John Schulman, Jie Tang, and Wojciech
Zaremba. Openai gym, 2016.
[37]  Luc. Prieur. Deep-Q learning for Box2d racecar RL problem.https://goo.gl/VpDqSw, 2017.
[38]Patrik Gerber, Jiajing Guan, Elvis Nunez, Kaman Phamdo, Tonmoy Monsoor, and Nicholas Malaya. Solving ope-
nai’s car racing environment with deep reinforcement learning and dropout.https://github.com/AMD-RIPS/
RL-2018/blob/master/documents/nips/nips_2018.pdf, 2018.
[39]Se Won Jang, Jesik Min, and Chan Lee.Reinforcement Car Racing with A3C.https://www.scribd.com/
document/358019044/, 2017.
[40]
Marc Massar and Serge Massar.  Mean-field theory of echo state networks.Physical Review E, 87(4):042809,
2013.
10 

An Adaptive Approach for Anomaly Detector Selection and
Fine-Tuning in Time Series
Hui Ye
Alibaba Inc
Beijing, China
yehui.yh@alibaba-inc.com
Xiaopeng Ma
Alibaba Inc
Beijing, China
xiaopeng.mxp@alibaba-inc.com
Qingfeng Pan
Alibaba Inc
Beijing, China
qingfeng.pqf@alibaba-inc.com
Huaqiang Fang
Alibaba Inc
Beijing, China
huaqiang.fhq@alibaba-inc.com
Hang Xiang
Alibaba Inc
Beijing, China
xingzhi.xh@alibaba-inc.com
Tongzhen Shao
Alibaba Inc
Beijing, China
yeqing.stz@taobao.com
ABSTRACT
The anomaly detection of time series is a hotspot of time series
data mining. The own characteristics of different anomaly detec-
tors determine the abnormal data that they are good at. There is
no detector can be optimizing in all types of anomalies. Moreover,
it still has difficulties in industrial production due to problems such
as a single detector can’t be optimized at different time windows of
the same time series. This paper proposes an adaptive model based
on time series characteristics and selecting appropriate detector
and run-time parameters for anomaly detection, which is called
ATSDLN(Adaptive Time Series Detector Learning Network). We
take the time series as the input of the model, and learn the time
series representation through FCN. In order to realize the adap-
tive selection of detectors and run-time parameters according to
the input time series, the outputs of FCN are the inputs of two
sub-networks: the detector selection network and the run-time pa-
rameters selection network. In addition, the way that the variable
layer width design of the parameter selection sub-network and the
introduction of transfer learning make the model be with more
expandability. Through experiments, it is found that ATSDLN can
select appropriate anomaly detector and run-time parameters, and
have strong expandability, which can quickly transfer. We investi-
gate the performance of ATSDLN in public data sets, our methods
outperform other methods in most cases with higher effect and
better adaptation. We also show experimental results on public
data sets to demonstrate how model structure and transfer learning
affect the effectiveness.
KEYWORDS
Self-adaption, Anomaly Detection, Joint Learning Network, Trans-
fer Learning, Time Series
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from permissions@acm.org.
DLP-KDD’19, August 5, 2019, Anchorage, AK, USA
©2019 Association for Computing Machinery.
ACM ISBN 978-1-4503-6783-7/19/08. . . $15.00
https://doi.org/10.1145/3326937.3341253
ACM Reference Format:
Hui Ye, Xiaopeng Ma, Qingfeng Pan, Huaqiang Fang, Hang Xiang, and Tongzhen
Shao. 2019. An Adaptive Approach for Anomaly Detector Selection and
Fine-Tuning in Time Series. In1st International Workshop on Deep Learn-
ing Practice for High-Dimensional Sparse Data (DLP-KDD’ ), August 5, 2019,
Anchorage, AK, USA.ACM, New York, NY, USA, 7 pages. https://doi.org/10.
1145/3326937.3341253
1  INTRODUCTION
Internet-based services have strict requirements for continuous
monitoring and in-time anomaly detection, Specifically, monitor-
ing performance ability and detecting performance anomalies are
important. Such as, e-commerce platforms need to monitor income
index and broadcast alert when obvious income decrease happens.
From the perspective of data science, key performance indexes
are usually portrayed as time series, and potential faults in ap-
plication are portrayed as anomaly. An anomaly (An outlier) in
time series, is a data point or a group of data points which signifi-
cantly different from the rest of the data points[8]. Due to the large
amounts of performance indexes and anomalies, human monitor-
ing of these indexes is impracticable which leads the demand for
automated anomaly detection using Machine Learning and Data
Mining techniques[6,10–12]. Many fast and effective anomaly de-
tectors were designed to localize these anomalies[2], such as outlier
detector[1], change point detector[7]. Although anomaly detec-
tors have proven effective in certain scenarios, applying them to
internet-based services remains a great challenge[9]. Due to the
large-scale distributed monitoring vision and complex trends of
indicators, it’s almost impossible to detect anomalies in all scenarios
with one type of detector. In order to ensure the performance of
the anomaly detection approach, expertise-based rules are required
for detector selection and run-time parameters fine-tuning[9]. Fur-
thermore, when a detector system is deployed online, the run-time
parameters of anomaly detector are usually required to adjust ac-
cording to real-time changes.
It’s hard to propose one general approach to detect all types of
anomaly, such as significant decrease or increase can be detected
by static threshold directly, continuous minor changing can be
detected by change point detector more quickly. State-of-the-art
detectors are usually designed to detect one type of anomaly[8].
When the multi-detector detection result voting method is adopted,
each detect needs to traverse all detectors and candidate run-time
arXiv:1907.07843v1  [stat.ML]  18 Jul 2019

DLP-KDD’19, August 5, 2019, Anchorage, AK, USAHui Ye, Xiaopeng Ma, Qingfeng Pan, Huaqiang Fang, Hang Xiang, and Tongzhen Shao
parameters combinations. The effect is greatly influenced by the
data set and voting rules and it is very time-consuming, which do
not meet the demands of industrial real-time monitoring scenarios.
Our proposed framework named ATSDLN, tackles the above chal-
lenges through an adaptive time series anomaly detector learning
network.
2  METHODS
Under the background of large industrial data scale, complicated
index system and an unusually large variety, on the one hand,
time series data usually changes with business changes. The same
time sequence may have great differences in different stages of
business projects; on the other hand, influenced by commercial
data and users’ behaviors, there are different low ebbs of the peak
flow on holidays, daytime and nights, big promotions and so on,
which cause the natural differences in data. If we do not consider
self-adaption when doing anomaly detection, we cannot balance
between the false positive rate and the false negative rate. Therefore,
choosing a universal detector to adapt to all data and scenarios is
unworkable. Multi-detection algorithm fusion is a very effective
method to improve the time series anomaly detection field, which
is usually conducted in the two stages as follows:
The anomaly detection stage: it is realized by selecting the
appropriate detector for the time series of the input.
The alarm convergence stage: it is realized by using the
abnormality that is detected by each detector as the input. The
alarm convergence can be achieved with the method of voting or
time series feature modeling.
•Voting method: absolute majority vote, relative majority
vote, weighted vote, etc.
•Deep learning: time series modeling of the detected anom-
alies.
Both of them are of highly expandability and support dynamic
expansion of anomaly detectors. The former is self-adaption based
on the original time series of the input, which is more flexible, this
study takes the former. As is shown in the experimental chapter,
the single detector is lower than our model in term of the accuracy,
recall, and f1, and the error rate is relatively high. The starting
point of this study is to set a certain sliding window size for the
time series, and optimize the accuracy, recall and false positive rate
of the anomaly detection through using the detector and run-time
parameters for the self-adaption selection of the current sliding
window time series.
Since different detectors have their own characteristics which
determine the type of time series they are good at, it is natural
to think about to determine which the detectors and run-time pa-
rameters are suitable for by the features of the time series. We
call this way the manual rule maintenance detector and run-time
parameters selection. The core work is to determine what features
of time series and what threshold should be used for judgment
(for instance, non-stationary time series with long-term trends can
adopt dynamic thresholds). The advantage of such artificial rules
is that it has strong interpretability. However, it is true that the
determination of these rules relies on manual experience, which
is difficult to enumerate the rules. As the data accumulation rules
become more and more difficult to maintain, the abnormal coverage,
correctness, versatility and expandability of the rules are also great
challenges.
Fortunately, in the era of artificial intelligence, it is natural to
think of using models to replace labor. Generally speaking, time se-
ries classification using traditional machine learning methods (such
as KNN, DTW) can achieve better results. However, as for big data,
deep learning tends to defeat traditional methods. Until recently,
a paper relevant to the research was published by Fawaz H I et
al. [4], which has demonstrated the feasibility of transfer learning
method for different time series data. The author argues that FCN
can learn time series representation well when the amount of data
is sufficient, and believes that the features extracted by the deep
network for the time series data are as similar and inherited as CNN
in terms of time series. Moreover, one of the challenges for super-
vised learning is the large number of labeled data. Unfortunately,
it is not readily available for the real-world labeled data problem
tended to the high cost and longtime consuming. This problem in
essence involves using transfer learning to obtain a solution. It can
be seen that the solution based on the transfer learning becomes a
better choice for the self-adaption anomaly detection problem.
A new ATSDLN modelis proposed in the paper, which realized
an adaptional classification of time series anomaly detectors and
run-time parameters selection by combining transfer learning and
dynamic adaptive joint learning. It is a pre-trained model based on
public data sets for transfer learning. Figure 1 is our frame diagram.
The model supports multiple channels, and can input the original
time series, prediction time series or residual sequence.
From the bottom to the top, the first part is the Fully Convolu-
tional Neural Network (FCN), which is made up of Convolution
layers and Global average pooling layer. As the Figure 1 shows,
transfer learning is applied to the FCN layer and fine-tuning in the
FC layers, which makes the network parameters initialized better,
so as to speed up the training and convergence and improve the
performance of time series classification model. The main function
of this part is to learn the rich time series representation by means
of a large amount of training data, and then produce time series
representation. This part introduces the ability of the migration
learning enhancement model to extract the ability of time series rep-
resentation, to deal with the problem of marking sample sparseness
and model mobility.
The second part is composed of two sub-networks, both of which
are supervised classification models. The left part is responsible for
the classification of the detector, while the right part is responsible
for the classification of the corresponding run-time parameters
of the detector, the two parts can jointly study. The expression
learned through the detector classification task will be used as the
input of the run-time parameters selection task, which can assist the
learning of the run-time parameters. Both of the sub-networks have
the problems of supervised classification. From the figure 1, it can be
seen that the output of p(x) determines a certain detector uniquely
for the current time series, and [q(x)] is the run-time parameters
that the current time series and anomaly detector choose. Because
the size of the candidate run-time parameters sets of each detector
is inconsistent, the last layer width of the right network follows the
left as the side detector changes, that the model supports flexible
addition and deletion detectors. It can be known from the above
that the selection of the run-time parameters on the right side

An Adaptive Approach for Anomaly Detector Selection and Fine-Tuning in Time SeriesDLP-KDD’19, August 5, 2019, Anchorage, AK, USA
Figure 1: Whole Net Structure, left represents anomaly detectors classification task, right represents run-time parameters
fine-tuning task. Blue layers are shared by the two sub-networks.
depends not only on the time series representation, but also on the
detector selected by the network on the left side. So in this part, the
expression learned in the left detector classification task is shared
to the task of the right run-time parameters selection on the right
and is taken as its input to assist in learning.
The third part, which is on the top, is the execution module for
the anomaly detection. It detects the anomaly of the detector and
the run-time parameters which is selected when time series use
models.
3  EXPERIMENTAL SETTING
The following parts form the core components of an joint learn-
ing approach. The two sub-networks in our approach refers to
anomaly detectors classification task and run-time parameters fine-
tuning task, which means the network predicts optimal detector and
fine-tunes the run-time parameters simultaneously without human
interfering. Firstly, we collect some classical detectors, which were
proposed to detect anomaly in different context. Secondly, a new
evaluation criterion was proposed to evaluate the performance of
these detectors in each time series data, this process also generates
the label of our two sub-tasks. Thirdly, an adaptive model is trained
to extract deep features of time series, which is crucial for optimal
detector prediction and the run-time parameters fine-tuning tasks.
Lastly, we transfer this representation learned from public data
sets to other unseen data sets and evaluate the usability of transfer
learning in time series anomaly detection.
3.1  Datasets
We set the different sizes of sliding window on webscope S5 data
sets
1
for the experimental sample, which contains outliers and
change points, and use the UCR Time series Classification Archive
2
as the source data sets for transfer learning.
Webscope S5
is a labeled anomaly detection data set. There are
367 time series in the data sets, each of which contains between
741 and 1680 data points at regular intervals. Each time series is
accompanied by an indicator series with 1 if the observation was
an anomaly, and 0 otherwise.UCRis a time series classification
data sets. There are 128 data sets with different applications. The
classification type of these data sets is from 2 to 60, and the the size
of data sets is from 20 to 8926.
Through traversing the candidate detector and the combining
operational parameters, the optimal detector and run-time parame-
ters are selected for the time series as a training data for supervised
learning. Then, by carrying out the pre-training of the transfer
1
https://research.yahoo.com/
2
https://www.cs.ucr.edu/

DLP-KDD’19, August 5, 2019, Anchorage, AK, USAHui Ye, Xiaopeng Ma, Qingfeng Pan, Huaqiang Fang, Hang Xiang, and Tongzhen Shao
learning on the UCR time series classification data set, the data
volume problem of the training data charged by the meter is solved.
3.2  Evaluation criterion
Experiments results were evaluated by comparing observed anom-
alies to true anomalies. In table 1, we present the evaluation mea-
sures of the model’s such as precision and recall, Error which were
used. FP denotes the number of false positive, FN the number of
false negative, TP the number of true positive and TN the number
of true negative.
Number of true positive whose proportion in anomaly detection
is small, in addition without considering precision’s inability to
accurately express the level of false positive ratio (or false alarm
ratio), especially when true positive is zero, precision is always zero.
there are not very good measures for assessing anomaly detection
methods. In our situation, the high false positive ratio will cause
alarm fatigue of the relevant personnel, which will lead to the
decrease of the attention of monitoring alarm. However, the number
of true negative is large, so the false positive rate is not sensitively
enough as it grows very slowly. Therefore, we propose a new metric
named Error which is defined as FP/(TP+FP+FN).
3.3  Detectors for time series anomaly detection
According to the shape and context of time series anomaly, it can
be summarized as outlier, mean-shift, cliff-type, deviating-trend,
new-shape. See the table 2 for details. The anomaly detectors used
in ATSDLN are just the same as EGADS.
In addition, the parameters fine-tuning is as important as the ac-
curacy of selecting the most suitable detector. Detector parameters
are divided into two categories: the first is the common parameters
needed by all detectors, including sliding window size, sensitivity,
number of historical samples. The second is the internal parameters
required by each detector algorithm, such as K-Multiple variance
of KSigma, eps and minPts of DBScan, confidence and drift range
of ChangePoint, search radius of DTW similarity, etc.
Figure 2: Example of anomaly types.
4  RESULTS AND DISCUSSIONS
Figure 3: Anomaly model performance on different detec-
tors(adaptively select best run-time parameters).
The second chapter mentions that the network is composed
of two sub-networks, both of which are supervised classification
models. The output of p(x) determines a certain detector uniquely,
and q(x) is the run-time parameters corresponding to the detector.
With the determined detector and run-time parameters, it is possible
to judge the abnormality of the time series execution abnormality
detection. The evaluation of part of the experimental effect adopts
the precision, recall and error described in evaluation criterion in
Chapter 3.2.
The main work of this paper is to select the appropriate detec-
tor as well as run-time parameters for a certain time series. The
length of the time series is called the window size of the time series.
The size of the window not only has relationship to the business
attributes, but also influences the sensitivity of the detector’s self-
adaption selection. In theory, the smaller the window, the more
sensitive the changes in the detector and parameters. The tradi-
tional voting method relies more on the accumulation of time series
data and has poor adaptability. As is shown in Fig. 4, the horizontal
axis is the window size of the time series, while the vertical axis if
the evaluation index calculated by the abnormality detection result.
It can be seen that the smaller the window, the worse the baseline
effect. According to our experiments, the window size will not af-
fect the performance of our model. The ATSDLN can better adapt
to different window size. In order to compare the performance of
different experiments, we choose the window size with 200 points.
4.1  Anomaly model performance analysis
In order to explore the necessity for self-adaption selection detec-
tors and operating parameters, 29 combination parameters of five
detectors are selected which described in detectors for time series
anomaly detection in Chapter 3.3. The experiments are performed
on the yahoo public data set. The results are shown in Figure 5,
the horizontal axis shows the 29 combinations of detectors and its
parameters, the vertical axis shows the performance under each

An Adaptive Approach for Anomaly Detector Selection and Fine-Tuning in Time SeriesDLP-KDD’19, August 5, 2019, Anchorage, AK, USA
Table 1: Evaluation Metrics
MetricDescription
PrecisionPrecision is defined as TP/(TP + FP)
RecallTrue positive rate or recall is defined as TP/(TP+FN)
False positive rateThe false positive rate is defined as FP/(FP+TN)
F1-scoreF1-score is dened as 2 * precision * recall /(precision + recall)
ErrorError is defined as FP/(TP+FP+FN)
Table 2: Anomaly and Detectors
typedescriptionsdetector
outliersignificantly differentKSigma/DBScan/LOF/Extreme LowDensity[1, 8]
mean-shiftsustained inapparent deviationCUSUM changepoint[7]
cliff-typeswitch to another sustained valueKernelDensity changepoint/KSigma/SimpleThreshold
deviating-trendnot in line with fitting trendSTL decomposition[3]
new-shapeun-similar with othersDTW similarity[5]
Figure 4: Baseline performance on different window size.
combination. There is no existence of fixed detector and parame-
ters which can be optimal at the whole time series. In addition, the
different effects of the run-time parameters are widely divergent
under the situation when the detector is determined.
4.2  Compare with single model
Figure 3 compared the results of ATSDLN with other single detector
models. It shows that the performance of our method is the best.
The method proposed in the paper, regardless of accuracy, recall
rate or F1, is superior to the single detector adaptive selection of
optimal parameters, and the false positive rate is also reduced.
Table 3: Peformance of different network architectures
model typePrecision  Recall  Error   F1
Baseline0.02780.00220.70350.0040
LSTM-DNN0.09400.51950.83350.1592
FCN-LSTM-DNN0.44190.00230.00280.0045
ATSDLN0.36060.45120.4445  0.4010
4.3  Comparison of different network
architectures
In this paper, we compare several network architectures to investi-
gate our proposed model’s effectiveness. The controlled models are
described as follows:
•Baseline: The majority voting algorithm based on EGADS.
•LSTM-DNN: A hybrid neural network composed of Long short-
term memory LSTM and DNN network.
•FCN-LSTM-DNN: The model adds a CNN layer to capture fea-
tures based on the LSTM-DNN model.
Table 3 shows that, when the multi-detector detection result
voting method is adopted, each detect needs to traverse all detectors
and candidate run-time parameters combinations, it is very time-
consuming, which do not meet the demands of industrial real-time
monitoring scenarios. Moreover, compared to the voting algorithm,
the neural network models behave higher F1 score, what’s more,
difference model structures can affect the evaluate metric. The CNN
shows the better ability of abstract feature extraction in our task.
4.4  Influence of share layers
As previously reported, the model selects the run-time parameters
for the current time series as well as the detector. The time series
representation learned through the detector classification task will
be used as the input of the run-time parameters selection task,
which can assist the learning of the run-time parameters. This part

DLP-KDD’19, August 5, 2019, Anchorage, AK, USAHui Ye, Xiaopeng Ma, Qingfeng Pan, Huaqiang Fang, Hang Xiang, and Tongzhen Shao
Figure 5: Anomaly model performance on different parameters.
Table 4: Effect of sharing layers
model type  Precision  Recall  Error   F1
NS-Model0.09820.51460.82530.1649
SSR-Model0.23660.33740.52120.2782
ATSDLN0.36060.45120.4445  0.4010
discusses the influence of share layers. The relevant models are
described as follows:
•NS-Model: without shared of network.
•SSR-Model: shared the shallow representation (the output
layer of FCN).
•ATSDLN: shared specific representation (the layers of the de-
tector classification task).
As is shown in Table 4, the effect of shared the shallow and
specific representations of time series is optimal through the classi-
fication network (anomaly detector selection) on the left and the
classification network (run-time parameters selection) on the right.
This is because the run-time parameters have a strong relativity
with the detector. In order to output appropriate detector categories,
the expression learned by the detector classification task will be
used as input of the parameter classification task to assist parameter
learning.
4.5  Influence of Transfer learning
To solve the shortage of data and let the network extract temporal
features and initialize the models better, we selecting some UCR
sample data sets for the comparative experiments of transfer learn-
ing.
•ATSDLN: Training without transfer learning.
•Transfer-1: Transfer from FordA to our data.
•Transfer-2: Transfer from Earthquakes to our data.
•Transfer-3: Transfer from coffe to our data.
Table 5: ATSDLN with Transfer learning
model type  Precision  Recall  Error   F1
ATSDLN0.36060.45120.44450.4010
Transfer-10.51910.36230.2513  0.4268
Transfer-20.37240.43500.42300.4013
Transfer-30.36130.45060.44340.4011
The second chapter mentions that transfer learning is applied
to the FCN layer and fine-tuning in the FC layers, which makes
the network parameters initialized better, so as to speed up the
training and convergence and improve the performance of time
series classification model. Table 5 shows that, in most of the cases,
the pre-trained model can improve the performance of model.
5  CONCLUSIONS
This paper proposed a new ATSDLN model, which realized an adap-
tional classification of time series anomaly detectors and run-time
parameters selection by combining transfer learning and dynamic
adaptive joint learning. The second Chapter mentions that the net-
work is composed of two sub-tasks: anomaly detector classification
and the run-time parameters fine-tuning network, both of which
are supervised classification models. Because the size of the candi-
date run-time parameters sets of each detector is inconsistent, the
last layer width of the right network (the run-time parameters fine-
tuning network) follows the left as the side detector changes, that
the model supports flexible addition and deletion detectors. Further-
more, because the run-time parameters have a strong relativity with
the anomaly detector, the effect of shared the shallow and specific
representations of time series is optimal through anomaly detec-
tors classification network and run-time parameters fine-tuning
network. Moreover, we pre-trained FCN layers based on different
data sets, the results investigated that transfer learning approach

An Adaptive Approach for Anomaly Detector Selection and Fine-Tuning in Time SeriesDLP-KDD’19, August 5, 2019, Anchorage, AK, USA
can improve the performance of our model. Experiment results
show that ATSDLN solves the problem of low precision and high
false alarm ratio when the data pattern is change. ATSDLN is also
applied to our industrial scenarios. In the future, we will consider
extract global features of time series and alarm suppression.
REFERENCES
[1]Markus M Breunig, Hans-Peter Kriegel, Raymond T Ng, and Jörg Sander. 2000.
LOF: identifying density-based local outliers. InACM sigmod record, Vol. 29. ACM,
93–104.
[2]Varun Chandola, Arindam Banerjee, and Vipin Kumar. 2009. Anomaly detection:
A survey.ACM computing surveys (CSUR)41, 3 (2009), 15.
[3]
Robert B Cleveland, William S Cleveland, Jean E McRae, and Irma Terpenning.
1990. STL: A seasonal-trend decomposition.Journal of official statistics6, 1 (1990),
3–73.
[4]Hassan Ismail Fawaz, Germain Forestier, Jonathan Weber, Lhassane Idoumghar,
and Pierre-Alain Muller. 2018. Transfer learning for time series classification. In
2018 IEEE International Conference on Big Data (Big Data). IEEE, 1367–1376.
[5]Tak-chung Fu. 2011. A review on time series data mining.Engineering Applications
of Artificial Intelligence24, 1 (2011), 164–181.
[6]Kyle Hundman, Valentino Constantinou, Christopher Laporte, Ian Colwell, and
Tom Soderstrom. 2018. Detecting spacecraft anomalies using lstms and nonpara-
metric dynamic thresholding. InProceedings of the 24th ACM SIGKDD Interna-
tional Conference on Knowledge Discovery & Data Mining. ACM, 387–395.
[7]Yoshinobu Kawahara, Takehisa Yairi, and Kazuo Machida. 2007. Change-point
detection in time-series data based on subspace identification. InSeventh IEEE
International Conference on Data Mining (ICDM 2007). IEEE, 559–564.
[8]
Nikolay Laptev, Saeed Amizadeh, and Ian Flint. 2015.   Generic and scalable
framework for automated time-series anomaly detection. InProceedings of the
21th ACM SIGKDD International Conference on Knowledge Discovery and Data
Mining. ACM, 1939–1947.
[9]Dapeng Liu, Youjian Zhao, Haowen Xu, Yongqian Sun, Dan Pei, Jiao Luo, Xi-
aowei Jing, and Mei Feng. 2015.  Opprentice: towards practical and automatic
anomaly detection through machine learning. InProceedings of the 2015 Internet
Measurement Conference. ACM, 211–224.
[10]Pankaj Malhotra, Anusha Ramakrishnan, Gaurangi Anand, Lovekesh Vig, Puneet
Agarwal, and Gautam Shroff. 2016. LSTM-based encoder-decoder for multi-sensor
anomaly detection.arXiv preprint arXiv:1607.00148(2016).
[11]Dominique T Shipmon, Jason M Gurevitch, Paolo M Piselli, and Stephen T Ed-
wards. 2017. Time series anomaly detection; detection of anomalous drops with
limited features and sparse examples in noisy highly periodic data.arXiv preprint
arXiv:1708.03665(2017).
[12]Haowen Xu, Wenxiao Chen, Nengwen Zhao, Zeyan Li, Jiahao Bu, Zhihan Li,
Ying Liu, Youjian Zhao, Dan Pei, Yang Feng, et al.2018. Unsupervised anomaly
detection via variational auto-encoder for seasonal kpis in web applications. In
Proceedings of the 2018 World Wide Web Conference on World Wide Web. Interna-
tional World Wide Web Conferences Steering Committee, 187–196. 

Probabilistic Regressor Chains
with Monte Carlo Methods
Jesse Read
1
and Luca Martino
2
1
LIX, Ecole Polytechnique, Institut Polytechnique de Paris, France
2
Dept. of Signal Theory and Comm., Univ. Carlos III de Madrid
Abstract
A large number and diversity of techniques have been offered in the
literature  in  recent  years  for  solving  multi-label  classification  tasks,  in-
cluding classifier chains where predictions are cascaded to other models
as additional features.  The idea of extending this chaining methodology
to  multi-output  regression  has  already  been  suggested  and  trialed:   re-
gressor chains.  However, this has so-far been limited to greedy inference
and has provided relatively poor results compared to individual models,
and  of  limited  applicability.   In  this  paper  we  identify  and  discuss  the
main limitations, including an analysis of different base models, loss func-
tions, explainability, and other desiderata of real-world applications.  To
overcome the identified limitations we study and develop methods for re-
gressor chains.  In particular we present a sequential Monte Carlo scheme
in the framework of a probabilistic regressor chain,  and we show it can
be  effective,  flexible  and  useful  in  several  types  of  data.   We  place  re-
gressor chains in context in general terms of multi-output learning with
continuous outputs,  and in doing this shed additional light on classifier
chains.
1    Introduction
Multi-dimensional data is ever-more present in industrial and scientific contexts.
For  example,  multi-label  classification  has  made  a  significant  impact  in  the
machine learning literature over recent years, where data points are naturally
associated with multiple outputs
1
.  Rather than a naive method of building one
model per output; advanced methods can model the outputs together, resulting
in better predictive performance.  Although the potential of individual models
is periodically revived under particular scenarios, the vast majority of literature
proposes joint modeling, and as a result show improvement in both predictive
1
Distinguished  from  multi-class  classification  in  that  a  single  output  may  take  multiple
values – but only one such value is assigned per output
1
arXiv:1907.08087v1  [cs.LG]  18 Jul 2019

y
4
y
3
y
2
y
1
x
5
x
4
x
3
x
2
x
1
y
4
y
3
y
2
y
1
x
5
x
4
x
3
x
2
x
1
Figure 1:  The naive vs chaining models.  Each targety
j
is learned by a base
model, where inputs are shown as incoming arrows, and output/prediction as
an outgoing arrow.
performance and efficiency.  A recent review of this area containing many useful
references, is given in [41].
An established method in multi-label classification is that ofclassifier chains,
where a model is trained for each label, but estimates of the other models are
used as additional features, in a cascaded chain along the target labels.  This is
exemplified (and contrasted to the naive approach) in Figure 1.
This  ‘chaining’  mechanism,  although  simple  in  its  basic  form,  has  proved
successful in multi-label classification and provided dozens of modifications, ex-
tensions, and improvements, in the literature (see, e.g., [36, 10, 34, 11, 41, 35, 32]
and references therein).
It is flexible, in the sense that any base model case be used to predict each
label, and powerful, in the sense that even relatively simple base models lead to
greater predictive performance than if they had been used separately.
Given its impact in multi-label classification, the motivation of this paper is
to more-thoroughly investigate the use of the chaining approach in the regression
context with continuous output variables. This investigation is needed since only
greedy inference can be applied directly, but even in this case the application of
chaining to the regression context is not straightforward and the effectiveness
of such application is not yet widely explored.
After summarizing background work (Section 2), we provide a rigorous dis-
cussion and development of probabilistic regressor chains, including a survey of
possible approaches (Sections 3 and 4).  Following this, we develop a sequential
Monte  Carlo  scheme  (Section  5).   This  scheme  allows  sampling  of  candidate
paths through the target space, which is useful for many applications.  We im-
plement and test several of these on synthetic and real-world datasets involving
multiple continuous outputs (Section 6), the results of which we reflect upon in
detailed discussion (Section 7).  After looking at connections to related and po-
tential future work (Section 8) we draw conclusions and make recommendations
(Section 9).
2    Chain Methods
Given  a  datasetD={(x
i
,y
i
)}
N
i=1
,  wherex
i
∈ X ⊆R
D
andy
i
∈ Y ⊆R
L
,
we are interested building a model that can provide predictions corresponding
2

toLtarget  variables
2
,ˆy=  [ˆy
1
,...,ˆy
L
],  for  any  given  input  observationx=
[x
1
,...,x
D
].
In the multi-outputclassificationscenario [36, 10, 34, 12], thej-th output
takes some valuey
j
∈{1,...,K
j
}(we may highlight the popular case of binary
outputs where eachy
i
∈{0,1}, known often asmulti-label classification) or – in
the case of continuous outputs, i.e., multi-outputregression– then eachy
j
∈R.
A naive approach is to simply build a separate model for each target inde-
pendently, such that
ˆy= [ˆy
1
,...,ˆy
L
] = [h
1
(x),...,h
L
(x)](1)
where each modelh
j
has been built from training set{(x
i
,y
ij
)}
N
i=1
, as a tradi-
tional single-output classifier or regressor according to the domain ofY
j
(clearly,
a regressor, ifY
j
∈R).  The exact class of model (type of regressor) is largely
dependent on preference and/or driven by domain assumptions and constraints.
Particularly  with  regard  to  multi-output  classification,  a  large  volume  of
literature proposes a plethora of models that out-compete this baseline by mod-
elling  the  dependencies  among  outputs;  consider  [36,  10,  40,  34,  11,  12,  41]
and references therein.  The multi-output regression literature is smaller in vol-
ume (consider, e.g., [3, 38]), being both more recently considered for specialized
methods, and being more difficult to obtain better results with such methods –
precisely a motivating factor behind this work.
In  prior  work  ([36,  10,  34,  12],  and  many  others),  a  chaining  mechanism
was  studied  for  multi-label  classification,  known  asclassifier  chains.   Due  to
the  relatively  large  amount  of  work  in  the  literature  on  this  topic,  including
continued  recent  interest  (e.g.,  [20,  39]  among  many  others),  we  argue  it  is
worth studying this mechanism in particular with application to multi-output
regression, which we will denoteregressor chains.
It  is  useful  to  study  regressor  chains  in  light  of  previous  developments  in
classifier  chains.   In  its  simplest  form,  the  estimates  of  other  labels  are  used
as feature inputs for the following classifier, thus augmenting the input space
along  the  chain.   Given  some  test  instancex,  we  may  obtain  an  estimate  of
ˆy= [ˆy
1
,...,ˆy
L
] as
ˆy= [h
1
(x),h
2
(x,ˆy
1
),...,h
L
(x,ˆy
1
,...,ˆy
L−1
)](2)
where a recursion takes placed based on ˆy
j
=h
j
(...).
In the classification context, this is known as aclassifier chainand, specif-
ically, one withgreedy  inference.  Note that modelsh
j
can be estimated indi-
vidually and in parallel at training time,  similarly to those in Eq. (1),  and –
likewise – those models may be any class appropriate for each individual target
(a binary classifier for binary output, etc).
In  this  case  of  greedy  inference,  a  single  path/combination  is  considered.
However, note that thisˆyin particular is just one possible prediction, and not
2
In cases where it is not clear from context,  we will denotey
ij
as the value of thej-th
attribute of thei-th instance
3

necessarily the best.  The addition of probabilistic inference was an important
development [10, 11], where a search is carried out, typically to obtain a MAP
estimate
3
, thus maximizing 0/1 loss; hence
ˆy=h(x) = argmax
y∈Y
P(y|x)
= argmax
y∈Y
L
∏
j=1
P(y
j
|x,y
1
,...,y
j−1
),(3)
whereYis  the  space  of  possible  paths  over  theLoutputs  andP(y
j
|x,·)  is
a pmf associated with thej-th model (henceforth we use the abbreviationP
j
where suitable).  This is known as aprobabilistic classifier chain.  The need for
a probabilistic interpretation (i.e., pmfsP
j
) can be addressed by building such
models; logistic regression is a common choice.
One may observe that the search space in Eq. (3) is exponential with the
number of labelsL.  Indeed, complete inference (all branches of the probability
tree are explored) is usually prohibitive.  Therefore, one may consider the search
space as a probability tree, and conduct a tree search, where eachP
j
provides
a weight on each branch.  Figure 3 offers some visual intuition.
y
3
y
2
y
1
x
x
0
0
0
1
1
0
0
.
9
1
0
.
8
0
.
4
1
0
0
1
0
.
6
0
.
7
1
0
1
0
.
6
Figure 2: Probabilistic classifier chains whereL= 3,y
j
∈{0,1}: As a probabilis-
tic graphical model (left), and with two explored paths inY
L
in the probability
tree.  Note that the best path (in red, right) is not found by greedy inference.
There are 2
L
possible paths (Y={0,1}
3
).  The label on each edge indicates
P
j
(y
j
= 1) (shown for explored paths).
Many search methods have been applied for this purpose (a survey is given
in [26]).  In particular we highlight the approach of Monte-Carlo sampling [34]
as – unlike many of the search approaches – is directly applicable to regressor
chains, and as such is most relevant to the material developed in Section 5 of
this work.  In this approach,Msamples are taken,m= 1,...,M, and weighted
as
y
(m)
j
∼P(y
j
|x,y
(m)
1
,...,y
(m)
j−1
)(4)
w
(m)
j
=w
(m)
j−1
·P(y
(m)
j
|x,y
(m)
1
,...,y
(m)
j−1
)(5)
3
Although configurations for other losses are also possible; see [10]
4

wherew
(m)
0
=  1.   An  example  is  shown  in  Figure  3  whereM=  2.   A  final
prediction is obtained as
ˆy=y
(m
∗
)
=argmax
y∈{y
(m)
}
M
m=1
P(y|x)(6)
wherem
∗
= argmax
m∈{1,...,M}
w
(m)
L
(index of the maximum weight), and where
y
(m)
= [y
(m)
1
,...,y
(m)
L
] is a complete sequence across label indices.  Note that
complexity is determined byM2
L
.
It  has  been  noticed  that  a  chaining  procedure  can  be  applied  in  an  off-
the-shelf  manner  to  the  multi-output  regression  context  involving  continuous
targets, namely with greedy inference;  see, e.g., [3].  However, as we highlight
and  discuss  in  the  following  section,  even  though  the  application  is  identical,
there  are  some  major  differences  in  the  way  regressor  chains  behave  and  the
relative results they obtain (with respect to non-chained methods).
3    The Poor Behaviour of Regressor Chains
Applying greedy inference in chains in the case of regression is – exactly as in
classification – a case of each output simply being “plugged in” to the following
model as an additional feature.  Recall that this simply means that predictions
ˆy
1
,...,ˆy
j−1
are treated as fixed observations (i.e.,  and not random variables)
when inferringy
j
.  Several papers have trialed this approach, e.g., [3].  Unfortu-
nately, predictive performance is not as impressive wrt independent regression
models.  We explain why.
Recall Eq. (2) from above.  A first choice of model in the regression context
may be least squares where ˆy
j
=h
j
(x) =w
>
j
[x
1
,...,x
D
,ˆy
1
,...,ˆy
j−1
]. Plugging
this in to the equation, and supposing for simplicityD= 1 input andL= 2
outputs, we observe that
4
ˆy
2
=h
2
(x,ˆy
1
)
=w
>
2
[x,ˆy
j
]
=w
>
2
[x,w
1
x]
=w
2,1
x+w
2,2
w
1
x
=x(w
2,1
+w
2,1
w
1
) =w
′
x
and thus clearly we see that label predictions ˆy
1
,...,ˆy
j−1
are superfluous in pre-
dicting ˆy
j
; the regressor chain in this context simply performs a series of linear
transformations which can naturally be represented as a single transformation.
It may be tempting to argue for application to the case wherex
j
is observed
only  attimex
j
.   In  this  scenario  we  presume  that  inputs  are  received  over
time, thus estimating  ˆy
j
=h(x
1
,...,x
j
,ˆy
1
,...,ˆy
j−1
).  Unfortunately, we may
4
Letw
j
= [w
j,1
, w
j,2
]
5

show that ˆy
1
,...,ˆy
j−1
are still not needed wrt ˆy
j
since all available information
already comes fromx
1
,...,x
j
directly via earlier labels.  This is seen clearly in
illustration; Figure 3.
y
1
y
2
x
1
x
2
Figure 3:    Even whenx
2
arrives only at timestep 2,  information can still be
carried  forward  fromx
1
(rather  than  viay
1
),  thus  making  the  label  cascade
superfluous wrt the prediction  ˆy
2
as long asf(x) is well modeled, even in this
case.
Another fundamental issue is the selection of loss metric.  An obvious and
popular  choice  for  regression  is  based  on  the  mean  squared  error  (MSE)  loss
criterion (as indeed considered in the earlier experimentation of regressor chains
in [3, 38] among others).
Under  random  variablesY=Y
1
,...,Y
L
,  we  see  that  the  minimum  MSE
(MMSE) estimator under observationxis given as follows,
ˆ
μ=E[Y
1
,Y
2
,...,Y
L
|x]
=E[Y|x] =
∫
yp(y|x)dy(7)
=
∫
y
p(y,x)
p(x)
dy
=
∫
y
p(y
1
|x)
∏
L
j=2
p(y
j
|x,y
1
,...,y
j−1
)p(x)
p(x)
dy
∝
∫
y·p(y
1
|x)
L
∏
j=2
p(y
j
|x,y
1
,...,y
j−1
)dy.
wrt marginal densitiesp
j
(homologous to the pmfs of Eq. (4)).  Let us emphasise
that
ˆ
μ= [ˆμ
1
,...,ˆμ
L
] is a vector ofLintegrals where
ˆμ
j
=
∫
y
j
p(y|x)dy
=
∫
y
j
p(y
1
,...,y
L
|x)dy
1
···dy
L
=
∫
y
j
p
j
(y
j
|x)dy
j
(8)
If we assume a Gaussian distribution
j
∈N(0,σ
2
j
) (a natural view of ordi-
nary least squares [17]) then again we may connect to the case discussed at the
beginning of this section, where ˆμ
1
=w
>
1
xand so on for ˆμ
1
,...,ˆμ
L
.
6

More generally, we are not only interested in obtaining point-wise estimators
μ
j
, but we are also interested in extracting all the statistical information encoded
within  this  posteriorp(y|x),  such  as  uncertainty measures,  credible  intervals,
and quantiles as well.  So, our goal is to approximate complex integrals involving
this posterior
p(y|x) =p(y
1
,y
2
,...,y
L
|x) =p(y
1
|x)
L
∏
j=2
p(y
j
|x,y
1
,...,y
j−1
)(9)
Having an estimate of the shape ofpthen allows us to estimate other values
aside from the expected value (i.e., Eq. (8)) such as the median or the mode.
We remark that classifier chains typically predicts a mode in the form of a MAP
estimate.
Notice, however, that – in spite of using the chain rule to factorize the joint
in this manner this estimate (and hence related integrals, Eq. (8)) are generally
intractable.  This is unlike in probabilisticclassifierchains where each pmfP
j
models a variable taking a finite number of discrete values – inherently more
tractable in most cases.
In all cases an exhaustive search in the joint is intractable for a large number
of outputsL, hence efficient tree search methods such as Monte Carlo sampling
(again,  refer  to  Figure  3).   However,  a  tree  cannot  be  formed  on  continuous
output  space,  and  hence  no  such  search  is  initially  possible  in  the  regression
context.   Discussion  of  the  output  space  also  brings  us  to  identify  a  further
pitfall in regression chains:  the possibility of extensive “error propagation”.  In
classifier chains, this is well known, and easily detectable (e.g., in ).  However,
theP
j
∈[0,1] space is inherently limited.  On the other hand, under regressior
chains, the estimate of greedy inference may completely degenerate and become
lost inp
j
∈Rspace, we progress down the chain towardsj=L.
Therefore we have isolated and discussed some main drawbacks to the appli-
cation of greedy regressor chains:  the type of loss functions often considered in
regression (e.g., MSE) totally change the behaviour of the chaining methodology,
and with a linear regression scheme, such as least squares, there is no benefit to
the chaining mechanism.  Even worse, error propagation may be catastrophic.
Having identified the lacking in regressor chains, as compared to their clas-
sification counterpart, in the following section we study the idea of probabilistic
regressor chains which we later build on to suggest new methods.
4    Probabilistic Regressor Chains with Monte Carlo
Search
In probabilistic classifier chains, inference may be cast as a search in the prob-
ability tree, as discussed above.  Many tree-search methods are applicable.  We
gave an example of Monte Carlo search which takesMweighted samples across
the tree (recall Eq. (4) and Eq. (5)).  In the regression context there is no inher-
ent tree to search.  We could however create a tree by using particular values
7

0.4
0.6
0.30.5
0.90.10.9
0.7
y
(1,2)
2
y
(3)
2
y
(3)
1
y
(1)
1
y
(2)
1
y
(1)
3
y
(2)
3
y
(3)
3
Figure 4:  A hypothetical search tree through particle space along the paths for
M= 3,L= 3.  Nodes show samplesy
(m)
j
and branches show evaluation of pdf
p
j
(y
(m)
j
|x,y
(m)
1
,...,y
(m)
j−1
).  The yellow branch indicates resampling (see Section
5) however this is shown for illustration;  this extra branch is not required for
inference.
y
(m)
j
∈Ras nodes.  This requires modeling of the marginals in such a way that
we may draw samples
y
(m)
j
∼p(y
j
|x,y
(m)
1
,...,y
(m)
j−1
),(10)
and in particular these samples should be at an ‘interesting’ part of the space,
such as near the modes.
Figure 4 shows an example illustration of samples{y
(m)
j
}forming paths and
thus a tree with each complete path from root to leave as a possible prediction
y∈R
L
.
This  is  an  interesting  idea,  as  with  a  cloud  of  samples,  we  can  not  only
obtain a tree and apply existing methods used in the classification context,, but
also  easily  obtain  an  approximation  a  MAP  estimator  as  well,  as  in  Eq.  (6).
Explicitly we can write this as:
y
(m
∗
)
= argmax
{
p(y
(1)
|x),···,p(y
(M)
|x)
}
,(11)
and more generally (estimators other than MAP), a prediction may be given as
path
ˆy=g
(
{y
(m)
,w
(m)
}
M
m=1
)
(12)
chosen by functiongover a tree with branches defined across nodes{y
(m)
}and
weighted by{w
(m)
j
}, i.e., holding the marginal branch cost from depthj−1 to
jby them-th sample.  Recall Figure 4.  It means that Eq. (11) makes use of the
8

fact thatp(y
(m)
|x) =
∏
L
j=1
w
(m)
j
.  In the remainder of this work we occasionally
omit the subscript and usew
(m)
=p(y
(m)
|x) as the path cost from root to a
leaf, i.e.,w
(m)
=p(y
(m)
|x) wherepas in Eq. (4) (for notational simplicity).
Suppose we define a cost functioncbased on path costsw
(m)
j
.  For example,
cost is given whenever crossing a low-density region according to the estimated
p
j
s.  To minimize expected loss,
E
Y∼D
[c(Y,h(x))|x] =
∫
Y
c(y,h(x))p(y|x) dy
we use our estimation ofp(and decomposition as ) and Monte Carlo samples
to replace the integral, thus giving something like Eq. (11) (depending on the
choice of loss function).
A fundamental consideration is how to estimate each componentp
j
ofp, and
how to draw samples from it.  The major issue at stake is that that a powerful
non-linear predictor is required to justify chains (as discussed above) yet such
a  predict  may  not  be  ideal  for  sampling  from.   We  address  this  issue  with  a
sequential Monte Carlo method, presented in the following section.  But let us
first look briefly at some available alternatives, all of which could be considered
a variation of probabilistic regressor chains.
4.1    Discretization and classification
A first approach to the inference problem is to simply discretize the label space
and proceed from a classification perspective.  This is not the same as taking
samples (which is done at prediction time).  As explained above, the classifica-
tion perspective of chains is easier to justify, and a wealth of methods available.
Of course not all problems are suited to discretization of the label space, but
often  it  is  suitable  and  even  common  practice,  for  example  in  the  domain  of
reinforcement learning (see, e.g., [42]).
In this case we are learningp(y
j
∈ S
(k)
j
|z)⇔P(y
j
=k) (the RHS relates
to Eq. (3)) where binS
(k)
j
⊂R;  and thus removing the need to estimate any
integrals.   Clearly  it  is  fundamental  to  choose  a  suitable  set  of  bins  (which
correspond to a finite set of class labels).
4.2    Bayesian regression
From the perspective of a greedy chain (earlier labels are fixed input), we may
elabouratep
j
as Bayesian linear regression:
p
j
=N(y
j
|μ
j
,Σ
j
)(13)
with sufficient statisticsμ
j
andΣ
j
.  As a Gaussian, sampling from this distri-
bution (e.g., as in Eq. (10)) is straightforward.  However, it based on a linear
combination ofμ
j
=θ
>
xand provides a unimodal Gaussian-shaped estimate,
not suitable for many types of data.
9

4.3    Variational inference
We  may  approximate  each
5
p
j
with  some  other  distributionq(y
j
|θ)≈p
j
as
in  variational  Bayesian  methods,  which  turns  inference  into  an  optimization
problem
θ
∗
= argmin
θ
KL(q(y
j
|θ)‖p
j
)
(minimizing Kullback-Leibler divergence); see, e.g., [1].  We could then sample
y
j
∼q(y
j
|θ) instead.  Unlike MCMC methods, this approach does not provide
an exact model ofp
j
in the limit (with sufficient samples).
4.4    Density estimation
Let  us  denotep
j
=p(y
j
|x,y
1
,...,y
j−1
)  =p(y
j
|z).   We  may  also  model  the
target densityp(y
j
|z) =p(y
j
,z)/p(z) using a non-parametric method such as a
Parzen window (i.e., a kernel density estimate, KDE), where
p(y
j
,z) =
1
N
N
∑
i=1
K
h
(z,z
i
)K
h
(y
j
,y
i
)    andp(z) =
1
N
N
∑
i=1
K
h
(z,z
i
)
for some kernelK
h
(of bandwidth parameterh).
Sampling can be carried out for certain kernels such the Gaussian kernel.  Al-
though of course, the general disadvantages of kernel methods apply (quadratic
complexity wrt number of examples, and difficulty in incremental modeling).
5    Sequential Monte Carlo Regressor Chains
The methods just described above are adequate to build a probabilistic regressor
chain if the resulting approximation ofp
j
is adequate for both sampling (obtain-
ingy
(m)
j
) and accurate evaluation (obtainingw
(m)
j
).  This restricts applicability
considerably, and our selection is reduced especially with high-dimensional in-
put observations.  For example, many methods may provide an evaluation of a
pdf, but not useful sampling.
In this section we build a state-space model for probabilistic regressor chains,
separating the sampling and evaluation functions. It is essentially aparticle filter
(PF, see, e.g., [13]).  We make some particular considerations and adaptations
for its application in a probabilistic regressor chain.
5.1    The particle filter
To briefly review:  a particle filter in a state space model consists of a model
M:
{
f(y
j
|y
j−1
)
`(x
j
|y
j
)
(14)
5
As a reminder,p
j
=p(y
j
|x, y
1
, . . . , y
j
)
10

running over time-stepsj= 1,...,L, encompassing the transition function and
observation function,fand`, respectively
6
.  See [13] for an in-depth introduc-
tion and survey.
Under  this  notation,  the  vanilla  particle  filtering  method  for  obtaining  a
marginal estimation (i.e., the prediction
7
) fory
j
can be written as:
y
(m)
j
∼f(y|y
j−1
)(15)
w
(m)
j
=w
(m)
j−1
·`(y
(m)
j
|x)(16)
ˆy
j
=E[Y
j
]≈
1
M
M
∑
m=1
w
(m)
j
y
(m)
j
(17)
We highlight the strong connection to Eq. (4)–Eq. (6) in Monte Carlo clas-
sifier chains.  However, in the classification context, the posterior pmfPcan be
sampled from easily; whereas here, since that might not be the case, we use the
auxiliary functionfto propose samples at each step in the chain.
There are important differences from typical applications of particle filters,
namely 1) in our case the model (Eq. (14)) is learned from the data (i.e.,  no
domain  knowledge  assumptions),  2)  a  single  observationxis  relevant  to  an
entire sequence of statesy
1
,...,y
L
(that is to say, the isotemporal case), and 3)
the full cascade is considered rather than the standard single-order Markovian
model.
5.2    Training
There are two functions which we need to learn; as according to Eq. (14):  the
transition  functionfand  observation  function`.   Unlike  the  vanilla  particle
filter model described above, we wish to take into account the chaincascade,
f(y
j
|y
1
,...,y
j−1
)
Any suitable method for modeling this density can be considered,  as long
as we are able to sample from it (the methods given in subsections 4.1–4.4 are
applicable here).  Except,  in this case we may removexwhich simplifies and
speeds-up sampling.
For function`we do only need to evaluate the function up to some normal-
izing constant, and thus we have more flexibility in choosing a function to learn.
Since we involve observationx
i
, predictive power is particularly important at
this step.  Any method giving accurate
`(x)∝p(y
j
|x,y
(m)
1
,...,y
(m)
j−1
)
6
Regarding  notation,  it  is  fundamental  for  those  familiar  with  the  literature  on  particle
filters and continuous state-space models, to observe that in this worky
j
is the state, andx
j
is the observation; as in line with the machine learning literature
7
In  machine  learning,  prediction  often  refers  to  anestimationfor  the  current  instance,
rather than for some future time instance, as often in dynamical systems terminology
11

may be considered.
There is no need to impose a particular choice at this stage – we will address
options in the experimental investigations in Section 6.
5.3    Inference
Algorithm 1 elaborates our Sequential Monte Carlo (SMC) scheme.  It can be
specifically designed  to measure  posteriorp(y|x);  namely to  approximate the
complex integrals involving of type Eq. (7) which represents a MMSE estimator,
or other loss functions that we are more interested in such as the mode.
Note that the Effective Sample Size (ESS) approximations is used to decide
when  the  resampling  step  (and  the  MCMC/AIS  schemes  if  required)  as  thus
prevent sample degeneration (i.e., error propagation), either
̂
ESS(  ̄w
1:M
) =
1
∑
M
i=1
 ̄w
2
i
or
̂
ESS(  ̄w
1:M
) =
1
max  ̄w
i
is typically appropriate [23].
Step 2c in the algorithm is not strictly necessary, nevertheless this step may
be useful in cases where the sequential scheme is struggling, and we include a
detailed description in A, of the application ofNindependent MCMC schemes,
specifically,NMetropolis-Hastings (MH) methods (at thej-th iteration of the
SMC algorithm above).
Of course, if a model efficiently meetsbothconstraints forfand`(as just
mentioned above) we can use the same model for both, thus simplifying Eq. (18)
and recovering the approach described in Section 5.
6    Experiments
In this section we compare some of the approaches we discussed, identified, and
developed  above.   Namely,  we  compare  independent  regression  models  (IR),
regressor  chains  with  greedy  inference  (RC)  with  our  Monte  Carlo  methods,
discussed in Section 4 as well as further developed as a Particle Filter in Section
5 (PFC). We compare different base estimators.  Recall that PFC takes both a
model for sampling and a model for evaluation – not necessarily from the same
model class.  These models are summarized and denoted as follows:
KeyAlgorithm
IRIndependent Regression
RCGreedy Regressor Chains
MCProbabilistic Regressor Chains (Monte Carlo)
PFProbabilistic Regressor Chains (Particle Filter)
BBayesian Regression
KKernel Ridge Regression (Gaussian Kernel)
grid searchα∈{1,0.1,0.01,0.001}andγ∈{0.01,0.1,1,10,100}
NDiscretized label space, 30 bins (classes per label)
. . . with Neural Network Classifier (2 hidden layers each of size 30)
R. . . with Random Forest Classifier, 100 estimators
12

Algorithm 1PFC: Sequential Monte Carlo (SMC) Method for PRCs
•INPUT:
–p
j
,f
j
, for allj, from training stage
–w
(m)
0
=
1
M
for allm.
–η∈[0,1] for ESS approximation
•Forj= 1,...,L:
1.  Form= 1,...,M:
–Draw samplesy
(m)
j
∼f(y
j
| ̃y
(m)
1
,..., ̃y
(m)
j−1
)
–Compute the transition weights
w
(m)
j
=w
(m)
j−1
`(y
(m)
j
|x, ̃y
(m)
1
,..., ̃y
(m)
j−1
)
f
j
(y
(m)
j
| ̃y
(m)
1
,..., ̃y
(m)
j−1
)
(18)
2.  If
̂
ESS(  ̄w
(1:M)
j
)≤ηM:
(a)  Resample{ ̃y
(1)
j
,..., ̃y
(M)
j
} ∼ {y
(1)
j
,...,y
(M)
j
}according to nor-
malized weights   ̄w
(m)
j
=
1
ˆ
Z
w
(m)
j
where
ˆ
Z=
∑
M
i=1
w
(i)
j
(i.e.,y
(m)
j
is resampled with probability   ̄w
(m)
j
; with replacement).
(b)  Setw
(m)
j
←
1
M
ˆ
Zfor allmas per [24].
(c)  (Optional) ApplyKsteps of an MCMC or AIS method (A); and
set (afterKiterations)
{ ̃y
(1)
j
,..., ̃y
(M)
j
}←{ ̃y
(1)
j,K
,..., ̃y
(M)
j,K
}
•OUTPUT: Predictiong
(
{y
(m)
},{w
(m)
}
)
as per Eq. (12),
whereˆy
(m)
={ ̃y
(m)
1
,..., ̃y
(m)
L
}
13

21012
x
1.5
1.0
0.5
0.0
0.5
1.0
y
1
{x
(i)
, y
(i)
2
}
N
i = 1
{x, y
(m)
1
}
M
m = 1
(a)y
1
∼f
1
(·|x)
1.51.00.50.00.51.0
y
1
1.0
0.5
0.0
0.5
1.0
y
2
{y
(i)
1
, y
(i)
2
}
N
i = 1
{y
(m)
1
, y
(m)
2
}
M
m = 1
(b)y
2
∼f
2
(·|x,y
1
)
12
j
1.5
1.0
0.5
0.0
0.5
1.0
y
j
{y}
N
i = 1
y
y
greedy
y
mcprc
{y
(m)
}
M
m = 1
(c)ˆy= [ˆy
1
,ˆy
2
]
123456
j
5
4
3
2
1
0
1
2
y
j
andro
data
y
y
greedy
y
PRC
samples
(d)ˆy= [ˆy
1
,ˆy
2
]
Figure 5:   The first three figures above related to the synthetic data shown in
Figure 6 (and the forth the Andro dataset).  For a given test instancex, samples
(shown in magenta) are taken across the chain (subfigs. (a) and (b) forf
1
andf
2
respectively) using functionf
j
which is learned from the training data (shown
in cyan).  A separate function evaluates the fitness of these samples, providing
weightw
(m)
, as shown implicitly in the size label of each sample.  Samples can
be viewed as trajectories (c, and – for the Andro dataset – d), and from this a
final trajectory is decided as a prediction.  Notice that in this dataset the true
trajectory (denoted in blue) can be approximated by our method, whereas this
is never the case under greedy chains (at least as clearly shown in the synthetic
dataset).  We remark also the bimodal nature of the distribution of Synth which
is difficult to capture with standard regression methods.  Details in Algorithm 1
and Section 6 in general.
14

such that (in the tables of results, Table 1), IR.B denotes independent Bayesian
regression, PF.R/B denotes particle filter chains with a discretized random for-
est base classifier for sampling, and Bayesian regression for evaluation; and so
on.  Note that MC and PF arealwaysset to maximize the 0/1 approximation
(by  selecting  a  mode),  whereas  IR  and  RC  (by  default)  maximize  MSE,  i.e.,
predict the mean.  In both cases we considerM= 100 samples/particles per
test example;η= 0.1.
IR and RC are implemented in the well-known Scikit-Learn framework
8
.  We
implemented our novel contributions using the Scikit-Multiflow framework
9
[27];
which is based on Scikit-Learn.  If not explicitly stated, then default parameters
are used.
We carry out an empirical evaluation on synthetic and real-world datasets.
The real-world sets are described and referenced in [38]
10
; covering a number of
real-world applications involving predicting the multi-components of sea-water,
residential  buildings,  concrete  pouring,  and  natural  resources;  so  as  to  over
sufficient variety.  The synthetic dataset is described and shown in Figure 6.
1.51.00.50.00.51.01.5
y
1
1.5
1.0
0.5
0.0
0.5
1.0
1.5
y
2
12
j
1.00
0.75
0.50
0.25
0.00
0.25
0.50
0.75
1.00
y
j
Figure  6:    A  bimodal  joint  distribution  over  two  labelsL=  2.   We  suppose
that both modes are equally probable givenx.  Left:  The true density.  Right:
hypothetical  “paths”  acrossj=  1,2.   The  black  points/lines  show  estimates
under a MAP estimator, red from an estimator of MSE, and yellow one possible
results under MAE.
We consider the following loss metrics:
MSE=
1
N
N
∑
i=1
L
∑
j=1
(y
ij
−ˆy
ij
)
2
andMAE=
1
N
N
∑
i=1
L
∑
j=1
|y
ij
−ˆy
ij
|
(mean squared error and absolute error, respectively) and denoting
0/1≈
1
N
N
∑
i=1
{
0    if‖ˆy
i
−y
i
‖
2
< c
1    otherwise
8
https://scikit-learn.org
9
https://scikit-multiflow.github.io/
10
Available online:http://mulan.sourceforge.net/datasets-mtr.html
15

Table 1:  Results of 10-fold cross validation.
MSE:
DatasetLIR.BIR.KRC.BRC.KMC.BMC.DPF.R/BPF.N/B
Synth21.031.021.041.051.441.021.511.42
Andro60.600.240.500.210.770.911.041.02
EDM20.610.430.600.420.970.800.981.17
ENB20.100.010.100.010.150.580.160.20
Jura30.380.350.380.350.570.770.580.50
Slump30.490.400.490.400.800.850.640.54
Avg Rank3.672.672.331.676.006.336.676.67
MAE:
DatasetLIR.BIR.KRC.BRC.KMC.BMC.DPF.R/BPF.N/B
Synth21.011.001.011.011.001.000.910.89
Andro60.620.330.560.310.700.760.950.75
EDM20.630.460.620.440.800.620.880.87
ENB20.220.070.220.060.280.640.320.36
Jura30.410.390.410.390.560.660.530.51
Slump30.540.420.550.430.670.760.610.56
Avg Rank4.003.503.002.505.335.836.005.83
≈0/1 (c= 0.1):
DatasetLIR.BIR.KRC.BRC.KMC.BMC.DPF.R/BPF.N/B
Synth21.001.001.001.000.941.000.510.59
Andro60.980.720.980.691.001.001.000.98
EDM20.870.690.860.640.880.780.820.70
ENB20.210.020.210.010.320.810.390.47
Jura30.730.700.730.700.880.980.890.87
Slump30.820.650.820.650.910.910.760.81
Avg Rank3.833.673.834.005.174.335.176.00
as an approximation of mean 0/1 loss (inverse accuracy) which approaches the
0/1-loss estimate as constantcgoes to 0.  This loss is designed to reward models
which find a joint mode, which should correspond to a path which is likely to
occur in practice (e.g., in the training data).
Averaged results over 10-fold cross validation are provided in Table 1 for the
different metrics.
7    Discussion
In this section we discuss empirical results.  We look at these results with the
goal of drawing conclusions about the behaviour of regressor chains in general,
16

and  secondly  as  justifying  both  acceptable  performance  and  usability  of  our
proposed methodologies.
The empirical results confirm that greedy regressor chains (RC) shows little
to  no  advantage  against  independent  estimators  when  a  linear  base  model  is
used  (only  a  small  exception  under  the  Andro  dataset,  if  we  are  to  compare
RC.B  and  IR.B).  These  findings  are  completely  in  line  with  the  analysis  so
far:  classification models involve an inherent non-linearity (such as for example
the sigmoid function in logistic regression) which adds predictive power via the
chain structure, but this not inherently the case in regression.
We do not need to discuss the power of non-linear modeling for regression,
as  this  is  an  elementary  concept,  but  it  is  particularly  interesting  to  observe
how well regressor chains with a non-linear base learner (e.g., RC.K) can per-
form better on average (i.e., in terms of average rank) against its independent
counterpart (IR.K). It is in this sense that we begin to find an argument to use
regressor chains.
Although regressor chains may be effective, we point out the risk of degener-
ation of estimates across the chain with poorly regularized base models.  Indeed,
we found this using standard stochastic gradient descent linear regression, esti-
mates diverged so far (obtaining greater than 1000 MSE) that it there was no
point to include them in the table.  This effect is well-mentioned in many analy-
ses of classifier chains in the literature under the term oferror propagation, but
in a multi-output binary classification setting, the posteriorP(y
j
|x,y
j−1
,...,y
1
)
such propagation is always constrained between 0 and 1.  However, under RCs
the trajectory may become increasingly lost and isolated (from the true path)
inR
L
space as prediction progresses along the chain.  Our choice of Bayesian
regression adds some regularization which counters this.  Nevertheless it is also
one of the issues we took into account with our developments of probabilistic
regressor chains.
Results show that acceptable predictive performance can be usually obtained
by Monte-Carlo approaches (MC, PF), although on average it does not achieve
top  results  overall.   At  first  glance  it  seems  difficult  to  justify  either  of  these
two methods in either of their configurations, but, we can take a closer look at
particular evaluation metrics.  We find that when it is important to find modes
of the posterior (0/1),  MC/B and PF./B outperform RC.B about half of the
time.  We can speculate that this would be similar in a hypothetical comparison
of  MC./K  but  the  implementation  we  used  (from  ScikitLearn)  does  not  offer
sampling from this method.  Furthermore, such a kernel-based approach has its
own  disadvantages  (quadratic  complexity,  difficult  application  to  incremental
learning,  and  so  on)  which  are  limiting  in  modern  settings  of  large  and  dy-
namic datasets.  In addition, we can emphasise the important result on Synth:
1.00 (RC.K) vs 0.51 (PF.R/B) is one of the largest differences in performances
obtained (actually 0.50 would be the Bayes optimal result for this data).  Fi-
nally, and perhaps most importantly:  Greedy RC provides almost no form of
interpretation.
Results are on the Synth dataset are worth exploring in more detail (shown
in  Figure  6;  results  shown  in  the  first  row  in  Table  1;  detailed  step-by-step
17

illustration  of  performance  in  Figure  5).   In  particular,  notice  that  any  path
crossing  a  low  density  region  is  unlikely  to  exist  in  practice,  even  though  it
provides the best estimate under MSE. In any kind of data with a multi-modal
density in the output space,  the our developed PF approach is highly suited,
as  it  is  able  to track  the  path-evolution across  different modes  along  its  pass
of the chain.  Furthermore, it is able to offer interpretation orexplainabilityof
results by showing actual paths taken, and the density estimate via the cloud
of particles; see, e.g., Figure 5.
It  is  a  pity  that  the  benchmark  datasets  we  used  as  per  related  studies,
do  not  seem  complex  enough  to  reveal  this  behaviour,  although  it  is  easy  to
provide examples of real-world possibilities.  For example, in the prediction of
trajectories for vehicles, it is useful only to estimate paths which do not cross
out of transportation axes (for example, a truck does not pass through a river
but over one of the bridges that cross it; for example as covered in [25] in the
discrete-waypoint  scenario).   Furthermore,  it  can  be  interesting  to  produce  a
set  of  possible  trajectories  rather  than  a  single  estimation.   Likewise,  in  time
series  forecasting  and  anomaly  detection,  we  may  want  to  consider  different
hypotheses, rather than outputting a single estimator of maximum likelihood.
The need for interpretable models is certainly of increasing interest, as ma-
chine learning methods are used in more sectors, for example medical and se-
curity, where it is often essential to be able to provide detailed explanation of
results.
For  simplicity,  in  the  Synth  data,  the  observationxdoes  not  affect  the
prediction fory
2
.  It means that if that variable was added (in a real-world case)
following building and deployment of the model predictingy
1
, it would be more
efficient to update the multi-output with a chain than an independent classifier.
Of course on this dataset any discussion of efficiency is not warranted, but as
the number of labels and instances grows, we can see chain methods operating
as a kind of transfer learning, adapting partially pre-trained models by adding
links from the outputs of those models.  A further discussion is beyond the scope
of this work.
8    Related  Methods  and  Additional  Considera-
tions
To  the  best  of  our  knowledge  this  is  the  first  work  treating  regression  chains
in depth, and particularly from a probabilistic point of view with a sequential
Monte Carlo approach.  Nevertheless, since it is tackling a well-established prob-
lem (i.e.,  multi-output regression) it is equally important to contribute a dis-
cussion of related methods in other areas, and additional considerations treated
in the classifier-chains literature already, as we do in this section.
18

8.1    Neural networks
A residual neural network (ResNet, [18]) includes skip layers similar to the way
a chain model does, except layer-wise rather than node-wise.  It has obtained
noteworthy  performance  on  deep  learning  tasks.   The  original  paper  (2015)
obtained good performance in image classification, though has also indeed been
studied in the context of regression (such as in [21]).  Aside from its prevalence
in  classification,  another  difference  is  that  in  ResNets  only  the  last  layer  is
used for prediction, with other labels simply forming internal nodes.  Although,
similar multi-label architectures (including, e.g., [5, 31]) have been used which
consider  each  (or  at  least  several  nodes/layers)  as  the  targets,  i.e.,  multiple
targets.  Although this work deals primarily with classification problems,  this
deep-learning approach tackles well one of the issues faced by regressor chains:
needing strong non-linearities to serve as useful representations, as highlighted
in our discussion and results.  Other neural models have been considered specific
to the multi-output regression case, including ensemble settings, e.g., [16].
8.2    Probabilistic models
A closely related approach to the inference in probabilistic regressor chains can
be seen as performing a standard regression with noisy inputs [9, 19].  Indeed,
suppose thatL= 2, and
y
1
∼p
1
(y
1
|x),
y
2
∼p
2
(y
2
|y
1
,x).(19)
Under the assumption of additive noise, we can write
y
1
=h
1
(x) +
1
(20)
y
2
=h
2
(x,y
1
) +
2
,(21)
whereh
j
are  the  regression  models.   For  performing  a  proper  inference,  all
the statistical features ofy
1
should be taken into account (i.e., the uncertainty),
hence a regression problem with noisy inputs. Gaussian Processes (GPs) provide
a  method  relevant  to  this  context,  e.g.,  [29,  6],  and  in  particular  the  idea  of
warped  GPs  [37,  22,  7]  (a  kind  of  hierarchical  GP,  thereby  giving  a  kind  of
‘depth’).   Most  of  these  cases  are  elaborated  whereL=  2.   We  remark  (also
with  regard  to  discussion  above)  that  there  is  of  course  no  clear  separating
definition between (deep) neural network and probabilistic models.
8.3    State space models
The previous  considerations have direct application  to the inference  and pre-
diction in so-called state-space models.  Such models are formed by a transition
19

dynamic equation and an observation equation
11
,
{
y
t+1
=h
d
(y
t
) +
d,t
,
x
t+1
=h
o
(y
t+1
) +
o,t
,
(22)
wherey
t
is thestateat timet, andis perturbation noise.  Note that even if
the  mappingshand  noisesare  known,  the  inference  and  prediction  in  this
stochastic  system  can  be  interpreted,  at  eacht,  as  a  noisy  input  regression
problem since
x
t+1
=h
o
(h
d
(y
t
) +
d,t
) +
o,t
,(23)
showing strong parallels with the noisy regression model above.  Furthermore,
when the elements of the dynamic system are not deterministically known the
problem becomes even more complex.  In [8, 2], authors suggest to modelh
d
,h
o
as two GPs.
8.4    Chain order
A natural question which arises is – does the order of the chain affect results?
This question has been answered in the classification context (in fact,  itdoes
affect  results)  in  various  other  works,  mainly  by  the  use  of  random  ensemble
methods (e.g., [36, 40]; each model with a different/random order), hill-climbing
approaches (e.g., [12, 34]; the best of a number of trialed orders is taken) and
methods based on label dependence (e.g., [26, 30] and references therein).  Most
of  these  methods  are  also  directly  applicable  to  the  regression  case;  indeed,
the chain-order space and complexity is exactly the same,  and thus ensemble
and hill-climbing methods need no specific adaptation; label-dependence based
methods only need to consider dependence among continuous variables rather
than discrete.  Thus, there is no reason to suggest why the regression context
needs special treatment, and for this reason we do not specifically readdress this
consideration in this work.
8.5    Multiple passes
Another aspect to consider is why not pass over the set of variables (i.e., through
the chain) multiple times per test instance.  This is an interesting proposal and
would  be  an  easy  extension  to  our  methods:  simply  iterate  over  the  chain  a
second time,  and plug in training labelsy
L+1
=y
1
,...,y
L+L
=y
L
and treat
them thenceforth as the target labels of interest.  We notice that one can view
this as a special case ofregressor stackingas described in [3] (in the general case,
we simply feed all predictions as inputs to a second model – not necessarily a
chain model).  On the other hand, time complexity increases significantly with
each pass along the chain.  One can also see a connection to recurrent neural
networks (RNN), as noticed in recent work by [28], unrolled across time.
11
Once more, we have opted for notation wherexis the observation
20

From the probabilistic perspective, an approach of many passes can be seen
as a kind of Gibbs sampling (where the graph is undirected).  In fact, an undi-
rected and fully connected network (rather than a ‘chain’) removes the question
of label order entirely.  This has been developed in the context ofconditional
dependency  networksas  presented  by  [15]  (for  multi-label  classification).   We
notice that this framework is also applicable to the regression case,  whenever
sampling from the conditional is possible; namely, (as in [15]) using Gibbs sam-
pling to estimate the marginal mode:
y
(m)
j
∼p(y
j
|x,y
6=j
)(24)
p(y
j
)≈
1
M−M
0
M
∑
m=M
0
y
(m)
j
(25)
(having adjusted the equations for continuous target variables) whereM
0
indi-
cates the initial samples during the burn-in time which are not considered.  This
is relatively straightforward to incorporate in the regression setting.  It is, how-
ever, worth emphasising that (as found empirically in [34], for example), that
the number of samples must be relatively much greater since a burn-in time of
M
0
> Lsamples is required, andML.
8.6    Other areas of application
Regressor chains can be applied to any problem involving multiple continuous
output  variables.   Time  series  forecasting  is  a  natural  application,  e.g.,  [29].
Previously classifier chains was applied to a discretized version of route predic-
tion  in  urban  traffic  modeling  [33];  and  an  application  of  regressor  chains  in
continuous space would be perhaps even more natural.
One interesting similarity is to the application of Monte Carlo tree search
for continuous action spaces in reinforcement learning (a good example of this
is given in [42]).  Forming a tree to search on top of a continuous space is part of
the problem we tackle. We notice that the authors of this cited work use a kernel
regression approach which is what we have empirically found to work well in
this work on regressor chains.  Unlike our study, there is no use of a chain in the
sense of a cascade, which is the main focus of this work.  Clearly investigation
of the use of regressor chains in such related areas could be promising.
9    Conclusions
In this work we have looked at extending the approach of chaining models to
the regression context.  This was motivated by the fact that, although the idea
had attracted initial interest and found potential applicability to multi-output
regression tasks, the behaviour of regressor chains was found not to emulate that
of classifier chains, thus warranting this in-depth study, to identify, unravel, and
overcome the weaknesses of this application.
21

We  identified,  discussed,  and  dealt  with  several  important  issues  in  this
regard:
•Regressor chains are only useful when non-linearities are used in the base
models, and this is equally applicable to the standard multi-output case,
and the case where attribute values arrive in sequence
•It is difficult to justify regressor chains for MSE estimation, unless paying
particular attention to the previous point.
•Error  propagation  (progressive  divergence  from  the  true  path  estimate)
can  be  much  more  severe  in  the  regression  case  due  to  the  unbounded
output space
•Greedy inference in regressor chains, on top of the above points, is unable
to provide useful representation or interpretation about the output space.
To our knowledge,  this is the first work which looks in-depth at regressor
chains in the probabilistic context.  We surveyed a number of applicable meth-
ods,  and  developed  our  own  based  on  sequential  Monte  Carlo  methodology,
particularly  crafted  to  tackle  these  identified  issues.   We  use  non-linear  base
models as particular to the ‘chains’ methodology where base models themselves
can be considered as a flexible hyperparameter, guided by aspects of the problem
domain, rather than a hardwired design – this, we argue, should not be seen as a
‘nuisance’ parameter but as an attractive feature for adaptation across different
areas.   We  provide  a  mode-seeking  mechanism,  rather  than  only  (but  as  well
as, potentially) an estimator for minimum squared error.  Error propagation is
controlled  by  a  resampling  scheme.   And  interpretation  is  provided  by  a  tree
generated by the point cloud of sample paths, which offer also a description of
the underlying density.
Probabilistic regressor chains have peculiarities that distinguish it from other
models, such as the full cascade involving all outputs and hyper-parametrization
of the base models.  However, to properly place regressor chains in context with
the wider literature, we also identified and discussed connections to a range of
related work which had not been noticed.
We may argue that our analysis not only facilitates understanding the per-
formance of regressor chains that we develop, but also earlier throws more light
into the performance considerations of classifier chains, modifications of which
are still under active development and recent publication.
Our Monte Carlo methods suggest to be promising especially for tasks where
path explainability (i.e., different hypotheses regrading the path taken through
output space) is of more importance than outputting the result of a minimum
mean squared error estimator.  Such tasks include medical research,  anomaly
detection,  de-noising,  and  missing-value  imputation;  providing  plenty  of  ap-
plication  lines  along  which  to  develop  this  work  further  and  built  additional
connections with related areas of the literature.  In future work we also intend
to explore areas (such as dynamic chains and recurrent models) that are being
22

developed in parallel in the classification context to approach themes relating
to chain order and structure.
References
[1]  David  Barber.Bayesian  Reasoning  and  Machine  Learning.   Cambridge
University Press, 2012.
[2]  H. Bijl,  T. B.  Schon,  J.  W.  van  Wingerden,  and M.  Verhaegen.  System
identification through online sparse Gaussian Process regression with input
noise.  InarXiv:1601.08068, pages 1–25, 2016.
[3]  Hanen Borchani, Gherardo Varando, Concha Bielza, and Pedro Larra ̃naga.
A survey on multi-output regression.Wiley Int. Rev. Data Min. and Knowl.
Disc., 5(5):216–233, September 2015.
[4]  Monica F. Bugallo, Luca Martino, and Jukka Corander.  Adaptive impor-
tance sampling in signal processing.Digital Signal Processing, 47(Supple-
ment C):36 – 49, 2015.
[5]  Moustapha Cisse, Maruan Al-Shedivat, and Samy Bengio.  Adios:  Archi-
tectures  deep  in  output  space.   InProceedings  of  The  33rd  International
Conference on Machine Learning, volume 48, pages 2770–2779, New York,
New York, USA, 20–22 Jun 2016. PMLR.
[6]  Patrick Dallaire, Camille Besse, and Brahim Chaib-draa.  An approximate
inference with Gaussian Process to latent functions from uncertain data.
Neurocomputing, 74(11):1945 – 1955, 2011.
[7]  Patrick Dallaire, Camille Besse, and Brahim Chaib-draa.  Deep Gaussian
Processes.Proceedings of the Sixteenth International Workshop on Artifi-
cial Intelligence and Statistics (AISTATS), pages 207–215, 2013.
[8]  M. P. Deisenroth, M. F. Huber, and U. D. Hanebeck.  Analytic moment-
based Gaussian process filtering.  InProceedings of the 26th Annual Inter-
national Conference on Machine Learning (ICML), pages 225–232, 2009.
[9]  P. Dellaportas and D. A. Stephens. Bayesian analysis of errors-in-variables
regression models.Biometrics, 51(3):1085–1095, 2009.
[10]  Krzysztof Dembczy ́nski, Weiwei Cheng, and Eyke H ̈ullermeier.  Bayes op-
timal multilabel classification via probabilistic classifier chains.  InICML
’10:  27th  International  Conference  on  Machine  Learning, pages 279–286,
Haifa, Israel, June 2010. Omnipress.
[11]  Krzysztof  Dembczy ́nski,  Willem  Waegeman,  Weiwei  Cheng,  and  Eyke
H ̈ullermeier.   On  label  dependence  and  loss  minimization  in  multi-label
classification.Mach. Learn., 88(1-2):5–45, July 2012.
23

[12]  Krzysztof  Dembczy ́nski,  Willem  Waegeman,  and  Eyke  H ̈ullermeier.   An
analysis of chaining in multi-label classification.  InECAI: European Con-
ference  of  Artificial  Intelligence,  volume  242,  pages  294–299.  IOS  Press,
2012.
[13]  P.  M.  Djuric,  J.  H.  Kotecha,  Jianqui  Zhang,  Yufei  Huang,  T.  Ghirmai,
M. F. Bugallo, and J. Miguez.  Particle filtering.IEEE  Signal  Processing
Magazine, 20(5):19–38, Sept 2003.
[14]  V. Elvira, L. Martino, D. Luengo, and M. F. Bugallo.  Heretical multiple
importance sampling.IEEE  Signal  Processing  Letters, 23(10):1474–1478,
2016.
[15]  Yuhong Guo and Suicheng Gu.  Multi-label classification using conditional
dependency  networks.   InIJCAI  ’11:   24th  International  Conference  on
Artificial Intelligence, pages 1300–1305. IJCAI/AAAI, 2011.
[16]  Esmaeil Hadavandi, Jamal Shahrabi, and Shahaboddin Shamshirband.  A
novel boosted-neural network ensemble for modeling multi-target regression
problems.Engineering Applications of Artificial Intelligence, 45:204 – 219,
2015.
[17]  Trevor Hastie, Robert Tibshirani, and Jerome Friedman.The Elements of
Statistical Learning.  Springer Series in Statistics. Springer New York Inc.,
New York, NY, USA, 2001.
[18]  Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.  Deep residual
learning for image recognition.2016 IEEE Conference on Computer Vision
and Pattern Recognition (CVPR), pages 770–778, 2016.
[19]  J. E. Johnson, V. Laparra, and G. Camps-Valls.  A derivative-based vari-
ance estimate for Gaussian Process regression.Submitted, pages 1–20, 2018.
[20]  Xie Jun,  Yu Lu,  Zhu Lei,  and Duan Guolun.  Conditional entropy based
classifier  chains  for  multi-label  classification.Neurocomputing,  335:185  –
194, 2019.
[21]  St ́ephane  Lathuili`ere,  Pablo  Mesejo,  Xavier  Alameda-Pineda,  and  Radu
Horaud.A   comprehensive   analysis   of   deep   regression.CoRR,
abs/1803.08450, 2018.
[22]  Miguel L ́azaro-Gredilla. Bayesian Warped Gaussian Processes. InAdvances
in Neural Information Processing Systems 25, pages 1619–1627. 2012.
[23]  L. Martino, V. Elvira, and F. Louzada. Effective sample size for importance
sampling based on discrepancy measures.Signal Processing, 131:386 – 401,
2017.
[24]  Luca Martino, Victor Elvira, and Gustau Camps-Valls. Group importance
sampling for particle filtering and MCMC.Digital Signal Processing, 82:133
– 151, 2018.
24

[25]  Luca Martino, Jesse Read, Victor Elvira, and Francisco Louzada.  Cooper-
ative parallel particle filters for online model selection and applications to
urban mobility.Digital Signal Processing, 60(January):172–185, 2017.
[26]  Deiner Mena, Elena Monta ̃n ́es, Jos ́e Ram ́on Quevedo, and Juan Jos ́e del
Coz.  Using A* for inference in probabilistic classifier chains.  InProceed-
ings of the Twenty-Fourth International Joint Conference on Artificial In-
telligence,  IJCAI 2015,  Buenos Aires,  Argentina,  July 25-31,  2015, pages
3707–3713, 2015.
[27]  Jacob  Montiel,  Jesse  Read,  Albert  Bifet,  and  Talel  Abdessalem.   Scikit-
MultiFlow:   A  multi-output  streaming  framework.Journal  of  Machine
Learning Research, 18, 2018.
[28]  Jinseok  Nam,   Eneldo  Loza  Menc ́ıa,   Hyunwoo  J  Kim,   and  Johannes
F ̈urnkranz.   Maximizing  subset  accuracy  with  recurrent  neural  networks
in multi-label classification. InAdvances in Neural Information Processing
Systems 30, pages 5413–5423, 2017.
[29]  J.  Qui ̃nonero-Candela,  A.  Girard,  and  C.  Rasmussen.   Prediction  at  an
uncertain input for Gaussian Processes and Relevance Vector Machines ap-
plication to multiple-step ahead time-series forecasting.Technical Report,
no. 1, pages 1–14, 2003.
[30]  Jesse Read, Concha Bielza, and Pedro Larra ̃naga.  Multi-dimensional clas-
sification with super-classes.Transactions  on  Knowledge  and  Data  Engi-
neering, 26(7):1720–1733, 2014.
[31]  Jesse Read and Jaakko Hollm ́en.  Multi-label classification using labels as
hidden nodes.  Technical Report 1503.09022v3, ArXiv.org, 2017.  ArXiv.
[32]  Jesse Read, Luca Martino, and Jaakko Hollm ́en.  Multi-label methods for
prediction with sequential data.Pattern Recognition, 63(Supplement C):45
– 55, 2017.
[33]  Jesse Read, Luca Martino, and Jaakko Hollm ́en.  Multi-label methods for
prediction  with  sequential  data.Pattern  Recognition,  63(March):45–55,
2017.
[34]  Jesse Read, Luca Martino, and David Luengo. Efficient Monte Carlo meth-
ods for multi-dimensional learning with classifier chains.Pattern Recogni-
tion, 47(3):1535–1546, 2014.
[35]  Jesse Read, Luca Martino, Pablo M. Olmos, and David Luengo.  Scalable
multi-output label prediction:  From classifier chains to classifier trellises.
Pattern Recognition, 48(6):2096 – 2109, 2015.
[36]  Jesse Read, Bernhard Pfahringer, Geoff Holmes, and Eibe Frank.  Classi-
fier chains for multi-label classification.Machine Learning, 85(3):333–359,
2011.
25

[37]  E.  Snelson,  Z.  Ghahramani,  and  C.  Rasmussen.   Warped  Gaussian  Pro-
cesses.  InAdvances  in  Neural  Information  Processing  Systems  16,  pages
1–8. 2003.
[38]  Eleftherios  Spyromitros-Xioufis,  Grigorios  Tsoumakas,  William  Groves,
and Ioannis Vlahavas.  Multi-target regression via input space expansion:
treating targets as inputs.Machine Learning, pages 1–44, 2016.
[39]  Pawe Teisseyre.  Ccnet:  Joint multi-label classification and feature selec-
tion using classifier chains and elastic net regularization.Neurocomputing,
235:98 – 111, 2017.
[40]  Grigorios Tsoumakas, Ioannis Katakis, and Ioannis Vlahavas.  Random k-
labelsets  for  multi-label  classification.IEEE  Transactions  on  Knowledge
and Data Engineering, 23(7):1079–1089, 2011.
[41]  Willem Waegeman, Krzysztof Dembczynski, and Eyke Huellermeier. Multi-
target prediction:  A unifying view on problems and methods. page ArXiV,
09 2018.
[42]  Timothy Yee, Viliam Lisy, and Michael Bowling.  Monte carlo tree search
in continuous action spaces with execution uncertainty.  InProceedings  of
the Twenty-Fifth International Joint Conference on Artificial Intelligence,
IJCAI’16, pages 690–696. AAAI Press, 2016.
A    Parallel Metropolis-Hastings (MH) chains
For completeness, we elaborate the algorithm based on [4, 14], starting from the
equal weighted set of samples obtained at step 2a of Algorithm 1,{ ̃y
(1)
j,0
,..., ̃y
(M)
j,0
}.
AfterKiterations, we obtain the final set of samples, illustrated as follows for
them-th particle:
•Fork= 1,...,K:
1.  Drawz∼q(y|y
(m)
j,k−1
).
2.  Setting for simplicityp
j
(z) =p
j
(z|x, ̃y
(m)
1:j−1
),  accept the movement
y
(m)
j,k
=zwith probability
α= min
[
1,
p
j
(z)q(y
(m)
j,k−1
|z)
p
j
(y
(m)
j,k−1
)q(z|y
(m)
j,k−1
)
]
(26)
Otherwise, with probability 1−α, sety
(m)
j,k
=y
(m)
j,k−1
Therefore final set of samples for an iteration is{ ̃y
(1)
j
,..., ̃y
(M)
j
}={ ̃y
(1)
j,K
,..., ̃y
(m)
j,K
}.
26 

A discriminative approach for finding and characterizing
positivity violations using decision trees
Ehud Karavani, Peter Bak, and Yishai Shimoni
∗
IBM-Research Haifa Labs
Abstract
The assumption of positivity in causal inference (also known as common support and co-
variate overlap) is necessary to obtain valid causal estimates.  Therefore, confirming it holds in
a given dataset is an important first step of any causal analysis.  Most common methods to date
are insufficient for discovering nonpositivity, as they do not scale for modern high-dimensional
covariate spaces, or they cannot pinpoint the subpopulation violating positivity.
To overcome these issues, we suggest to harness decision trees for detecting violations.  By
dividing the covariate space into mutually exclusive regions, each with maximized homogeneity
of  treatment  groups,  decision  trees  can  be  used  to  automatically  detect  subspaces  violating
positivity.  By augmenting the method with an additional random forest model, we can quantify
the robustness of the violation within each subspace.  This solution is scalable and provides an
interpretable characterization of the subspaces in which violations occur.
We provide a visualization of the stratification rules that define each subpopulation, com-
bined with the severity of positivity violation within it.  We also provide an interactive version
of the visualization that allows a deeper dive into the properties of each subspace.
1    Introduction
Causal inference is the field dedicated to estimating causal effects of some interventions from real
world retrospective data.  At its most basic concept, estimating an effect of an intervention is done
by comparing two groups, one that received the intervention, and another that received a different
intervention (e.g.,  placebo or no intervention).  However,  there are three assumptions needed for
this  derived  quantity  to  be  interpreted  as  acausaleffect,  namely,  no  unmeasured  confounders,
consistency, and positivity [1].
Positivity is the assumption that every sample has some positive probability to be assigned to
every treatment.  If we denote covariate space asXand treatment assignment asA, then positivity
can be formalized as Pr[A=a|X]∀a∈A[2].
Violation of this assumption, also known as non-positivity, or lack of covariate overlap, suggests
that there is some combination of features (an instantiation ofX) for which the probability to be
treated  is  either  1  or  0,  and  hence,  deterministic.   This  implies  that  that  particular  subspace  of
covariates is populated solely by samples from one group.  This, in turn, makes it impossible (or
∗
Corresponding author: yishais@il.ibm.com
1
arXiv:1907.08127v1  [stat.ML]  18 Jul 2019

much less probable) to infer the counterfactual outcome for these samples, as there is no data from
the other group to infer from.
In  some  cases,  such  as  when  caused  by  randomness,  non-positivity  might  be  solved  by  some
interpolation.   In  others,  the  cause  can  be  structural  (for  example,  medical  guidelines  prevent
people over 60 to be assigned a treatment).  In such cases, cohort refinement is necessary, exclusion
criteria must be updated, and the causal question needs to be adjusted [2] (for example, if all people
over 60 are excluded then the estimand is no longer effect in the population, but rather effect in
people under 60).  Ignoring the violation invalidates the causal question as it makes the two groups
incomparable.
Therefore, it is of interest for researchers to be able to easily identify if violations exist in the data,
and moreover, to characterize the covariate subspaces in which violations occur.  Nevertheless, as
the complexity of covariate spaces increases, by being of both high-dimensional and of various types
(i.e., mixing continuous, binary and categorical variables), this task becomes highly challenging.
1.1    Related work
There  are  few  methodologies  currently  in  practice  to  find  violations  of  positivity.   These  can  be
broadly cast into two groups, one that is based on statistical tests comparing the two groups on
each  covariate  marginally,  and  another  based  on  comparing  propensity  scores  across  these  two
groups.
1.1.1  Marginally comparing covariates
The  task  of  finding  lack  of  covariate  overlap  can  be  translated  to  the  task  of  checking  whether
the distribution of covariates is similar between the two treatment groups.  Checking for distances
between distributions is a thoroughly investigated problem in statistics.  However, most statistical
tests  do  not  scale  naturally  for  multivariate  distributions  [3].   Additionally,  multivariate  density
functions  cannot  be  assessed  easily  to  help  observe  how  distributions  of  the  two  groups  differ.
Therefore, an intuitive solution is to reduce the multivariate task to many single-variate tasks.  In
other words,  examining the distribution of each covariate separately (i.e.,  marginally) [4].  Note,
however, that overlap in each covariate marginally does not guarantee the multivariate joint distri-
bution also overlap, as exemplified in Figure 1A, showing a synthetic 2-dimensional covariate space
in which positivity is clearly violated, but this cannot be observed in any single dimension.
To  overcome  this  generalization  of  marginals  to  joint  overlap,  [5]  suggested  tabular  analysis
to check for violations on the intersection of several covariates.  While their method characterizes
the violating subspaces in a simple and intuitive way, it has two drawbacks:  (1) it does not scale
properly for more than a handful of covariates,  due to its 2-dimensional tabular nature;  and (2)
the  handling  of  continuous  variables  is  suboptimal,  as  it  is  done  by  using  predefined  bins  (e.g.,
quartiles).  Such binning can be intuitive, but also quite sensitive, since the number of bins (as well
as the spacing of their edges) can significantly impact the false-positive and false-negative detection
rates.  In addition, proper binning is particularly hard for heavy-tail distributions that are abundant
in real-world data.
1.1.2  Propensity based methods
Another approach to mitigate this ”curse of dimensionality” is with the use of propensity scores
(the  probability  Pr[A=  1|X]).   From  a  theoretical  perspective  [6],  it  is  possible  to  compare  the
2

distribution of propensity scores (rather than covariates) between groups and alert for violations
once the mass of the two distributions does not overlap, especially their tails (see Figure S2).
This method attracts researchers for being grounded in theory.  However, it also has two main
drawbacks. Firstly, propensity scores can be viewed as a dimensionality reduction from the covariate
space onto a single number,  and almost always bear some information loss [7].  Specifically,  two
different subspaces can be mapped into the same scalar, suggesting an observed overlap can picture
an  overly  optimistic  view  of  the  true  violations  in  the  original  covariate  space.   Secondly,  once
a violation is detected,  it  is usually hard to characterize  the covariate  subspace causing it,  as it
depends  on  the  interpretability  of  the  model  used  to  obtain  those  propensity  scores.   Therefore,
while this approach can provide an overview of the problem, it usually fails to convey information
beyond the binary a problem does/does-not exists.
In this work,we introduce a method to identify whether violations of positivity exist in a given
dataset.  While current methods seem to trade-off between the two, our method can both scale for
complex high-dimensional spaces, while also being highly interpretable.
2    Results
As  its  name  suggests,  lack  of  common  support  can  be  detected  by  measuring  large  statistical
distance  between  the  covariate  distribution  of  treated  and  untreated  groups.   This  comparison
of  distributions  is  known  in  statistics  astwo-sample  test[8].   To  accommodate  these  tests  for
complex high-dimensional spaces, recent works have suggested utilizing automatic machine learning
discriminators to try and differentiate between the two samples [9, 10, 11].
Inspired by this approach, we apply a machine learning model to detect positivity violations.
Essentially,  if  a  violation  exists  (i.e.,  common  support  is  lacking),  it  suggests  a  volume  of  the
covariate  space  is  occupied  solely  by  one  group.   This  subspace  can  then  be  identified  by  the
model,  which  will  use  the  samples  populating  it  to  achieve  better  discrimination  score.   Ideally,
on well-balanced datasets, like the ones needed for causal inference, the model will not be able to
discriminate the two groups and its prediction will be no better than a random coin flip.
However,  we  do  not  use  any  discriminitaive  model,  but  decision  trees  specifically.   Decision
trees are hierarchical classification models, usually constructed by greedy algorithms.  At each step,
the algorithm selects one covariate and one cutoff-value, so when splitting on them, the resulting
subsets have maximal homogeneity [12].  This process results in the decision tree dividing the entire
covariate  space  into  mutually  exclusive  regions  such  that  each  region  has  its  purity  (i.e.,  group
homogeneity) maximized [13].
We  harness  this  property  for  the  detection  of  positivity  violations.   We  train  a  decision  tree
classifier  using  the  treatment  assignment  as  the  target  variable.   While  being  constructed,  the
tree  tries  to  maximize  group  discrimination  by  finding  regions  in  the  covariate  space  populated
exclusively by only one treatment group.  These covariate subspaces are, by definition, violating the
positivity assumption.
To characterize the subspaces violating positivity, we utilize another useful property of decision
trees which is their interpretability.  Since the covariate space has been divided into disjoint union of
regions, it enables us to refer to covariate subspaces and decision tree’s leaves interchangeably [13].
Furthermore, since the division is done by simple stratification rules, it allows translating a path
from root to leaf into a covariate-level query and provide a simple and intuitive characterization of
3

the samples found violating positivity (see Methods).
To illustrate, once a tree is constructed, we go over its leaves and examine their purity.  If a leaf
contains samples from both the treated and untreated groups, we can assume that these samples
are not violating positivity.  But if a leaf contains samples from only one group and not the other
(i.e., a homogenic leaf), we can assume that the subspace defined by the leaf is violating positivity,
and the samples mapped to that leaf should be handled.
It is worth noting,  however,  that decision trees are notorious for overfitting.  With unlimited
depth, they can divide the space so much that each datapoint will be classified correctly [14].  This
implies they can be overly-sensitive to violations, not all of which are meaningful, as many violating
subspaces will be comprised from a handful of samples each.  One can be easily convinced that this
overly-fine  division  of  the  space  is  similar  to  the  depiction  of  decision  tree’s  overfit.   Therefore,
controlling  for  the  tree’s  overfit  also  controls  for  the  sensitivity  of  violation  detection.   Luckily,
overfitting can be mitigated automatically by constructing a heavily, yet carefully, regularized tree;
one  that  will  allow  the  model  to  generalize  well  to  new  out-of-bag  samples  [15]  (see  Methods).
Nonetheless, reducing the rates of false-positives might come at the price of increasing the rate of
true violations the tree falsely failed to detect (i.e., higher false-negatives).  Alternatively, hyper-
sensitivity  might  be  seen  as  an  advantage  for  researchers.   As  it  will  allow  them  to  go  over  the
putative  violations  flagged  by  the  algorithm  and  apply  domain-expert  knowledge  to  understand
whether they are meaningful or not, while knowing they are less likely to miss true violations due
to the model’s low false-negative rate.
Likewise, we can also hint at whether a violation is due to randomness or not, by using a random
forest.  Random forests are ensembles of decision trees, originally invented to mitigate the tendency
of  a  single  decision  tree  to  overfit,  a  problem  we  just  linked  to  the  meaningfulness  of  putative
violations.  They do so by constructing many trees, each using a bootstrap sample of the dataset
(a random sample with replacement) and a smaller random set of covariates, and then aggregating
each trees prediction into a final one [16].
We use a random forest to test the consistency of a datapoint being tagged as a violation, by
applying all trees to the original dataset and counting the fraction of trees in which a sample was
considered in violation.  If that number is small, we can suspect the violation was due to a random
”fluke” in the dataset (as the forest itself builds on a random sample of the dataset) captured by
the trees overfit.  This logic is unidirectional, since if the fraction is large, we cannot conclude the
violation has a structural cause, since it can still arise from a sampling error in the original dataset.
It is up to the researcher to investigate the subspace in order to determine if a consistent violation
is due to structural causes or randomness, and how to resolve it.
Lastly, this approach allows us to control for what is defined as a positivity violation.  Strictly
speaking, a violation is a covariate subspacexwhich contains samples from one group only, which
translates to Pr[A=a|X=x] equaling either 1,  or 0.  But consider the case that,  for example,
of  having  10,000  untreated  samples  over  the  age  of  60,  and  only  1  treated  sample.   We  define
those cases assoft  violations.  Whether these should be considered a violation or not are left to
the discretion of the researcher, as it translates to a bias-variance tradeoff;  since excluding those
samples will bias the original estimand but including them will cause the estimator to be highly
variable.  To illustrate, from inverse probability weighting perspective, that single treated individual
now counts as 10,000 ones.  Leaf homogeneity is directly linked to how balanced the corresponding
subspace is, and by tuning the threshold of leaf homogeneity, we can define what counts as violation
(see Methods).
4

2.1    Use case
A main component of our method is its visualization.  Briefly, we visualize the leaves of our decision-
tree as fixed-height rectangles with their y-axis location corresponding to tree-depth and their width
corresponding to the number of samples mapped to them (see Methods and Figures 1B, 2B). Each
treatment group is assigned a categorical color and rectangles are colored by the majority group of
the each leaf.  Additional color opacity is controlled by the consistency measurement derived from
the forest.
Size  and  coloring  are  incorporated  to  give  an  easy  overview  on  the  severity  of  the  violations
found  in  the  dataset.   Large  violating  subspaces  (as  in  many  samples  belonging  to  them)  will
occupy larger real-estate, and consistent violations (repeatedly rediscovered in the random forest)
will  be  opaque  and  intense.   The  combination  of  the  two  ensures  that  meaningful  violations  are
visualized  conspicuously.   Moreover,  an  interactive  version  (Figure  S1),  allows  the  researcher  to
hover over the tree to get more details on the violation (e.g., exact number of samples from each
group, the query to extract that subspace, etc.).
We present two use cases for the method. The first one, shown in Figure 1, is a synthetic example
of a rotated square.  It shows two groups (orange and blue), overlapping except for the first quadrant
having samples exclusively from group 1, suggesting Pr[A= 1|X
1
>0, X
2
>0] = 1.  The marginal
distributions  of  the  two  groups  are  similar  and  would  avoid  detection  by  the  marginal  methods
described above.  Comparing propensity scores by group (Figure S2), would detect a problem, but
reverse engineering these propensities to characterizable subspaces is model dependent.
Figure 1B shows the decision-tree corresponding to the data from panel A. The prominent blue
rectangle corresponds to the violated subspace of the first quadrant.  It is meaningful as it is both
wide, opaque (see Methods) and has low vertical location.  In contrast, theres an orange rectangle
at the bottom left,  but it is thin,  and therefore contains few samples.  Additional rectangles are
transparent,  suggesting  they  are  not  meaningful,  as  they  were  rarely  found  to  violate  positivity
within the random forest (i.e., inconsistent).
Figure  2,  shows  a  real  world  example  of  an  observational  study  about  the  effect  of  smoking
cessation on weight gain [17].  Since this is a high-dimensional example,  Figure 2A presents a t-
distributed stochastic neighbor embedding (t-SNE) projection [18] of that data onto two dimensions.
One property of t-SNE is that close points in the lower dimension are close in the original domain
with high probability.  We can see that the two groups overlap and that orange points are found
next  to  blue  ones,  hinting  no  violation  is  present.   Figure  2B  reinforces  that,  as  we  can  see  all
leaves of the corresponding tree are transparent,  indicating no discrimination could be made (in
the original domain, of course), and so no positivity violation could be found.
3    Methods
We  used  Python  3.6  together  with  scikit-learn  [19]  for  the  main  analysis  and  tree  construction.
Matplotlib [20] was used for static tree visualization and Bokeh [21] for the interactive one.  Code
can be available by request, please contact the authors.
3.1    Constructing a decision tree
Decision trees can gain 100% accuracy on any dataset,  but that does not mean their prediction
is good, as it will probably fail to generalize for out-of-box samples.  Similarly, an overfitted tree
5

Figure 1:  A synthetic example of applying positivity-detection tree.  (A) Scatter plot of the two-
dimensional data containing a positivity violation, where samples in the first quadrant are exclu-
sively assigned to group 1 (blue) and not group 0 (orange).  Samples that where flagged as being a
part of a violating subspace are depicted in ’plus’ marker.  Marginal distributions are also presented
(top and right histograms) to show that examining each covariate separately would not detect a
violation exist.  (B) Visualization of the corresponding tree.  Main observation is that the tree was
able  to  capture  the  violation  in  the  first  quadrant  (prominent  rectangle  in  corresponding  blue).
We  note  another  opaque  orange  box  to  its  left  that  the  tree  was  able  to  detect,  but  being  slim
means the number of samples is small and therefore can be negligible.  The rest of the rectangles
are transparent,  suggesting that the individuals are not participating in violating subspaces in a
consistent way.
is one that detects meaningless violations, since each sample can be assigned to a leaf of its own,
creating a violation of 1 sample against 0 samples from the other group.
Therefore, when building a decision-tree, it is of importance that it will be properly regularized.
To perform this model selection, we used random hyperparameter search in a cross-validation fashion
to find the hyperparameters that provided best performance (in terms of area under the receiver
operating characteristic curve) on the validation folds.  Other search paradigms can be plugged in
the tool, as long as they adhere to scikit-learns interface.
3.1.1  Constructing a forest
When constructing a random forest, each tree in the forest should be specified similarly to the main
reference tree.  This is done to make all trees comparable,  so insights drawn from the forest are
relevant to the main decision tree.
3.2    Significance testing
There are several metrics we can apply to check for the significance of a violation.
6

Figure 2:  Similar to Figure 1 but using real data from the NHEFS studying the effect of smoking
cessation on weight gain.  Since the data is of high-dimension, (A) contains a scatter plot of the
t-SNE projection onto two-dimensions of the data.  Overlap of points from group 0 (orange) and
group 1 (blue) hints there are no major violations of nonpositivity (as close points in the projected
space  are  also  close  with  high  probability  in  the  original  space).   Applying  our  method  on  the
original domain space and visualizing it in (B) confirms this, as the rectangles are so transparent
(meaning, inconsistent in their units violating positivity), that the plot seems to be blank.
3.2.1  Consistency
Consistency is a measure for samples.  It is done by applying the forest on the dataset.  We place
an indicator for each tree and each sample indicating whether that sample was flagged for being a
part of a violating subspace by that tree.  The consistency of a sample is the fraction of times it
was counted as a violation among all the trees in the forest (a number between zero and one).  The
consistency of a leaf is an aggregation of the consistency of the samples mapped to it.  For each leaf
in the main tree, the consistency of the samples mapped to that leaf is averaged.
3.2.2  Probability
Probability is a measure for leaves, which we model using hypergeometric distribution.  Given two
possible  interventionsA=  0,1,  we  can  denote  the  number  of  samples  from  each  group  in  the
entire dataset asN
0
, N
1
accordingly.  For a given leaf (or a covariate subspace),  we can haven
0
untreated  andn
1
treated  patients  belong  to  it.   These  samples  (n
0
, n
1
)  originate  from  the  root
samples (N
0
, N
1
).  Therefore,  we can model the leaf as a sample from the population (root) the
following way:
•N=N
0
+N
1
the population size,
•K=N
1
the number of successes in the population,
•n=n
0
+n
1
the number of draws,
7

•k=n
1
the number of observed successes.
And the probability of a leaf is the probability mass function Pr[X=k] givenX∼Hypergeometric(N, k, n).
The smaller the probability the rarer it is to get that subspace by chance.
3.2.3  Prediction performance
Overall sense of the severity of the violations can be obtain by testing the prediction performance
of the classification.  This can be done by applying any of numerous classification metrics common
in the field of machine learning [22].  Counterintuitively, keeping in mind that in contrast to usual
machine learning, a desired score in our case is a one suggesting the classifier is no better than a
random coin-flip (e.g., zero-one loss or area under the receiver operating curve of 0.5).  Random-like
prediction  performance  can  hint  that  the  covariates  of  the  two  intervention  groups  overlap  and
cannot be discriminated from each other.
3.2.4  Soft violations
Violations are calculated based on impurity measures   either entropy:−
∑
i
p
i
logp
i
, or gini:  1−
∑
i
p
2
i
.  The advantage of those impurity measures is that they are invariant to whether imbalance
was caused due ton
0
n
1
orn
0
n
1
.  To obtain strict classical positivity, we would tune our tree
to flag every leaf with impurity-measure of zero, which suggests eithern
0
= 0 orn
1
= 0.  However,
as explained above, we might be interested in subspaces where unbalancing is simply large, i.e.  the
ratio
n
1
n
0
is either very large or very small.  This can be obtained by setting some small positive
thresholdt, for which leaves with impurity below will be flagged as violating.
Relative violationsA common case is that treatment prevalence is low in the overall population
(i.e.,N
1
< N
0
).  In such cases, what regards as a soft violation should be adjusted according to
the overall prevalence rate.  Denoting the impurity measureH, we suggest comparingH(root) to
H(leaf).  Specifically, we calculate the conditionH(root)−H(leaf)> t
′
, for a small positivet
′
,
in order to determine whether to flag out a leaf.  By enforcing positive difference (i.e.H(leaf)>
H(root)) we assert that we dont mind the leaf being more heterogenic than the overall population
(the root).  Given a desired thresholdtfrom above, it can be transformed intot
′
= max{H(root)−
t,0}.
3.3    Visualization
We provide both static and interactive visualizations of the decision tree.  The goal of the static
visualization is to get a concise overview about how severe the violations in the dataset are.  The
interactive one can also further explore the leaves to obtain more details (as described above) about
the subspaces they represent.
The visualization is built out of fixed-height rectangles.  Each such rectangle represents a leaf,
which  width  corresponding  to  the  number  of  samples  it  contains  and  the  y-axis  location  to  its
depth.  Therefore, the entire of the x-axis represents all the samples in the datasets, grouped by
their corresponding leaves; and shallower leaves in the tree are lower on the y-axis.
Each treatment group gets its own color.  The color of a leaf is the color associated with the
majority group mapped to it.  Additional color opacity is determined by the average consistency
8

values of the samples belonging to the leaf.  The aggregation is not limited to average and could be
also median or any other summary statistic over the consistency values.
Combining the shaping and coloring, we get that important subspaces are large (wide rectangle),
consistent (opaque) and simple (few features involve in defining it, therefore the leaf is shallow in
the tree, and therefore it is closer to the axes).  On the other hand, unimportant subspaces will be
depicted as transparent or small (negligible) rectangles.  This way, the more eye-catching the plot
is  the more severe violations are in the dataset, so ideally, one should expect a blank plot.
3.4    Characterization - rule extraction
Given a leaf, characterization of the subspace defined by it is straightforward.
Data:A treeT, a desired leafl.
Result:A covariate-level queryQdefining the subspace corresponding tol.
Initialize empty queryQ.;
traverse from root nodeT(root) to leafl:
foreach nodekalong the pathdo
LetX
i
be the covariate inquired for split on nodek;
Letcbe the cutoff for that split;
Lets∈{≤, >}be the sign used to split;
UpdateQ=Q∧(X
i
sc);
end
Algorithm 1:Algorithm for extracting covariate-level characterization from a decision tree leaf,
characterizing the samples belonging to the covariate subspace correspnding to that leaf.
Since a decision tree can reuse covariates in different depths of the tree, a subspace query can
have redundant rules (e.g.,x
3
>0∧x
3
>1 that can be simply formatted asx
3
>1).  To simplify
such repetitions, query pruning can be applied.  When encountering a repeated rule (in terms of
both covariate and cutoff sign), the rule closer to the leaf is kept, while the rule closer to the tree
root is discarded.  This promises rules kept are more specific to the subspace (as rules are more
general the closer they are to the root).
3.5    Data
Real data is from a National Health Epidemiologic Followup Study (NHEFS) from the National
Health and Nutrition Examination Survey (NHANES), studying the effect of smoking cessation on
weight  gain  [17].   The  data  was  obtained  from  [1]  website,  as  it  is  used  as  a  canonical  example
worked throughout the book.  We followed it by controlling for demographics, smoking history and
activity levels as confounders.
4    Summary and discussion
Positivity is a necessary assumption for causal inference, ensuring treatment groups are comparable,
so  causal  conclusions  could  be  drawn.   Therefore,  verifying  it  holds  is  an  important  part  of  the
analysis process.  We present a scalable approach for detecting if positivity violations occur in a
dataset and characterizing the subspaces these violations originate from.
9

We do so by exploiting decision trees for the task.  We train them to differentiate the treatment
groups, so they divide the covariate space into disjoint regions, each region with maximized homo-
geneity in terms of treatment assignment.  If such homogeneous treatment regions are found, they
are, by definition, positivity violating subspaces.
Since these regions are represented by the tree’s leaves,  we can characterize them intuitively,
using  covariate-level  queries  defined  by  the  path  along  the  decision  tree.   Such  simple  portrayal
is  comparable  with  tabular  methods  for  detecting  positivity  [5].   However,  in  contrast  to  such
methods, we can effortlessly scale to detect complex spaces, since detection is done algorithmically.
The  tree  representation  can  handle  more  variables  than  a  table,  and  rules  for  each  variable  are
chosen automatically so as to maximize discrimination, rather than being predefined by the user.
By correctly exploiting decision trees,  our method does not trade-off between interpretability
and scalability.
However, using off-the-shelf decision trees is not problem-free.  We discussed their tendency to
overfit and linked it to their over-sensitivity and discovery of assumingly meaningless violations.
We also suggested a range of ways to mitigate those false-discoveries using regularization, domain
expert  knowledge,  probability  and  measuring  how  consistent  violations  are  across  an  additional
Random Forest.
To  summarize  the  findings  in  a  concise  way,  we  accompany  the  analysis  above  with  a  dedi-
cated  visualization  of  the  decision  tree.   The  visualization  aim  to  highlight  the  most  meaningful
subspaces violating positivity.  It allows an easy overview of the scale and severity of violations in
a dataset.  The interactive version also allows a more thorough investigation into the subspaces to
obtain additional information (see snapshot in Figure S1).  Since the methodology is heuristic and
threshold-based, the visualization can guide users toward choosing these hyperparameters.
Finally, we demonstrated the method on both synthetic and real-world examples.  We showed
how  to  interpret  the  visualization  in  both  a  positive  example  (lack  of  covariate  overlap)  and  a
negative (good covariate overlap) one.
As data increase in complexity, so does the methods dealing with it should adjust to keep pace.
Utilizing decision trees to act as interpretable detectors of biases in data can turn useful across a
wide range of domains,  in which treatment assignment in the context of causal inference is only
one of them.  We believe this method to be useful for causal inference researchers.  We advocate
incorporating it in workflows to help detect biases in the data prior to analyzing it, and therefore
focusing on causal questions that can be supported by the data.
Acknowledgments
The  authors  would  like  to  thank  the  researchers  of  the  Machine  Learning  for  Healthcare  group
at IBM-Research Haifa Labs.  Specifically,  to Chen Yanover and Tal El-Hay for their thoughtful
insights and help with background research.
References
[1]  Miguel A Hernan and James M Robins.Causal inference.  CRC Boca Raton, FL:, 2010.
[2]  Daniel Westreich and Stephen R Cole.  Invited commentary:  positivity in practice.American
journal of epidemiology, 171(6):674–677, 2010.
10

[3]  Munmun  Biswas  and  Anil  K  Ghosh.   A  nonparametric  two-sample  test  applicable  to  high
dimensional data.Journal of Multivariate Analysis, 123:160–171, 2014.
[4]  Ariel Linden.  Graphical displays for assessing covariate balance in matching studies.Journal
of evaluation in clinical practice, 21(2):242–247, 2015.
[5]  Lynne  C  Messer,  J  Michael  Oakes,  and  Susan  Mason.   Effects  of  socioeconomic  and  racial
residential segregation on preterm birth: a cautionary tale of structural confounding.American
journal of epidemiology, 171(6):664–673, 2010.
[6]  Paul R Rosenbaum and Donald B Rubin.  The central role of the propensity score in observa-
tional studies for causal effects.Biometrika, 70(1):41–55, 1983.
[7]  Bernhard C Geiger and Gernot Kubin.  Relative information loss in the pca.  InInformation
Theory Workshop (ITW), 2012 IEEE, pages 562–566. IEEE, 2012.
[8]  Erich L Lehmann and Joseph P Romano.Testing  statistical  hypotheses.  Springer Science &
Business Media, 2006.
[9]  David Lopez-Paz and Maxime Oquab.  Revisiting classifier two-sample tests.arXiv  preprint
arXiv:1610.06545, 2016.
[10]  Michal Ozery-Flato, Pierre Thodoroff, and Tal El-Hay.  Adversarial balancing for causal infer-
ence.arXiv preprint arXiv:1810.07406, 2018.
[11]  Ian  Goodfellow,  Jean  Pouget-Abadie,  Mehdi  Mirza,  Bing  Xu,  David  Warde-Farley,  Sherjil
Ozair,  Aaron  Courville,  and  Yoshua  Bengio.   Generative  adversarial  nets.   InAdvances  in
neural information processing systems, pages 2672–2680, 2014.
[12]  J. Ross Quinlan.  Induction of decision trees.Machine learning, 1(1):81–106, 1986.
[13]  Lior  Rokach  and  Oded  Maimon.   Decision  trees.   InData  mining  and  knowledge  discovery
handbook, pages 165–192. Springer, 2005.
[14]  Lior  Rokach  and  Oded  Maimon.Data  mining  with  decision  trees:   theory  and  applications,
volume 69.  World scientific, 2008.
[15]  Ron Kohavi et al. A study of cross-validation and bootstrap for accuracy estimation and model
selection.  InIjcai, volume 14, pages 1137–1145. Montreal, Canada, 1995.
[16]  Leo Breiman, Jerome H Friedman, Richard A Olshen, and Charles J Stone.Classification and
regression trees.  Wadsworth & Brooks/Cole Advanced Books & Software, 1984.
[17]  National Center for Health Statistics.  NHANES I Epidemiologic Followup Study (NHEFS),
1992.
[18]  Laurens van der Maaten and Geoffrey Hinton. Visualizing data using t-sne.Journal of machine
learning research, 9(Nov):2579–2605, 2008.
[19]  Fabian Pedregosa, Ga ̈el Varoquaux, Alexandre Gramfort, Vincent Michel, Bertrand Thirion,
Olivier Grisel, Mathieu Blondel, Peter Prettenhofer, Ron Weiss, Vincent Dubourg, et al. Scikit-
learn:  Machine learning in python.Journal of machine learning research, 12(Oct):2825–2830,
2011.
11

[20]  J. D. Hunter.  Matplotlib:  A 2d graphics environment.Computing In Science & Engineering,
9(3):90–95, 2007.  doi:  10.1109/MCSE.2007.55.
[21]  Bokeh  Development  Team.Bokeh:  Python  library  for  interactive  visualization,  2014.   URL
http://www.bokeh.pydata.org.
[22]  M Hossin and MN Sulaiman. A review on evaluation metrics for data classification evaluations.
International Journal of Data Mining & Knowledge Management Process, 5(2):1, 2015.
12

Supplementary figures
Figure S1:  A snapshot of the exact same plot as Figure 1B, only its interactive version, where a
box  with  additional  information  is  shown  upon  hovering  over  the  leaf  (for  details  see  Methods).
The information isleaf  depth(the shallower the leaf,  the simpler the corresponding subspace is,
therefore violations there might be more important); thenumber of samples from each group(328
from  group  1,  and  none  from  group  0);impurity(this  case  entropy,  corresponding  to  the  group
counts);probabilityof the subspace, modeled with hypergeometric distribution shows a small value
meaning this violation is unlikely to happen by chance;is
violatingdenotes whether the leaf counts
as  a  violation  by  the  tree;aggregated  consistencyvalue  of  the  samples  belonging  to  that  leaf  (a
value being close to 1 means they were consistently flagged in the random forest, thus the opaque
color of the rectangle); and finally, the data query characterizing the subspace corresponding to the
leaf (in this case, defining the first quadrant, see Fig 1A).
13

Figure S2:  A more classic approach for detecting positivity violation for the two datasets presented
in the main text, by examining the overlap of the propensity score distributions between the treat-
ment groups.  (A) is for the synthetic example showing a bulge in density around propensity = 1
exclusive for group 1,  which suggest a violation does exist (Fig 1).  Conversely,  for the real-data
example in (B) we see a good overlap of scores between groups, enforcing the fact we were not able
to detect violations using the decision-tree and that the t-SNE projection showed good mixture of
the groups (Fig 2).  We note that this method may detect a problem exists, but characterizing its
origin depends on the model used to obtain the scores.
14 

Model-free Control of Chaos with Continuous Deep Q-learning
Junya  Ikemoto
∗
and  Toshimitsu  Ushio
†
Graduate School of Engineering Science, Osaka University
Toyonaka, Osaka, 560-8531, Japan
(Dated: 16 July 2019)
The OGY method is one of control methods for a chaotic system.  In the method,  we have to calculate a
stabilizing periodic orbit embedded in its chaotic attractor.  Thus, we cannot use this method in the case where
a precise mathematical model of the chaotic system cannot be identified.  In this case, the delayed feedback
control proposed by Pyragas is useful. However, even in the delayed feedback control, we need the mathematical
model to determine a feedback gain that stabilizes the periodic orbit.  To overcome this problem, we propose
a model-free reinforcement learning algorithm to the design of a controller for the chaotic system.  In recent
years, model-free reinforcement learning algorithms with deep neural networks have been paid much attention
to.   Those  algorithms  make  it  possible  to  control  complex  systems.   However,  it  is  known  that  model-free
reinforcement learning algorithms are not efficient because learners must explore their control policies over the
entire state space. Moreover, model-free reinforcement learning algorithms with deep neural networks have the
disadvantage in taking much time to learn their control optimal policies. Thus, we propose a data-based control
policy consisting of two steps, where we determine a region including the stabilizing periodic orbit first, and
make the controller learn an optimal control policy for its stabilization.  In the proposed method, the controller
efficiently explores its control policy only in the region.
I.  INTRODUCTION
It is known that many unstable periodic orbits are embed-
ded in chaotic attractors.  Using this property, Ott, Grebogi,
and  Yorke  proposed  an  efficient  chaos  control  method  [1].
However, when we use this method, we have to calculate a sta-
bilizing periodic orbit embedded in the chaotic attractor pre-
cisely.  In the case where we cannot identify a precise mathe-
matical models of the chaotic systems, the delayed feedback
control [2] is known to be very useful. Many related methods
have  been  proposed  [3–7].   Moreover,  the  prediction-based
chaos control method using predicted future states was also
proposed  [8].   However,  it  is  difficult  to  determine  a  feed-
back gain of the controller in the absence of its mathemati-
cal model.  To overcome this problem, a method of adjusting
the gain parameter using the gradient method was proposed
[9].   Neural  networks  have  been  used  as  model  identifica-
tion  [10,  11].   Reinforcement  Learning  (RL)  has  been  also
applied to the design of the controller [12–18].  Recently, RL
with deep neural networks, which is called Deep Reinforce-
ment Learning (DRL), has been paid much attention to. DRL
makes  it  possible  to  learn  better  policies  than  human  level
policies in Atari video games [19] and Go [20].  DRL algo-
rithms have been applied not only to playing games but also
to controlling real-world systems such as autonomous vehi-
cles and robot manipulators. As an application of the physics
field, the control method of a Kuramoto-Sivashinsky equation,
which is one-dimensional time-space chaos, using the DDPG
algorithm [21] was proposed [22].
In  this  paper,  we  apply  a  DRL  algorithm  to  the  control
of  chaotic  systems  without  identifying  their  mathematical
model.   However,  in  model-free  RL  algorithms,  the  learner
has to explore its optimal control policy over the entire state
∗
ikemoto@hopf.sys.es.osaka-u.ac.jp
†
ushio@sys.es.osaka-u.ac.jp
space, which leads to inefficient learning. Moreover, when we
use deep neural networks, it takes much time for the learner
to optimize many parameters in the deep neural network.  In
this paper, we propose an efficient model-free control method
consisting of two steps.  First, we determine a region includ-
ing a stabilizing periodic orbit based on uncontrolled behavior
of the chaotic systems.  Next, we explore an optimal control
policy in the region using deep Q networks while we do not
control the system outside the region. Without loss of the gen-
erality, we focus on the stabilization of a fixed point embedded
in the chaotic attractor.
This  paper  organizes  as  follows.   In  Section  II,  we  show
a method to determine a region including a stabilizing fixed
point.  In Section III, we propose a model-free reinforcement
learning method to explore an optimal control policy in the
region.  In Section IV, numerical simulations of the proposed
chaos control of the Gmoowski-Mira map, which is an exam-
ple of discrete-time chaotic system, is performed to show the
usefulness of the proposed method.  Finally, in Section V, we
describe the conclusion of this paper and future work.
II.  ESTIMATION OF REGION
We consider the following chaotic discrete-time system.
x
k+1
=F(x
k
,u
k
),(1)
wherex∈R
n
is the state of the chaotic system andu∈R
m
is the control input. We assume that the functionFcannot be
identified precisely. Thus, we cannot calculate a precise value
of the stabilizing periodic orbits embedded in its chaotic at-
tractor.  On the other hand, although the state of the chaotic
system  does  not  converge  to  the  periodic  orbit,  it  is  some-
times  close  to  any  unstable  periodic  orbit  embedded  in  the
chaotic attractor.  Using this property, we observe the behav-
ior of the chaotic system without the control input and sample
states that are close to the stabilizing periodic orbit.   In the
following,  for simplicity,  we focus on the stabilization of a
arXiv:1907.07775v1  [eess.SY]  16 Jul 2019

2
FIG. 1. Example of the regionDfor the Gumowski-Mira map. The
estimated fixed point is
ˆ
x
f
= [0.994,0.001]
T
.  We set the region
D={(x,y)|||x−
ˆ
x
f
||
∞
≤1}.
fixed point embedded in the chaotic attractor. We observe be-
haviorsx
k
(k= 0,1,...)of the uncontrolled chaotic system
(u
k
= 0) and sample states
 ̄
x
(l)
=x
k
l
(l= 1,2,...,L)satis-
fying the following condition from the behaviors, whereLis
the number of the sampled states.
‖x
k
l
+1
−x
k
l
‖
p
< ,(2)
where‖·‖denotes the`
p
-norm overR
n
andis a sufficiently
small positive constant. We estimate the stabilizing fixed point
ˆ
x
f
based onLsampled states
 ̄
x
(l)
.
ˆ
x
f
=
1
L
L
∑
l=1
 ̄
x
(l)
(l= 1,2,...,L).(3)
Note  that  there  may  exist  more  than  one  fixed  point  in  the
chaotic attractor in general. In such a case, we calculate clus-
ters of the sampled data corresponding to the fixed points and
select the cluster close to the stabilizing fixed point.
Then,  we set a regionDappropriately based on the esti-
mated fixed point
ˆ
x
f
, where the center ofDis the estimated
fixed point
ˆ
x
f
. We have to select the region enough large that
the stabilizing fixed point is sufficiently far from the bound-
ary of the region.   Since we use a deep neural network,  we
can make a learner learn a nonlinear control policy for a large
region while both the OGY method and the delayed feedback
control method are linear control methods. As an example, we
show an estimation of the fixed point of the Gumowski-Mira
map in Fig. 1.
Furthermore,  we transform  the  statexinto  the following
new states∈S.
s:=φ(x),(4)
FIG. 2. Interactions between a system and a controller. In this paper,
we regard the transformed states∈Sas the state in the RL frame-
work. The controller observes the transformed statesand computes
the control inputuin accordance with its policyμ.  The controller
inputs the controller inpututo the system and the state of the system
moves fromstos
′
.  Finally, the controller observes the next trans-
formed states
′
and receives the immediate rewardr. The controller
updates its control policyμbased on the transition(s,u,s
′
,r).
whereφ:R
n
→ Sis the following coordinate transforma-
tion.
φ(x) :=
{
x−
ˆ
x
f
x∈D
s
out
x/∈D
.(5)
The transformed state spaceSisD
′
∪{s
out
}, whereD
′
=
{φ(x)|x∈D}.   The  states
out
represents  that  the  current
state of the chaotic systems lies out of the regionDso that
the control input is set to 0 and we do not sample the state for
learning. Then, the origin of the state spaceD
′
coincides with
the estimated fixed point
ˆ
x
f
.
III.  DEEP REINFORCEMENT LEARNING FOR CHAOS
CONTROL
The  goal  of  RL  is  to  learn  an  optimal  control  policy  in
the  long  run  through  interactions  between  a  controller  with
a learner and a system.  First, the controller observes the sys-
tem statexand computes the control inputuin accordance
with its control policyμNext, the controller inputs the control
inpututo the system and the state of the system moves from
xtox
′
.  Finally, the controller observes the next statex
′
and
receives the immediate rewardr.   The immediate reward is
determined by the reward functionR. In this paper, we make
the controller learn its control policy only in the regionDto
improve  its  learning  efficiency.   Thus,  we  defines∈ Sas
the state of the RL framework.  Interactions between them is
shown in Fig. 2.
In this paper, the reward functionR:D
′
×R
m
×S →R
is defined by
R(s,u,s
′
) =
{
−(s
′
−s)
T
M
1
(s
′
−s)−u
T
M
2
uifs
′
6=s
out
−qotherwise,
(6)
whereM
1
andM
2
are positive definite matrices andqis a
sufficiently  large  positive  constant.   Since
ˆ
x
f
is  an  approx-
imation  of  the  fixed  point,  the  controller  requires  exploring

3
the fixed point through its learning.  Thus, we define the re-
ward  functionRthat  takes  the  maximum  reward  when  the
state of the system is stabilized at the fixed pointx
f
.  In the
case ofs
′
=s
out
, the reward function takes the sufficiently
large penalty−q.  Moreover, since the goal of RL is to learn
the control policy that maximizes the long-term reward,  we
define the following value functions.
V
μ
(s) =E
[
∞
∑
n=i
γ
n−i
r
n
|s
i
=s
]
,(7)
Q
μ
(s,u) =E
[
∞
∑
n=i
γ
n−i
r
n
|s
i
=s,u
i
=u
]
,(8)
whereγ∈[0,1)is a discount rate to prevent divergences of
the value functions.  Eqs.  (7) and (8) are called a state value
function  and  a  state-action  value  function  (Q-function),  re-
spectively.  These value functions represent the mean of the
discounted  sum  of  immediate  rewards  which  the  controller
receives  in  accordance  with  its  control  policyμ,  where  we
do not include immediate rewards in Eqs.   (7) and (8) after
the state of the system moves tos
out
, that is, the transformed
states
out
is a termination state for a learning episode.
Furthermore,  we  apply  DRL  to  design  the  controller.   In
DRL, the control policy function and value functions are ap-
proximated by deep neural networks.  DDPG [21] and A3C
[23]  are  DRL  algorithms  for  continuous  control  problems.
However,  it  is  difficult  to  handle  these  algorithms  because
the control policy function and value functions are approxi-
mated by separate deep neural networks in these algorithms.
On  the  other  hand,  in  a  continuous  deep  Q-learning  algo-
rithm  [24],  we  can  approximate  the  control  policy  function
and value functions by only one deep neural network.  Thus,
in  this  paper,  we  use  the  continuous  deep  Q-learning  algo-
rithm. The illustration of the deep neural network used in the
algorithm is shown in Fig. 3, whereθis the parameter vector
of the deep neural network.The input to the deep neural
network is the transformed statesand outputs are the approx-
imated state value functionV(s;θ), the control inputμ(s;θ),
and elements of the lower triangular matrixP
L
(s;θ)with the
diagonal terms exponentiated.  We define the normalized ad-
vantage function (NAF) as follows.
A(s,u;θ) =
−
1
2
(u−μ(s;θ))
T
P
L
(s;θ)P
L
(s;θ)
T
(u−μ(s;θ)),
(9)
whereuis the control input to the system at the transformed
states.  Note thatP
L
(s;θ)P
L
(s;θ)
T
is the positive definite
matrix becauseP
L
(s;θ)is the lower triangular matrix. There-
fore, the maximum value of the NAF with respect to the con-
trol inputuis 0. Then, the control inputu=μ(s;θ). Eq. (9)
is the quadratic approximation of the advantage function [25]
that represents how much the control inputuis superior to the
control input computed in accordance with the policyμ.
By adding the NAF and the approximated state value func-
tion, we approximate the Q-function as follows.
Q(s,u;θ) =V(s;θ) +A(s,u;θ).(10)
We  describe  the  learning  method.   We  define  the  following
TD-error  to  update  the  parameter  vector  of  the  deep  neural
network.
J(θ) =E
[
(Q(s,u;θ)−(r+γmax
u
′
Q(s
′
,u
′
;θ)))
2
]
=E
[
(Q(s,u;θ)−(r+γV(s
′
;θ)))
2
]
,(11)
whereV(s
out
;θ) = 0.  The parameter vectorθis updated to
the direction of minimizing the TD-error using an optimizing
algorithm such as Adam [26].
In the learning, we use a target network [19], which is an-
other deep neural network, to update the parameter vectorθ,
where the parameter vector of the target network is denoted by
θ
−
. When we compute the approximated state value function
V(s
′
;θ)in Eq. (11), we use the output of the target network
as follows.
J(θ) =E
[
(Q(s,u;θ)−(r+γV(s
′
;θ
−
)))
2
]
.(12)
The target network prevents the learning from being unstable.
The parameter vectorθ
−
is updated by the following equation.
θ
−
=βθ+ (1−β)θ
−
,(13)
whereβis the learning rate of the target network and set to
a sufficiently small positive constant.  This update method is
called a soft update.
Moreover, we use the experience replay [19]. In the experi-
ence replay, the controller does not immediately use the tran-
sition(s,u,s
′
,r)obtained by the exploration for its learning.
The controller stores the transition in the replay bufferBonce
and randomly selectsNtransitions to make a minibatch at the
time of the update ofθ.  The experience replay is a method
to remove the correlation of transitions.  Note that, since we
learn an optimal policy only in the regionD
′
, we do not store
all behaviors but the transitions in the region.
In the exploration for the optimal control policy, the con-
troller determines the control input as follows.
u=μ(s;θ) +δ,(14)
whereδis an exploration noise according with an exploration
noise processNthat we properly have to set.
The whole learning algorithm is shown in Algorithm 1 and
the controlled chaotic system is illustrated in Fig. 4.Mis the
number of behaviors.Kis the maximum discrete-time step
of one behavior.Iis the frequency of the update ofθperk
p
discrete-time steps.

4
FIG.  3.   Illustration  of  the  deep  neural  network  for  the  continuous  deep  Q-learning  algorithm.   The  input  to  the  deep  neural  network  is
the transformed statesand outputs are the approximated state value functionV(s;θ), the control inputμ(s;θ), and elements of the lower
triangular matrixP
L
(s;θ). We define the normalized advantage function (NAF) as Eq. (9). Moreover, by adding the NAF and the approximated
state  value  function,  we  approximate  the  Q-function.   Note  thatQ(s,u;θ) =V(s;θ)when  the  approximated  Q-functionQ(s,u;θ)is
maximized for the control inputu.
FIG. 4. Illustration of controlled chaotic systems by the proposed learning controller. The chaotic system and the main-network keep generating
transitions(s,u,s
′
,r), wheres,u,s
′
, andrare the transformed state of the chaotic system, the control input, the next transformed state of the
chaotic system, and the immediate reward. The transition(s,u,s
′
,r)is stored in the replay bufferB. At the time of updating the parameter
vector of the deep neural networkθ,Ntransitions(s
(n)
,u
(n)
,s
′(n)
,r
(n)
) (n= 1,2,...,N)are randomly selected to make a minibatch.
The parameter vectorθis updated based on the minibatch.  On the other hand, the parameter vector of the target networkθ
−
is updated by
θ
−
←βθ+ (1−β)θ
−
.

5
Algorithm 1Continuous Deep Q-learning for Chaos Control
1:Initialize the replay bufferB.
2:Randomly initialize the main Q network with weightsθ.
3:Initialize the target network with weightsθ
−
=θ.
4:Estimate the fixed point
ˆ
x
f
and selectD.
5:forbehavior= 1,...,Mdo
6:Initialize the initial statex
0
.
7:Initialize a random processNfor action exploration (δ∼N).
8:fork= 0,...,Kdo
9:ifk%k
p
= 0then
10:foriteration= 1,...,Ido
11:Sample   a   random   minibatch   ofNtransitions
(s
(n)
,u
(n)
,s
′(n)
,r
(n)
), n= 1,...,NfromB.
12:Sett
(n)
t
(n)
=
{
r
(n)
+γV(s
′(n)
;θ
−
)s
′(n)
6=s
out
r
(n)
otherwise
13:Updateθby  minimizing  the  TD  error:J(θ)  =
1
N
∑
N
n=1
(Q(s
(n)
,u
(n)
;θ)−t
(n)
)
2
.
14:Update the target network:θ
−
←βθ+ (1−β)θ
−
.
15:end for
16:end if
17:ifx
k
∈Dthen
18:Transform the observed statex
k
intos=φ(x
k
).
19:Determine the exploratory actionu=μ(s;θ) +δ.
20:Inpututo the chaotic system and the state moves to the
next statex
k+1
.
21:Observe the next statex
k+1
.
22:Transform the observed statex
k
intos
′
=φ(x
k+1
).
23:Return the immediate rewardr=R(s,u,s
′
).
24:Store the transition(s,u,s
′
,r)inB.
25:else
26:The state is transited to the next statex
k+1
without the
control input.
27:end if
28:x
k+1
←x
k
.
29:end for
30:end for
IV.  EXAMPLE
In  order  to  show  the  usefulness  of  the  proposed  method,
we perform the numerical simulation of the chaos control of
the  Gumowski-Mira  map  [27],  which  is  an  example  of  the
discrete-time chaotic system. The Gumowski-Mira map is de-
scribed by
x
k+1
=y
k
+b(1−0.05y
2
k
)y
k
+f
1
(x
k
) + 0.1u
k
,(15)
y
k+1
=−x
k
+f
1
(x
k+1
),(16)
wheref
1
is given by
f
1
(x) =ηx+
2(1−η)x
2
1 +x
2
.(17)
In this paper, we assume thatb= 0.008andη=−0.8, where
we cannot use these parameters to design the controller.
By simulations, we observe the uncontrolled behaviors of
the chaotic system to estimate the fixed point. We set= 0.02
andp=  1(`
1
-norm) in Eq. (2).   Then,  the estimated fixed
FIG. 5.   Points of states of the chaotic system without the control
input.   The orange plots are states which satisfy Eq. (2) with=
0.02.   We  regard  the  mean of  orange  points  as  an estimated  fixed
point.
point is
ˆ
x
f
= [0.994,0.001]
T
.  Thus, we select the following
regionDshown in FIG. 5.
D:={(x,y)|−0.006≤x≤1.994,−0.999≤y≤1.001}.
(18)
Then, if[x,y]
T
∈D, the transformed state iss= [s
x
,s
y
]
T
=
[x−0.994,y−0.001]
T
.  Otherwise, the transformed state is
s=s
out
.
We  use  a  deep  neural  network  with  three  hidden  layers,
where all hidden layers have 32 units and all layers are fully
connected layers.  The activation functions are ReLU except
for the output layer. Regarding the activation functions of the
output layer, we use a linear function at both units for the ap-
proximated state value functionV(s;θ)and elements of the
matrixL
p
(s;θ), while we use a 2 times weighted hyperbolic
tangent function at the units for the control inputsμ(s;θ). The
size of the replay buffer is1.0×10
6
and the minibatch size
is 64. The parameter vector of the deep neural network is up-
dated by ADAM [26], where its stepsize is set to1.25×10
−3
.
The soft update lateβfor the target network is 0.01, and the
discount rateγfor the Q-function is 0.99. For the exploration
noise processN, we use an Ornstein Uhlenbeck process [28].
Moreover, we set parameters of the reward function (6) as
follows.
M
1
=
[
0.080
00.08
]
,(19)
M
2
= 0.18,(20)
q= 20.0.(21)
In the simulation, we assume that state transitions of the sys-
tem occur 10800 times per one behavior (K= 10800). More-
over, we assume that the parameter vector of the deep neural
networkθis updated twice (I= 2) every 80 state transitions
(k
p
= 80).
We show simulation results. The learning curve is shown in
Fig. 6. The horizontal axis represents the number of episodes
and the vertical axis represents the mean value of the imme-
diate  rewards  obtained  within  10800  transitions  (0≤k≤

6
FIG. 6.   Learning curve.   It is the mean of the immediate rewards
obtained  within  10800  transitions  after  the  each  learning  episode.
The solid line represents the average learning performance obtained
in 100 times of learning and the shade represents the 99%confidence
interval.
10800). The solid line represents the average learning perfor-
mance obtained in 100 times of learning and the shade repre-
sents the 99%confidence interval. It is shown that high imme-
diate rewards are obtained as updates of the parameter vector
of the deep neural network are repeated.
Moreover, the time response of the controlled chaotic sys-
tem by the controller that learned its control policy sufficiently
is shown in Fig. 7, where the initial state isx
0
= [0.2,1.8]
T
.
It is shown that the controller inputs small control inputs when
its state enters the regionDand stabilizes to the fixed point.
Shown in Fig. 8 is the control input at each state in the region
Dby the learned controller.  It is shown that the learned con-
troller is not linear but nonlinear.  Thus, the proposed method
with continuous deep Q-learning can learn a nonlinear control
policy for stabilizing a desired fixed point without identifying
a mathematical model of the chaotic system.
V.  CONCLUSION AND FUTURE WORK
In  this  paper,  we  proposed  the  control  method  to  stabi-
lize a periodic orbit embedded in discrete-time chaotic sys-
tem using DRL, where the model of the discrete-time system
is  not  identified.   Moreover,  we  show  the  usefulness  of  the
proposed learning algorithm by the numerical simulation of
the  Gumowski-Mira  map.   It  is  future  work  to  propose  the
chaos control method for continuous-time chaotic system with
a P
 ́
oincare map.
ACKNOWLEDGMENTS
This work was partially supported by JST-ERATO HASUO
Project  Grant  Number  JPMJER1603,  Japan  and  JST-Mirai
Program Grant Number JPMJMI18B4, Japan.
[1]  E.  Ott,  C.  Grebogi  and  J.  A.  Yorke,  Phys.  Rev.  Lett.64,  11
(1990).
[2]  K. Pyragas, Phys. Lett. A170, 6 (1992).
[3]  T. Ushio, IEEE Trans. Circuits and Systems-1,43, 9 (1996).
[4]  H. Nakajima, Phys. Lett. A232, 3-4 (1997).
[5]  K. Pyragas, Phys. Lett. A206, 5-6 (1995).
[6]  S. Yamamoto, T. Hino, and T. Ushio, IEEE Trans. Circuits and
Systems-1,48, 6 (2001).
[7]  H. Nakajima, and Y. Ueda, Phys. Rev. E,58, 1757 (1998).
[8]  T. Ushio, and S. Yamamoto, Phys. Lett. A,264, 1 (1999).
[9]  H. Nakajima, H. Ito, and Y. Ueda, IEICE Trans. Fundamentals,
E80-A, 9 (1997).
[10]  A. Boukabou, and N. Mansouri, Nonlinear Analysis: Modeling
and Control,10, 2 (2005).
[11]  L. Shen, M. Wang, W. Liu, and G. Sun, Phys. Lett. A372, 46
(2008).
[12]  R. Der and M. Herrmann, inProceedings of IEEE International
Conference on Neural Networks, Orlando, 1994,vol.  4,  pp.
2472-2475 (1994).
[13]  R. Der and M. Herrmann, Nonlinear Theory and Applications,
pp. 441-444 (1996).
[14]  M. Funke, M. Herrmann, and R. Der, International Journal of
Adaptive Control and Signal Processing, pp. 489-499 (1997).
[15]  R. Der and M. Herrmann, Classification in the Information Age,
pp. 302-309 (1998).
[16]  J. Randlov, A. G. Barto, and M. T. Rosenstein, Computer Sci-
ence Department Faculty Publication Series (2000).
[17]  S. Gadaleta and G. Dangelmayr,  Chaos:  An Interdisciplinary
Journal of Nonlinear Science,9, 3 (1999).
[18]  S. Gadaleta and G. Dangelmayr,Proceedings of IEEE Interna-
tional Joint Conference on Neural Networks, Washington, 2001,
vol. 2, pp. 996-1001 (2001).
[19]  V.  Mnih,  K.  Kavukcuoglu,  D.  Silver,  A.  A.  Rusu,  J.  Veness,
M. G. Bellemare, A. Graves, M. Riedmiller, A. K. Fidjeland,
G. Ostrovski, S. Petersen, C. Beattie, A. Sadik, I. Antonoglou,
H. King, D. Kumaran, D. Wierstra, S. Legg, and D. Hassabis,
Nature (London),518, pp. 529-533 (2015).
[20]  D. Silver, A. Huang, C. J. Maddison, A. Guez, L. Sifre, G. van
den Driessche, J. Schrittwieser, I. Antonoglou, V. Panneershel-
vam, M. Lanctot, S. Dieleman, D. Grewe, J. Nham, N. Kalch-
brenner, I. Sutskever, T. Lillicrap, M. Leach, K. Kavukcuoglu,
T. Graepel, and D. Hassabis, Nature (London),529, pp. 484-
489 (2016).
[21]  T. P. Lillicrap, J. J. Hunt, A. Pritzel, N. Heess, T. Erez, Y. Tassa,
D. Silver,  and D. Wierstra,arXiv preprintarXiv:1509.02971,
(2015).
[22]  M.  A.  Bucci,  O.  Semeraro,  A.  Allauzen,  G.  Wisniewski,  L.
Cordier,  and  L.  Mathelin,arXiv preprintarXiv:1906.07672
(2019).
[23]  V. Mnih, A. P. Badia, M. Mirza, A. Graves, T. P. Lillicrap, T.
Harley, D. Silver, and K. Kavukcuoglu, inProceedings of In-
ternational Conference on Machine Learning, New York, 2016,
edited by M. F. Balcan and K. Q. Weinberger (2016).
[24]  S. Gu, T. Lillicrap, I. Sutskever, and S. Levine, inProceedings
of International Conference on Machine Learning, New York,
2016,edited by M. F. Balcan and K. Q. Weinberger (2016).
[25]  R. S. Sutton, D. McAllester, S. Singh, and Y. Mansour, inNeu-
ral Information Processing Systems, Denver, 1999,edited by S.

7
FIG. 7.  Time response of the chaotic system by the controller that
sufficiently  learned  its  control  policy,  where  the  initial  statex
0
is
[0.2,1.8]
T
.
FIG. 8.  Learned control input at each state in the regionD
′
.  The
color represents the value of the control input. The learned controller
is not linear but nonlinear.   The cross mark represents the conver-
gence states= [0.006,−0.001]
T
(x= [1.000,0.000]
T
) in Fig.
7.
A. Solla, T. K. Leen, and K. Mller, (1999).
[26]  D. P. Kingma and J. Ba,arXiv preprintarXiv:1412.6980 (2014).
[27]  C.  Mira,  inThe Chaos Avant-garde: Memories of the Early
Days of Chaos Theory,edited  by  R.  Abraham  and  Y.  Ueda,
(World Scientific, 2000).
[28]  G. E. Uhlenbeck and L. S. Ornstein, Phys. Rev.36, 5 (1930). 

1
Prioritized Guidance for Efficient Multi-Agent
Reinforcement Learning Exploration
1
st
Qisheng Wang
Southeast UniversityNanjing, China
qishengw@seu.edu.cn
2
nd
Qichao Wang
Southeast UniversityWuxi, China
Abstract—Exploration   efficiency   is   a   challenging   problem
in  multi-agent  reinforcement  learning  (MARL),  as  the  policy
learned  by  confederate  MARL  depends  on  the  collaborative
approach among multiple agents. Another important problem is
the less informative reward restricts the learning speed of MARL
compared  with  the  informative  label  in  supervised  learning.  In
this  work,  we  leverage  on  a  novel  communication  method  to
guide MARL to accelerate exploration and propose a predictive
network  to  forecast  the  reward  of  current  state-action  pair
and  use  the  guidance  learned  by  the  predictive  network  to
modify the reward function. An improved prioritized experience
replay  is  employed  to  better  take  advantage  of  the  different
knowledge   learned   by   different   agents   which   utilizes   Time-
difference   (TD)   error   more   effectively.   Experimental   results
demonstrates that the proposed algorithm outperforms existing
methods  in  cooperative  multi-agent  environments.  We  remark
that  this  algorithm  can  be  extended  to  supervised  learning  to
speed  up  its  training.
Index  Terms—Multi-agent-reinforcement  learning;  priority;
guidance;  exploration  efficiency
I.  INTRODUCTION
Model-free  reinforcement  learning  (RL)  has  been  proven
a  promising  technique  for  sequence  decision  making  in  a
wide  range  of  applications  such  as  robotic  arm  control[1],
autopilot[2]  and  wireless  communication  anti-jamming[3].
In  particular,  combined  with  deep  learning  (DL)  as  value
function  simulator,  the  deep  reinforcement  learning  (DRL)
exhibits powerful capabilities in real-world control problems
such  as  Go[4]  and  Atari  games[5].  However,  the  inefficient
exploration   restricts   the   application   of   RL   as   the   agent
requires  high  specimen  complexity  to  learn  an  acceptable
behavior  policy[6].  Large  sample  and  long-time  exploration
are unacceptable in practical applications.
One  possible  solution  is  exploiting  the  joint  exploration
of  multi-agent  RL  (MARL)  to  accelerate  the  convergence
of  policy  iteration.  The  strategy  obtained  by  confederate
exploration  depends  on  the  collaborative  approach  among
multiple  agents  to  large  degree.  Multi-agent  coordinately
uses  concurrent  exploration  of  the  state-action  space  of  the
common  environment  in  the  early  stage  of  RL  to  avoid  all
agents exploring the same or similar subspace simultaneously,
which in turn will result in insufficient diversity of samples.
Stochastic  policy  based  RL  algorithms  such  as  TRPO[7],
PPO[8]  and  A3C[9]  need  to  generate  samples  online  to
execute  gradient  descent,  causing  slow  efficiency  and  high-
cost   exploration.   Especially,   the   A3C   algorithm   supports
multi-agent asynchronous exploration (which to some degree
proves  the  benefits  brought  by  multi-agent  coordination),
while involves risk of failure to converge when implemented
in concurrent MARL.
Value-based Q-learning[10], DQN[4] and other algorithms
derived from this, such as Double DQN (DDQN)[11], Dueling
DQN[12]  and  Prioritized  experience  replay[13],  all  perform
well on discrete control problems. DQN has achieved beyond-
human  level  in  both  Go  and  Atari  games.  DDQN  takes
advantage of separate target network to calculate the expected
Q  value  to  alleviate  the  over-fitting  problem  in  the  value
function  approximation,  which  effectively  improves  the  al-
gorithm  stability.  Dueling  DQN  and  Prioritized  experience
replay  modify  the  network  architecture  and  achieve  better
policy evaluation. However, they cannot effectively deal with
the continuous control problems existing widely in real world.
When the  action  dimension is particularly high,  above algo-
rithms  may  lose  effectiveness.  High  resolution  quantization
level can partially solve this challenge but the computational
complexity becomes unacceptable.
Policy-based  deterministic  policy  gradient  (DPG)  algo-
rithm[14]  try  to  directly  outputs  action  instead  of  state-
action  value  approximation,  thus  naturally  suitable  for  con-
tinuous  control  problems.  The  Actor-Critic  (AC)  algorithm
deep  deterministic  policy  gradient  (DDPG)[15]  combining
DPG with Q-function approximation has outperformed other
algorithm. Nonetheless, DDPG is fragile to hyperparameters.
The improved multi-agent DDPG (MADDPG) algorithm[16]
allows  each  agent  to  learn  its  own  behavior  strategy,  which
may overfit to other agents.
In  this  work,  we  leverage  on  a  novel  communication
method to guide MARL to conspire. Inspired by the tangible
that many soldiers can effectively conduct military operations
under the organization of army leader, we lead into a comman-
der to coordinate behaviors of multiple RL agents. The state-
action evaluation network Critic in AC algorithm is a qualified
candidate for such a task, which means all agents share a Q-
value network called Commander, and each maintains its own
arXiv:1907.07847v1  [cs.LG]  18 Jul 2019

2
action network
1
.
We  consider  the  problem  of  insufficient  information  on
reward in RL, which plays a similar role as label in supervised
learning.  In  MARL  circumstance,  all  agents  cooperate  to
achieve  the  same  purpose,  thus  we  can  estimate  the  reward
distribution of different actions under the progressive optimal
policy,  and  the  evaluated  value  reflecting  this  distribution
can  promote  a  more  efficient  exploration.  To  achieve  this
goal with acceptable computational complexity, we propose a
predictable network called PrecoderNet to forecast the reward
of eachs-apair. The output of Commander is regarded as the
target of the PrecoderNet, and the prediction of PrecoderNet
called  guidance  can  subsequently  indicate  which  region  to
explore.  The  PrecoderNet  used  to  fit  the  reward  distribution
is  also  shared  by  all  agents.  The  experimental  results  show
that the guidance based on prior experience can make multi-
agent  effectively  improve  the  efficiency  of  exploration  and
convergence in the process of collaborative learning.
Furthermore, we use the prioritized replay buffer to reduce
calculation complexity and accelerate exploration. Prioritized
experience takes advantage of Q-learning to approximate the
value function and introduces the time difference error (TD-
error), the difference between the target network and the esti-
mated network, as the priority of samples to improve gradient
descent.  Meanwhile,  the  priority  stored  in  the  root  node  of
the  tree-structured  prioritized  experience  can  reflect  whether
the  agent  leans  well  or  not.  According  to  the  similarity  of
different  agents  ̨a
 ́
r  experience  priorities,  some  agents  share
their  experience  replay  to  reduce  the  correlation  of  samples
in the experience pool and avoid the bad trajectories tried by
other agents so that exploration can focus more on effective
sub-region  than  the  entire  space  only  after  a  short  learning
period.
The  proposed  prior  experience  based  multi-agent  coordi-
native exploration with prioritized guidance, called MAEPG,
is  an  extension  of  the  AC  algorithm.  We  perform  it  in
simulated environment gym for multiple agents to effectively
and efficiently explore common environments to speed up the
exploration process. Experimental results show the benefits of
the prioritized guidance for MARL compared with DQN and
MADDPG  in  both  single  agent  and  multi-agent  situations,
which  can  achieve  better  performance  as  the  agent  number
increases.
The  rest  of  this  paper  is  organized  as  follows.  Section
2  briefly  reviews  previous  literatures  on  MARL.  After  the
introduction  of  RL  background  (Section  3),  we  describe  the
proposed algorithm in Section 4. The experimental results are
given in Section 5, and Section 6 concludes the paper showing
some discussion about the approach. More information on the
algorithm are included in the Appendix.
II.  RELATEDWORK
MARL is used to solve strategic learning problems that re-
quire multiple agents to collaborate or compete to accomplish
1
Which is similar to the centralized critic in MADDPG, but our comman-
der use guidance to predict the distribution of reward. Meanwhile, the action
network of each agent perform different degrees of association according to
the similarity of their experience pool priorities as described in Section 4.
complex tasks. Although behavioral criteria can be predefined,
agents need to continually learn to find approximate optimal
solutions  for  current  tasks  in  complex  environments,  espe-
cially  when  the  environment  is  likely  to  change[17].  Multi-
agents interact with the environment to obtain feedback values
to advance the learning of better strategies, which has crucial
significance for the development of RL.
When  multiple  agents  simultaneously  interact  with  a  dy-
namic  environment  and  treats  the  others  as  part  of  sur-
roundings,  the  environment  is  unstable  from  the  perspective
of  current  agent  because  the  strategies  of  other  agents  are
constantly changing during learning[18]. The randomness of
environment has catastrophic impacts on the RL, resulting in
slow  or  even  no  convergence  of  policy.  In  response  to  this
problem, the use of regret bound to constrain the multi-agent
environment and ensure convergence was be discussed in [19]
and  [20].  However,  this  theoretical  analysis  does  not  work
well in practical applications. In many cases, agents suspend
learning due to the instability of the environment when they
are still far away from the regret bound. MARL was improved
based  on  game  theory  in  [21]  by  using  empirical  game-
theoretic analysis to calculate which strategy would be chosen
in the case of multi-agent. Whereas, this method could lead to
inconsistent learning speed of the agent as the faster agent will
make more use of the slower one and thus causing overfitting.
Lack  of  effective  communication  mechanisms  for  multi-
agent  joint  exploration  is  another  problem.  In  [22],  a  large
forward feedback neural network was used to map the input
of  all  agents  to  the  action  space  while  each  agent  occupies
a  part  of  the  input  unit  and  broadcasts  its  own  hidden  layer
information  to  other  agents  during  communication.  As  the
number  of  agents  increases,  the  overhead  of  communication
is  too  large  and  the  stability  of  the  algorithm  decreases.  A
centralized evaluation network was used in [16] to control the
behavior  of  all  agents  and  achieved  a  certain  improvement
in  some  cooperation  and  competition  tasks.  However,  they
actually allow each agent to learn a separate behavioral policy,
which  may  lead  to  suboptimal  solutions  to  a  certain  extent.
The minimax concept in game theory based on [23] was used
to  limit  the  learning  step  size  of  the  agent  to  strengthen  the
algorithm  stability  in  [16]  which  in  the  meantime  sacrificed
the speed advantage that multi-agent exploration should have.
If  multiple  agents  can  interact  with  each  other  in  a  more
efficient  approach  in  the  learning  process,  they  should  be
able  to  achieve  certain  gains.  For  example,  directly  calling
someone to warn of danger is more effective than igniting a
fire as warning signals.
Another undeniable problem is the insufficient-information
reward  in  RL  compared  with  the  label  in  supervised  learn-
ing[6].  Although  the  use  of  reward  instead  of  labels  greatly
improves the mobility and practical application of RL, it cost
more  resources  in  exploration,  especially  for  MARL.  When
most  agents  get  feedbacks  with  insufficient  information,  the
consequence is that the entire learning process is difficult to
perform. A method for increasing the information of reward
based on the latent state is proposed in [24], using the expe-
rience stored from previous trajectories as the representation
of  reward  to  train  a  network  to  predict  the  reward  of  the

3
new  state  action  pair  and  add  it  to  the  feedback  value  in
logarithmic form. However, this requires numerous repetitive
simulations,  which  is  too  costly  in  complex  environments.
Although  multi-head  output  layers  were  used  to  reduce  the
risk  of  overfitting,  this  prediction  is  easily  limited  by  the
prior  experience,  resulting  in  insufficient  generalization  and
increased network complexity.
The proposed algorithm in this paper combines the advan-
tages of the above work and attempts to improve the existing
problems mentioned. Based on the idea of centralized critic in
[16], we use a critic network called Commander to coordinate
the  behavior  of  each  agent  and  add  guidance  for  a  more
informative reward to fit the distribution of reward functions
during the process of exploration. Inspired by [24], one shared
network  called  PrecoderNet  is  used  for  prediction  ,  which
increases  the  information  of  reward  values  while  reducing
complexity  meanwhile.  Furthermore,  according  to  [13],  we
add priority to the experience replay and the actor networks of
agents are united in varied contribution weights according to
the similarity of their tree-structured experience pool priorities
stored in the root node so that our agents can effectively utilize
the  knowledge  learned  by  others  when  it  encounters  a  new
state without exploring the entire state action space, which is
more like the way humans behave.
III.  PRELIMINARIES
Markov  Decision  Process(MDP):  We  model  the  multi-
agent RL problem as MDP, consisting ofMagents (M∈Z
+
),
of which the interaction between agent and environment can
be  represented  by  a  quintuple  <S,A,r,γ,π>.Srepresents  the
state space whileAmeans the action space. Rewardr:S×A→R
is the feedback from environment measuring the chosen action
under current state.γ∈(0,1]is a discount factor that converts
an infinite sequence problem into a matter with a maximum
upper bound in order that the MDP can converge within finite
steps.πrepresents the policy on which the agent selects action
depends, and the chosen action isa=π(s).
DeepQ-networks(DQN):    DQN[4]    approx    imates
thevalue-basedQ-learningstate-valuefunction
Q
π
(s,a)=E
s
[R
t
|s
t
=s,a
t
=a]as a deep neural network with
parameterθ, whereR
t
=E[
∑
∞
t=0
γ
t
r
t
]is the expected return
of the current state-action against the discount factor. The goal
of  DQN  is  to  maximize  the  target  y=r+max
a
′
[Q(s
′
,a
′
;θ)]
of  the(s-a)  pair,  and  update  Q-value  by  bellman  equation
Q
π
(s,a)  =E
s
′
[r(s,a) +γE
a
′
vπ
[Q
π
(s
′
,a
′
)]]in  dynamic
programming.  Then  the  gradient  descent5
θ
E(y−Q(s,a))
will  be  carried  out  after  random  sampling  in  the  experience
replay,  and  the  action  with  the  largest  Q  value  is  selected
with probability1−or randomly selected with.
Deep Deterministic Policy Gradient(DDPG): DDPG[15]
is an AC algorithm using the policy-based deterministic policy
networkμparameterized  byθ
μ
to  generate  deterministic
actiona=μ(s|θ
μ
).  DDPG  updates  the  learned  actor  policy
networks parameterized byθ
μ
with gradient descent by taking
advantage of the Q-networkθ
Q
in DQN as the critic so that
it can maximize the output Q-value.
We  also  offer  the  summary  of  symbols  and  notations  for
convenience shown in Table 1.
TABLE I: Summary of symbols and notations
a
i
t
Action the agentichoose at time slott
s
i
t
State the agentireach at time slott
r
i
t
Reward of the agentiat time slott
σ
i
t
Guidance to enrich the information ofr
(i)
t
R
Improved prioritized experience replay
N
Sampling mini-batch
ρ
Visiting times of a certain specimen
η
Discount factor of guidanceσ
γ
Discount factor of long-term reward
τ
Soft update parameter
δ
Bias to guarantee positive priority
φ
i
t
Priority of specimen of agentiat time slot t
q
i
Contribution weight of agentiin exploration
n
i
t
Noise added to action for explorating
IV.  ALGORITHM
The  proposed  MAEPG  is  an  extension  of  DDPG  in  the
field  of  MARL,  which  enables  better  corporate  behaviors
between  agents  and  improves  the  exploration  policy  by  in-
creasing the information of reward to improve the efficiency
of  concurrent  RL.  Our  algorithm  consists  of  a  multi-agent
joint actor networkActorNetA
i
M
i=1
with an improved priority
experience replay R, a centralized guidance network and critic
network called PrecoderNet and Commander, respectively, as
shown  in  Figure  1.  RL  agents  can  only  explore  a  part  of
Observation
Guidance
PrecoderNet
Agent 1
Agent M
...
ActorNet 1
ActorNet M
...
CriticNet
Action
Gradient
Prioritized Replay Memory
P
root
P
56,78
P
12,34
P
1
P
2
P
3
P
4
P
5
P
6
P
7
P
8
...
Store experience
[data1]     [data2]     [data3]     [data4]     [data5]     [data6]     [data7]     [data8] 
Priority for gradient
Guidance g(r)
data
i
=[s
i
,a
i
,r
i
,s
i+1
,φ
i
 ]
Fig. 1: Architecture of MAEPG algorithm
the  whole  exploration  space  with  high  state-action  dimen-
sion,  especially  in  the  continuous  control  problems.  That  is,
partially  observed  environment  restricts  the  performance  of
MARL  agents.  The  experience  replay  in  DQN  and  DDPG
makes  it  possible  for  agents  to  continuously  optimize  based
on the previous trajectories stored in the buffer. As the agent
number increases, each agent will learn complementary action
policies in different sub regions. Enlightened by the intuitive
that myriad soldiers can better defend the fighters in a globally

4
optimal operational strategy under the leadership of a general,
all  the  cooperative  agents  share  a  centralized  critic  network
called  Commander  and  maintain  their  own  action  network
called  ActorNetA
i
.  At  the  same  time,  partial  observation
of  various  agent  was  fed  into  the  PrecoderNet  to  generate
the  guidanceσ
i
for  increasing  the  information  of  reward
function  to  provide  a  more  accurate  ongoing  direction  and
accelerate  the  exploration  so  that  the  exploration  focuses
on  the  effective  subspace.  ActorNetA
i
selects  action  to
interact  with  environment  under  the  guidanceσ
i
,  obtains
feedbackr
t+1
and the new states
t+1
from the surrounding.
In  the  meantime,  our  Commander  access  the  chosen  action
by the approximate Q-valueQ
C
(s
t
,a
t
). The sample priority
is shown in (1) by the TD-error.
φ
i
t
=Q
C
(s
t
,a
t
)−r
t+1
+δ(1)
Where  micro  accountδ >0ensures  a  positive  priority.
Thenφ
i
t
is  stored  the  latest  transition  in  the  prioritized
experience  replay[13].  Since  larger  TD-error  means  greater
contribution when conducting the gradient descent, the infor-
mation in the learning process is effectively increased.
A.  Improving priority experience replay
The  prioritized  experience  replay  R  (as  the  blue  cylinder
illustrated  in  Fig.  1)  considers  the  importance  of  different
samples  and  describes  it  as  the  difference  between  access
value  from  Commander  and  the  obtained  reward  as  shown
in  (1).  Sampling  by  priority  (mini  batch  is  N)  utilizes  the
samples  with  large  TD-error  to  make  the  gradient  descent
faster  simultaneously  ensuring  all  samples  are  likely  to  be
used (the effect ofδ). The experience replay is stored in the
form of   ̨a
ˇ
rsum-tree  ̨a
 ́
s to improve sampling efficiency and save
storage space. The lowest level leaf node stores the transition
and  priority  while  the  remaining  nodes  only  store  the  sum
of  the  priority  of  their  children  nodes.  Inspired  by  [25]  and
considering  the  tangible  that  visiting  time  of  a  sample  can
also  reflect  the  importance  of  this  specimen,  we  store  the
visiting time calledρ
i
t
of the leaf node in the tree-structured
experience replay and update the priority via (2)
φ
i
t
=φ
i
t
+
ρ
i
t
∑
j
ρ
j
t
(2)
Boltzman  distribution[26]  of  thei-thagent  can  be  defined
according  to  the  sum  of  priorityΦ
i
t
stored  in  the  root  node
of the experience replay to further take the different agents  ̨a
 ́
r
contribution into consideration as shown in (3).
q
i
=
exp(Φ
i
t
)
∑
j
exp(Φ
i
t
)
(3)
Each  agent  uses  (3)  as  weights  to  better  improve  the  eval-
uation  of  Commanders.  That  is,  the  loss  function  of  the
Commander  considering  the  contribution  of  different  agents
is (4) and (5).
L(θ
C
) =
1
m
m
∑
j=1
q
j
(Q
C
(s
t
,a
t
)−y
j
)
2
(4)
y
j
=r+γQ
C
′
(s
t+1
,a
t+1
)|
a
t+1
=A
′
(s
t+1
)
(5)
The policy gradient can be written as (6) and (7):
O
θ
C
J(θ
C
) =E
s,a∼R
[O
θ
A
A(a|s)O
a
Q
C
(s,a)|
a=A(s)
](6)
O
θ
A
A(a|s) =−O
θ
A
Q
C
′
(s
t+1
,a
t+1
)|
a
t+1
=A
′
(s
t+1
)
(7)
Where the evaluated networkAand the target networkA
′
parameterized  byθ
A
andθ
A
′
relatively  are  used  to  mitigate
the  over-fitting  problem  according  to  [4].  Meanwhile,  the
Commander  also  contains  an  evaluated  networkCand  a
target  networkC’parameterized  byθ
C
andθ
C
′
relatively
as  shown  in  Fig  2.  We  soft  update  all  the  target  networks
byθ=τθ+ (1−τ)θ.  In  this  way,  we  use  the  agents
with greater TD-errors to provide more information for Com-
mander’s decision making, which in turn makes Commander
more  comprehensive  and  efficient.  We  remark  that  similar
methods  of  using  TD  error  as  priority  can  also  be  used  in
surprised learning to enhance training efficiency. Overall, the
improved priority experience replay leads to more coordinated
concurrent learning among MARL.
Environment
Gym-
Pendulum-v0
actor A
online PolicyNet 
parametered 
A

target PolicyNet 
parametered 
'A

update 
A

policy gradient 
w.r.t.
A

soft update 
optimizer
A(s
t
)
Gaussian 
noise
t
a
1
(  ,  ,   )
t   t    t
s  r s

Experience
 replay memory
with priority
precoder P
target PolicyNet 
parametered 
policy gradient 
w.r.t.
P

soft update 
optimizer
'
P

(  ,  ,  )
t   t   t
s  a  r
critic C
online PolicyNet 
parametered 
target PolicyNet 
parametered 
update 
C

policy gradient 
w.r.t.
soft update 
optimizer
C

C

'C

a=A(s
t
)
gradient w.r.t. a
gradient w.r.t. guidance 
Guidance    =P(s
t
,a
t
,r
t
)
t

t

a=A (s
t
)
Target y
i
Storage (s
t
,a
t
,r
t
,s
t+1
)
N=(s
i
,a
i
,r
i
,s
i+1
)
Sampling:mini batch
Sampling policy
update 
P

online PolicyNet 
parametered 
P

Fig. 2: Network structure of MAEPG algorithm
B.  Precoding the reward
A  scalar  reward  signal  evaluates  the  quality  of  each  tran-
sition, and the agent has to maximize the cumulative reward
along the course of interaction. The RL feedback (the reward)
is  less  informative  than  in  supervised  learning,  where  the
agent  would  be  given  the  correct  actions  to  take.  It  is  still
unclear  whether  the  reward  predefined  in  the  Gym  environ-
ments  and  Atari  environment  is  optimal  or  not.  In  MARL,
we should pay more attention to the form of reward because
of the unstable environmental caused by multi-agents and the
cooperation  or  competitive  interaction  of  various  agents.  In
general,  reward  with  more  information  and  constraints  will
have positive effects on RL learning and make RL attractive
for multi-agent learning.

5
Fig.  3:  The  walking  posture  of  a  doll  with  inappropriate
reward
Fig. 4: The walking posture of a doll with informative reward
For example, the goal of an MDP task is to make a virtual
person  move  forward  in  a  virtual  environment.  Setting  the
reward  value  as  the  forward  speed  cause  the  doll  to  swing
wildly while moving forward as shown in Figure 3. In MARL,
these  useless  actions  of  agents  not  only  wastes  exploring
resources  bur  also  greatly  interfere  the  direction  of  other
agents[27]. In order to make the walking of the doll closer to
a normal person, the modified reward is set as the difference
between  the  virtual  doll  and  the  walking  posture  of  human
beings,  and  better  results  can  be  obtained  as  shown  in  Fig
4,  which  indicates  the  informative  reward  is  significant  for
MARL.
In [24], representations from latent state is used to correct
the  reward.  Based  on  numerous  pre-experiments,  and  all
previous  state-action-reward  values  are  stored  for  training
a  predictive  network  is  feasible  but  cost  too  much.  We
propose a PrecoderNet parameterized by
P
to use the output
Commander as label to estimate the reward of current state-
action  pair,  collecting  (s-a)  from  all  agents  for  real-time
training without pre-experiment as in In Fig 2.
After the interaction between agents and environment, we
input (s-a) to the PrecoderNet to obtain the guidanceσ
i
t
as the
correction item, and a discount factorηis used to determines
how much the correction is used as shown in (8).
r
t
=r
t
+ησ
i
t
(8)
L(θ
P
) =
1
2
E
(s,a,r,s
′
)
[C(s,a)−r(s,a)]
2
(9)
Then we do the gradient descent update on PrecoderNet as
shown in (10):
O
θ
P
J(θ
P
) =E
(s,a∼R)
[O
θ
P
(C(s,a)−r(s,a))O
θ
C
C(s,a)]
(10)
The gradient flow from Commander through ActorNet and
PrecoderNet, and the final gradient of Commander is the sum
of the two gradient calculations of ActorNet and PrecoderNet.
Multi-agent joint PrecoderNet and Commander  ̨a
 ́
rs update will
be more efficient and faster. To sum up, the more informative
rewards  leads  to  more  efficient  and  effective  explorations  of
all agents.
V.  EXPERIMENTS
The  proposed  algorithm  is  performed  in  the  RL  envi-
ronment  Gym  Pendulum-v0.  This  RL  task  is  to  maintain
a  vertical  tilt  of  a  center-fixed  pendulum  in  the  vertical
direction[28] by applying apposite torque, as shown in Figure
5.  In  this  environment,  the  closer  the  non-positive  reward
is  to  zero,  the  more  perfect  current  state  is  to  the  ideal
location.  Since  the  action  is  torque  (∈[−2,2]),  the  value  of
the action is continuous, and the state action dimension to be
explored is infinite. We hope to finish the task quickly through
collaborative MARL and compare the proposed MAEPG with
DQN and MADDPG as benchmarks.
A.  Hyper parameters
In  all  experiments,  we  used  an  Adam  optimizer[29]  with
a  learning  rate  of  1e-3.  The  discount  factorγ= 0.99when
calculating the target Q value, andτis set to 0.005 for soft
update of all target networks. The ActorNet, Commander, and
PrecoderNet  all  use  a  four-layer  neural  network  including
two  hidden  layers.  The  number  of  hidden  layer  neurons  in
ActorNet  is  180  while  in  Commander  and  PrecoderNet  the
number  is  300.  In  the  Pendulum  task,  the  action  dimension
is  1,  so  the  input  size  of  ActorNet  is  3  while  the  input
size  of  Commander  and  PrecoderNet  is  4,  and  their  output
sizes are all equal to 1. In the experiment, the guidance from
PrecoderNet is assigned to reward multiplied a discount factor
η= 0.1, and the number of agents isM=1, 2, 3. In addition,
gaussian  white  noisen
i
t
of  which  the  mean  value  is  0  and
the variance is 0.1 has been used to increase the diversity of
exploration.
B.  Results
We first compare the convergence time needed with regard
to DQN, MADDPG and MAEPG with a single agent. During
the  experiment,  the  DQN  algorithm  quantifies  the  action
between the maximum and minimum values of action torque
as 100 discrete values stepped by 0.04. We designed a multi-
head network structure for multi-agent DQN which means the
first  three  layers  (including  one  input  layer  and  two  hidden
layers)  are  shared  by  all  agents,  like  the  Commander  in
MAEPG, and finally the action of each agent is determined by
their respective output layers. As shown in Figure 6, DQN is
difficult to converge with only one agent while MADDPG and
MAEPG  converge  ultimately  with  unequal  speed.  MAEFG
can converge in 220 episodes, and MADDPG need about 340
cycles  to  achieve  the  same  convergence  level.  As  shown  in
Fig. 7 and Fig. 8, when agent number M is more than 2, the
multi-agent DQN still cannot learn a feasible behavior policy.
Then   we   compare   the   performance   of   MADDPG   and
MAEPG with agent numberM=2 and 3. It can be seen that
the  convergence  speed  of  MAEPG  is  greatly  improved  with
the  increase  ofMand  significantly  outperform  MADDPG

6
050100150200250300350400450500
Eposide(2000 steps per ep)
-2.5
-2
-1.5
-1
-0.5
0
0.5
Accumulative reward
#10
4
Accumulative reward of Pendulumn task
One agent DQN
One agent DDPG
One agent MAEPG
Fig.  5:  Convergence  speed  comparison  among  single  agent
MAEPG,  DQN  and  MADDPG.  The  horizontal  axis  is  the
number of episode (two thousand steps per episode), and the
vertical axis is the accumulated reward calculated per 5 cycles.
The  larger  the  reward  is,  the  farther  the  current  position  is
from the target position which demonstrate a bad state.
050100150200250300350400450500
Eposide(2000 steps per ep)
-2.5
-2
-1.5
-1
-0.5
0
0.5
Accumulative reward
#10
4
Accumulative reward of Pendulumn task
Two agents DQN
Two agents MADDPG
Two agents MAEPG
Fig. 6: Convergence speed of two agents
050100150200250300350400450500
Eposide(2000 steps per ep)
-2.5
-2
-1.5
-1
-0.5
0
0.5
Accumulative reward
#10
4
Accumulative reward of Pendulumn task
Three agents DQN
Three agents MADDPG
Three agents MAEPG
Fig. 7: Convergence speed of three agents
in  terms  of  stability.  The  average  reward  and  gain  attained
when the three algorithms converge are shown in Table 2. The
gain in form of percentage represents the degree to which the
average reward of MAEPG is better than MADDPG. Having
considered  the  importance  of  different  agents  and  samples
to  the  overall  learning  progress  in  a  multi-agent  scenario,
MAEPG  learned  faster  and  maintains  the  pendulum  in  a
vertically upward ideal position with smaller swing compared
with MADDPG.
The  experimental  results  shows  the  proposed  MAEPG
outperforms  the  benchmarks  under  collaborative  MARL  ex-
ploration. Further discussions about the experiments are pre-
sented in appendix.
VI.  CONCLUSION
In  this  paper,  we  proposed  a  novel  cooperative  algorithm
called  MAEPG  for  multi-agent  RL  to  achieve  coordinately
efficient and effective exploration by using knowledge learned
by  a  centralized  Commander  and  guidance  perceived  from
previous  experience.  In  particular,  we  assist  the  multiple
agents to better communicate via ameliorating the prioritized
experience  replay  (Section  4.1)  and  the  priority  can  help
agents  to  explore  more  efficiently.  We  also  propose  a  cen-
tralized precoder network to enrich the information of reward
in  RL  tasks  (Section  4.2)  to  accelerate  the  learning  process
in   MARL.   The   experiment   we   carried   out   demonstrates
that the proposed algorithm outperforms existing methods in
cooperative  multi-agent  environments.  We  remark  that  this
algorithm can be extended to supervised learning to speed up
its training.
VII.  APPENDIXA
For  completeness,  we  provide  the  MAEPG  algorithm  as
below.
Algorithm  1MAEPG in MARL coordinate exploration
1:Initialize Commander, ActorNet and PrecoderNet
Initialize target networks
Initialize improved prioritized replay buffer R
2:forepisode= 1,2,3,...,Kdo
3:Reset the environment
4:forstep= 1,2,...,Kdo
5:foriin agentsdo
6:Each agentichoose actiona
i
t
=π
θ
A
i
(s
i
t
)
7:Execute actiona
i
t
, obtain rewardr
i
t
8:Observe new states
i
t+1
9:Get guidanceσ
i
t
=π
θ
P
(s
i
t
,a
i
t
)
10:Get Q-valueQ
C
(s
i
t
,a
i
t
) =π
θ
C
(s
i
t
,a
i
t
)
11:Computer
t
=r
t
+ησ
i
t
and priorityφ
i
t
via (2)
12:Store transition(s
i
t
,a
i
t
,r
i
t
,s
i
t+1
,φ
i
t
)in R
13:end for
14:Sample a mini-batch ofNtransitions from R
Calculate the visiting timesρof transitions in R
Update the prioritiesφ
i
t
via (2)
Update the contribution weightsq
i
via (3)
Update the Commanderθ
C
via (4)(6)
Update the PrecoderNetθ
P
via (9)(10)
15:Update the target networks:θ
′
=τθ+ (1−τ)θ
′
16:end for
17:end for

7
VIII.  APPENDIXB
In the experiment, we observed the behavioral trajectory of
the two agents under the MADDPG and MAEPG algorithms.
Fig.8  and  Fig.9  are  the  learning  curves  of  the  two  agents
under  the  proposed  MADDPG  and  MAEPG  algorithms,  re-
spectively. The abscissa is the exploration time slot, and the
ordinate  is  the  action  value  corresponding  to  the  time  slot
(the torque magnitude and direction in the vertical pendulum
experiment).
0200400600800100012001400160018002000
Time slot
-1
-0.8
-0.6
-0.4
-0.2
0
0.2
0.4
0.6
0.8
1
Action adopted
Learning curves of MADDPG agent
positive torque(action)
negative torque(action)
Fig. 8: Two-agent MADDPG action learning curve.
0200400600800100012001400160018002000
Time slot
-1.5
-1
-0.5
0
0.5
1
Action adopted
Learning curves of MAEPG agent
positive torque(action)
negative torque(action)
Fig.  9:  Two-agent  MAEPG  action  learning  curve.  The  ab-
scissa is a time slot while each time slot is learned 500 times,
and the ordinate is the action finally learned by the time slot.
The blue curve indicates that the moment is positive, that is,
the opposite pendulum applies a moment to the right, and the
yellow curve indicates that the moment is negative.
Since  the  DQN  algorithm  cannot  converge  in  the  multi-
agent collaborative exploration environment, only the learning
curves  of  MAEPG  and  MADDPG  are  compared.  It  can  be
seen  from  the  figure  that  the  policy  learned  by  MAEPG
converges  faster,  reaching  the  steady  state  of  the  pendulum.
Then the torque is maintained at a small value, while MAD-
DPG  takes  a  long  time  to  converge  and  final  outputs  is  still
relatively unstable.
REFERENCES
[1]  S. Gu, E. Holly, T. Lillicrap, and S. Levine, “Deep reinforcement learn-
ing for robotic manipulation with asynchronous off-policy updates,” in
IEEE International Conference on Robotics and Automation, 2017.
[2]  E.  Perot,  M.  Jaritz,  M.  Toromanoff,  and  R.  D.  Charette,  “End-to-end
driving in a realistic racing game with deep reinforcement learning,” in
Computer Vision and Pattern Recognition Workshops, 2017.
[3]  G.  Han,  X.  Liang,  and  H.  V.  Poor,  “Two-dimensional  anti-jamming
communication based on deep reinforcement learning,” inIEEE Inter-
national Conference on Acoustics, 2017.
[4]  M. Volodymyr, K. Koray, and S. David, “Human-level control through
deep reinforcement learning,”Nature, vol. 518, no. 7540, p. 529, 2015.
[5]  M. Guzdial and M. Riedl, “Toward game level generation from game-
play videos,”arXiv preprint arXiv:1602.07721, 2016.
[6]  Y.  Li,  “Deep  reinforcement  learning:  An  overview,”arXiv  preprint
arXiv:1701.07274, 2017.
[7]  J. Schulman, S. Levine, P. Moritz, M. I. Jordan, and P. Abbeel, “Trust
region policy optimization,”Computer Science, pp. 1889–1897, 2015.
[8]  J. Schulman, F. Wolski, P. Dhariwal, A. Radford, and O. Klimov, “Prox-
imal policy optimization algorithms,”arXiv preprint arXiv:1707.06347,
2017.
[9]  V.  Mnih,  A.  P.  Badia,  and  M.  Mirza,  “Asynchronous  methods  for
deep  reinforcement  learning,”  inInternational  conference  on  machine
learning, pp. 1928–1937, 2016.
[10]  C.  J.  C.  H.  Watkins  and  P.  Dayan,  “Technical  note:  Q-learning,”
Machine Learning, vol. 8, no. 3-4, pp. 279–292, 1992.
[11]  H.  V.  Hasselt,  A.  Guez,  and  D.  Silver,  “Deep  reinforcement  learning
with double q-learning,”Computer Science, 2015.
[12]  Z.   Wang,   T.   Schaul,   M.   Hessel,   and   V.   Hasselt,   “Dueling   net-
work  architectures  for  deep  reinforcement  learning,”arXiv  preprint
arXiv:1511.06581, 2015.
[13]  T. Schaul, J. Quan, I. Antonoglou, and D. Silver, “Prioritized experience
replay,”arXiv preprint arXiv:1511.05952, 2015.
[14]  D. Silver, G. Lever, N. Heess, T. Degris, D. Wierstra, and M. Riedmiller,
“Deterministic policy gradient algorithms,” inICML, 2014.
[15]  T.  P.  Lillicrap,  J.  J.  Hunt,  A.  Pritzel,  N.  Heess,  T.  Erez,  Y.  Tassa,
D. Silver, and D. Wierstra, “Continuous control with deep reinforcement
learning,”Computer Science, vol. 8, no. 6, p. A187, 2015.
[16]  R.  Lowe,  Y.  Wu,  A.  Tamar,  J.  Harb,  O.  P.  Abbeel,  and  I.  Mor-
datch,  “Multi-agent  actor-critic  for  mixed  cooperative-competitive  en-
vironments,”  inAdvances  in  Neural  Information  Processing  Systems,
pp. 6379–6390, 2017.
[17]  M. Tan, “Multi-agent reinforcement learning: Independent vs. cooper-
ative agents,”Machine Learning Proceedings, pp. 330–337, 1993.
[18]  C. Claus and C. Boutilier, “The dynamics of reinforcement learning in
cooperative  multiagent  systems,”AAAI/IAAI,  vol.  1998,  pp.  746–752,
1998.
[19]  M. H. Bowling, “Convergence and no-regret in multiagent learning,” in
International  Conference  on  Neural  Information  Processing  Systems,
2004.
[20]  M.  Bowling  and  M.  Veloso,  “Rational  and  convergent  learning  in
stochastic  games,”  inInternational  joint  conference  on  artificial  in-
telligence, vol. 17, pp. 1021–1026, Lawrence Erlbaum Associates Ltd,
2001.
[21]  M. Lanctot, V. Zambaldi, A. Gruslys, A. Lazaridou, K. Tuyls, J. Pérolat,
D.  Silver,  and  T.  Graepel,  “A  unified  game-theoretic  approach  to
multiagent reinforcement learning,” inAdvances in Neural Information
Processing Systems, pp. 4190–4203, 2017.
[22]  A.   Celikyilmaz,   A.   Bosselut,   X.   He,   and   Y.   Choi,   “Deep   com-
municating   agents   for   abstractive   summarization,”arXiv   preprint
arXiv:1803.10357, 2018.
[23]  S. Li, Y. Wu, X. Cui, H. Dong, F. Fang, and S. Russell, “Robust multi-
agent  reinforcement  learning  via  minimax  deep  deterministic  policy
gradient,” inAAAI Conference on Artificial Intelligence (AAAI), 2019.
[24]  G.   Vezzani,   A.   Gupta,   L.   Natale,   and   P.   Abbeel,   “Learning   la-
tent  state  representation  for  speeding  up  exploration,”arXiv  preprint
arXiv:1905.12621, 2019.
[25]  C. Dai, L. Xiao, X. Wan, and Y. Chen, “Reinforcement learning with
safe  exploration  for  network  security,”  inICASSP  2019-2019  IEEE
International  Conference  on  Acoustics,  Speech  and  Signal  Processing
(ICASSP), pp. 3057–3061, IEEE, 2019.
[26]  E.    Parisotto,    J.    L.    Ba,    and    R.    Salakhutdinov,    “Actor-mimic:
Deep  multitask  and  transfer  reinforcement  learning,”arXiv  preprint
arXiv:1511.06342, 2015.
[27]  X.  B.  Peng,  G.  Berseth,  K.  Yin,  and  M.  Van  De  Panne,  “Deeploco:
Dynamic locomotion skills using hierarchical deep reinforcement learn-
ing,”ACM Transactions on Graphics (TOG), vol. 36, no. 4, p. 41, 2017.
[28]  G.   Brockman,   V.   Cheung,   L.   Pettersson,   J.   Schneider,   J.   Schul-
man,   J.   Tang,   and   W.   Zaremba,   “Openai   gym,”arXiv   preprint
arXiv:1606.01540, 2016.
[29]  D. P. Kingma and J. Ba, “Adam: A method for stochastic optimization,”
arXiv preprint arXiv:1412.6980, 2014. 

Automating concept-drift detection
by self-evaluating predictive model degradation
Tania Cerquitelli, Stefano Proto, Francesco Ventura, Daniele Apiletti, Elena Baralis
Department of Control and Computer Engineering
Politecnico di Torino
Turin, Italy
name.surname@polito.it
ABSTRACT
A key aspect of automating predictive machine learning entails the
capability of properly triggering the update of the trained model. To
this aim, suitable automatic solutions to self-assess the prediction
quality and the data distribution drift between the original training
set and the new data have to be devised.
In this paper, we propose a novel methodology to automatically
detect prediction-quality degradation of machine learning mod-
els due to class-based concept drift, i.e., when new data contains
samples that do not fit the set of class labels known by the currently-
trained predictive model.
Experiments on synthetic and real-world public datasets show
the effectiveness of the proposed methodology in automatically
detecting and describing concept drift caused by changes in the
class-label data distributions.
KEYWORDS
AutoML, predictive analytics, concept drift, model degradation,
unsupervised self-evaluation
1  INTRODUCTION
In many application domains, from industrial production environ-
ments to smart cities, from network traffic classification to text
mining, it is quite common that the nature of the collected data
changes over time due to the evolution of the phenomena under
analysis, e.g., equipment maintenance, road topology changes, up-
dated configurations, and environmental factors. However, collect-
ing historical training sets including all possible class labels may
be very hard, too expensive, or even unfeasible. Hence, when per-
forming predictions, new data belonging to unseen class labels, i.e.,
labels that the predictive model did not know at training time, are
likely to be presented at some point in the future, leading to wrong
predictions.
Frequently updating the prediction models by extending the
training set to the new data can be computationally intensive and,
worse, may require the intervention of domain experts along with
data scientists to translate the changes of the phenomenon into
appropriate choices for the predictive task. For these reasons, it is
often unfeasible or at least highly sub-optimal to simply retrain the
model very frequently.
To this aim, we introduce a self-evaluation step to automatically
identify and quantify the degradation of the prediction quality over
time. An additional challenge in this approach is provided by the
absence of the ground-truth predictions for the newly classified
samples. Hence, the solution is based onunsupervisedevaluation
metrics. These metrics can provide a twofold contribution: (i) au-
tomatically trigger a predictive model retraining, by determining
when it is required to better fit the new data, and (ii) describe the
changes in data distributions motivating the model update.
Many works addressed the problem of detecting data distribu-
tion changes in machine learning. In [17], three different strategies
are presented: (i) instance selection, (ii) instance weighting and (iii)
ensemble learning. In the first case, the goal is to consider sam-
ples relevant to the current concept: these approaches are mainly
based on trailing windows moving over the latest instances. The
instance-weighting strategy is based on learning algorithms able
to consider weights separately for each instance, whereas the latter
exploits ensembles to better capture different nuances in the data.
In our solution, we exploit a trailing window on new data samples
similarly to strategy (i), but we propose a new evaluation metrics to
self-evaluate degradation between the training set and the current
dataset, since the training set describes what the current predictive
model has learnt.
A survey on concept drift adaptation is provided in [5]. In this
context, we focus on class-based concept drift for predictive analyt-
ics, for which a unifying view is provided and its nuances are ex-
plored in [10]. Different techniques for monitoring two distributions
at different time windows have been proposed. An entropy-based
measure for data streams has been proposed in [19] to detect abrupt
concept drifts due to context changes produced by sensors (e.g.,
wearable devices). In [3] the authors propose an adaptive sliding
window technique along with a Naïve Bayes predictor to monitor
the performance of a predictive model over time. Another approach
addressing concept drift detection in textual data, based on support
vector machines, is presented in [7]. An analysis of discrete-time
Markov chains affected by concept drift has been recently proposed
in [14] providing a collection of change-detection mechanisms and
an adaptive learning algorithm suited to this specific context. Re-
cent approaches aiming at detecting concept drift in the context
of online learning with imbalanced classes are presented in [20],
whereas the challenge of detecting model degradation when in-
cremental learning is applied was addressed in [15]. Many related
works validate their approaches on controlled synthetic datasets
with known concept drifts, besides considering real-world datasets.
The solution presented in this paper improves the state-of-the-
art by defining a methodology for detecting concept drifts on new
incoming data over time (i) automatically (self-evaluation), (ii) in
a general purpose manner (not tailored to a specific use case or
application domain, nor to a specific data type), and (iii) with scala-
bility in mind. The algorithm has been designed to be horizontally
arXiv:1907.08120v1  [cs.LG]  18 Jul 2019

scalable on Big Data contexts by means of the Map Reduce pro-
gramming paradigm and is implemented on top of Apache Spark.
The paper is organized as follows. Section 2 introduces the overall
methodology to automatically provide up-to-date predictive models
when required. Section 3 presents the new self-evaluation strategy
proposed to detect predictive degradation and concept drift, while
Section 4 discusses some preliminary experiments to evaluate the
proposed approach. Section 5 draws conclusions and discusses
future extensions of the research work.
2  AUTOMATED CONCEPT DRIFT
MANAGEMENT
We present a novel unsupervised methodology able to automati-
cally detect class-based concept drifts by evaluating the degradation
of the predictions. Specifically, we aim at identifying when addi-
tional or different class labels are required because the current ones
misrepresent the new data samples.
The proposed methodology consists of three steps, as depicted
in Figure 1. (i)Model degradation self-evaluationstep, performed
through a novel unsupervised approach assessing the degradation
of a prediction model over time. (ii)Semi-supervised data labeling
step, to assign labels to the new automatically-discovered classes
of data. A small subset of representative samples of the new classes
will be manually inspected by domain experts. Their label assign-
ments will be used for the remaining samples in each corresponding
class. (iii)Automated KDD (Knowledge Discovery Process) to build a
new predictive model, able to correctly fit the new incoming data dis-
tributions and classification labels. This step can be automatically
triggered based on the results of the previous ones, e.g., when the
model degradation is higher than a given threshold. The latter step
has already seen applications of state-of-the-art approaches tailored
to specific data types, such as in [2] for predictive maintenance,
in [4,12] for addressing topic detection among textual document
collections, and for network traffic characterization in [1].
The contribution of this paper focuses on step (i), which is a
core step required to provide a solution for self-evaluating the
model degradation over time, aimed at detecting concept drifts. The
contribution is detailed in Section 3.
Figure 1: Building blocks of the proposed framework.
3  SELF-EVALUATING MODEL DEGRADATION
The knowledge of a prediction model is based on the informa-
tion learnt from the training samples (historical data with labels).
Hence, predictions for new data describing evolving phenomena
may become misleading or erroneous, due to the different data
distributions of the new samples. To efficiently capture this model
degradation over time, the proposed approach performs (i)Baseline
computation,by computing unsupervised quality metrics on the
training set, and (ii)Self-evaluation,by periodically recomputing
the same metrics on the new data and comparing it to the metrics
in (i). While new data are continuously classified by the model over
time, the quality assessment has to be performed periodically. Since
the quality metrics depend on the cardinality of the new data and
their labels, in the current version we trigger self-evaluation when
any class label is affected by a percentage increase in the number
of its new samples with respect to the previous run above a given
threshold (e.g., 20%).
Finally,  to  fully  automate  the  process,  a  degradation  thresh-
old should be defined to trigger predictive model rebuilding. This
threshold depends on the expectations of domain experts and end-
users, the risks and costs related to the specific application, and
also the number of records and classes of the dataset. Its evaluation
is out of the scope of this paper.
Self-evaluating predictive model quality over time.
Tradi-
tional evaluation techniques for predictive analytics (e.g., f-measure,
precision, recall) are not applicable to our context since they require
ground-truth labeled data, which is missing for newly-classified
samples. Hence, we exploit an unsupervised index that, given a
dataset of samples divided into classes (labels), is able to quantify
both the intra-class cohesion and the inter-class separation. The
degradation is then defined as a negative change in the index value
of the newly-classified data with respect to the value obtained on
the training set, considered as a baseline.
The proposed approach is independent of a specific quality index
selection. In this work we exploit the Silhouette [13], a succinct
measure of the fit of each sample within its predicted class. It mea-
sures how similar a sample is to its own class (cohesion) compared
to other classes (separation). The Silhouette value ranges from -1
to +1, with higher values indicating a better match to the assigned
class and a poor match to other classes. In order to compute the
Silhouette, for each sample, the pairwise distance between itself
and each other sample of the dataset have to be calculated. For this
reason, the traditional computation of the Silhouette coefficient is
not suitable for Big Data scenarios. However, scalable approaches
have been proposed in literature. We adopt the approach proposed
in [18]. The Silhouette measure can be used for any data type by
using the appropriate distance-similarity measure (e.g., Euclidean
distance for structured and numerical data, cosine similarity for
textual data, Jaccard for Boolean data [16]).
Estimating model degradation.To this aim, we compare two
quality index values: (i) the baseline, computed on the training set
only, and (ii) the current one, computed on newly-labeled data. The
change in quality has to be quantified separately for each class.
Hence, at each index computation step, for each class, a curve is
plotted, representing the Silhouette values of each point, sorted in
increasing order. To enable pairwise Silhouette curve comparison,
the two curves should be characterized by the same number of
points. Hence, a down-sampling of the curve characterized by the
largest cardinality may be required.
An upward shift of the Silhouette curve represents an improve-
ment in terms of intra-class cohesion and inter-class separation,
while, on other hand, a downward shift denotes a degradation. The
2

degradation of the Silhouette curve is able to detect the presence of
new samples not fitting the distribution of the data seen at model-
training time. Hence, it is likely that the current prediction model
is not able to correctly assign the class labels to these new samples.
Furthermore, the correct class labels might be new (additional) ones,
unknown for the current model.
To quantify the shift of the Silhouette curves, the MAAPE (Mean
Arc-tangent Absolute Percentage Error) [6] has been used, although
other error metrics could be used alternatively. Given a prediction
model trained on a set of classesCat timet
0
, whose training set
has a Silhouette valueSil
t
0
, the degradation of a classc∈Cat time
tis described by the following relation:
DEG(c,t)=α∗MAAPE(Sil
t
0
,Sil
t
)∗
N
c
N
(1)
α=

1i f:
Sil
t
0
≥Sil
t
−1i f:
Sil
t
0
<Sil
t
(2)
The coefficientαdefines if the degradation is positive, meaning
a possible reduction in performance of the prediction model, or
negative, when the new data fit the training distribution, hence
increasing the cohesion of classc. From (1), the degradation is mod-
elled as the MAAPE error between the baseline SilhouetteSil
t
0
on the training set and the possibly-degraded SilhouetteSil
t
com-
puted at timeton newly-labeled data. The degradation estimation
is weighted by the ratioN
c
/N, whereN
c
is the number of new
records assigned to classcandNis the total number of new sam-
ples, withNcapped at the number of samples in the training set
N
t r ain
. The cap is introduced to allow a fair comparison when
N>>N
t r ain
To this aim,Sil
t
is computed on a trailing window
containing the latestNsamples up to the number of samples of the
training setN
t r ain
. Finally, the degradation of the whole model at
timetis computed as the sum of the degradation values for each
class:
Í
c∈C
DEG(c,t).
As a heuristics to automate the degradation assessment, we are
currently triggering the self-evaluation when at least one class
has seen an increase of a given percentage inN
c
with respect
to the latest computation (e.g., 20%). This heuristics allows us to
avoid delaying the detection of concept drift by providing excessive
inertia to the approach. Finally, we are considering to trigger a full
model rebuild when the overall degradation or at least a single-
class degradation are above given thresholds (e.g., 10-15% overall
and 5-10% single class). The assessment of the thresholds and the
evaluation of different heuristics will be addressed as future work.
4  PRELIMINARY EXPERIMENTAL RESULTS
We present experimental results on two datasets containing concept
shifts represented by the presence of data belonging to previously
unseen classes, unknown to the predictive model. The first datataset,
D1, is a synthetic dataset created with thescikit-learnPython library
[11]. It has been generated with 4 normally distributed classes and
800,000 records, 200,000 for each class, and 10 features. Dataset
D2, on the contrary, is a real-world dataset containing Wikipedia
articles, extracted from 3 classes:mathematics,literature, andfood-
drink. For each class, a selection of 1,000 articles appearing in the
Wikipedia index for that class have been downloaded. Each article
has been pre-processed to obtain an embedded representation of 100
(a) Degradation with class 2.
(b) Degradation with class 3.
Figure 2: Dataset D1. Model degradation over time, with
training on classes 0 and 1.
features for it. The document-embedding process takes advantage of
a Doc2Vec model [9], pre-trained on the English Wikipedia corpus
[8]. For all datasets, a Random Forest classifier has been used as
predictive model. Using a 3-fold cross-validation, the average f-
measure of the predictive model is 0.964 for dataset D1, and 0.934
for dataset D2.
The experimental goal is to show the capability of the proposed
methodology to correctly assess the model degradation over time
when concept drifts are introduced. For both experiments, the train-
ing set is composed by a stratified sample over classes 0 and 1 of
about 60% of records in each class. The remaining part of the dataset
(40% class 0, 40% class 1, the unknown class 2 and/or 3 according
to the dataset) is used as test set to assess model degradation. The
first four test sets, fromt
1
tot
4
, contain only data known to belong
to the classes included in the training set, whereas the last test sets,
fromt
5
tot
n
, contain both known-class samples and unknown-class
samples, in different proportions. The test sets have been designed
to simulate the flow of time, so subsequent tests extend the data
of previous ones, e.g.,t
1
contains half of the test set for class 0,t
4
contains the whole test set for classes 0 and 1,t
5
contains all the
test samples for classes 0 and 1 and 20% of the unknown class (class
2 or 3), then at each step another 20% of the unknown class is added
for the evaluation of degradation untilt
n
.
Figure 2 shows the MAAPE degradation percentage for the train-
ing classes 0 and 1 in D1 at different time periods, when data belong-
ing to the previously unseen classes 2 (Figure 2a) and 3 (Figure 2b)
arrive starting from timet
5
. While fromt
1
tot
4
the overall MAAPE
degradation is always below 5%, fromt
5
the overall MAAPE degra-
dation, i.e. the sum of both classes (0 and 1), is constantly higher
3

(a) Degradation with class 2.
(b) Degradation with class 3.
Figure 3: Dataset D1. Baseline and degraded Silhouette
curves for each class label at timet
9
.
than 10%, and the trend is coherent with the introduced drift propor-
tion. Figures 3a and 3b report the detailed Silhouette degradation of
the known classes 0 and 1 at timet
9
, when there are new samples
of the unknown classes 2 and 3 in the test set.
Figure 4 shows the average percentage degradation of the Wikipedia
document classification model. From the histogram, it is possible to
see that, up to timet
4
, the new unseen data classified by the model
fits well the learnt distribution, with an overall MAAPE below 15%.
At timet
5
, samples of an unknown class start arriving and the
overall MAAPE raises above 28%.
In both datasets, the sum of the degradation for all known classes
correctly detected when the shift was introduced, even if the pro-
portion of new shifted data was low (i.e., 20% of the unknown class).
Specifically, we note that the overall degradation at least duplicates
from the pre-drift (t
1
tot
4
) to the post-drift (t
5
tot
n
), hence proving
to be a promising detector of these events.
Figure 4: Dataset D2. Model degradation over time, with
training on classes 0 (food-drink) and 1 (literature) and
degradation introduced by the new class 2 (mathematics).
5  CONCLUSIONS AND FUTURE WORKS
This paper presented a novel strategy to detect concept drift, due to
the arrival of new unseen samples not fitting the data distribution
available at model-training time. The proposed approach is based
on the evaluation of the predictive model degradation through an
unsupervised metric (i.e. the Silhouette index) in a self-evaluating
fashion, and shows promising experimental results on two datasets.
Future directions of this research include: (i) a comparison with
state-of-the-art techniques focusing on drift recognition efficiency,
(ii) the introduction of alternative unsupervised metrics besides
the Silhouette index, (iii) the improvement of the self-evaluation
triggering mechanism (currently set as a percentage of new data),
and (iv) further experiments to assess the generality and the perfor-
mance of the approach over different real-world datasets presenting
known concept drifts.
REFERENCES
[1]Daniele Apiletti, Elena Baralis, Tania Cerquitelli, Paolo Garza, Danilo Giordano,
Marco Mellia, and Luca Venturini. 2016. Selina: a self-learning insightful network
analyzer.IEEE Transactions on Network and Service Management13, 3 (2016),
696–710.
[2]
Daniele  Apiletti,  Claudia  Barberis,  Tania  Cerquitelli,  Alberto  Macii,  Enrico
Macii,  Massimo  Poncino,  and  Francesco  Ventura.  2018.iSTEP,  an  Inte-
grated  Self-Tuning  Engine  for  Predictive  Maintenance  in  Industry  4.0.  In
IEEE International Conference on Parallel & Distributed Processing with Appli-
cations, Ubiquitous Computing & Communications, Big Data & Cloud Comput-
ing, Social Computing & Networking, Sustainable Computing & Communications,
ISPA/IUCC/BDCloud/SocialCom/SustainCom 2018, Melbourne, Australia, December
11-13, 2018. 924–931.  https://doi.org/10.1109/BDCloud.2018.00136
[3]Albert Bifet and Ricard Gavalda. 2007. Learning from time-changing data with
adaptive windowing. InProceedings of the 2007 SIAM international conference on
data mining. SIAM, 443–448.
[4]
Evelina Di Corso, Tania Cerquitelli, and Francesco Ventura. 2017.  Self-tuning
techniques for large scale cluster analysis on textual data collections. InPro-
ceedings of the Symposium on Applied Computing, SAC 2017, Marrakech, Morocco,
April 3-7, 2017. 771–776.  https://doi.org/10.1145/3019612.3019661
[5]João Gama, Indr
 ̇
e Žliobait
 ̇
e, Albert Bifet, Mykola Pechenizkiy, and Abdelhamid
Bouchachia. 2014. A survey on concept drift adaptation.ACM computing surveys
(CSUR)46, 4 (2014), 44.
[6]Sungil Kim and Heeyoung Kim. 2016.   A new metric of absolute percentage
error for intermittent demand forecasts.International Journal of Forecasting32, 3
(2016), 669–679.
[7]Ralf Klinkenberg and Thorsten Joachims. 2000.  Detecting Concept Drift with
Support Vector Machines.. InICML. 487–494.
[8]Jey Han Lau and Timothy Baldwin. 2016.  An empirical evaluation of doc2vec
with practical insights into document embedding generation.arXiv preprint
arXiv:1607.05368(2016).
[9]Quoc Le and Tomas Mikolov. 2014. Distributed representations of sentences and
documents. InInternational conference on machine learning. 1188–1196.
[10]Jose G Moreno-Torres, Troy Raeder, RocíO Alaiz-RodríGuez, Nitesh V Chawla,
and Francisco Herrera. 2012. A unifying view on dataset shift in classification.
Pattern Recognition45, 1 (2012), 521–530.
[11]F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M.
Blondel, P. Prettenhofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Passos, D. Cour-
napeau, M. Brucher, M. Perrot, and E. Duchesnay. 2011. Scikit-learn: Machine
Learning in Python.Journal of Machine Learning Research12 (2011), 2825–2830.
[12]Stefano Proto, Evelina Di Corso, Francesco Ventura, and Tania Cerquitelli. 2018.
Useful ToPIC: Self-Tuning Strategies to Enhance Latent Dirichlet Allocation. In
2018 IEEE International Congress on Big Data, BigData Congress 2018, San Francisco,
CA, USA, July 2-7, 2018. 33–40.  https://doi.org/10.1109/BigDataCongress.2018.
00012
[13]
Peter J. Rousseeuw. 1987. Silhouettes: A graphical aid to the interpretation and
validation of cluster analysis.J. Comput. Appl. Math.20 (1987), 53 – 65.
[14]M. Roveri. 2019. Learning Discrete-Time Markov Chains Under Concept Drift.
IEEE Transactions on Neural Networks and Learning Systems(2019), 1–13.   https:
//doi.org/10.1109/TNNLS.2018.2886956
[15]Y. Sun, K. Tang, Z. Zhu, and X. Yao. 2018. Concept Drift Adaptation by Exploiting
Historical Knowledge.IEEE Transactions on Neural Networks and Learning Systems
29, 10 (Oct 2018), 4822–4832.   https://doi.org/10.1109/TNNLS.2017.2775225
[16]Pang-Ning Tan, Michael Steinbach, and Vipin Kumar. 2005.Introduction to Data
Mining, (First Edition). Addison-Wesley Longman Publishing Co., Inc., Boston,
4

MA, USA.
[17]Alexey Tsymbal. 2004. The problem of concept drift: definitions and related work.
Computer Science Department, Trinity College Dublin106, 2 (2004), 58.
[18]
Francesco Ventura, Stefano Proto, Daniele Apiletti, Tania Cerquitelli, Simone
Panicucci, Elena Baralis, Enrico Macii, and Alberto Macii. 2019.   A new un-
supervised predictive-model self-assessment approach that SCALEs. In2019
IEEE International Congress on Big Data (BigData Congress).  IEEE,  144–148.
https://doi.org/10.1109/BigDataCongress.2019.00033
[19]
P. Vorburger and A. Bernstein. 2006.  Entropy-based Concept Shift Detection.
InSixth International Conference on Data Mining (ICDM’06). 1113–1118.   https:
//doi.org/10.1109/ICDM.2006.66
[20]
S. Wang, L. L. Minku, and X. Yao. 2018.  A Systematic Study of Online Class
Imbalance Learning With Concept Drift.IEEE Transactions on Neural Networks
and Learning Systems29, 10 (Oct 2018), 4802–4821.    https://doi.org/10.1109/
TNNLS.2017.2771290
5 

OCC: A Smart Reply System for Eicient In-App
Communications
Yue Weng
∗
Uber AI
San Francisco, California 94103
yweng@uber.com
Huaixiu Zheng
†
Uber AI
San Francisco, California 94103
huaixiu.zheng@uber.com
Franziska Bell
Uber AI
San Francisco, California 94103
fran@uber.com
Gokhan Tur
Uber AI
San Francisco, California 94103
gokhan@uber.com
ABSTRACT
Smart reply systems have been developed for various messaging
platforms. In this paper, we introduce Uber’s smart reply system:
one-click-chat (OCC), which is a key enhanced feature on top of
the Uber in-app chat system. It enables driver-partners to quickly
respond to rider messages using smart replies. e smart replies are
dynamically selected according to conversation content using ma-
chine learning algorithms. Our system consists of two major compo-
nents: intent detection and reply retrieval, which are very dierent
from standard smart reply systems where the task is to directly
predict a reply. It is designed specically for mobile applications
with short and non-canonical messages.  Reply retrieval utilizes
pairings between intent and reply based on their popularity in chat
messages as derived from historical data. For intent detection, a set
of embedding and classication techniques are experimented with,
and we choose to deploy a solution using unsupervised distributed
embedding and nearest-neighbor classier. It has the advantage of
only requiring a small amount of labeled training data, simplicity in
developing and deploying to production, and fast inference during
serving and hence highly scalable. At the same time, it performs
comparably with deep learning architectures such as word-level
convolutional neural network. Overall, the system achieves a high
accuracy of 76% on intent detection. Currently, the system is de-
ployed in production for English-speaking countries and 71% of
in-app communications between riders and driver-partners adopted
the smart replies to speedup the communication process.
CCS CONCEPTS
•Computing methodologies→Natural language processing;
Classication and regression trees; Neural networks;
KEYWORDS
smart reply; machine learning; natural language processing; intent
detection; unsupervised learning; distributed embedding; neural
networks
∗
Equal Contribution
†
Equal Contribution
1  INTRODUCTION
Uber’s ride-sharing business connects driver partners to riders who
need to transport around cities. e app provides navigation and
many other innovative technology and features that assist driver-
partners with nding riders at the pick-up locations. Uber’s in-app
chat [10], a real-time in-app messaging platform launched in early
2017, is one of them. Before having the functionality to chat within
the app, communication between customers occurred outside of the
mobile app experience using third-party technologies. is resulted
in safety concerns, higher operational costs, fewer completed trips,
and most importantly, limits the company’s ability to understand
and resolve challenges both riders and driver partners were having
while using the app. Although the newly added chat feature has
solved many of these problems by bringing the chat experience
into the app, it still requires driver-partners to type messages while
driving, which is a huge safety concern.  According to a public
study, compared to regular driving, accident risk is about 2.2 times
higher when talking on a hand-held cell phone and 6.1 times higher
when texting [13]. erefore, to provide a safe and smooth in-app
chat experience for driver-partners, we developed One-Click Chat
(OCC), a smart reply system that allows driver-partners to respond
to messages using smart replies selected dynamically according to
the conversation context, as shown in Figure 1.
ere has been a surge of interest in developing and using smart
reply and chatbot systems on commercial platforms [2,6,15]. How-
ever, building an intelligent system to automatically generate sug-
gested replies is not a standard machine learning problem. Anjuli et
al. [6] proposed to divide the task into two components: predicting
responses and identifying a target response. Specically, to predict
responses, they leveraged a sequence-to-sequence (Seq2seq) [12]
framework with long short-term memory (LSTM) [4] trained on
large-scale email conversations; to obtain the nal response, they
rst proposed a semi-supervised approach to generate a response
pool and then select from it based on the LSTM predictions to
control the actual replies as free text generation is still not mature
enough for commercial use [6]. Similarly, LinkedIn used a statistical
model for predicting responses for incoming messages [5].
In contrast, instead of predicting responses directly, our work
experiments with techniques that perform language understanding
(i.e., intent detection) and reply retrieval separately. Our approach
arXiv:1907.08167v1  [cs.CL]  18 Jul 2019

Figure 1: With one-click chat, driver-partners can more eas-
ily respond to rider messages.
requires a much smaller scale labeled dataset for training.  Com-
pared to the generic smart replies, OCC is designed for Uber’s
domain-specic use case to streamline communications between
driver-partners and riders during the pick-up stage.  In addition,
in-app messages on the Uber platform are typically very short (av-
eraging 4-5 words) and non-canonical (with typos, abbreviations
etc.) compared to other platforms such as email. is poses unique
challenges to designing and developing such a smart reply system.
In this paper, we share our experiences building and integrating
Uber’s smart reply system. e main contributions of this work are
as follows:
•Introducing an end-to-end smart reply system architecture,
a mobile-friendly solution, in Section 2.
•Presenting a novel approach to break the task of smart
reply down into two steps - intent detection and reply
retrieval, tailored specically for short messages on the
mobile platform.
•Proposing a mixture of unsupervised embedding and nearest-
neighbor supervised learning approaches which do not
require a large amount of labeled data.  is combined
approach achieves comparable performance to deep learn-
ing architectures, but is much easier to implement and
deploy. e step-by-step algorithmic approach is discussed
in Section 3.
•Conducting comprehensive experiments to compare dier-
ent models and uncover their underlying mechanisms and
shortcomings. Experiments are discussed in Section 4.
2  ONE-CLICK CHAT SYSTEM
As one of the world’s largest and most recognized rider-sharing
providers, there are hundreds and thousands of messages exchanged
on the platform every day. OCC, one of the latest key enhanced
features on our chat platform, aims to provide driver-partners with
Figure 2: e machine learning algorithm empowers the
ow of the OCC experience. Two key steps are involved: 1)
intent detection and 2) reply retrieval.
Figure 3: e architecture for Uber’s smart reply system,
OCC, consists of a ve-step workow.
a one-click chaing experience by oering them the most relevant
replies.
To nd the best replies to each incoming message, we formulate
the task into a machine learning problem with two major compo-
nents:
(1)  Intent Detection
(2)  Reply Retrieval
Figure 2 illustrates how OCC works in the real world. Specically,
a driver-partner receives an incoming rider message askingWhere
are you right now?, which is very common during pick-up. In intent
detection, the OCC system detects the intent of the message as
Where are you?.  en in reply retrieval, the system surfaces the
top four most relevant replies to the driver-partner, which, in this
example, areYes, I am omw,Sorry, in trac,I am at pick-up address,
andCall me please. Now, the driver-partner can select one of these
four replies and send it back to the rider with a single tap.  e
above process nishes one round of communication with smart
replies.
2

Figure 4: Chat message length frequency, on average4-5
words per message.
OCC system is fully integrated with our in-house chat platform.
As depicted in Figure 3, the system architecture follows a ve-step
workow:
(1)  Sender (rider app) sends a message to driver partner.
(2)Mobile side triggers and sends the message to a back-end
service that calls the machine learning model hosted on
Uber’s in-house machine learning platform Michelangelo
[3].
(3)e model preprocesses and encodes the message, gener-
ates prediction scores for each possible intent, and sends
them back to the back-end service.
(4)Once the back-end service receives the predictions, it fol-
lows a predened reply retrieval policy to nd the best
replies (in this case, the top four).
(5)Receiver (driver-partner app) receives the smart replies
and renders them for the driver-partner to select.
3  MACHINE LEARNING METHODOLOGY
By design, OCC aims to provide an easy chat experience for driver-
partners during the pick-up stage for Uber-specic scenarios and
topic domains. As a result, it shares a few technical challenges that
are unique to mobile messaging systems:
•Messages are short compared to email or other commu-
nication channels, 4−5 words per message on average
given it is mostly used during pick-up, see Figure 4 for the
message length statistics.
•Messages are non-canonical, containing abbreviations, ty-
pos,  and colloquialisms.   Even for simple message like
Where are you, there are many variations includingwhere
r u :) ?,w Here are youand more.
We designed our machine learning system with these challenges
in mind, and adopted a mixture of unsupervised embedding and
supervised classication techniques to tackle them accordingly.
is section describes each component of the pipeline shown in
Figure 2 in detail.
3.1  Features and Data
We used millions of encrypted and anonymized historical in-app
conversation data for our unsupervised embedding model.  For
supervised classication model, we collected and annotated thou-
sands of conversational messages. Each of which is labeled as one
of the intents in our system (such asI am here). Here, we assume the
messages are all single intent and validate the assumption manually.
For the majority of the messages, they are short and convey a single
intent in a single exchange of communication, even though there
are exceptions. For this version of OCC, we use the text message as
the only feature in the modeling process. For future iterations, con-
textual features such as length of conversation and trip information
may be leveraged by the models.
3.2  Intent Detection
Given the nature of our message data (short and non-canonical
with typos, etc.), we decide to put the emphasis on intent detection.
As we tackle intent detection [1], we encounter several technical
challenges due to the complexity of human language itself and the
nature of messages exchanged on a mobile platform. For instance,
there are many ways to ask the same question, such asWhere are
you going?,Where are you heading?, andWhat’s your destination?.
With typos and abbreviations, chat messages introduce even more
permutations. In addition, chat messages are typically very short,
which makes distinguishing them from each other very challenging.
Creating a system with replies for millions of individual questions
does not scale, so we need a system that can identify the intent
or topic behind each question, allowing us to provide replies to a
nite set of intents.
We formulate the language understanding task as a classication
problem in order to have full control over message replies.  We
experimented with four dierent approaches for intent detection.
•Frequency-based, a context-agnostic approach that sug-
gests intents based on their frequency.
•CNN-based deep learning approach, both word and char-
acter level [7].
•Embedding [8] plus nearest neighbour classier (NNC),
which is a combination of unsupervised and supervised
learning approach. It requires much smaller labeled data
and performs on par with deep learning methods on a test
dataset.
Since both frequency and CNN-based approaches are relatively
straight forward, we focus on the embedding-based NNC for the
rest of the section.
3.2.1  Message Embeddings.We embedded messages using the
Doc2vec model [8], an unsupervised algorithm proposed by Le and
Mikolov (2014), that learns xed-length feature representations
from variable-length pieces of text, such as sentences, paragraphs,
and documents.  Because our messages are domain-specic and
contain a lot of typos and abbreviations, we decided to train our
own embedding model using in-house data. Our Doc2vec model
was trained on millions of anonymized, aggregated in-app chat
messages and was then used to map each message to a dense vector
embedding space.  Figure 5 visualizes the word vectors in a two-
dimensional projection using a t-SNE plot [14]. Since it captures the
semantic meaning of words, the model can cluster similar words
together.  For example,feeis close tochargeandrefund, but far
away fromfriend.
3

Figure 5:  is two-dimensional t-SNE projection of the
Doc2vec word embedding illustrates the ability of the model
to automatically organize concepts and learn implicitly the
relationships between words, clustering them based on se-
mantics.
More formally, given a sequence of training wordsw
1
,w
2
,....,w
T
from the documentD, the objective of the Doc2vec model is to use
a neural network to nd the parameter setsθ
∗
in order to maximize
the conditional probability of a target wordw
t
givenkcontextual
words before and aer the target word,
θ
∗
=argmax
θ
÷
t∈S
P(w
t
|w
t−k
,...,w
t+k
;θ)(1)
whereSis a sample of words fromDandθ∈θ
d
,θ
w
,θ
somax
, where
θ
w
are word vectors,θ
somax
contains the weights for a somax
hidden layer andθ
d
are paragraph vectors. In short, the algorithm
itself has two stages:  1)training stageto optimize word vectors
θ
w
, somax weightsθ
somax
and paragraph vectorsθ
d
on already
seen paragraphs to maximize the probability of target word given
contextual words; and 2)the inference stageto compute paragraph
vectorsdfor new documents, which can be never seen before, by
gradient descending ondwhile holdingθ
somax
andθ
w
xed [8].
3.2.2  NNC Approach.We build a nearest-neighbor classier
on top of the distributed representation of labeled messages from
document embedding model Doc2vec. e main motivation is that
we have a relatively small set of (thousands of ) labeled data to train
a classication model. Overing is a big concern, and hence the
non-parametric nearest-neighbor classier can largely avoid such
a problem.
Figure 6 illustrates the process of nearest-neighbor classier
using document embedding. First, with the trained Doc2vec model,
noted asM, we can obtain document vectord
i
j
for any document,
which is the dense vectors representing theith document which
Figure 6: Illustration of the process of nearest neighbor clas-
sier based on document embedding and cosine distance.
belongs tojth intent class. Using labeled data, we then compute
thecentroidD
j
of each intent class from the dense vectors as:
D
j
=
1
N
j
N
j
’
i=1
d
i
j
(2)
whereN
j
is the number of labeled messages ofjth intent class. Each
intent class now is represented by this centroid.
During the inference stage, an inference step is taken to use
Mto compute the paragraph vector for a new paragraphm
k
=
w
1
,w
2
,...w
n
, wherew
1
,w
2
,...w
n
are the word tokens. We obtain
the corresponding dense vector
d
k
=M(m
k
)
Using labeled data, we then compute the vector cosine distance
between the message vector and each of the intents’ centroids and
pick topKclosest intents measured by cosine distance as top-K
predictions of intent.
C
j
k
=
d
k
·D
j


d
k


·


D
j


Figure 6 illustrates a toy example with only two intent classes.
An incoming message is mapped to the embedding space. As it is
closer to theWhat color is your car?intent centroid, it would be
classied as such rather thanI am here.
3.3  Reply Retrieval
Once the system detects the intent for the message, reply retrieval
becomes relatively straightforward as the topic domain is specic to
Uber’s in-app communications. For the example shown in Figure 2,
the reply to a message withwhere are youintent has only a small
set of possible variations given its context as a response on the Uber
platform. In this case, there are only a couple of answers such as
Yes, I am omw,Sorry, in tracand so on, depending on the location
of the driver partner.
Here, we leverage historical conversation pairs to nd the most
frequent reply candidates for each intent class.  In essence, we
4

Figure 7: (a) Precision and (b) Recall of the models for top-10intents.
Model
Accuracy
NNC0.759
Word-CNN0.756
Char-CNN0.772
Frequency-based0.155
Table 1: Model accuracy of intent detection.
perform intent classication on all messages and map out the intents
of each message in a conversation. For each turn of the conversation,
the intent of theincoming messageis paired with the intent of the
response message. For a particular intent ofincoming message, we
measure the frequency of the intents from theresponse messages,
and select the most frequent ones as well as all possible variations
as candidate replies.  Aer that, our content team performs one
more round of augmentation and reordering to make the candidate
replies as easily understood and accurate as possible. is whole
process creates the intent-reply mapping for reply retrieval.
During serving time, in order to gain more coverage, we pick
the topKpredicted intents and dynamically de-duplicate repeated
reply candidates by order.  For instance, when we get predicted
intentsI
1
andI
2
, we rst look up the intent-reply mapping
I
1
:R
1
,R
2
;I2 :R
1
,R
3
,R
4
.
Instead of providing replyR
1
twice, we merge them and keep their
order. So the nal smart reply list is
[R
1
,R
2
,R
3
,R
4
]
In addition, corner cases such as extremely short messages (e.g.,
having only one word) and low condence predictions (e.g., multi-
intent messages) are handled by rules rather than our algorithm.
4  EXPERIMENT ANALYSIS
In this section, we evaluate the intent detection task and report
overall performance for the approaches described in the above
section.
Figure 8: Top-Kaccuracy of intent detection.
4.1  Results
Model Accuracy: One of the most important metrics for evaluat-
ing our system is the overall accuracy for intent detection as we
strictly control the number of replies for each intent in the product.
Table 1 shows the model accuracy for the four dierent models
we experiment with. e naive frequency-based approach has an
accuracy of 15.5% which is simply the population of the top-1 intent
classes. e best performing model is Char-CNN model with an
accuracy of 77.2%, followed by the NNC with an accuracy of 75.9%.
Word-CNN performs slightly (75.6%) worse compared to NNC.
Figure 8 further shows the top-Kaccuracy of the four approaches.
e overall trend with increasingKagrees with the top-1 accuracy
except that NNC performs slightly beer than Char-CNN aer
K=5. Except the naive frequency-based approach, all three models
reach>90% accuracy atK=4. Given the small amount of labeled
data (thousands) we have for training, it is not surprising that NNC
performs comparable to the two deep learning architectures, as
typically deep learning approaches start to be advantageous when
the training data size is large enough.
Figure 7 shows the precision and recall of NNC, Word-CNN and
Char-CNN on the top-10 intents. Specically, for precision, NNC
model shows relatively even performance across all top-10 classes.
While deep learning models (Char-CNN) in particular show lower
5

(a)
(b)
Figure 9: Model prediction comparison: (a) Word-CNN vs
Char-CNN models, (b) NNC vs Char-CNN models. e per-
centage of test samples falling into dierent buckets are
plotted.
Figure 10: In this two-dimensional t-SNE projection of sen-
tence embedding, the model clusters messages around in-
tent.
precision for the top-5 intents compared to the remaining ones.
is highlights a key dierence between the NNC model and deep
learning architectures. Because NNC is non-parametric, it is less
biased towards popular classes.  e paern observed above for
precision is reversed when considering recall: deep learning models
are performing beer than NNC for top classes (top-3 in particular)
as shown in Figure 7(b) due to the same biased towards predicting
popular classes compared to NNC.
Model Complementary: Next, we look at how complementary
the predictions are between NNC and deep learning models using
Ludwig [9]. As shown in Figure 9(a), Word-CNN has a rather large
overlap with Char-CNN in predictions: they have 69.3% predictions
being correct at the same time, and 9.4% predictions being the
same but wrong at the same time. Together, they made the same
predictions on 78.7% test samples. In contrast, Figure 9(b) shows
that NNC and Char-CNN have less overlap in their predictions:
66.5% being right and 4.7% being the same but wrong at the same
time. Looking at the portion of predictions where one model being
right and the other being wrong, we nd that NNC and Char-CNN
have 19.7% such predictions compared to 14.4% from Word-CNN
and Char-CNN. It conrms that non-parametric model NNC is
indeed more complementary to Char-CNN than Word-CNN.
Analysis of NNC Model:
Finally, in order to beer understand
the underlying mechanism of such a good performance for a simple
nearest-neighbor classier, we look at the embedding represen-
tation of the messages and their corresponding labels. Figure 10
shows examples of three dierent intent classes in a t-SNE plot.
Surprisingly, the message embedding vectors are clustered for each
intent even aer projected down to 2dspace. is conrms the high
quality of the message embeddings and its capability to capture
semantic meanings of dierent intents even though most messages
are rather short and can contain various typos and abbreviations.
e separation between the three classes is also rather pronounced.
As a result, it is expected that a very simple non-parametric nearest-
neighbor classier can perform on par with sophisticated deep
learning architectures such as Char-CNN.
e above analysis demonstrates that the quality of document
embedding is critical to the good performance of NNC. Furthermore,
we perform a hyperparameter search to understand the correla-
tion between the hyperparameters of the Doc2vec model and the
intent detection performance usinggensim[11]. Empirically, we
nd that document vectors with distributed bag of words (DBOW)
work beer than those obtained with distributed memory (DM) for
intent detection. Figure 11 shows the hyperparameter search for
DBOW and its impact on the downstream classication accuracy.
It is clear that the accuracy is rather sensitive to the parameters
alphaandsamplebut varies very lile for all the other parameters.
Specically,alphais the initial learning rate of DBOW and we
found that a moderate learning rate around 0.02 is optimal.sam-
pledetermines the amount of down-sampling on high-frequency
words. Empirically, we observed that a smallsamplegives the best
performance, implying that lile or no down-sampling is necessary.
It is therefore reasonable to conclude that high-frequency words
are key to capture the semantic meaning of the short chat messages,
and thus crucial for our intent detection task.
6

Message contentFirst predictionSecond predictionLabel
is Uber is for my daughter. She’s going
to school and coming right back. anks
You are picking up<person>I’m going to<loc>I’m going to<loc>
Ok I’ll drive on the Main StreetWrong sideI am at<loc>I’m going to<loc>
I will come to 51 and 6Come to<loc>Can we meet at<loc>?I’m going to<loc>
Table 2: Examples of prediction errors by NNC model onI am going to ¡loc¿intent.
Figure 11: Hyper-parameter search for Doc2vec model with
distributed bag of words (DBOW). e intent detection accu-
racy is plotted against several parameters showing both the
average and standard deviation.
Model Deployment:Due to its simplicity to develop and de-
ploy, its requirement of small amount of labeled data, and its advan-
tage of speedy inference, we decided to deploy the NNC model in
production for our smart reply OCC system. rough experimenta-
tion, we observed that 23% of trips in English-speaking countries
on the Uber platform involved two-way in-app communications
between riders and driver-partners. Among these in-app commu-
nications, over 71% of them adopted the smart replies suggested
by OCC to speedup and smooth out the process. Such an adoption
rate is consistent with the system accuracy on intent detection.
4.2  Error Analysis of NNC Model
e NNC model has relatively high performance on most classes,
as discussed above. In this section, we conduct an error analysis
on intents where the NNC model doesn’t perform very well to
understand the weakness of the model.  One such intent isI am
going to ¡loc¿.  Table 2 shows the raw message and its top 2 pre-
dictions for this intent class in the test set. For the rst message,
it contains dual intents. e rst part of the message informs the
driver-partner thatit is for another person. e second half tells the
driver-partnerwhere she is going, which matches the model predic-
tion. Multi-intent issues are challenging and beyond the current
design of our system.  Regarding the second and third messages,
the algorithm misclassies the intents but was able to capture the
locationinformation correctly. is analysis points out directions
for further improvements of our system in the future.
5  CONCLUSIONS AND FUTURE WORK
In conclusion, we introduce a novel smart reply system designed to
speed up in-app communication between riders and driver-partners
on Uber’s platform. Our smart reply system is unique in handling
short chat messages with various non-canonical text data.  e
algorithm we adopt also has the advantage of requiring a rather
small amount of labeled data to achieve a relatively high perfor-
mance. In contrast to existing smart reply systems, we break the
task down into two steps of intent detection and reply retrieval
instead of directly predicting reply.  For the task of intent detec-
tion, we experimented with four models, and showed that a simple
approach of nearest-neighbor classier together with document
embedding proves to be powerful enough to achieve an accuracy
of≥75%, which is comparable with the two deep learning mod-
els. Further analysis reveals that the non-parametric NNC model
is more complementary to Char-CNN than Word-CNN, as Char-
CNN and Word-CNN belong to the same class of deep learning
architecture.  Finally, we analyze the document embeddings and
uncover that the key to the success of NNC model is its high quality
embeddings which provides clear separations between dierent
intent classes.  Due to the advantages of easy development and
deployment, and the fast inference, the NNC model is deployed
in production to serve the trac of Uber’s smart reply system.
rough experimentation, we observed that≥71% of all two-way
communications in English on Uber’s in-app messaging platform
adopted the smart replies recommended by our OCC system to
speed up the communication process.
In the future, there are several areas where we can further im-
prove the system. First, the current system only uses the message
itself as a feature for intent detection. Including additional features
around the trip can certainly provide beer intent modeling. Sec-
ond, the reply retrieval is done using static mapping from intent to
replies. Dynamic reply retrieval holds great promise for providing
more context-aware replies. is can be achieved by ranking the
replies dynamically using a ranking algorithm by taking into ac-
count the contextual information. Lastly, active learning feedback
loop can be another avenue to steadily correct the errors made by
the models and improve the system performance.
6  ACKNOWLEDGMENTS
e authors wish to thank Uber’s Conversational AI, Applied Ma-
chine Learning, Communications Platform, and Michelangelo teams,
Anwaya Aras, Chandrashekar Vijayarenu, Bhavya Agarwal, Lingyi
Zhu, Runze Wang, Kailiang Chen, Han Lee, Molly Vorwerck, Jerry
Yu, Monica Wang, Manisha Mundhe, Shui Hu, Zhao Zhang, Hugh
Williams, Lucy Dana, Summer Xia, Tito Goldstein, Ann Hussey,
Yizzy Wu, Arjun Vora, Srinivas Vadrevu, Huadong Wang, Karan
Singh, Arun Israel, Arthur Henry, Kate Zhang, and Jai Ranganathan.
7

REFERENCES
[1]David J. Brenes, Daniel Gayo-Avello, and Kilian P
 ́
erez-Gonz
 ́
alez. 2009. Survey and
evaluation of query intent detection methods. InProceedings of the 2009 workshop
on Web Search Click Data, WSCD@WSDM 2009, Barcelona, Spain, February 9,
2009. 1–7. hps://doi.org/10.1145/1507509.1507510
[2]Mahew Henderson,  Rami Al-Rfou,  Brian Strope,  Yun-Hsuan Sung,  L
 ́
aszl
 ́
o
Luk
 ́
acs, Ruiqi Guo, Sanjiv Kumar, Balint Miklos, and Ray Kurzweil. 2017. Ecient
Natural Language Response Suggestion for Smart Reply.CoRRabs/1705.00652
(2017). arXiv:1705.00652 hp://arxiv.org/abs/1705.00652
[3]Jeremy Hermann and Mike Del Balso. 2018. Meet Michelangelo: Uber’s Machine
Learning Platform. hp://eng.uber.com/michelangelo/. (2018).
[4]S. Hochreiter and J. Schmidhuber. 1997.   Long short-term memory.Neural
Computation9(8):1735-1780 (1997).
[5]Nimesh Chakravarthi Je Pasternack. 2017. Building Smart Replies for Member
Messages. Press Release. hps://engineering.linkedin.com/blog/2017/10/building-
smart-replies-for-member-messages. (2017).
[6]Anjuli Kannan, Karol Kurach, Sujith Ravi, Tobias Kaufmann, Andrew Tomkins,
Balint Miklos, Greg Corrado, L
 ́
aszl
 ́
o Luk
 ́
acs, Marina Ganea, Peter Young, and
Vivek Ramavajjala. 2016. Smart Reply: Automated Response Suggestion for Email.
CoRRabs/1606.04870 (2016). arXiv:1606.04870 hp://arxiv.org/abs/1606.04870
[7]Yoon Kim. 2014.  Convolutional Neural Networks for Sentence Classication.
InProceedings of the 2014 Conference on Empirical Methods in Natural Language
Processing, EMNLP 2014, October 25-29, 2014, Doha, Qatar, A meeting of SIGDAT,
a Special Interest Group of the ACL. ACL, 1746–1751.
[8]oc V. Le and Tomas Mikolov. 2014. Distributed Representations of Sentences
and Documents.CoRRabs/1405.4053 (2014). arXiv:1405.4053 hp://arxiv.org/
abs/1405.4053
[9]   Piero Molino. [n. d.]. Ludwig.  hps://github.com/uber/ludwig.
[10]Uber Newsroom. 2017. Connect Ahead of the Pickup with In-App Chat. Press
Release. hps://www.uber.com/newsroom/in-app-chat/. (2017).
[11]
Radim
ˇ
Reh
 ̊
u
ˇ
rek and Petr Sojka. 2010. Soware Framework for Topic Modelling
with Large Corpora. InProceedings of the LREC 2010 Workshop on New Challenges
for NLP Frameworks. ELRA, Vallea, Malta, 45–50.  hp://is.muni.cz/publication/
884893/en.
[12]Ilya Sutskever, Oriol Vinyals, and oc V. Le. 2014.   Sequence to Sequence
Learning with Neural Networks. InAdvances in Neural Information Processing
Systems 27: Annual Conference on Neural Information Processing Systems 2014,
December 8-13 2014, Montreal, ebec, Canada. 3104–3112.
[13]Suzie Lee et al. omas A. Dingusa, Feng Guo. 2016. Driver crash risk factors
and prevalence evaluation using naturalistic driving data.PNAS13, 10 (2016).
[14]Laurens van der Maaten and Georey E. Hinton. 2008. Visualizing Data using
t-SNE.
[15]Anbang Xu, Zhe Liu, Yufan Guo, Vibha Sinha, and Rama Akkiraju. 2017. A New
Chatbot for Customer Service on Social Media. InProceedings of the 2017 CHI
Conference on Human Factors in Computing Systems, Denver, CO, USA, May 06-11,
2017.3506–3510. hps://doi.org/10.1145/3025453.3025496
8 

MNRAS000, 1–16 (2019)Preprint 19 July 2019Compiled using MNRAS L
A
T
E
X style file v3.0
Comparing Multi-class, Binary and Hierarchical Machine
Learning Classification schemes for variable stars
Zafiirah Hosenie,
1?
Robert Lyon,
1
Benjamin Stappers,
1
Arrykrishna Mootoovaloo
2
1
Jodrell Bank Centre for Astrophysics, School of Physics and Astronomy, The University of Manchester, Manchester M13 9PL, UK.
2
Imperial Centre for Inference and Cosmology (ICIC), Imperial College, Blackett Laboratory, Prince Consort Road, London SW7 2AZ, UK.
Accepted 2019 July 15. Received 2019 July 15; in original form 2019 March 06
ABSTRACT
Upcoming synoptic surveys are set to generate an unprecedented amount of data. This
requires an automatic framework that can quickly and efficiently provide classification
labels for several new object classification challenges. Using data describing 11 types
of variable stars from the Catalina Real-Time Transient Surveys (CRTS), we illustrate
how to capture the most important information from computed features and describe
detailed methods of how to robustly use Information Theory for feature selection and
evaluation. We apply three Machine Learning (ML) algorithms and demonstrate how
to  optimize  these  classifiers  via  cross-validation  techniques.  For  the  CRTS  dataset,
we find that the Random Forest (RF) classifier performs best in terms of balanced-
accuracy and geometric means. We demonstrate substantially improved classification
results by converting the multi-class problem into a binary classification task, achieving
a balanced-accuracy rate of∼99 per cent for the classification ofδ-Scuti and Anomalous
Cepheids  (ACEP).  Additionally,  we  describe  how  classification  performance  can  be
improved via converting a ‘flat-multi-class’ problem into a hierarchical taxonomy. We
develop a new hierarchical structure and propose a new set of classification features,
enabling the accurate identification of subtypes of cepheids, RR Lyrae and eclipsing
binary stars in CRTS data.
Key words:stars: variables- general – methods: data analysis - Astronomical instru-
mentation, methods, and techniques.
1    INTRODUCTION
Astronomy has experienced an increase in the volume, qual-
ity  and  complexity  of  datasets  produced  during  numerical
simulations and surveys. One factor that contributes to the
data  avalanche  is  the  new  generation  of  synoptic  sky  sur-
veys, for example, the Catalina Real-Time Transient Surveys
(CRTS) (Drake et al. 2017). In addition, the Large Synoptic
Survey Telescope (LSST, Ivezic et al. (2008)) for example,
which is now on the horizon, will produce∼15 Terabytes
of raw data per night (Juric et al. 2015). However, despite
this data deluge, source variability is often still visually in-
spected to detect new promising candidates/variable stars.
Visual inspection does have utility for detection and classi-
fication. Human experts can extract new useful information
despite unevenly sampled data sets and also have the ability
to distinguish noisy data from data exhibiting interesting be-
haviour/characteristics. They can also incorporate complex
contextual information into their decision making. However,
?
E-mail: zafiirah.hosenie@gmail.com
the efficacy of the manual approach decreases as the volume
of data grows exponentially, as will be the case for the next
generation  of  surveys.  Visual  inspection  becomes  inconsis-
tent, consequently, mistakes are made, and rare/interesting
objects can be missed.
To address this problem, Machine Learning (ML) has
been applied to variable-star classification in multiple time-
series datasets (see Belokurov et al. 2003; Willemsen & Eyer
2007).  In  ML,  variable  stars  are  represented  by  features:
independent  measures  that  contain  information  useful  for
differentiating  variable  stars  into  their  respective  classes.
Therefore,  several  developments  have  been  made  towards
determining  the  best  methods  and  features  for  describ-
ing variable-stars, including the Lomb-Scargle periodogram
(Lomb 1976; Scargle 1982), Bayesian Evidence Estimation
(Gregory & Loredo 1992) as well as hybrid methods (Saha &
Vivas 2017). In addition, Eyer & Blake (2005) analysed the
small sharp features of light curves and included them as in-
put features to a Na
 ̈
ıve Bayes classifier (Zhang 2004). While
Djorgovski et al. (2016) developed an automatic framework
to  detect  and  classify  transient  events  and  variable  stars.
©2019 The Authors
arXiv:1907.08189v1  [astro-ph.IM]  18 Jul 2019

2Z. Hosenie et al.
18.0
20.0
Magnitude
RRab: J000031.7-412854
14.5
15.0
15.5
RRc: J000044.8-430758
16.0
17.0
RRd: J000956.0-242445
15.0
16.0
Magnitude
Blazhko: J001108.0-593330
13.0
14.0
15.0
Contact & Semi-Detached EB: J000025.8-393651
14.0
14.5
Detached EB: J000111.5-223745
16.0
16.5
Magnitude
Rotational: J000733.1-294903
12.0
13.0
14.0
LPV: J001234.2-225517
0.00.51.01.52.0
Phase
15.5
16.0
16.5
δ-Scuti: J012028.9-292610
0.00.51.01.52.0
Phase
13.0
13.5
14.0
Magnitude
ACEP: J003041.3-441620
0.00.51.01.52.0
Phase
13.0
13.5
14.0
Cep-II: J004302.8-533428
Figure 1.Examples of folded light curves from the CRTS for the various types of variable stars considered in our analyses.
They used a subset of the CRTS data to perform classifica-
tion between two types of variable stars (W Uma and RR
Lyrae) and obtained completeness rates of∼96-97 per cent.
Kim & Bailer-Jones (2016) developed theUPSILONpack-
age to classify periodic variable stars using 16 extracted fea-
tures from light curves, which achieves good results. Maha-
bal et al. (2017) developed a classifier based on the Convolu-
tional Neural Network (CNN) model using labelled datasets
of periodic variables from the CRTS (Drake et al. 2009; Djor-
govski  et  al.  2011;  Mahabal  et  al.  2012;  Djorgovski  et  al.
2016).  They  transformed  a  light  curve  (time  series)  into
a two-dimensional mapping representation (dm−dt) which
is based on the changes in magnitude (dm) over the time-
difference  (dt).  Using  multi-class  classification,  their  algo-
rithm achieved an accuracy of∼83 per cent. Narayan et al.
(2018) developed an ML approach to classify variable ver-
sus transient stars. Similarly, they performed a multi-class
classification of combined variable stars & transients, and a
“purity-driven” sub-categorisation of the transient class us-
ing multi-band optical photometry. Revsbech et al. (2018)
used a data augmentation technique to mitigate the effects
of bias in their data by generating additional training data
using Gaussian Processes (GPs). They used a diffusion map
method that calculates a pair-wise distance matrix that out-
puts diffusion map coefficients of the light curves. These co-
efficients  act  as  feature  inputs  to  a  Random  Forest  (RF)
classifier used to help identifying Type Ia supernova.
We found that it is fundamentally important to develop
accurate  and  robust  automated  classification  methods  for
this  problem  using  machine  learning  and  other  statistical
approaches.  This  paper  describes  a  new  automatic  classi-
fication  pipeline  for  the  classification  of  variable  stars  via
application to archival data. To our knowledge, this is the
first time the southern CRTS (Drake et al. 2017) data set
has been used to build/evaluate an automatic classification
system.
Similar work has been completed in recent years (Kim &
Bailer-Jones 2016; Mahabal et al. 2017; Narayan et al. 2018),
though the features used for learning are rarely evaluated in
a statistically rigorous way. We found that using a large set
of features does not imply higher classification metrics. We
therefore  perform  an  in-depth  analysis  of  ML  features  to
understand their information content, and determine which
give  rise  to  the  best  classification  performance.  We  utilize
various visualization techniques and the tools of Information
Theory to achieve this.
Based  on  our  analyses  we  find  that  accurate  variable
star classification is possible with just seven features - much
fewer  than  in  other  works.  In  addition,  we  show  that  this
classification problem cannot be solved with a ‘flat’ multi-
class classification approach, as the data is inherently imbal-
anced. To partially alleviate the ‘imbalanced learning prob-
lem’ (Last et al. 2017), we developed an approach inspired by
earlier work in this area (Richards et al. 2011). This involved
converting  a  standard  multi-class  problem  in  to  a  hierar-
chical  classification  problem,  by  aggregating  sub-classes  in
MNRAS000, 1–16 (2019)

Machine Learning Classification for variable stars3
to super-classes. This results improved performance on rare
class  examples  typically  misclassified  by  multi-class  meth-
ods.  We  adopt  a  similar  methodology  to  Richards  et  al.
(2011), however we i) propose a different hierarchical classifi-
cation structure, ii) use a different feature analysis/selection
methodology resulting in different feature choices, iii) apply
hyper-parameter optimisation to build optimal classification
models, and finally iv) apply the resulting approach to CRTS
data.
The outline of this paper is as follows. In§2, we provide
a brief description of the dataset used and in§3 we present
the feature generation techniques we employ here; while in
§4 we explain how we build the classification pipeline. In§5
we apply state-of-the-art feature visualisation techniques to
visualise how separable our features are before performing a
multi-class classification. In§6, we provide an in-depth fea-
ture evaluation to determine the usefulness of our extracted
features before performing a binary classification. In§7, we
present a hierarchical taxonomy for classification and discuss
our results; finally, we summarise our results and conclusions
in§8.
2    DATA
We  use  the  publicly  available  CRTS  (Drake  et  al.  2017)
dataset that covers the sky with declinations between−20
◦
and−75
◦
.  The  sources  in  the  dataset  have  median  mag-
nitudes  in  the  range  11<V<19.5.  The  dataset  con-
tains  different  forms  of  periodic  variable  stars,  these  are
stars that undergo regular changes in brightness every few
hours or within a few days or weeks. The periodic variable
stars  in  the  dataset  can  generally  be  classified  into  three
broad  classes:  namely  eclipsing,  pulsating,  and  rotational.
The classes can be further divided into sub-types, for exam-
ple pulsating stars consist ofδScutis, RR Lyrae, Cepheids,
and the Long Period Variables (LPVs) group which includes
both semi-regular variables and Mira variable stars. The RR
Lyrae class consists of RRab’s (fundamental mode), RRc’s
(first  overtone  mode),  and  RRd’s  (multimode).  However,
many  RR  Lyrae  stars  are  known  to  exhibit  the  Blazhko
effect (long-term modulation) (Blazhko 1907). In addition,
the Cepheids include type-II Cepheids (Cep-II), Anomalous
Cepheids  (ACEPs),  and  Classical  Cepheids.  The  eclipsing
binary  variables  in  the  data  are  divided  into  detached  bi-
naries (EA) and contact plus semi-detached binaries (Ecl).
The rotational class consists of variable stars including the
ellipsoidal variables (ELL) and spotted RS Canum Venati-
corum (RS CVn) systems. A more detailed overview of the
data set is given in Drake et al. (2017) and Catelan & Smith
(2015)  gives  a  more  detailed  overview  of  the  properties  of
the various types of pulsating stars.
The  dataset  contains  about  37,745  periodic  variable
stars (Catalina Surveys Data Release 2,
1
CSDR2). For our
analysis, we use a sample of 37,437 out of the 37,745 stars
from the CSDR2. We have excluded Type 11: Miscellaneous
variable  stars  (periodic  stars  that  were  difficult  to  classify
as  presented  in  Drake  et  al.  (2017))  and  Type  13:  LMC-
Cep-I  which  as  a  group  consists  of  only  10  examples.  We
1
Catalina Surveys Data Release 2
1. RRab
2. RRc
3. RRd
4. Blazhko
5. Ecl
6. EA
7. Rotational
8. LPV
9.
δ
Scuti
10. ACEP
12. Cep-II
0
1000
2000
3000
4000
Number of Samples
4325
3752
502
171
45094509
3636
1286
147
153153
Figure 2.Class distributions for the CSDR2 datasets. We down-
sample Type 5: semi-detached binary stars to 4,509 samples to
prevent larger classes from dominating the training sets. The ex-
cluded samples∼14,294 for Type 5: Ecl are then included in the
test set for prediction. These distributions highlight the remaining
imbalance in the datasets.
remove the smallest classes as there are too few samples to
characterise  those  classes,  as  we  also  know  that  classifiers
given such data will struggle to categorise them accurately
due to the imbalanced learning problem (Last et al. 2017).
Furthermore, we downsample Type 5: semi-detached binary
stars to 4,509 samples as this class of object originally con-
sisted of 18,803 samples. We perform this downsampling to
prevent  the  large  class  from  dominating  the  training  sets,
which could otherwise potentially bias a classifier. The ex-
cluded samples of Type 5 are then included in the test set.
Fig. 1 shows examples of folded light curves for each class
under consideration. We also present the number of samples
considered for the 11 different types of variable stars in Fig.
2. Note that∼14,294 samples of Type 5: Ecl, unused during
training, were eventually used in the test set.
3    FEATURE GENERATION
In  general,  machine  learning  algorithms  use  training  data
to build a mathematical model, where the training data is
comprised of feature data. These features may have varying
utility, that is, information rich features are desirable as they
can  be  used  to  build  more  accurate  classification  systems.
In this work, we generate statistical features from the light
curves  to  characterize  and  distinguish  different  variability
classes. LetS=
{
X
1
, . . .,X
n
}
, represent the set of variable
star data available to us, thenX
i
is an individual star repre-
sented by variables known asf eatur es. An arbitrary feature
of starX
i
is denoted byX
j
i
, wherej=1, . . .,l.Each variable
star has an associated labelysuch thaty∈Y=
{
y
1,
. . .,y
k
}
.
For  multi-class  scenarios  the  possible  labels  assignable  to
variable stars vary as1≤y≤12but since we do not con-
sider Type 11 examples for reasons given at the end of§2, we
note thaty,11. Meanwhile for binary class classification
scenarios, we consider binary labelsy∈Y=
[
0,1
]
.
The  goal  is  to  build  a  machine  learning  algorithm
that learns to classify variable stars described by features,
from  a  labelled  input  vector,  also  known  as  the  training
set,X
T r ain
.  The  training  set  consists  of  pairs  such  that
MNRAS000, 1–16 (2019)

4Z. Hosenie et al.
Table 1.The seven features used as inputs to our classification scheme. Six features based on simple statistics,
are extracted directly from light curves using FATS. Note that the period feature is obtained from the Drake et al.
(2017) catalog.
Features
Description
Symbol
Mean
μ=
1
N
Õ
N
i=1
m
i
wheremis the magnitude andNis the number of data points.
μ
Standard Deviation
σ=
√
1
N−1
Õ
N
i=1
(
m
i
−μ
)
2
σ
Skewness
γ=
N
(
N−1
)(
N−2
)
Õ
N
i=1
(
m
i
−μ
σ
)
3
γ
Kurtosis
kurt=
N
(
N+1
)
(
N−1
)(
N−2
)(
N−3
)
Õ
N
i=1
(
m
i
−μ
σ
)
4
−
3
(
N−1
)
2
(
N−2
)(
N−3
)
kurt
Mean-variance
This is a simple variability index and is defined as the ratio of the standard
deviation,σ, to the mean magnitude,μ.
σ
μ
Period
Drake  et  al.  (2017)  used  the  Lomb-Scargle  (L-S)  periodogram  analysis  to-
gether with an Adaptive Fourier Decomposition (AFD) method to calculate
the  period  of  unevenly  sampled  data.  More  information  about  this  feature
can be found in Drake et al. (2017).
T
Amplitude
The amplitude is half of the difference between the median of the maximum
5% and the median of the minimum 5% magnitudes.
Amp
X
T r ain
=
{(
X
1
,y
1
)
, . . .,
(
X
n
,y
n
)}
. The learnt mapping func-
tion between input feature vectors and labels inX
T r ain
, can
then be utilised to label new unseen stars, inX
T est
.
In  this  work,  we  focus  mainly  on  using  the  statistical
properties of the data with no preconceived notions of their
suitability or expressiveness as input features to our ML al-
gorithms.  As  a  result  we  focus  on  7  features,  of  which  6
are intrinsic statistical properties relating to location (mean
magnitude),  scale  (standard  deviation),  variability  (mean
variance), morphology (skew, kurtosis, amplitude), and time
(period). These features are highly interpretable, and robust
against  bias.  Note  that  we  remove  data  points  from  light
curves  that  are  3σabove  or  below  the  mean  magnitude,
whereσis  the  standard  deviation  and  it  is  an  important
step to remove any outliers in the data. This cleaning does
not alter the light curves significantly as it removes less than
1 per cent of their data points.
Afterwards,  we  used  the  FATS
2
(Nun  et  al.  2015)
Python  Library  to  extract  these  features.  FATS  takes  as
input the unfolded light curves and it outputs various sta-
tistical features: the mean, standard deviation, skew, kurto-
sis, mean-variance, and amplitude. We also incorporate the
period for each star given in the catalog as a feature to our
ML algorithms. The description of the input features used
for classification is listed in Table 1. Practitioners should be
cautious when applying the mean magnitude as a feature in
combination with data obtained at another telescope. It has
the potential to bias a training set against fainter/brighter
sources. We note that adding the telescope label as a feature
may overcome this issue, but we leave that to future work.
One  important  aspect  of  the  training  process  used  to
build a classification model is data pre-processing. Some ML
algorithms,  e.g  functions/classifiers  that  calculate  the  dis-
tance between data points, will not work properly without
normalisation  or  standardisation  since  the  range  of  values
2
FATS: Feature Analysis for Time Series
of the features/raw data varies widely. We therefore employ
a normalisation method,
ˆ
S, to standardize the feature data
such that all values in the feature space are scaled between
0 and 1.
4    CLASSIFICATION PIPELINE
In this section, we describe the process used to perform the
classification of variable stars, for instance, training, hyper-
parameter optimisation and prediction. We first extract fea-
tures and then split the feature data into the training (70
per cent) and the test (30 per cent) data. The training data
is used to train the model while the test data is used to eval-
uate the performance of the trained model. Once the data is
split into two, we perform a simple normalization where each
featureX
j
i
is divided by its maximum,max(X
j
i
)(see Eq. 1).
The goal of normalisation is to ensure that all features use
a common scale. This is beneficial for ML algorithms that
are sensitive to feature distributions, for instance, distance-
based  algorithms  that  require  Euclidean  distance  compu-
tation (for e.g.k−Nearest Neighbours (kNN)). Some mod-
els (e.g. Decision Tree (DT), Random Forest (RF)) are less
sensitive to feature scaling. However, it is good practice to
standardize when comparing between classification systems
to rule out potential sources of disparity in our results. Note
that  in  this  context,  we  found  that  this  simple  normalisa-
tion was enough to yield good performance. ForX
T est
, the
features are then rescaled usingmax(X
j
T r ain
i
),
X
T r ain
=




X
T r ain
i
max
(
X
T r ain
i
)




;X
T est
=




X
T est
i
max
(
X
T r ain
i
)




.(1)
Afterwards, we apply some feature evaluation strategies
to check whether the features show some separability. Then,
for our classification purposes, we apply three different clas-
sification algorithms: DT, RF andkNN, accomplished with
Scikit-Learn (Pedregosa et al. 2011).kNN (Buturovic 1993)
MNRAS000, 1–16 (2019)

Machine Learning Classification for variable stars5
Input	Data
Preprocessing/	
Feature	Selection
Optimization
Evaluation
Variable	Stars	
Light	Curves
(11	Types)
Feature	Extraction
FATS
Split	Data
Training	and	Test	
set
Feature	
Normalisation
Visualization
-Density	Plots
-Box	and	whisker
-t-SNE
Feature	Evaluation
-Correlation	Test
-JMI	&	MI	using	
Information	theory
Hyper-parameter	
optimization
-Randomized	gridsearch
with	cross-validation
Final	Classification
-best	hyper-parameters				
used	in	ML	algorithms
Evaluation	Metrics
-Use	trained	model	and	
evaluate	on	test	data
:
:
:
:
Prediction	Phase
Training	Phase
Figure 3.The different stages of our classification framework. First, we use light curves of variable stars as input data. For the first
stage  process,  features  are  extracted  using  FATS  and  then  are  later  split  into  training  and  test  sets.  The  second  stage  involves  data
preprocessing  and  feature  selection.  In  this  process,  the  extracted  features  are  normalised,  visualised  and  selected  based  on  various
techniques.  Afterwards,  the  third  stage  covers  hyper-parameter  optimisation  using  the  randomized  grid  search  with  cross-validation
methods. Finally, the last stage uses the best hyper-parameter to re-train the ML algorithms using the entire normalised training set in
stage 2 and evaluate it on the normalised test set in stage 2 using various metrics to quantify the models.
is  a  simple  instance-based  technique  that  assigns  an  unla-
beled  example,  the  label  of  itsknearest  neighbours.  This
method  is  based  on  the  Euclidean  distance  measure.kNN
performs effectively when the training data set is sufficiently
large. However, one disadvantage ofkNN is that all the fea-
tures are needed when computing the distance between data
points. If a small portion of the data set consists of discrimi-
natory information and the larger portion contains irrelevant
features, the distance between the instances will be more in-
fluenced by the irrelevant samples and their feature values.
In  contrast,  Decision  trees  (DTs)  (Quinlan  1986)  at-
tempt  to  split  input  data  recursively  according  to  feature
values.  Each  split  creates  a  branch,  and  there  can  be  ar-
bitrarily many branches in a tree. Each branch eventually
terminates at a leaf node which is associated with a specific
label. The goal of tree learning is to build a tree structure
that has decision paths (from tree root to leaf nodes) that
accurately separate examples moving down the tree so that
they arrive at the correct leaf node (i.e. obtain the correct la-
bel). Generally, using a single decision tree for classification
often leads to poor performance due to low or high variance.
For instance, a small change in the training set can lead to
a very different learned tree structure. Given the weakness
of  individual  trees  to  training  variance,  multiple  trees  can
be  combined  to  overcome  this  problem.  Any  method  that
combines  multiple  single-model  classifiers  in  this  manner,
is known as an ensemble method (Dietterich 2000). For in-
stance,  a  Random  Forest  (RF)  (Breiman  2001)  is  simply
an addition of decision trees that aggregate tree decisions,
usually leading to improved classification performance. Such
ensemble methods have been shown (Richards et al. 2011;
Lochner et al. 2016; Narayan et al. 2018) to achieve better
results than single-model learners on a variety of datasets.
A  major  problem  faced  when  using  various  classifiers
is  hyper-parameter  optimization.  This  is  crucial  for  find-
ing the hyper-parameters which yield the best overall clas-
sification  performance  for  a  specific  problem.  The  most
widely used techniques areHyperopt(Bergstra et al. 2013),
a  bayesian  optimisation  approach,  grid  search  and  man-
ual  search.  In  our  study,  we  adopt  a  randomized  search
that iterates a number of times through pre-specified hyper-
parameters and finds the optimum parameter that outputs
the  best  balanced-accuracy  for  a  classifier.  Together  with
the  randomized  grid  search  for  hyper-parameter  optimiza-
tion, we apply 5-fold stratified cross-validation (see§4.1) on
the training set to evaluate model performance, that is, the
70  per  cent  training  set  is  further  split  into  training  and
validation sets. We cross-validate to ensure any observed re-
sults are real and not just due to some dataset specific effect.
We note that CRTS data exhibits distributional disparities -
some types of star are common in the data, while others are
relatively rare. Traditional machine learning classifiers per-
form poorly on such data (He & Garcia 2008). They become
biased towards correctly classifying the common classes, a
strategy that typically yields the greatest overall accuracy.
In  some  cases,  this  bias  can  be  overcome  by  re-weighting
training examples so that rare examples are weighted higher
than common ones. However where/when imbalance is man-
ifested via complex data characteristics (class overlap, small
disjuncts, sub-class inseparability, see (He & Garcia 2008)),
re-weighting  alone  is  insufficient.  Based  on  our  analysis  of
our data presented in§5.1 &§5.2, we see enough imbalanced
characteristics to suggest that our problems cannot be solved
by weighting alone, nonetheless we apply re-weighting with
the aim of mitigating such problems.
We  then  proceed  with  cross-validation,  use  the  best
model hyper-parameters found during this process and re-
train the model with the entire 70 per cent training set. The
MNRAS000, 1–16 (2019)

6Z. Hosenie et al.
0.00.20.40.60.81.0
Skew
RRab
RRc
RRd
Blazhko
Ecl
EA
Rot
LPV
δ-Scuti
ACEP
Cep-II
0.00.20.40.60.81.0
Mean
RRab
RRc
RRd
Blazhko
Ecl
EA
Rot
LPV
δ-Scuti
ACEP
Cep-II
0.00.20.40.60.81.0
Sigma
RRab
RRc
RRd
Blazhko
Ecl
EA
Rot
LPV
δ-Scuti
ACEP
Cep-II
0.00.20.40.60.81.0
Kurtosis
RRab
RRc
RRd
Blazhko
Ecl
EA
Rot
LPV
δ-Scuti
ACEP
Cep-II
0.00.20.40.60.81.0
Period
RRab
RRc
RRd
Blazhko
Ecl
EA
Rot
LPV
δ-Scuti
ACEP
Cep-II
0.00.20.40.60.81.0
Amplitude
RRab
RRc
RRd
Blazhko
Ecl
EA
Rot
LPV
δ-Scuti
ACEP
Cep-II
0.00.20.40.60.81.0
Mean Variance
RRab
RRc
RRd
Blazhko
Ecl
EA
Rot
LPV
δ-Scuti
ACEP
Cep-II
Figure  4.One-dimensional  density  estimates  of  the  selected  features  by  class.  The  features  considered  are  (a)  Skew,  (b)  Mean,  (c)
Sigma, (d) Kurtosis, (e) Period, (f) Amplitude, (g) Mean Variance.
trained model is then evaluated on the test set (30 per cent),
X
T est
using  various  evaluation  metrics  described  in§A.
The performance of our pipeline is evaluated on balanced-
accuracy,  the  Geometric-mean  score,  F1-score,  recall  and
standard  confusion  matrices.  The  classification  pipeline  is
summarised in Fig. 3.
4.1K-Fold cross validation
When  using  machine  learning  algorithms,  another  major
problem  is  an  overoptimistic  result,  i.e  the  output  results
are too good to be true on training data, due to over/under
fitting. Over-fitting mostly happens when we perform train-
ing and evaluation on the same data. Therefore, classifica-
tion algorithms must be tested on independent data to avoid
this problem. One method for avoiding this involves splitting
MNRAS000, 1–16 (2019)

Machine Learning Classification for variable stars7
−75−50−250255075
t−SNE Feature1
−75
−50
−25
0
25
50
75
t
−
SNE Feature
2
RRab
EA
Rotational
LPV
(a) t-SNE with large sample data
−20−100102030
t−SNE Feature1
−40
−30
−20
−10
0
10
20
30
40
t
−
SNE Feature
2
Blazhko
δ-Scuti
ACEP
Cep-II
(b) t-SNE with small sample data
Figure 5.(a) shows the t-distributed stochastic neighbour embedding (t-SNE) visualization for the feature set after normalisation with
large  sample  data  (RRab,  EA,  Rotational  and  LPV).  We  note  that  the  classes  are  quite  well-separated  in  the  embedding  space.  (b)
illustrates  t-SNE  visualization  for  the  feature  set  after  normalisation  with  the  small  sample  size  data  (Blazhko,δ-Scuti,  ACEP  and
Cep-II). No distinct separation is seen within the small sample dataset.
the  data  into  training  and  testing  sets  as  explained  in§3.
Another common method for splitting datasets for evalua-
tion is known asK-fold cross-validation, that is, the train-
ing  datasetSis  split  randomly  intoKmutually  exclusive
subsets
(
S
1
,S
2
, . . .,S
K
)
of  nearly  the  same  size.  The  classi-
fication  algorithm  is  trained  and  testedKtimes.  For  each
time stept∈
{
1,2, . . .,K
}
, the algorithm is trained onK−1
folds  and  one  foldS
t
is  used  for  validation.  In  addition,  a
stratification  of  the  data  is  applied  such  that  for  each  of
theK−f ol ds,  the  data  are  arranged  to  ensure  each  fold
preserves  the  percentage  of  samples  for  each  class  in  the
dataset at large. The overall balanced-accuracy of an algo-
rithm trained/tested via cross-validation is simply the aver-
age of each of theKbalanced-accuracy measures obtained
after each time step.
5    MULTI-CLASS CLASSIFICATION
Our main goal is to perform a multi-class classification using
our classification pipeline previously described. We first ap-
ply some feature evaluation strategies to check whether our
extracted features in§3 are good for classification. The most
common methods that characterise ‘good’ features: look for
the presence of linear correlations between the features and
the class labels, and/or we sometimes indirectly measure fea-
ture utility by using classification performance (for e.g Bates
et al. (2011)) as a proxy. If performance is good, we assume
the features have utility. However, it is often misleading to
evaluate features based on classifier performance as it varies
according to the classifier used (Brown et al. 2012).
In  this  work,  we  employ  the  three  primary  considera-
tions  as  in  Lyon  et  al.  (2016)  to  evaluate  our  features.  A
feature must i) show importance in discriminating between
the different classes/types of variable stars, ii) maximise the
separation between the various variable stars, and iii) lastly
yield a good performance when used in conjunction with a
classification algorithm. We have therefore applied two fea-
ture visualisation strategies to our features given in Table 1
before performing a multi-class classification.
5.1    Visualisation of feature space with
one-dimensional density estimates
One way to visualise the features we extracted in§3, is to
plot one-dimensional density estimates of the observed dis-
tribution as shown in Fig. 4. This plot allows us to visually
compare the distributions of the normalised features for the
different classes of variable stars. The plots depict distinct
feature-by-feature characteristics of each class. It enables us
to identify outliers and determine if there is multi-modality
in the feature space. For example, the RR Lyrae skew distri-
butions are mostly narrow and peaked, showing that these
classes are well-characterised by the skewness. In addition,
the density plots provide us with information of which fea-
tures are fundamentally important in discriminating differ-
ent sets of classes. Some classes have overlapping distribu-
tions for one or more feature variables. This applies to the
RR  Lyrae,  eclipsing  binary  and  the  Cepheid  stars.  Whilst
other classes, such as the LPVs have trivially separable dis-
tributions, suggesting that the LPV class should be easy to
classify. However, more rigorous investigation is needed to
determine with confidence whether these features are useful
for classification purposes.
5.2    t-SNE
After visualising the individual features separately, we wish
to understand the relationship between our features but this
is difficult to do given the feature dimensionality we are deal-
ing with. Yet it is possible to overcome this problem by re-
ducing the dimensionality so that it is representable in a 2-
or 3-D representation space. t-Distributed Stochastic Neigh-
MNRAS000, 1–16 (2019)

8Z. Hosenie et al.
RRab
RRc
RRd
Blazhko
Ecl
EA
Rot
LPV
δ
-Scuti
ACEP
Cep-II
Predicted label
RRab
RRc
RRd
Blazhko
Ecl
EA
Rot
LPV
δ-Scuti
ACEP
Cep-II
True label
0.920.000.000.020.010.010.020.000.000.010.00
0.000.770.060.000.120.000.040.000.000.000.00
0.050.470.330.010.110.000.030.000.000.010.00
0.750.000.000.210.020.000.020.000.000.000.00
0.040.100.030.000.600.060.150.000.000.010.00
0.030.000.000.000.030.900.020.000.000.010.00
0.040.080.020.000.130.020.650.020.000.010.02
0.000.000.000.000.000.000.020.980.000.000.01
0.000.000.000.000.040.000.000.000.960.000.00
0.130.000.000.000.000.040.000.000.000.740.09
0.000.000.000.000.040.070.200.020.000.150.52
Confusion matrix for Random Forest Classifier
0.0
0.2
0.4
0.6
0.8
Figure  6.Normalised  confusion  matrix  for  multi-class  classification  with  the  RF  classifier  using  the  best  hyper-parameters  from  a
randomized  grid  search  cross-validation.  The  RF  classifier  was  applied  on  a  70%  training  set  and  evaluated  on  a  30%  test  set.  The
classifier performs poorly on under-represented class labels.
bor Embedding (t-SNE, van der Maaten & Hinton (2008))
is a tool for performing this reduction and visualisation
3
.
More  specifically,  similar  objects  in  high-dimensional
space are clustered together with nearby points using a k-D
tree (Bentley 1975) of all the points. Using a Student-t dis-
tribution (same as the Cauchy distribution (Cauchy 1853)),
the Euclidean distance between each point and itsk-nearest
neighbours is computed. This distance is further converted
into  a  probability  distribution.  Similar  points  have  a  high
probability of being assigned to the same class and differ-
ent  points  have  a  low  probability  of  being  picked.  After-
wards,  t-SNE  constructs  a  similar  probability  distribution
using  a  gradient  descent  method,  in  the  low-dimensional
space over the points, thus minimizing the Kullback-Leibler
divergence between the two probability distributions (Kull-
back & Leibler 1951).
Generally,  classes  that  are  well  separated  in  a  t-SNE
visualization, yield good levels of classification performance
by machine learning systems. However, the converse is not
strictly true (Lochner et al. 2016). We use t-SNE only for
the  visualization  of  class  separability  as  there  are  various
limitations with t-SNE, as neither the sizes of the clusters
nor distance between the points may be informative (Wat-
tenberg et al. 2016). For our high dimensional visualisation,
we partition the data into two categories: i) data with large
3
sklearn.manifold.TSNE
sample  sizes  that  consists  of  RRab,  RRc,  Ecl,  EA,  Rota-
tional and LPV stars and ii) data with a small sample size
containing  RRd,  Blazhko,δ-scuti,  ACEP  and  Cep-II.  Fig.
5(a) shows quite well-separated classes for the large sample
sizes  and  we  would  expect  our  ML  algorithms  to  perform
well  using  this  data.  Fig.  5(b)  strongly  suggests  insepara-
bility of the classes for the small sample data. This insep-
arability  may  be  attributed  to  the  fact  that  there  are  few
examples  of  each  class.  Also,  another  possible  explanation
is that, for these stars, other features might be required to
enable  separability.  After  performing  some  feature  visuali-
sation,  we  decided  to  use  all  of  the  features  as  inputs  to
perform a multi-class classification.
5.3    Performance of Multi-class classification
We implement three classifiers, RFs, DTs andkNN to per-
form an 11-classes classification. Of these, RF achieves the
best performance with a balanced-accuracy rate of∼70 per
cent  on  the  30  per  cent  test  data.  This  poor  performance
is not surprising, given the large class imbalance present in
the  data,  i.e.  the  classes  with  small  sample  sizes  make  up
just∼6 per cent of the whole dataset. The results presented
here are mainly focused on the RF classifier as this achieves
the best performance balanced-accuracy. In Fig. 6, we plot
the confusion matrix of the RF classifier which depicts the
predicted class versus the true class in a tabular form. The
MNRAS000, 1–16 (2019)

Machine Learning Classification for variable stars9
γ
μ
σ
Kurt
T
Am p
σ
μ
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Type 1: RRab
Type 6: EA
Figure 7.The box and whisker plots show how the features separate RRab (Type 1) and EA (Type 6) examples. The orange colored
boxes describe the feature distribution for RRab sources, where the corresponding black circles represent extreme outliers. The box plots
in green describe the EA distributions. There is no clear separation of the period (T) between the two classes. The other features show
varying degrees of improved separability, and are generally easily separable at a visual level between the two different types. Refer to
Table 1 for definitions of the features used.
results obtained by a perfect classifier would result in val-
ues  only  along  the  diagonal  of  the  confusion  matrix.  The
off-diagonals give us information about the various types of
errors that the classifier makes.
We note that some of the mistakes made by the classifier
can be attributed to the fact that some of the science classes
are physically similar, for example, the RR Lyrae, eclipsing
binaries  and  Cepheids  subclasses.  We  also  note  that  most
of  the  misclassified  examples  arise  from  classes  for  which
there  are  few  training  examples,  hence  indicating  bias  to-
ward  larger  classes,  which  illustrates  that  class  imbalance
is an issue. Classes comprising of many examples are more
likely to be correctly classified, implying that having more
examples of the under-represented science classes will help
the classification.
6    BINARY CLASSIFICATION
Given  the  complication  of  the  multi-class  classification
scheme,  decomposing  the  multi-class  problem  into  smaller
binary class problems may alleviate this issue. This may re-
duce the higher complexity inherent to an 11-class problem.
Therefore,  in this  section  we  consider  binary  cases  for  the
classification scheme.
In  addition,  the  poor  performance  of  the  multi-class
classification in the previous section can be attributed not
only to class imbalance but also to the relative importance of
features. Therefore, to further investigate whether the fea-
tures  we  used  are  important  for  classification,  we  perform
an in-depth analysis of the features used for binary classifi-
cation in§6.1, 6.2 & 6.3 by using roughly balanced classes.
Feature selection strategies can be grouped in various cate-
gories: classifier-independent (filter methods) and classifier-
dependent (wrapper and embedded methods) are the most
common. Whilst it is possible to evaluate feature importance
using some classification models (e.g. using a random forest),
we instead decouple feature analysis from any specific clas-
sifier model. We do this as wrapper methods are susceptible
to  overfitting,  which  can  lead  to  feature  choices  that  may
not generalise well beyond the classifier used during selec-
tion (Brown et al. 2012). Thus in this paper, we used mostly
filter  methods.  These  methods  rank  the  features  based  on
statistical measures of information content, determined by
calculating the correlations/relationships between them.
Recall that in§5.2, we sub-divided the data set into two
subsets, namely small and large samples, for which each has
roughly  equal  number  of  examples.  We  therefore  consider
pair-wise combinations of each class within the small-sample
dataset and perform feature selection and binary classifica-
tion. This is repeated for the large-sample dataset. Here, we
report on results for Type 1 (RRab) & Type 6 (EA) only for
in-depth feature analyses. However, similar performance is
obtained for the other pair-wise combinations. For the per-
formance of binary classification, we report the results ob-
tained with Type 1 (RRab) & Type 6 (EA) from the large
sample  dataset  and  Type  9  (δ-Scuti)  &  Type  10  (ACEP)
from the small-sample dataset.
6.1    Data visualisation for binary classes
The discriminating capabilities of the features are examined
for some binary cases. To determine if there is some amount
of separability between the two classes, we plot the box and
whisker plots for the different features extracted. The data
has been pre-processed by performing the normalization de-
scribed  in§3.  Here,  we  take  Type  1  (RRab)  as  the  nega-
tive class and Type 6 (EA) as the positive class. For each
individual feature, the median value of the negative class is
subtracted. This ensures a fair separability scale and centres
the plots around the median, hence a distinct separation is
seen  more  clearly  between  the  two  classes.  The  box  plots
centred on the median value represent the feature distribu-
MNRAS000, 1–16 (2019)

10Z. Hosenie et al.
Table 2.The point-biserial correlation coefficient and the Mutual
InformationM I(X;Y)for each feature for the binary class pair:
RRab  (Type  1)  and  EA  (Type  6)  is  illustrated.  Higher  mutual
information  is  desirable.  A  high  MI  value  implies  that  there  is
a  strong  correlation  between  the  features  and  the  class  labels.
In  addition,  the  Joint  Mutual  Information  (JMI)  rank  is  given
for each feature. A lower JMI rank is preferred. The JMI ranking
illustrates the importance of each feature after taking into account
the redundancy between features.
Features
Classes
Type (1 & 6)
r
p b
MIJMI
Skew
0.6480.5032
Mean
- 0.5470.2606
Std
- 0.4810.4024
Kurtosis
0.2480.4863
Period,T
0.0190.3361
Amplitude
- 0.3750.3075
MeanVari-
ance
- 0.3680.1747
tion of the negative class. Fig. 7 shows a reasonable amount
of separability between Type 1: RRab and Type 6: EA. For
each individual feature, we note a clear separability between
the two classes, except for the Period,T. At this point, we
are  tempted  to  write-off  this  feature,  however,  for  a  more
rigorous analysis of feature selection, we extend our inves-
tigation  by  looking  for  any  linear  correlation  between  the
features and the class label.
6.2    Point Biserial Correlation Test
The point biserial correlation coefficient,r
pb
(Gupta 1960)
is applied to find the relationship between a continuous vari-
ablex, and binary variable,y. Similarly to other correlation
coefficients,  it  varies  between  -1  and  +1,  where  +1  corre-
sponds to a perfect positive relation and -1 corresponds to
a  perfect  negative  relation  while  a  value  of  0  means  there
is no association at all. The point biserial correlation coef-
ficient is similar to the Pearson product moment (Pearson
1895). More detailed information can be found in Lyon et al.
(2016).
Table 2 illustrates the correlation between the seven fea-
tures  studied  and  the  target  class  variable,  for  one  binary
class. From Table 2, it is observed that there are three fea-
tures that show strong correlations
(
>|0.45|
)
, for instance,
the skew, the mean and the standard deviation. It can also
be seen from Table 2 that theTexhibits a weak correlation
for this binary class pair. This means thatTmight not be
useful for classification. However, again one should be care-
ful when judging the feature importance based upon their
linear correlations. Features having linear correlations close
to zero, may have useful non-linear correlations.
Table  3.A  summary  of  the  performance  results  of  the  vari-
ous classifiers, ordered from best-performing to worst-performing
based  on  the  balanced-accuracy  and  G-mean  for  binary  classi-
fication.  Two  values  are  given  for  all  metrics.  For  each  binary
case presented, the first values represent metric values for Type 1
(RRab) and Type 9 (δ-Scuti). The second values are the metrics
values for Type 6 (EA) and Type 10 (ACEP). In addition, the
average of those metrics are summarised in single value.
Classifiers
PrecisionRecallF1-ScoreG-meanBalanced Accuracy
Type 1 (RRab) and Type 6 (EA) Classification
RF
0.97/0.970.97/0.970.97/0.970.97/0.970.94/0.94
∼0.97∼0.97∼0.97∼0.97∼0.94
DT
0.96/0.960.96/0.960.96/0.960.96/0.960.92/0.92
∼0.96∼0.96∼0.96∼0.96∼0.92
KNN
0.95/0.970.97/0.950.96/0.960.96/0.960.92/0.91
∼0.96∼0.96∼0.96∼0.96∼0.92
Type 9 (δ-Scuti) and Type 10 (ACEP) Classification
RF
1.0/1.01.0/1.01.0/1.01.0/1.01.0/1.0
∼1.0∼1.0∼1.0∼1.0∼1.0
DT
1.00/0.960.96/1.000.98/0.980.98/0.980.95/0.96
∼0.98∼0.98∼0.98∼0.98∼0.96
KNN
0.98/0.980.96/0.980.97/0.970.97/0.970.93/0.94
∼0.97∼0.97∼0.97∼0.97∼0.93
6.3    Information Theory
To investigate the relative importance of the features, we im-
plement the Information Theoretic method that Lyon et al.
(2016) applied to the pulsar search problem. According to
Guyon & Elisseeff (2003), features that appear to be infor-
mation poor, may provide new and meaningful information
when combined with one or more other features. Information
theory is mainly based on the entropy of a feature,X. The
Mutual Information (MI, Brown et al. (2012)), which mea-
sures the amount of information between the input feature
Xand the true class labelYis defined as:
I
(
X;Y
)
=H
(
X
)
−H
(
X|Y
)
,(2)
whereH(X)is the entropy andH
(
X|Y
)
is the conditional
entropy. The conditional probability represents the amount
of uncertainty remaining inX, after knowingY. Hence, the
mutual  information  is  indicative  of  the  amount  of  uncer-
tainty inXthat is removed by knowingY. MI can be zero if
and only ifXandYare statistically independent. Therefore,
it is useful for features to have high MI. A high MI indicates
that  a  feature  is  correlated  with  the  target  variable,  and
thus can in principle be used by a classifier to yield accurate
classifications.
The MI value of the seven features are listed in Table 2.
Using the MI method, we are able to choose the features that
best  describe  the  difference  between  two  types  of  classes.
However, the selected features might have redundant infor-
mation, for example two features that give high MI might
have the same information, in which a single selected feature
could be all that is required to achieve the same classification
results.
Therefore,  a  ranking  system  can  be  applied,  which  is
MNRAS000, 1–16 (2019)

Machine Learning Classification for variable stars11
also  known  as  the  Joint  Mutual  Information  (JMI)  (Yang
&  Fong  2011)  criterion.  The  JMI  enables  the  detection  of
complimentary information, and thereby a reduction in the
number of features by eliminating redundancy. The JMI per-
forms a selection from a sample of feature sets based on the
amount of complementary information and ranks them. It
starts from the feature that possesses the largest MI value,
X
1
. A greedy iterative process is used to decide which fea-
tures  complementX
1
(Guyon  &  Elisseeff  2003).  The  JMI
score is given by,
JMI
(
X
J
)
=
’
X
K
∈F
I
(
X
J
X
K
;Y
)
,(3)
whereX
J
X
K
is the joint probability of two features andFis
the selected features. The iterative process continues until a
set of features are selected or all features are ranked. The use
of the JMI enables a reduction in the amount of redundancy
within the features.
We have applied the JMI to our feature data as shown
in Table 2. We note that features which appear to be of low
information content, as determined via visual analysis and
study using the point-biserial correlation coefficient, now ap-
pear to be useful. It is tempting to write off features that
show low scoring linear correlations. However, it can be seen
that even though the Period,T, exhibits a low linear correla-
tion, it is ranked as the ‘1
st
’ best feature by the JMI. Given
that we have shown that all the seven features have utility,
we apply them all for binary classification.
6.4    Performance of Binary Classification
For  binary  classification,  we  train  three  classifiers  inde-
pendently using roughly balanced pair-wise class combina-
tions from the large-sample and small-sample datasets. We
present the results for i) Type 1: RRab & Type 6: EA and
ii) Type 9-δ-Scuti & Type 10: ACEP only to show the differ-
ence between utilizing the two different sized datasets. Sim-
ilar results are obtained with other pair-wise combinations
of binary classes achieving balanced-accuracy and G-Mean
values that vary by∼ ±0.03.
We  found  that  the  RF  performs  best  with  an  overall
balanced-accuracy of 0.94 with a G-mean value of 0.97 for
Type 1: RRab & Type 6: EA. In addition, we observe that
the two science classes in the small dataset samples (Type
9-δ-Scuti and Type 10: ACEP) have some level of misclassifi-
cation in multi-class classification, while in the case of binary
classification, the RF (being the best performing algorithm)
outputs a balanced-accuracy of 1.0 with a G-mean value of
1.0.  The  results  for  both  cases  studied  are  summarised  in
Table 3.
As discussed in§5.3, multi-class classification gave un-
desirable  results.  On  the  other  hand,  using  binary  classi-
fication  (§6.4)  we  show  how  to  obtain  improved  balanced-
accuracies   for   the   science   classes,   achieving   balanced-
accuracies>90per  cent  in  all  cases  we  investigated.  We
thus now attempt to build upon the result by following an
hierarchical approach to classification which will allow us to
break the problem into sets of binary comparisons or smaller
multi-class comparisons.
Eclipsing
(9018)
Pulsating
(10489)
Ecl
Type	5	
(4509)
EA
Type	6
(4509)
RR	Lyrae
(8750)
LPV
Type	8	
(1286)
Cepheids
(306)
휹-Scuti
Type	9
(147)
RRab
Type	1
(4325)
RRc
Type	2
(3752)
RRd
Type	3
(502)
Blazhko
Type	4
(171)
ACEP
Type	10
(153)
Cep-II
Type	12
(153)
Variable	Stars
Rotational
Type	7:	(3636)
Figure 8.A hierarchy of variable-star classification for data used
in§2  which  is  constructed  based  on  the  understanding  of  their
physical  properties.  At  the  top  layer,  the  variable-stars  can  be
split into three major classes: eclipsing, rotational and pulsating
systems.  The  number  in  parenthesis  represents  the  number  of
samples in each particular class.
7    HIERARCHICAL CLASSIFICATION -
RESULTS AND DISCUSSION
Using some astrophysical properties of the variable stars in
our dataset, we group the variable sources into categories as
shown in Fig. 8. The first level of the hierarchy is split into
three broad science classes: eclipsing, rotational and pulsat-
ing. From the top level, we continue to subdivide the classes,
for instance, at the third level, we are left with exactly two
main  classes:  RR  Lyrae  and  Cepheids  with  6  science  sub-
classes  in  the  final  sub-node.  For  further  details  on  hier-
archical  classification,  we  refer  the  reader  to  the  excellent
review by Silla & Freitas (2011).
Firstly,  we  perform  a  multi-class  classification  on  the
first hierarchy layer to distinguish between eclipsing, rota-
tional  and  pulsating  stars.  This  method  helps  to  address
some of the class imbalance issues. However, this separation
is  not  perfect  because  the  rotational  class  has  many  less
examples than the other two classes. The same evaluation
methodology  as  in§4  is  employed  and  the  results  for  the
top layer is summarised in Table 4. We obtain a balanced-
accuracy rate of∼61per cent with a G-mean value of∼0.79
for the first layer.
We then move down the hierarchy to perform two sep-
arate classifications for layer 2, keeping the same examples
in  the  training  sets  and  the  test  sets  as  in  the  top  layer.
We  subdivide  the  eclipsing  binary  group  into  Ecl  and  EA
classes  and  perform  a  binary  classification.  The  result  of
this experiment shows that we are successful in classifying
between  the  two  classes  of  objects  with  a  0.86  balanced-
accuracy  and  0.93  G-mean  value.  In  the  second  layer,  we
undertake a multi-class classification of four distinct types
of classes: RR Lyrae, LPV, Cepheids andδ-Scuti. We achieve
a balanced-accuracy of 0.98 in distinguishing between those
classes.
Eventually, we follow the hierarchy down to the third
layer where we investigate the categorization of two classes:
RR Lyrae and Cepheids. Our aim here is to find to what ex-
tent we will be successful in distinguishing between the sub-
classes  of  RR  Lyrae  (RRab,  RRc,  RRd  and  Blazhko)  and
Cepheids (ACEP and Cep-II). The analysis shows that we
are successful in distinguishing between RRab and RRc with
high balanced-accuracy. However, most of the RRd sources
MNRAS000, 1–16 (2019)

12Z. Hosenie et al.
Eclipsing
Rotational
Pulsating
Predicted label
Eclipsing
Rotational
Pulsating
True label
0.660.190.15
0.110.740.15
0.070.060.87
Confusion matrix for Random Forest Classifier
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
(a) First level
Ecl
EA
Predicted label
Ecl
EA
True label
0.920.08
0.060.94
Confusion matrix for Random Forest Classifier
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
(b) Second level
RR Lyrae
LPV
Cepheids
-Scuti
Predicted label
RR Lyrae
LPV
Cepheids
-Scuti
True label
0.990.000.010.00
0.000.990.010.00
0.050.000.950.00
0.000.000.001.00
Confusion matrix for Random Forest Classifier
0.0
0.2
0.4
0.6
0.8
1.0
(c) Second level
RRab
RRc
RRd
Blazhko
Predicted label
RRab
RRc
RRd
Blazhko
True label
0.980.000.000.02
0.000.900.100.00
0.060.500.440.01
0.810.000.000.19
Confusion matrix for Random Forest Classifier
0.0
0.2
0.4
0.6
0.8
(d) Third level
ACEP
Cep-II
Predicted label
ACEP
Cep-II
True label
0.960.04
0.150.85
Confusion matrix for Random Forest Classifier
0.2
0.4
0.6
0.8
(e) Third level
Figure 9.The normalized confusion matrices for the best classifier (RF) for hierarchical classification.
MNRAS000, 1–16 (2019)

Machine Learning Classification for variable stars13
Table 4.A summary of the performance results of the RF classifier for the variable-star hierarchical classification. We report metrics
per class, separated by ‘/’. Also, we compute the average metrics taking into consideration the overall classes, summarised in a single
value.
PrecisionRecallF1-ScoreG-MeanBalanced Accuracy
First Level: Eclipsing, Rotational and Pulsating Classification
0.97/0.19/0.510.66/0.74/0.870.79/0.30/0.640.78/0.78/0.860.59/0.60/0.75
∼0.86∼0.70∼0.74∼0.79∼0.61
Second Level: RR Lyrae, LPV, Cepheids andδ-Scuti
1.00/1.00/0.75/0.960.99/0.99/0.95/1.000.99/1.00/0.84/0.980.99/1.00/0.97/1.000.98/0.99/0.93/1.00
∼0.99∼0.99∼0.99∼0.99∼0.98
Second Level: Ecl and EA
0.90/0.500.92/0.940.95/0.650.93/0.930.86/0.86
∼0.95∼0.92∼0.93∼0.93∼0.86
Third Level: RRab, RRc, RRd and Blazhko
0.96/0.93/0.36/0.290.98/0.90/0.44/0.190.97/0.91/0.40/0.230.97/0.92/0.65/0.440.94/0.85/0.40/0.18
∼0.90∼0.90∼0.90∼0.92∼0.86
Third Level: ACEP and Cep-II
0.86/0.950.96/0.850.91/0.900.90/0.900.82/0.80
∼0.91∼0.90∼0.90∼0.90∼0.81
are classified as RRc and Blazhko sources are classified as
RRab.  To  check  whether  our  results  are  affected  by  class
imbalance,  we  downsample  RRc  in  the  training  set  to  the
same number of samples as RRd and perform a binary clas-
sification. This process is repeated for RRab, whereby the
number  of  objects  is  decreased  to  the  same  number  as  in
Blazhko class. We train a binary classifier, keeping the test
set  the  same  for  RRc  &  RRd  and  RRab  &  Blazhko.  We
found that using balanced classes does increase the perfor-
mance of the classifier significantly, for instance, we are able
to distinguish between RRab & Blazhko and RRc & RRd
with a balanced-accuracy rate of 80 per cent and 75 per cent
respectively.
For   an   in-depth   analysis   of   the   RR   Lyrae   sub-
classification,  we  use  the  data  provided  by  Drake  et  al.
(2017)  that  utilised  the  Adaptive  Fourier  Decomposition
(AFD) method (Torrealba et al. 2015) to determine the pe-
riod  of  each  source.  To  see  how  the  visually  selected  pe-
riodic  variables  differ  from  the  initial  candidates;  we  plot
the  amplitude  and  the  period  distribution  of  the  variable
stars  available  in  the  catalog.  From  Fig.  10,  we  note  that
it  is  a  challenging  task  to  separate  the  subclasses:  RRab
& Blazhko and RRc & RRd. We found that our ML clas-
sifier  also  struggles  to  separate  those  classes.  In  addition,
we observe a clear separation between RRab and RRc, and
our classification pipeline is also able to separate these two
classes. In the same vein, Malz et al. (2018) point out it is
generally challenging to have a clear separation between RRc
and RRd even though they have different pulsating modes
and due to the rarity of RRd sources, they are often sub-
sumed by RRc labels. Moreover, Drake et al. (2017) argued
that RRd phased light curves often appear like those of RRc
and Blazhko stars often resemble RRab’s when phase-folded
over multiple cycles.
Furthermore, we analyse the classification of Cepheids
and we obtain an error classification rate of∼19 per cent. On
the same note, Drake et al. (2017) argued that classifying
ACEP and BL Her (a sub-groups of Cep-II) is difficult for
field stars because of the mixture of stellar populations in
the field and the inadequate distance information.
For our hierarchical model, we present the RF classifier
results  only  as  it  performs  well  compared  to  other  classi-
fiers  discussed  in  this  paper.  From  the  results  in  Table  4
and Fig. 9, we see immediately a disparity in performance
among  the  classes.  This  discrepancy  in  misclassification  is
due to the comparative size of each of the science classes. We
note that we obtain high performance with classes that are
data-rich. To alleviate the class-imbalance problem, one can
either gather different catalogs for the under-sampled classes
or augment the existing available catalogs via sophisticated
statistical machine learning approaches.
In  Fig.  11,  we  plot  the  precision-recall  curve  for  each
class and we note that the classification performance is very
good. The area under the precision-recall curve values are
greater than 0.85 for several classes, except for Type 7: Ro-
tational, Type 3: RRd and Type 4: Blazhko. This correlates
with the results presented in Table 4. In addition, we com-
pare our proposed hierarchical approach to an already imple-
MNRAS000, 1–16 (2019)

14Z. Hosenie et al.
0.20.40.60.81.01.21.41.61.8
Period (days)
0.0
0.5
1.0
1.5
2.0
2.5
3.0
Amplitude,
A
VCSS
1. RRab
2. RRc
3. RRd
4. Blazhko
(a) The period-amplitude distribution
0.20.40.60.81.01.21.41.61.8
Period (days)
10
0
10
1
10
2
10
3
Number of Samples
RRab
RRc
RRd
Blazhko
(b) The period distribution
Figure 10.We plot the distribution of RR Lyrae sub-types (RRab, RRc, RRd and Blazhko) using available data from the ascii catalog
of the sources in Drake et al. (2017).
mented machine learning package known asUPSILON(Kim &
Bailer-Jones 2016). The latter used a RF classifier, trained
on 16 features extracted from OGLE (Udalski et al. 1997)
and EROS-2 (Tisserand et al. 2007) periodic variable stars
light curves; while our model is trained on 7 features from
CRTS  data.  The  comparison  is  made  with  only  8  classes
out of 11 asUPSILONhas not been trained on all the vari-
able stars available in CRTS data. We report the results in
terms of recall and F1-score in Table 5. It is seen that our
hierarchical model outperforms theUPSILONmodel in clas-
sifying  most  of  the  variable  stars,  except  for  Type  6:  EA.
We can plausibly say that our hierarchical classifier yields
good performance with 7 features in classifying sub-groups
of  stars  as  compared  to  theUPSILONpackage.  For  a  com-
parison  in  terms  of  features  used,  we  report  results  when
using a ‘flat’ multi-class model (RF) in§5.3 with 7 features
and compare it with the hierarchical model. The hierarchical
model outperforms both theUPSILONmodel and the multi-
class model developed in this paper. This clearly shows that
it is not necessary to extract many features to obtain higher
classification metrics. In addition, we have shown that con-
verting a ‘flat’ multi-class problem into a hierarchical system
improves variable star classification.
8    CONCLUSION AND FUTURE WORK
With the upcoming synoptic surveys (for e.g. LSST, Ivezic
et al. (2008)), automated transient/variable-star classifica-
tion is becoming an increasingly important field in astron-
omy.  It  presents  a  difficult  computational  challenge  which
we  have  nonetheless  attempted  to  tackle  in  this  work.
We describe the core challenges associated with automatic
variable-star classification and subsequently explored the na-
ture of the data to be processed. We then applied various
approaches with the aim of accurately classifying 11 types of
variable star. Some of the methods we applied are similar to
current techniques, while others are new to this field. Com-
pared to other related work, we utilized only 7 input features
during classification, where 6 features are based on statistical
properties of the unfolded data and the Period,T, is obtained
directly from the data catalog. We used these features as in-
puts to three separate commonly employed ML algorithms.
We  demonstrate  that  the  RF  classification  algorithm  per-
formed best in all test cases. Treating the variable-star clas-
sification  as  a  multi-class  problem  with  11  classes,  results
in a poor performance. In doing so, the RF algorithm is ef-
ficient at identifying RRab, RRc, Ecl, EA, Rotational and
LPV classes, but is unsuccessful in distinguishing, for exam-
ple,δ-Scuti and ACEP. However, by decomposing the multi-
class problem into several binary classification problems, we
gain a significant improvement in balanced-accuracy - with
a  balanced-accuracy  rate  of  1.0  for  the  classification  ofδ-
Scuti  and  ACEP.  Our  results  suggest  that  decomposing  a
multi-class  problem  into  several  binary  classification  steps
could yield improved results.
We therefore developed a hierarchical approach for clas-
sifying the 11-variable-star classes in our data, by aggregat-
ing those classes that show similarities. We show that a hi-
erarchical taxonomy for n-class objects improves the classi-
fication rate. We are now successful in identifying sub-types
of cepheids and eclipsing binaries with a balanced-accuracy
rate of 81 per cent and 86 per cent respectively. Whilst the
hierarchical approach does not work well for all classes, this
is understandable in cases with high class-imbalances and a
lack of training examples.
We  have  presented  an  approach  to  analysing  variable
star data in such a way, that is beneficial to machine learning
feature analysis and extraction. This process yields insights
that allow us to obtain improved classification performance.
In other words, we have taken a principled approach to fea-
ture analysis and design, especially for multi-class problems
with a highly imbalanced datasets. We employ new meth-
ods for feature selection and evaluation and we show that
converting a multi-class problem towards a hierarchical clas-
sification scheme helps to reduce the class-imbalance prob-
lem as well as provide a significant improvement for variable
stars  classification.  In  the  near  future,  we  wish  to  investi-
gate the impact of data augmentation on the performance
of our ML classifiers. Moreover, flagging data (as we did for
the “Miscellaneous class”) is often undesirable. One school
of  thought  is  to  treat  them  as  outliers  but  another  might
argue that these could perhaps indicate new discoveries. It
is a major task with such a classification scheme, since we
MNRAS000, 1–16 (2019)

Machine Learning Classification for variable stars15
Table 5.Comparison of our Hierarchical model, Multi-class model andUPSILONpackage (Kim & Bailer-Jones 2016).
For a fair comparison, we test these models on 8 classes and report the scores in terms of recall and F1-score. The
model with higher classification score in highlighted in blue.
Types of Variable Stars
UPSILON ModelOur Multi-Class ModelOur Hierarchical Model
with 16 Featureswith 7 Featureswith 7 Features
RecallF1-ScoreRecallF1-ScoreRecallF1-Score
RRab0.750.860.920.730.980.97
RRc
0.780.870.770.460.900.91
RRd0.110.200.330.140.440.40
Ecl (EC & ESD)0.750.730.600.740.920.95
EA
0.970.980.900.680.940.65
LPV0.920.960.980.950.991.00
δ-Scuti
0.860.930.960.701.000.98
Cep-II
0.380.550.520.320.850.90
0.00.20.40.60.81.0
Recall
0.0
0.2
0.4
0.6
0.8
1.0
Precision
Eclipsing (0.97)
Rotational (0.30)
Pulsating (0.80)
Ecl (1.00)
EA (0.82)
RR Lyrae (1.00)
LPV (1.00)
Cepheids (0.90)
δ-Scuti (1.00)
RRab (0.99)
RRc (0.97)
RRd (0.39)
Blazhko (0.26)
ACEP (0.87)
Cep-II (0.93)
Figure 11.Precision-Recall curves for each node in the hierar-
chical model. Each curve represents a different variable stars with
the area under the precision-recall curves score in brackets. This
metric is computed on the 30% of the dataset used for testing,
except that Type 5: Ecl stars has∼15647 samples.
now have to tackle the problem in an unsupervised way, a
topic currently in its infancy.
ACKNOWLEDGEMENTS
We thank the referee for useful comments and suggestions in
improving this manuscript. ZH acknowledges support from
the UK Newton Fund as part of the Development in Africa
with Radio Astronomy (DARA) Big Data project delivered
via  the  Science  &  Technology  Facilities  Council  (STFC).
BWS  acknowledges  funding  from  the  European  Research
Council  (ERC) under  the  European Union's  Horizon 2020
research  and  innovation  programme  (grant  agreement  No.
694745). AM is supported by the Imperial President’s PhD
Scholarship.
APPENDIX A:  EVALUATION METRICS
The performance of any machine learning algorithm is evalu-
ated using measures such as the balanced-accuracy, the pre-
cision,  the  recall,  the  F1  score,  sensitivity  and  specificity
(Chao et al. 2004). They are defined in terms of True Posi-
tive
(
T
P
)
Rate, False Positive
(
F
P
)
Rate, True Negative
(
T
N
)
Rate and False Negative
(
F
N
)
Rate. The sensitivity metric
is defined as the true positive rate or positive class accuracy,
while specificity is referred to as the true negative rate or
equivalently negative class accuracy (Danjuma 2015).
•Sensitivity  Measure:  Equation  A1  also  known  as  the
true positive rate or “recall”. It measures the proportion of
actual positives correctly identified by the model.
Sensitivity/Recall=
T
P
T
P
+F
N
(A1)
•Specificity Measure: Equation A2 also known as True
Negative rate. It measures how well a model identifies neg-
ative results.
Specificity=
T
N
T
N
+F
P
(A2)
•Precision: It is a measure of retrieved instances that are
correctly labelled. Precision is described in Equation A3.
Precision=
T
P
T
P
+F
P
(A3)
•F1-score: It is a metrics that aims to quantify overall
performance,  expressed  in  terms  of  precision  and  recall  as
shown in Equation A4.
F1-Score=
2×Precision×Recall
Precision+Recall
(A4)
•Balanced accuracy measure: It is defined as the average
of recall obtained on each class and it is a metric that deal
with imbalanced classes.
MNRAS000, 1–16 (2019)

16Z. Hosenie et al.
Table A1.Confusion matrix implemented for our specific prob-
lem, where the positive class corresponds to Class I and the nega-
tive class to Class II for the two classification schemes. True/false
positives/negatives  are  represented  asT
P
,F
P
,T
N
,andF
N
re-
spectively.
Class IIClass I
Actual
Class
Class IIT
N
F
P
Class IF
N
T
P
Predicted Class
Balanced Accuracy=
Sensitivity+Specificity
2
×100%(A5)
•Geometric  Mean  Score:  G-Mean  is  defined  as  the
squared root of the product of class-wise sensitivity. It max-
imizes the accuracy on each class in addition to keep these
accuracies balanced.
G-Mean=
√
Sensitivity×Specificity(A6)
•Precision-Recall curve: PR curve illustrates the trade-
off between TPR and positive predictive value for a model
at different probability thresholds.
•Confusion Matrices: TheT
P
,F
P
,T
N
,andF
N
can be vi-
sualized  by  a  confusion  matrix  as  illustrated  in  Table  A1,
where  the  predicted class is indicated in  each column and
the actual class in each row. In this case, from Table A1, the
true positives
(
T
P
)
are Class I examples that were correctly
classified as Class I, false positivesF
P
correspond to Class II
examples wrongly classified as Class I. In a similar way, false
negativesF
N
and true negativesT
N
can be explained. For
binary classification problems, Class I corresponds to posi-
tive class and Class II corresponds to negative class. After
the training and testing process, we evaluate our pipeline us-
ing balanced-accuracy, G-mean, F1-score, recall values and
confusion matrices.
REFERENCES
Bates S., Bailes M., Bhat N., Burgay M., et al., 2011, Monthly
Notices of the Royal Astronomical Society, 416, 2455
Belokurov V., Evans N. W., Le Du Y., 2003, Monthly Notices of
the Royal Astronomical Society, 341(4), 1373
Bentley J. L., 1975, Communications of the ACM, 18 (9), 509
Bergstra J., Yamins D., Cox D. D., 2013, in Proceedings of the
12th Python in science conference. pp 13–20
Blazhko S., 1907, Astronomische Nachrichten, 175, 325
Breiman L., 2001, Machine Learning, 45, 5
Brown  G.,  Pocock  A.,  Zhao  M.-J.,  Luj ́an  M.,  2012,  Journal  of
machine learning research, 13, 27
Buturovic L. J., 1993, Pattern Recognition, 26, 611
Catelan M., Smith H. A., 2015, Wiley-VCH
Cauchy A., 1853, C.R. Acad. Sci, 37, 198
Chao  C.,  Liaw  A.,  Breiman  L.,  2004,  University  of  California,
Berkeley
Danjuma K. J., 2015, CoRR, abs/1504.04646
Dietterich T. G., 2000, Multiple Classifier Systems, 1857, 1
Djorgovski S. G., Donalek C., Mahabal A., et al., 2011, preprint
Djorgovski S. G., Graham M. J., Donalek C., et al., 2016, preprint
Drake A. J., Djorgovski S. G., Mahabal A., et al., 2009, ApJ, 696,
870
Drake A. J., Djorgovski S. G., Catelan M., Graham M. J., et al.,
2017, Monthly Notices of the Royal Astronomical Society, 469
(3), 3688
Eyer L., Blake C., 2005, MNRAS
Gregory P. C., Loredo T. J., 1992, Astrophysical Journal
Gupta S., 1960, Psychometrika, 25(4), 393
Guyon  I.,  Elisseeff  A.,  2003,  Journal  of  Machine  Learning  Re-
search, 3, 1157
He H., Garcia E. A., 2008, IEEE Transactions on Knowledge &
Data Engineering, pp 1263–1284
Ivezic Z., Kahn S. M., Tyson J. A., et al., 2008, American Astro-
nomical Society
Juric M., Kantor J., Lim K. T., Lupton R. H., et al., 2015, As-
tronomical Data Analysis Software and Systems, 512
Kim D.-W., Bailer-Jones C. A., 2016, Astronomy & Astrophysics,
587, A18
Kullback  S.,  Leibler  R.  A.,  1951,  The  Annals  of  Mathematical
Statistics, 22(1), 79
Last F., Douzas G., Bacao F., 2017, arXiv:1711.00837
Lochner M., McEwen J. D., Peiris H. V., et al., 2016, The Astro-
physical Journal Supplement Series, 225(1), 14
Lomb N. R., 1976, Astrophysics and Space Science, 39, 447
Lyon R. J., Stappers B. W., Cooper S., Brooke J. M., Knowles
J. D., 2016, Monthly Notices of the Royal Astronomical Soci-
ety, 459, 1104
Mahabal A. A., Donalek C., Djorgovski S. G., et al., 2012, New
Horizons in Time Domain Astronomy, 285, 355
Mahabal A., Sheth K., Gieseke F., et al., 2017, IEEE Symposium
Series on Computational Intelligence, p. 2757
Malz  A.,  Hlozek  R.,  Allam  T.  J.,  Bahmanyar  A.,  et  al.,  2018,
arXiv:1809.11145
Narayan G., Zaidi T., Soraisam M. D., et al., 2018, Astrophysical
Journal Supplement Series, 236(1)
Nun I., Protopapas P., Sim B., et al., 2015, arXiv:1506.00010
Pearson  K.,  1895,  Proceedings  of  the  Royal  Society  of  London,
58, 240
Pedregosa F., et al., 2011, Journal of Machine Learning Research,
12, 2825
Quinlan J. R., 1986, Machine Learning, 1, 81
Revsbech E. A., Trotta R., van Dyk D. A., 2018, MNRAS, 473,
3969
Richards J. W., et al., 2011, The Astrophysical Journal, 733, 10
Saha A., Vivas A. K., 2017, The Astronomical Journal, 154
Scargle J. D., 1982, Astrophysical Journal, 263, 835
Silla C. N. J., Freitas A. A., 2011, Data Mining and Knowledge
Discovery, 22, 31
Tisserand P., et al., 2007, A&A, 469, 387
Torrealba G., Catelan M., Drake A. J., Djorgovski S. G., et al.,
2015, Monthly Notices of the Royal Astronomical Society, 446,
2251
Udalski A., Kubiak M., Szymanski M., 1997, Acta Astron., 47,
319
Wattenberg M., Fernanda V., Johnson I., 2016, Distill
Willemsen P., Eyer L., 2007, arXiv:0712.2898v1
Yang  H.,  Fong  S.,  2011,  Proceedings  of  the  13th  international
conference on Data warehousing and knowledge discovery, pp
471–483
Zhang H., 2004, FLAIR, 2
van der Maaten L., Hinton G., 2008, Journal of Machine Learning
Research, pp 2579–2605
This paper has been typeset from a T
E
X/L
A
T
E
X file prepared by
the author.
MNRAS000, 1–16 (2019) 

 
 
Design and Evaluation of Product Aesthetics:  
A Human-Machine Hybrid Approach 
 
by 
 
Alex Burnap 
 
John R. Hauser 
 
and 
 
Artem Timoshenko 
 
July 2019 
 
 
Alex Burnap is a Postdoctoral Fellow in Marketing, MIT Management School, Massachusetts Institute of 
Technology, E62-366, 77 Massachusetts Avenue, Cambridge, MA 02139, (405) 880-3660, 
aburnap@mit.edu. 
John R. Hauser is the Kirin Professor of Marketing, MIT Management School, Massachusetts Institute of 
Technology, E62-538, 77 Massachusetts Avenue, Cambridge, MA 02139, (617) 253-2929, 
hauser@mit.edu. 
Artem Timoshenko is an Assistant Professor of Marketing at Kellogg School of Management, 
Northwestern University, 2211 Campus Drive, Suite 5391, Evanston, IL 60208, (617) 803-5630, 
artem.timoshenko@kellogg.northwestern.edu. 
 
 
 
We thank Jeff Hartley, Joyce Salisbury, Zheng Shen, Sharon Sheremet, John Manoogian II, and Andrew 
Norton for valuable insights into how product aesthetics are designed and evaluated; Mark Beltramo, 
Fred Feinberg, Ari Helljaka, Honglak Lee, Ye Liu, and Yanxin Pan for mathematical modeling discussion; 
and Emrah Bayrak, Songting Dong, Nasreddine El-Dehaibi, Siham El Kilal, Gui Liberali, Ye Liu, Max Yi Ren, 
Erin MacDonald, and Glen Urban for helpful comments and suggestions. 
  

 
 
Design and Evaluation of Product Aesthetics:  
A Human-Machine Hybrid Approach 
 
Abstract 
 
 Aesthetics  are  critically  important  to  market  acceptance  in  many  product  categories.  In  the 
automotive  industry in particular, an improved aesthetic design can boost  sales by 30% or more. Firms 
invest heavily in designing and testing new product aesthetics. A single automotive “theme clinic” costs 
between $100,000 and $1,000,000, and hundreds are conducted annually. We use machine learning to 
augment  human  judgment  when designing and  testing new product aesthetics. The model combines a 
probabilistic  variational  autoencoder  (VAE) and adversarial  components  from generative  adversarial 
networks  (GAN), along  with modeling  assumptions that  address  managerial  requirements for  firm 
adoption. We  train  our  model  with data  from  an  automotive  partner—7,000  images  evaluated  by 
targeted  consumers and 180,000  high-quality  unrated images.  Our  model  predicts  well  the  appeal  of 
new aesthetic designs—38% improvement relative to a baseline and substantial improvement over both 
conventional machine  learning  models  and  pretrained deep learning  models. New  automotive  designs 
are generated in a controllable manner for the design team to consider, which we also empirically verify 
are appealing to   consumers. These results, combining   human   and   machine   inputs   for practical 
managerial usage, suggest that machine  learning offers significant  opportunity  to  augment  aesthetic 
design. 
 
 
Keywords: Aesthetics, Generative Adversarial Networks, Generating New Products, Machine Learning, 
Prelaunch Forecasting, Product Development, Variational Autoencoders.  
 
 
 
  

1 
 
1. Introduction 
 Consumers  consistently  rank aesthetics among the three most  important  attributes in  product 
choice (Bloch 1995; Creusen and Schoormans 2005). For example, the visual design of the original iPod 
was  judged  to  be  a  critical  factor  in  its  market  acceptance (Reppel,  Szmigin,  and  Gruber  2006). In 
categories  such  as  home  appliances,  aesthetics help  firms establish product  differentiation  beyond 
functional  attributes (Bloch  1995;  Crilly, Moultrie,  and  Clarkson 2004;  Person  et  al. 2007); for  instance, 
the  Dyson  DC01 used transparent  design  to  communicate its complexity to  consumers, helping  it 
become the   best-selling   vacuum   in   the   U.K. (Noble   and   Kumar   2010). Firms   use   aesthetics   to 
strategically  position  and  enhance  brand  recognition (Aaker  and  Keller  1990;  Karjalainen  and  Snelders 
2010; Keller 2003); trade dress violations (non-functional attributes that signal brand identity) are hotly 
contested  in Lanham  Act  (§43A)  litigation. Aesthetics  pervade  marketing—visually-appealing products 
and packaging drive consumers to choose one product over another, especially at the point of purchase 
in  crowded  brick-and-mortar stores,  supermarkets,  and  online  retailers (Clement  2007;  Orth  and 
Malkewitz 2008).  
Developing  product  aesthetics can require  substantial  investment, yet returns on  investment 
are  found  across  markets—a  study  of  93  firms  across  nine  product  categories  found that firms  that 
heavily  invested  into  aesthetic  design  had  32%  higher  earnings  than  industry  averages (Hertenstein, 
Platt,  and  Veryzer  2005). Marketing  and  product  managers  routinely  manage  the  aesthetic  design  of 
products,  services,  and  digital  marketplaces. In  this  paper,  we  propose  a  methodology  to  improve  the 
process of aesthetic product design and testing. While the basic concepts of the proposed methodology 
are applicable across markets, we demonstrate the approach in the automotive industry.  
In the automotive industry, product aesthetics can explain up to 60% of uncertainty in purchase 
decision for certain segments (Kreuzbauer and Malter 2005). Automotive design significantly affects its 
market  performance (Cho,  Hasija,  and  Sosa  2015;  Jindal  et  al.  2016;  Rubera  2015),  in  large  part  by 
influencing  consumer  consideration (Liu  et  al.  2017;  Palazzolo  and  Feinberg  2015).  For  example,  the 
redesign of the Buick Enclave in 2008 commanded a 30% increase in MSRP over the Buick Rendezvous it 
replaced, and the redesign of the 2005 Volkswagen Beetle resulted in a 54% market share gain in just a 
single year (Kreuzbauer and Malter 2005; Blonigen, Knittel, and Soderbery 2013). On the other hand, the 
visual appeal of the 2001 Pontiac Aztec was cited as a reason for its lack of market success (Vlasic 2011). 
Not  surprisingly,  automotive  firms  invest  heavily  in  design  and  redesign—$1.25  billion  on  average  with 
up to $5.7 billion invested in critical designs (Blonigen, Knittel, and Soderbery 2013; Pauwels et al. 2004; 
Rubera 2015). 

2 
 
Traditionally, human judgment enters the aesthetic product design pipeline in at least two ways. 
While  there  are  established  aesthetic  heuristics  and  cognitive  design  principles (Coates  2003;  Crilly, 
Moultrie, and Clarkson 2004; Norman 2004), aesthetic design is often generated and screened by design 
teams who have an “eye” for visual design. Design teams are powerful within organizations; their 
aesthetic judgments are hard to overrule (Vlasic 2011). 
Human   judgment   also   affects   aesthetics   through   consumer   evaluations.   Firms   often   ask 
consumers to evaluate alternative designs in laboratory test markets, A/B tests, or “theme clinics.” In a 
typical  automotive  theme  clinic,  a  few  hundred  targeted  consumers  are  recruited  and  brought  to  a 
central location to evaluate  aesthetic  designs. Consumers view  the aesthetic  designs and rate  them on 
established benchmarks such as semantic scales for sporty, appealing, innovative, and luxurious (Coates 
2003; Manoogian II 2013). Theme clinics are costly. Automotive firms typically invest between $100,000 
and  $1,000,000  per  theme  clinic  for  a  single  new  vehicle  design.  With  multiple  aesthetic  designs  per 
vehicle and over a hundred vehicles in its worldwide product line, General Motors alone spends tens of 
millions of dollars on theme clinics. With the additional hidden costs incurred when designers routinely 
and manually screen hundreds of aesthetic designs to narrow down alternatives for a theme clinic, costs 
can exceed $100 million for a single manufacturer. 
In this paper, we augment human judgment with machine learning tools to address both aspects 
of  aesthetic  design: (1) the  generation  and (2) the testing  of  new  aesthetic  designs.  For  testing,  we 
predict  how consumers  would  rate product  aesthetics  directly  from  visual  images.  Specifically,  we  use 
an encoding model to represent visual designs (images) using a smaller number of 500 “features,” and 
train  a predictive  model that  predicts  aesthetic  ratings  based  on  those  features.  We  use  the  predictive 
model to screen newly proposed aesthetic designs so that only the highest-potential designs are tested 
in theme clinics (or their equivalent for non-automotive applications). 
For generation, we  create  new  designs  to  inspire  the  design team.  We  develop  a generative 
model that creates new product designs that are predicted to be aesthetically appealing while satisfying 
product  attributes  desired  by  the  designers  (e.g.,  “Cadillac-like”). This   gives   the   design   team   a 
controllable  tool  which they  may use to  morph  through  the  design  space. While some images  are 
nonsensical, other generated images inspire creative aesthetic design by bending product forms.  
Our  focus is augmentation of  human  expertise  and  creativity,  rather  than  its automation. Our 
focus addresses several  key managerial  issues related  to  integrating  machine  intelligence  into  existing 
human workflows. This combination of machine learning and human judgment (machine-human hybrid) 
leads to better designs and a reduction in the costs of design generation and testing. 

3 
 
2. Conceptual Model of Aesthetic Product Design 
2.1. Augmenting the Design Process 
 Figure  1  summarizes  the  current  design  process  and  the  proposed  role  of machine  learning 
augmentation.  Consider  first  the  current  process  as  shown  in  the  first  two  rows  (coded  as  black).  The 
process  begins  with  a  market  definition  that  is  external  to  the  aesthetic  design  efforts.  For  example, 
Apple  targeted  smartphones  with  a touchscreen;  Zenni  Optical  aimed  to  develop  prescription  sports 
glasses;  IKEA  targeted affordable yet  aesthetically pleasing  furniture. In  automotive  markets,  firms 
target  particular  segments  such  as  luxury  compact  utility  vehicles  (currently  the  Cadillac  XT5,  Buick 
Envision,  Volvo  XC60,  BMW  X3,  and  others).  Market  definition  provides  soft  constraints  on  aesthetics 
based on the targeted consumers and the firm’s capabilities (Box 1). 
 Aesthetic designers then create hundreds to thousands of freehand sketches that are converted 
to 2D images (Box 2). For example, Dyson and General Motors may generate several hundred sketches 
per  new  product  model,  while  IKEA  may  generate  fewer  given its product  line  variety and  turnover 
(Bouchard,  Aoussat,  and  Duchamp  2006;  Toffoletto  2013).  The  human  design  team  next  screens 
potential  designs  to  a smaller  set  of testable design concepts in a process known as “downselecting” 
(Box  3).  Consumers  evaluate  the  remaining  designs  in  theme  clinics  resulting  in  more  screening. 
Successful   designs   are   advanced   downstream   for   further   development,   including   engineering, 
manufacturing, and marketing communications (advertising, social media, websites, etc.). The process is 
highly iterative and  asynchronous  across  both  generation  and  testing;  our  augmentation applies  to  all 
iterations. 
Figure 1. Augmenting Aesthetic Design with Machine Learning 
 

4 
 
 The red trapezoids and arrows highlight the machine learning augmentation. After the machine 
learning  models  are  trained,  we  use  them  to  augment  both  design concept testing and  generation.  In 
testing, we evaluate design concept images using the predictive model to help eliminate designs likely to 
score  low in  theme  clinics. This enables  faster  iteration  as  the design  team focuses on the  remaining 
high-potential images. 
By  focusing  on  high-potential  images,  theme  clinics  are  more  efficient  and  effective. The 
resulting aesthetic designs are likely more profitable when introduced to the market. The firm benefits 
from  shorter product  development  times by more  rapidly sending final  designs  to  downstream  firm 
stages. Cost  reductions  result  from the corresponding lower product “drop rate” (i.e., the share of 
design concepts later terminated in downstream firm stages) (Cooper 1990; Danneels and Kleinschmidtb 
2001). As  a final added  benefit, rigorous quantitative evaluation of aesthetics helps “shield” designs 
from   downstream   changes   driven   by   engineering,   manufacturing,   or   accounting (Hartley   1996; 
Manoogian II 2013; Vlasic 2011). 
The generative  model creates  many  designs that  are  realistic  and  aesthetically  appealing,  and 
can stretch designs in ways that spark creativity among designers (Coates  2003; Martindale 1990). The 
designers can control  the  generative  model  through  specifying  designer  attributes. Example  attributes 
are ‘red,’ ‘Cadillac-like,’ ‘Sport Utility Vehicle (SUV),’ ‘2015 vintage,’ or ‘viewed from the side.’ (The 
vintage variable is important when training the model. It captures the changing nature of fashion in the 
automotive industry (Hekkert, Snelders, and Wieringen 2003; Martindale 1990). 
This  intended  use  is  motivated  by  our  experience  with  real  design  teams—human  creativity  is 
augmentable but currently nowhere near automatable. Designers must innovate product designs while 
anticipating changes in consumer demand; a challenging task given the often significant time it takes to 
develop  a  new  product, e.g.,  Adidas  apparel  12-18  months,  GM  vehicles  36+  months (Adidas  AG  2017 
Annual  Report 2017; Manoogian  II 2013).  Our  focus on  augmentation  guides  the  modeling  decisions  in 
our approach; the final aesthetic decisions remain with the design team. 
2.2. Technical Challenges in Augmenting Aesthetic Design 
 Both the predictive model and the generative model require that we address critical challenges 
in  working  with product  aesthetics images and  with  the  traditional  aesthetic  design  pipeline.  First, 
images are inherently high dimensional. Even modest quality images are 100 x 100 pixels for each of red, 
green, and blue colors together comprising 30,000 variables—far too many to be input to conventional 
choice  models.  Previous  work  has instead primarily represented  aesthetics  in  choice  models  using 
characteristic  lines (Chan,  Mihm,  and  Sosa  2018;  Ranscombe  et  al.  2012),  landmark  points (Landwehr, 

5 
 
Labroo,  and  Herrmann  2011),  silhouettes (Orsborn,  Cagan,  and  Boatwright  2009;  Reid,  Gonzalez,  and 
Papalambros  2010),  and  Bezier  curves (Kang  et  al.  2016);  or  aggregated  numbers  such  as  J.D.  Power 
APEAL or online reviews (Cho, Hasija, and Sosa 2015; Homburg, Schwemmle, and Kuehnl 2015; Jindal et 
al.  2016;  Pauwels  et  al.  2004). We focus  on working  with images, the  industry  standard, due  to  their 
realism  in  representing  the  design. Design  concept realism  greatly  affects  consumer  evaluation and 
enhances  accuracy and  precision  in  attribute-based  product  evaluation  and  forecasting  (Dotson  et  al. 
2016;  Reid,  MacDonald,  and  Du  2013; Hauser,  Eggers,  and  Selove  2019). Choice  modeling  with images 
has only recently been enabled by deep learning, including relevant work in aesthetic prediction (Pan et 
al.  2017; Vasileva  et  al.  2018) and aesthetic generation (Kang  et  al.  2017;  Sbai  et  al.  2019). Our  work 
fundamentally differs from these works as we tackle key managerial issues required for adoption within 
companies; specifically, limited data  sizes, and modeling  decisions that augment rather  than  automate 
existing human workflows within firms. 
Second, gathering consumer evaluations is costly and this results in limited training data. In our 
application,  we  are  fortunate  to  have  7,000  aesthetic  ratings by  consumers  for  vehicles,  but  even  that 
would be insufficient to estimate a predictive model with 30,000 variables. To address limitations on the 
size  of  the  training  sample,  we  need  to either  (a) reduce  the  number  of  explanatory  variables using 
dimensionality  reduction  or  (b)  increase  the  amount  of  training  data  to  make  the  predictive  model 
feasible. We do  both  by training an encoding  model to embed  images  in  a  low-dimensional  space. 
Embeddings reduce the dimensionality, and allow us to combine the relatively small (and expensive for 
the  firm)  sample of  labelled  training  data  (images  with  aesthetic  ratings)  with  a much  larger  sample of 
unlabeled  training  data  (images  without  ratings). Success  depends  upon  whether  the  dimensionality 
reduction  preserves  the  important information  from  the  full  images while  still allowing us to  predict 
human aesthetic judgment and generate perceptually realistic new designs.  
Embeddings using  a  neural  network have  seen  recent  adoption  in  marketing  science;  for 
example,  Timoshenko  and  Hauser  (2019)  embed  textual  data  to  identify  consumer  needs; Sun,  Ghose, 
and  Liu  (2018)  embed  consumer  purchasing  behavior;  Liu,  Lee,  and  Srinivasan  (2018)  embed  product 
reviews  to  predict  sales  conversion;  Zhang  et  al. (2017)  embed  Airbnb  photos  to  predict  demand;  Liu, 
Dzyabura, and Mizik (2017) embed social media images to predict identity; Chakaborthy, Kim and Sudhir 
(2019) embed reviews to identify sentiment and missing evaluations. In our case, good embeddings are 
those which reduce dimensionality to low-dimensional “features” while still allowing us to rate product 
aesthetics and generate  realistic  new designs. (A “feature” in our context is an abstract representation 
inherent to embeddings. It is not an attribute such as “round headlight” or “an 8
o
 slope.”) 

6 
 
 Third, aesthetic evaluations are holistic (Berlyne 1971; Bloch 1995; Crilly, Moultrie, and Clarkson 
2004;  Martindale  1990).  Aesthetic  images  cannot  be  decomposed  as  is  done  in  marketing-science 
methods  such  as  conjoint  analysis  (Orme  and  Chrzan  2017).  Design  aspects  are  interdependent;  we 
cannot  expect  consumers  to  evaluate  design  aspects  separately.  For  example,  even  for  pre-defined 
aesthetic  aspects,  a  consumer  cannot  evaluate  the  aesthetics  of  a  new  BMW  X3  design  as  an  additive 
sum  of  the  shape  and  position  of  headlights,  the  slope  of  the  hood,  and  the  height  of  the  beltline. 
Rather, the Gestalt interplay of all design elements, including subtle elements such as the “Hoffmeister 
kink,”  drive  consumer  evaluations  of  qualitative  attributes  such  as  appealing,  sporty,  aggressive, 
luxurious, or modern (Coates 2003). The same interdependence is true for embedded features, thus we 
use  deep neural networks for the encoder, predictive, and generative models to capture complex  non-
linear interactions among the reduced embedded “features.” 
 Fourth, the design process is highly iterative and asynchronous. Multiple design teams (and sub-
teams)  in  both  design  concept  testing  and  generation  must  be  able  to  use  the  machine  learning 
augmentation  for  their corresponding  roles. For example, the  design  team may  split  into  sub-teams  to 
work  on  several  promising design  concepts  in  parallel,  while  the current theme  clinics may  be testing 
entirely different  design  concepts. To  enhance  parallel  development,  we require an ability  to  separate 
the predictive  and  generative  models into  standalone  components. At  the  same  time,  we  require  the 
ability to combine these models for usage and training. 
3. Overview of a Machine Learning Approach to Augment Aesthetic Product Design 
Let 푋
푖
 be  the  (height  x  width  x  color)  matrix  of  pixels  of  image 푖.  The  proposed  approach 
requires   two   inputs:   product   images   labeled   with   aesthetic   ratings   evaluated   by   consumers, 
{
(
푋
푖
,푦
푖
)|
 푖=1..푁
}
, and   unlabeled   product   images   without   ratings   but   with   product   attributes, 
{
(푋
푗
,푎⃗
푗
)
|
 푗=1..푀
}
. For example, 푦
푖
 might be the average consumer evaluation of the aesthetic appeal 
of product design 푖, and 푎⃗
푗
 may be attributes (if known) such as color and brand. In a typical application, 
the  firm  would  only  have  consumer  evaluations  for  a  small  fraction  of  images, 푁≪푀. Our  two  high-
level  goals  are  to  test  new  product  aesthetics  by  predicting consumer ratings, 푦̂
푛푒푤
,  for  new  product 
images created by the design team, 푋
푛푒푤
, as well as generate new product designs, 푋
̂
푔푒푛
, according to 
attributes desired by  the  design  team, 푎⃗
푔푒푛
,  and  with  predicted  aesthetic  ratings, 푦̂
푔푒푛
,  that  indicate 
consumer acceptance. 

7 
 
Figure 2. Proposed Machine Learning Augmentation Approach 
 
Figure  2  summarizes  the  general  input  and  output  flow  of  the  proposed  machine  learning 
augmentation  for  aesthetic  design.  For  every product  design 푖, the  encoding model in  Figure 2  (red 
trapezoid on the  left)  uses  a  function, 푞
(
ℎ
⃗⃗
푖
 
|
푋
푖
,푦
푖
,푎⃗
푖
,훽
⃗
) to  embed  the 196,608-dimensional  image, 푋
푖
, 
its aesthetic rating (if known), 푦
푖
, and its attributes (if known), 푎⃗
푖
, to a 512-dimensional embedding, ℎ
⃗⃗
푖
. 
Note the 196,608-dimensional images are due to being 256 x 256 x 3 (height x width x color), while the 
512-dimensional embedding size is chosen by us. The embedding (purple square in the middle of Figure 
2)  makes  it  tractable  to  use  the  predictive  model, 푝
푝푟푒푑
(
푦̂
푖
 
|
 ℎ
⃗⃗
푖
,훽
⃗
),  (green  trapezoid  near  the top  of 
Figure  2)  to  predict  ratings  for  new  images  and  for  generated  images.  The embedding  also  makes  it 
tractable to use the generative model, 푝
푔푒푛
(
푋
푖
 
|
ℎ
⃗⃗
푖
,훽
⃗
), (blue trapezoid on the right of Figure 2) to create 
new  high-potential  images, 푋
푔푒푛
. When  generating  images,  we  sample ℎ
⃗⃗
 such  that 푝
푝푟푒푑
(
푦̂
|
ℎ
⃗⃗
,훽
⃗
) is 
large, and produce either a set of images or a video displaying images as we change ℎ
⃗⃗
 smoothly.  
The  three  models  in  the  proposed  approach—the  generative  model,  encoding model,  and 
predictive  model—are  formulated  as  probability  distributions which  are  connected  by  the  embedding. 
We learn an embedding distribution for each product design rather than a point estimate. Each product 
design 푖 has  its  own  embedding distribution ℎ
⃗⃗
푖
 ~ 푞
(
ℎ
⃗⃗
푖
 
|
푋
푖
,푦
푖
,푎⃗
푖
,훽
⃗
). Learning the  parameters  of  the  
distribution  leverages  the  variational  inference  literature (Blei,  Kucukelbir,  and  McAuliffe  2017;  Jordan 
et  al.  1999), thereby enabling Bayesian parameter estimation at data  sizes otherwise intractable  for 
MCMC  sampling. Variational  approaches have  seen recent  adoption  in  marketing;  for  example, Braun 
and  McAuliffe (2010) derive  variational  bounds  for  the mixed multinomial logit model; Ishigaki, Terui, 
Sato, and Allenby (2018) estimate a latent topic choice model for sparse transaction data; Ansari, Li, and 
Zhang (2018) estimate a  topic  model  for a  recommender  system. In  our  case,  a  variational  Bayesian 

8 
 
approach improves predictive performance and allows better interpolation by the generative model. 
We use deep neural networks (augmented through adversarial training) to parametrize all three 
models. The  loss  functions  for  the  deep  neural  networks  are  based  on  maximizing  the  data  log 
likelihood—minimizing loss is the same as choosing parameters that lead to distributions that have high 
data  likelihood.  We develop the  deep  neural  network model by  first  using  conditional  probability  to 
separate  the  log-likelihood  function  into  components  that  are  based  on  prediction,  generation,  and 
encoding (§4). We then approximate the true log-likelihood with a lower bound based on the observed 
data  (evidence  lower  bound).  Finally,  we  assume  priors  from  a  parametric  family  of  probability 
distributions and choose parameters to maximize the approximate log-likelihood based on the observed 
images and ratings. The overall combined model is maximized jointly and is based on those images that 
have ratings and those that do not have ratings. For the remainder of paper, when it is clear in context, 
we  refer  to  the  predictive  model,  generative  model,  and  encoding  model  as  the  predictor,  generator, 
and encoder, respectively. 
4. Proposed Approach: Variational Autoencoder and Generative Adversarial Network  
4.1. Embeddings Are Chosen to Approximate the Joint Distribution of Images and Ratings 
Our goals are to augment design concept  testing by predicting aesthetic  ratings, 푦̂
푛푒푤
, for new 
design  images, 푋
푛푒푤
, as  well  as augment  design  concept  generation  by creating new  designs, 푋
푔푒푛
, 
given attributes, 푎⃗
푔푒푛
, desired by the design team. 
Let 훽
⃗
 be  a  vector of  model parameters.  To  ease  notation,  we  temporarily write all  parameters 
and  likelihoods  for  a  single  datum 푖.  We  seek  a  joint  distribution, 푝(푦
푖
,푋
푖
|푎⃗
푖
,훽
⃗
),  for  the  ratings  and 
images   conditioned  on  the   design  attributes and  the  parameters.  The  joint   distribution  can  be 
decomposed  into  a  predictive  model  and  a  generative  model  by  the  laws  of  conditional  probability: 
푝
(
푦
푖
,푋
푖
|푎⃗
푖
,훽
⃗
)
= 푝
푝푟푒푑
(푦
푖
 
|
 푋
푖
,푎⃗
푖
,훽
⃗
)
푝
푔푒푛
(푋
푖
|푎⃗
푖
,훽
⃗
).  Unfortunately,  representing  and estimating  the 
two conditional distributions is not feasible when product images are high dimensional. 
To address high-dimensionality, we approximate the true joint distribution using embeddings. In 
our case, the embedding compresses information from high-dimensional images, aesthetic ratings, and 
product  attributes  to  enable  tractable predictive  and  generative  models. We  choose  embeddings  such 
that   the   embeddings-based   likelihood   closely   approximates   the true   but   intractable likelihood, 
푝
(
푦
푖
,푋
푖
|푎⃗
푖
,훽
⃗
)
. 
 We estimate an embedding posterior distribution, 푞
푒푛푐
(
ℎ
⃗⃗
푖
|
푋
푖
,푦
푖
,푎⃗
푖
,훽
⃗
), for each product design 
푖 such that ℎ
⃗⃗
푖
 has substantially fewer dimensions (e.g., 512) than 푋
푖
 (e.g., 196,608), yet retains most of 

9 
 
the  information  contained  in  the images,  ratings,  and  product  attributes.  To infer embeddings,  we  use 
variational  Bayes  methods  to  approximate  the  true  joint  log-likelihood, log푝(푦
푖
,푋
푖
|푎⃗
푖
,훽
⃗
),  with  an 
approximate log-likelihood, ℓ
푎푝푝푟표푥
푖
(
훽
⃗
 
)
,  dependent  on  the  embeddings, ℎ
⃗⃗
푖
 (Blei,  Kucukelbir,  and 
McAuliffe 2017; Jordan et al. 1999). Note that while this technique could introduce new data-dependent 
parameters, 훽
⃗
푖
, we implicitly include them in the set of “global” parameters, 훽
⃗
, as  they  will  later  be 
efficiently learned with a deep learning model (amortized inference, Hoffman et al. 2012). 
To  obtain  this  approximation,  we  first  condition  the true log  likelihood, log푝(푦
푖
,푋
푖
|푎⃗
푖
,훽
⃗
), on 
the   embeddings   via   marginalization,   which   leads   to   the   logarithm   of   an   expectation.   We   then 
approximate  the  logarithm  of  the expectation  by  the  expectation  of  the  logarithm.  By  Jensen’s 
Inequality, the approximation is a lower bound to the true log likelihood. Rearranging terms we arrive at 
the  approximate  likelihood  in  Equation  1. Given  an image, 푋
푖
, its rating, 푦
푖
, and  its attributes, 푎⃗
푖
,  we 
seek   to   maximize ℓ
푎푝푝푟표푥
푖
(훽
⃗
) and   thus   approximately   maximize log푝(푦
푖
,푋
푖
|푎⃗
푖
,훽
⃗
).   Appendix A2 
provides  a  more-detailed  derivation  that  combines  standard  variational  Bayes  theory  with  predictive 
models. If 퐷
퐾퐿
(∙||∙) signifies the Kullback-Leibler (KL) divergence, then: 
(1) 
ℓ
푎푝푝푟표푥
푖
(
훽
⃗
)
=E
ℎ
⃗⃗⃗
푖
[
log푝
푝푟푒푑
(
푦
푖
|ℎ
⃗⃗
푖
,훽
⃗
)
+log푝
푔푒푛
(
푋
푖
|ℎ
⃗⃗
푖
,훽
⃗
)
−log푞
푒푛푐
(
ℎ
⃗⃗
푖
|푋
푖
,푦
푖
,푎⃗
푖
,훽
⃗
)
+log 푝
푝푟푖표푟
(
ℎ
⃗⃗
푖
|푎⃗
푖
)]
=퐸
ℎ
⃗⃗⃗
푖
[
log푝
푝푟푒푑
(
푦
푖
|ℎ
⃗⃗
푖
,훽
⃗
)
+log푝
푔푒푛
(
푋
푖
|ℎ
⃗⃗
푖
,훽
⃗
)]
−퐷
퐾퐿
(푞
푒푛푐
(
ℎ
⃗⃗
푖
|푋
푖
,푦
푖
,푎⃗
푖
,훽
⃗
)
||푝
푝푟푖표푟
(
ℎ
⃗⃗
푖
|푎⃗
푖
)
) 
Equation  1  is  intuitive.  The  first  term  seeks  to  maximize  our  ability  to  predict  aesthetic  ratings 
based on the embeddings. The second term seeks to reproduce  images based on the embeddings. The 
last  term  is  the  negative  of  KL  divergence  from  the  embedding  (distribution)  to  the  prior  on  the 
embeddings.  The  KL  term  acts  to  regularize  the  embedding  such  that  the  distributions of  encoded 
images do not stray too far from the prior. The KL divergence prevents the encoder from “cheating” by 
giving each image a unique sub-region of the embedding space, effectively memorizing training data and 
hurting   generalization   performance. Note   that for this   derivation we   have   assumed   conditional 
independence between  images,  ratings,  and  attributes  given  the  embedding. This allows  our  model  to 
use  these  data  separately, as  guided  by the challenges  discussed  in §2.2  with regards  to labelled  data 
and the multiple stakeholders involved in current design workflows. 
Because the approximate log-likelihood, ℓ
푎푝푝푟표푥
푖
(훽
⃗
), is a lower bound to the true log likelihood, 

10 
 
log푝(푦
푖
,푋
푖
|푎⃗
푖
,훽
⃗
), the approximation is commonly called the “evidence lower bound” (ELBO; Jordan et 
al. 1999). We derived Equation 1 for every datum 푖, which leads to an overall full data approximate log-
likelihood, ℒ
(
훽
⃗
)
, which we maximize over parameters, 훽
⃗
, using the observed images and ratings: 
(2) 
ℒ
(
훽
⃗
)
=∑ℓ
푎푝푝푟표푥
푖
(훽
⃗
)
푖
 
Equation  2  assumes  global  parameters  for  (1)  predicting  ratings  based  on  embeddings  and  (2) 
generating images based on embeddings. If we did not make the assumption of global parameters, then 
the  model  would  not  be  useful  for  either  prediction  or  generation.  We  also  specify  a  common  prior 
describing  the  desired  probabilistic  structure  of  embedding  (distributions).  We  make Equations  1  &  2 
“variational”  by  assuming  that  each  datum 푖 has   its   own   embedding   distribution   defined   by 
distributional  model  parameters  conditioned  on  the  images  and  attributes.  Finally,  we  note  that  the 
embedding  portions  of  Equations  1  &  2  are  equivalent  to  those  derived  from  minimizing  the  KL 
divergence  from  (1)  a  true  (unknown)  distribution  of  the  embeddings  conditioned  on  the  images  and 
attributes  to  (2)  the  best  variational  distribution  of  the  embeddings  conditioned  on  the  images and 
attributes (Jordan et al. 1999).  
4.2 Decomposition Defines the Predictive, Generative, and Encoding Models 
Because of the non-linear relationship between images, ratings, and embeddings we use neural 
networks for the predictive, generative, and embedding models. To train these neural networks feasibly, 
we  decompose  the  global  parameter  space  (훽
⃗
)  into  parameters  for  the  predictive  model  (훽
⃗
푃
),  the 
generative model (훽
⃗
퐺
), and encoding model (훽
⃗
퐸
). We do so by using conditional probability to separate 
Equation 2 into its component models. Decomposition enables us to train and use each neural network 
separately  and  iteratively,  which  helps  to  overcome  a  key  managerial  issue,  namely,  that  the  model 
must  be  usable  in  an  asynchronous  and  iterative  environment  by  teams  from  industrial  design, 
marketing, brand strategy, and so on. Specifically: 
(3) 
ℒ(훽
⃗
)= ℒ
푝푟푒푑
(
훽
⃗
푃
)
+ ℒ
푔푒푛
(
훽
⃗
퐺
)
+ ℒ
푒푛푐
(
 훽
⃗
퐸
)
 
ℒ
푝푟푒푑
(
훽
⃗
푃
)
=∑퐸
ℎ
⃗⃗⃗
푖
[log푝
푝푟푒푑
(푦
푖
|ℎ
⃗⃗
푖
,훽
⃗
푃
)]
푖 ∈ 푟푎푡푒푑
 
ℒ
푔푒푛
(
훽
⃗
퐺
)
=∑퐸
ℎ
⃗⃗⃗
푖
[log푝
푔푒푛
(
푋
푖
 
|
 ℎ
⃗⃗
푖
,훽
⃗
퐺
)]
푖 ∈푟푎푡푒푑,푢푛푟푎푡푒푑
 

11 
 
ℒ
푒푛푐
(
 훽
⃗
퐸
)
=−∑
{
퐷
퐾퐿
(푞
푒푛푐
(
ℎ
⃗⃗
푖
|푋
푖
,푦
푖
,푎⃗
푖
,훽
⃗
퐸
)
||푝
푝푟푖표푟
(
ℎ
⃗⃗
푖
|푎⃗
푖
)
) 
푖 ∈ 푟푎푡푒푑,푢푛푟푎푡푒푑
+ 퐷
퐾퐿
(
푞
푎푡푡푟
(
휋⃗⃗
푖
|
푋
푖
,훽
⃗
퐸
)
|| 푝
푎푡푡푟
(휋⃗⃗
푖
|푎⃗
푖
)
)}
 
 This  decomposition  is possible  since the embedding “bottlenecks” information contained  in 
images, ratings, and attributes that is necessary to both predict ratings and generate new designs (Shu, 
Bui, and Ghavamzadeh 2016). We further promote separation in practice depending on the data regime, 
specifically,  the  presence  of  rating  and attribute  information. With unlabeled  (i.e.,  unrated)  data, we 
focus  on  learning  images  and  attributes  without rating  dependency. Because the  generative  likelihood 
and the encoder likelihood do not depend upon the ratings or the parameters of the predictive model, 
we use all labeled and unlabeled images in the neural network for the embeddings. 
For (relatively)  less expensive unlabeled data, we have  access to product attributes (e.g., color, 
brand). Accordingly,  the  encoder log-likelihood, ℒ
푒푛푐
(
 훽
⃗
퐸
)
, differs  from  that  in  Equation  1  because  we 
also learn the relationship between images and their attributes. Thus, in addition to the embeddings, ℎ
⃗⃗
푖
, 
we use  variational  inference  to encode  attribute  information  with 휋⃗⃗
푖
.  Following  the  same  reasoning 
used to derive Equation 1, we obtain the last KL divergence term in the encoder log-likelihood. This term 
acts  as  a  classifier  for  attributes, 푎⃗
푖
, when the attributes  are  known.  We  use  the  classifier to  predict 
attributes  when they  are unknown or  ambiguous (e.g.,  when  generating  new  designs).  See  also 
Appendix A3 and Keng (2017).  
4.3. Deep Neural Networks to Parametrize Variational Probability Models 
We  choose  probability  distributions  for  the  predictive,  generative,  and encoding  models  in 
Equation 3 using the framework of variational autoencoders (VAE; Kingma and Welling 2013). We later 
augment  the  VAE  with  concepts  from  adversarial learning as  used  in  Generative  Adversarial  Networks 
(GANs, Goodfellow et al. 2014).  
Predictive  Model. We  use  a  deep  neural  network, 푓
푃
(
 ℎ
⃗⃗
푖
,훽
⃗
푃
)
,  that  maps  the  embeddings  to  a 
prediction  on  the  rating  of  interest,  say  a  1-to-5 rating on “appeal.” Information  about  the  full  images 
and  attributes is  summarized  in  the  embeddings.  For  the  predictive  model, we   choose  Laplace 
distributions   with   means 푦
푖
 and   unit   diversity, 푝
푝푟푒푑
(
푦
푖
 
|
ℎ
⃗⃗
,훽
⃗
푃
)=
1
2
푒
−|푦
푖
−푓
푃
(ℎ
⃗⃗⃗
푖
,훽
⃗⃗⃗
푃
)|
.   Define 푦̂=
푓
푃
(
 ℎ
⃗⃗
푖
,훽
⃗
푃
)
 as the predicted rating from the neural network, then the predictive distribution implies that 
we minimize the mean absolute error of predicted versus true ratings. 

12 
 
(4) 
ℒ
푝푟푒푑
(
훽
⃗
푃
)
=∑퐸
ℎ
⃗⃗⃗
푖
[log푝
푝푟푒푑
(푦
푖
|ℎ
⃗⃗
푖
,훽
⃗
푃
)]
푖 ∈푟푎푡푒푑
=−∑
|
푦
푖
−푦
푖
̂
|
푖 ∈ 푟푎푡푒푑
 
Generative Model. We use a deep neural network, 푓
퐺
(ℎ
⃗⃗
푖
 ; 훽
⃗
퐺
) that generates candidate images 
from  an  embedding.  We  train  the  model  on  observed  images,  but  use  it  for  both  observed  and  new 
images. We choose the generative model to be a high-dimensional Laplace distribution with means, 푋
푖
, 
and  unit  diversity, 푝
푔푒푛
(
푋
푖
|
 ℎ
⃗⃗
푖
, 훽
⃗⃗⃗⃗
퐺
) ∝ 푒
−|푋
푖
−푓
퐺
(ℎ
⃗⃗⃗
푖
,훽
⃗⃗⃗
퐺
)|
 .  Define 푋
̂
푖
 as  the  predicted  image  from  the 
neural  network  with  elements 푥̂
푖푑
 for each of  the 3퐷 pixels  in that  image  (3D  because  there  are  three 
colors). 
For many products, and vehicles in particular, we help the generative model by using “masks.” A 
mask defines the general nature of a product, say “SUV-like” and is represented as a matrix with the 
same height and width as the product image. The mask’s 퐷 pixels  are  binary  values  describing  the 
presence  of the  product  of  a  general shape. Masks  focus  generative  models  on product  designs  rather 
than other potentially unrelated information in product  images. In the generator, masks are analogous 
to  a  4
th
 color;  they  are  predicted  by  the  same  deep  neural  network  using  the  (now-augmented) 
parameters, 훽
⃗
퐺
. Let 푀 be the mask with elements 푚
푑
 and let 푀
̂
푖
 be the predicted mask with elements 
푚̂
푖푑
. Then, following the same arguments used for pixels, the log-likelihood function for the generative 
model is: 
(5) 
ℒ
푔푒푛
(
훽
⃗
퐺
)
=∑퐸
ℎ
⃗⃗⃗
푖
[log푝
푔푒푛
(
푋
푖
,푀
푖
|
 ℎ
⃗⃗
푖
,훽
⃗
퐺
)]
푖 ∈ 푟푎푡푒푑,푢푛푟푎푡푒푑
 
=−∑
{
1
3퐷
∑
|
푥
푖푑
−푥̂
푖푑
|
푑
+
1
퐷
∑
|
푚
푑
−푚̂
푖푑
|
푑
}
푖 ∈ 푟푎푡푒푑,푢푛푟푎푡푒푑
 
 Encoding Model. We use a deep neural network, 푓
퐸
(
푋
푖
,푎⃗
푖
,훽
⃗
퐸
)
, to map images, 푋
푖
, and product 
attributes, 푎⃗
푖
,  to  an  embedding, ℎ
⃗⃗
푖
, with distributional parameters, 휇⃗
푖
(푋
푖
,푎⃗
푖
) and 휎⃗
푖
(푋
푖
,푎⃗
푖
). Note that 
we omit the (labeled) rating dependency of the encoder as discussed in §4.2, as well as implicitly include 
per-datum variational distributional parameters in 훽
⃗
퐸
 . The estimation is “amortized” into a single neural 
network (Shu et al. 2018). 
For  the  embedding variational  family,  we  choose  multivariate  Gaussian  mixture  distributions 
with  mixture  components depending on product  attributes, 푎⃗
푖
,  (e.g.,  ‘SUV’). In  other  words, an 
embedding, ℎ
⃗⃗
푖
, has a Gaussian mixture marginal distribution, but ℎ
⃗⃗
푖
|푎⃗
푖
 has a single Gaussian conditional 
distribution  given  attributes (Dilokthanakul  et  al.  2016). This expands  a representation  capacity  of  our 

13 
 
model (Ranganath,  Tran,  and  Blei  2015),  without  resorting  to  more  complicated autoregressive  and 
flow-based methods (Chen et al. 2016). 
We further assume  each 퐾-dimensional  Gaussian has diagonal  covariance,  thereby  factorizing 
into 퐾 conditionally independent  Gaussians  in  which 퐾 is  the  dimensionality  of  the  embeddings. If 푘 
indexes    the    elements    of    the    embedding,    then    the    variational    assumption    implies    that 
푞
푒푛푐
(
ℎ
⃗⃗
푖
 
|
 푋
푖
,푎⃗
푖
,훽
⃗
퐸
)∝
  
∏
휎
푖푘
−1
푒
−
1
2
(
ℎ
푖푘
−휇
푖푘
)
2
휎
푖푘
−2
퐾
푘=1
where  the 휇⃗
푖
 and 휎⃗
푖
 are  functions  of 푋
푖
, 푎⃗
푖
,  and 훽
⃗
퐸
. 
Using known formulae for 퐷
퐾퐿
(풩
(
휇
푖푘
,휎
푖푘
)
 || 풩
(
0,1
)
), we obtain a simpler representation for the first 
divergence term in the encoder log-likelihood (Kingma and Welling 2013). 
For the second divergence term in the encoder log-likelihood, we show in Appendix A3 that we 
may  approximate 퐷
퐾퐿
(
푞
푎푡푡푟
(
휋⃗⃗
푖
|
푋
푖
,훽
⃗
퐸
)
|| 푝
푎푡푡푟
(휋⃗⃗
푖
|푎⃗
푖
)
)
≅푐표푛푠푡푎푛푡− log푞
푎푡푡푟
(
푎⃗
푖
|푋
푖
,훽
⃗
퐸
)
. This  results 
in  the  encoder  acting  as  a  multinomial  classifier, 푞
푎푡푡푟
(
푎⃗
푖
|푋
푖
,훽
⃗
퐸
)
, to  predict  attributes  from  product 
images. Specifically,  we  have 퐶 multinomial  distributions,  where 퐶 is  the  number  of  attributes  (e.g., 
brand, bodytype) and ℓ
푐
 is the number of levels of attribute 푐 (e.g., Cadillac). 
The  encoder  neural  net  for 휇⃗
푖
 and 휎⃗
푖
 thus  also  produces 휋⃗⃗
푖
,  from  which  we  draw  Dirichlet 
probabilities, 푎̂
푖
=푞
푒푛푐
(
휋⃗⃗
푖
|푋
푖
,훽
⃗
퐸
)
, using a soft-max function. We recognize 퐸
휋
⃗⃗⃗
푖
[
log푞
푒푛푐
(
휋⃗⃗
푖
|푋
푖
,훽
⃗
퐸
)]
 as 
the  cross-entropy  for  a  draw  of  the  attributes, 푎⃗
푖
,  from  the multinomial  probabilities, 푎̂
푖
.  This  provides 
the  second  term  in  Equation 6.  This  term  rewards the  encoder  for  its  ability  to  predict  the  attributes 
based on the images. During training, this term encourages the encoder to learn attributes, while during 
prediction  (when  we  do  not  know  attributes)  this  term  allows  us  to  estimate  unknown  product 
attributes, 푎̂
푖
, by sampling from the multinomial distribution indexed by 휋⃗⃗
푖
. Putting both terms together 
we obtain: 
(6) 
ℒ
푒푛푐
(
 훽
⃗
퐸
)
=∑
{
∑
[
1
2
(
휇
푘푖
2
+휎
푘푖
2
)
−log휎
푘푖
−
1
2
]
퐾
푘=1
+∑∑푎
푖푐ℓ
log푎̂
푖푐ℓ
ℓ
푐
ℓ=1
퐶
푐=1
}
푖∈ 푟푎푡푒푑,푢푛푟푎푡푒푑
 
4.4. Adversarial Formulation, Generative Adversarial Network (GAN) Modification  
Equations  3  through 6 specify  a  set  of  log-likelihood  functions  for  the  neural  networks  that 
together compose the VAE in Figure 2. The log-likelihoods balance the ability to predict ratings, generate 
new   images,   and   represent   images   by   embeddings.   But   to   be   effective   for machine   learning 
augmentation,  we  require  that  the  embeddings  encode and generate  images  well.  For  example,  if  we 
are generating luxury crossover utility vehicles (luxury CUVs), the images should look like well-designed 
luxury  CUVs. After  extensive  experimentation  and  tuning,  we  found  it  necessary  to  augment  the  VAE 

14 
 
using the concept of adversarial training found in generative adversarial networks (GANs). We note our 
extension is similar to concurrent work by Heljakka, Solin, and Kannala (2019). 
The basic idea is that we reward the generative model for generating images that  are  different 
than  the  prior,  but  we  reward  the  encoder  if  it  can  distinguish  a  generated  image  from an  observed 
image because it is too far from the prior. The GAN is implemented with competing objectives—a term 
in the generative model is the negative of a term in the encoder. Because the generator and encoder are 
trained iteratively, the generator and encoder reach a min-max  solution to a two-player game. That is, 
we converge to a fixed point where generated images and actual images are both encoded to the same 
embedding space (Goodfellow et al. 2014).  
We  augment  the  variational  autoencoder  with the  adversarial  training concept  from GANs,  by 
adding  the  following  term  to  the likelihood  of  the  encoder  to  reward  the  encoder  for  distinguishing 
generated  images  from  observed  images.  We  subtract  the  same  term  from  the  log-likelihood  of  the 
generator  to  reward the  generator  to  produce  images  that  are  hard  to  distinguish  from  observed 
images. These  terms  do  no  simply  cancel  out  as  we  iteratively  train  the  encoder  and  predictor  while 
fixing  the  generator,  and vice versa. We  use  the  methods  of  §4.4  to  simplify  this expression  with 
normally distributed prior and posterior distributions to obtain an analog to Equation 6. 
(7) 
∑퐷
퐾퐿
(푞
푒푛푐
(
ℎ
⃗⃗
푖
|푋
푖
,푎⃗
푖
,훽
⃗
퐸
)
||푝
푝푟푖표푟
(
ℎ
푖
⃗⃗⃗⃗
|푎⃗
푖
)
) 
푖 ∈푔푒푛푒푟푎푡푒푑 푖푚푎푔푒푠
 
This approach to adversarial training differs from conventional GANs in that we are not learning 
an implicit generative model by rewarding a “discriminator” (i.e., the analogue of the encoder in our 
work) to classify images as real or generated. We instead perform adversarial training in the embedding 
space much like feature matching and perceptual similarity approaches (Larsen, Sønderby, and Winther 
2015). We maintain the probabilistic  interpretation  using  the  Kullback-Leibler  divergence  term  rather 
than previously-used feature matching on point estimates conceptually similar to Huang et al. 2018). 
4.5. Synthesizing the VAE, Adversarial (GAN-like), and Neural Network Loss Function Perspective 
§§4.1-4.3  used  the  perspective  of  VAEs  and  probability  models  to  derive  an  approximate 
separable likelihood function, the components of which are based on deep neural networks. These VAE 
components  may  be  viewed  as  combining  semi-supervised  VAEs (Kingma  et  al.  2014) with  conditional 
VAEs (Sohn,  Lee,  and  Yan  2015).  In  §4.4  we  augmented  the  VAE  perspective  with  adversarial  methods 
(GANs) to encourage the generator to generate recognizable new images while encouraging the encoder 
to  recognize  generated  images  as  generated  rather  than  observed. In  contrast  to typical  VAE-GAN 

15 
 
approaches (Larsen,  Sønderby,  and  Winther  2015; Zhao  et  al.  2016; Berthelot et  al.  2017), adversarial 
autoencoders (Makhzani et  al. 2015) and adversarial generative  encoders (Heljakka, Solin, and Kannala 
2018;  Ulyanov,  Vedaldi,  and  Lempitsky  2018),  we retain the  probabilistic interpretation of  the VAE 
viewpoint  as  our  adversarial  losses  are  motivated  by  divergences  of  the  embedding  distribution. The 
combined  approach  improves  embeddings  and  minimizes “posterior collapse” in VAEs;  our  model 
converges and the embeddings differ from the priors. 
Table  1  summarizes  the  log-likelihood  functions  as  loss  functions  comparable  to  more  typical 
neural  network  frameworks.  We  do  so  recognizing  that 푙표푠푠
(
훽
⃗
푃
,훽
⃗
퐺
,훽
⃗
퐸
)
= − ℒ(훽
⃗
푃
,훽
⃗
퐺
,훽
⃗
퐸
). Table  1 
further indicates which images are included in summations. 
5. Moving from Theory to Practical Implementation 
The  basic  structure  of  our  machine  learning  augmentation  is  derived  by  using  deep  neural 
networks to approximate separable log-likelihood functions. From this perspective, our augmentation is 
a VAE modified with an adversarial (GAN) component. We differ from most VAEs and GANs because we 
include  as  well  information  from  product  ratings,  product  attributes,  and masks,  all  three of which  are 
necessary  to  enhance  predictive  ability  and  generate  realistic  new  aesthetic  designs.  But  given  the 
challenges discussed in §2, we must further customize and “tune” the model. 
5.1. Custom Deep Learning Architecture 
 Many deep learning models are trained for one application (e.g., object detection) and modified 
for another application (e.g., aesthetic rating prediction), often referred to as “transfer learning” 
(Evgeniou and Pontil 2004). Such customized models have proven effective on image data for identifying 
product returns and brand identity (Dzyabura et al. 2019; Liu, Dzyabura, and Mizik 2019), and on textual 
data  for  identifying  customer  needs  and  predicting  sales  conversion (Liu,  Lee,  and  Srinivasan 2019; 
Timoshenko and  Hauser  2019).  Unfortunately,  we  were  unable  to  identify  any pre-trained models  that 
generate new highly-rated automotive images and which would be controllable in a manner that may be 
used  by  designers  (e.g.,  morph  Brand A  sedan  with  Brand B  sport-utility  vehicle).  The  demands  of 
interconnecting   attributes,   masks,   ratings,   high-resolution   images,   and   adversarial   training   for 
generation  together  require  a  custom  deep  learning  architecture  trained  on  unique  data.  Because  the 
custom deep learning model required substantial “tuning,” we were careful to hold out data for model 
evaluation.  We  randomly  split  data  into  training,  validation,  and  testing  sets  using  a  seeded  random 
number  generator  for  reproducibility.  Validation  data  were  used  to  set  model  hyperparameters  (e.g., 
learning rates) and monitor training progress. Testing data were used only for model evaluation. 

16 
 
Table 1. Predictive, Generative, and Encoding Loss Functions (where loss = – log-likelihood) 
 Loss Function Intuition 
Predictive Model (summed over rated images) 
|
푦
푖
−푦
푖
̂
|
 
Laplace term rewards the predictor for predicting ratings.  
Generative Model (summed over rated, unrated images, or, when indicated, generated images) 
1
3퐷
∑
|
푥
푖푑
−푥̂
푖푑
|
푑
 
Laplace term rewards generator for predicting images that 
are close to true images. 
1
퐷
∑
|
푚
푖푑
−푚̂
푖푑
|
푑
 
Laplace term rewards generator for predicting masks that 
correctly segment the design within the image. 
∑
[
1
2
(
휇
푘푔
2
+휎
푘푔
2
)
−log휎
푘푔
−
1
2
]
퐾
푘=1
 
Adversarial term rewards the generator for images that 
are drawn from the same distribution as observed images. 
Summed over generated images only (푔). 
Encoding Model (summed over rated, unrated images, or, when indicated, generated images) 
∑
[
1
2
(
휇
푘푖
2
+휎
푘푖
2
)
−log휎
푘푖
−
1
2
]
퐾
푘=1
,  
 
휇⃗
푖
,휎⃗
푖
=푓
퐸
(
푋
푖
,푎⃗
푖
,훽
⃗
퐸
)
 
KL divergence rewards the encoder for embeddings close 
to the prior. 
−
∑∑
푎
푖푐ℓ
log푎̂
푖푐ℓ
ℓ
푐
ℓ=1
퐶
푐=1
,
,  푎̂
푖
=푓
퐸
(푋
푖
,훽
⃗
퐸
) 
Cross entropy rewards encoder for predicting attributes 
from images. 
−∑
[
1
2
(
휇
푘푔
2
+휎
푘푔
2
)
−log휎
푘푔
−
1
2
]
퐾
푘=1
 
Adversarial term rewards encoder for distinguishing 
generated images from observed images. Summed over 
generated images only (푔). 
 
 Figure  3  summarizes  the  deep neural network  architectures  for the  predictive,  generative,  and 
encoding  models.  Each  architecture  is based  on many modeling  decisions (and tuning). To  simplify the 
description of the architectures, Figure 3 uses “blocks” of neural network “layers.” The  layers  in  each 
block are given at the top of Figure 3. Each of these layers (e.g., 2D convolution) performs the indicated 
operations  on  “features”  from  the  previous  layers.  For  example,  2D  convolution  applies  two-
dimensional  filters  to  the  input  in  an  analogy  to  neuronal  receptive  fields (Olshausen  and  Field  1996). 
We  use  spectral normalization as  a  regularization  technique  to control  the  magnitude  of  gradients 

17 
 
during model training (see §5.3). A leaky rectified linear layer acts as a nonlinear activation function to 
transform values from the previous layer, thereby enabling the neural network to learn complex feature 
interactions. A residual connection simply adds the original input from the first layer of the block to the 
now transformed features at the end of the block. In doing so, the intermediary layers learn the residual 
error  from  the  previous  block. 2D  average  pooling  reduces  the  dimensionality  of  the  previous  layer  by 
down-sampling patches of 2D features to a single value. 
Figure 3. Deep Neural Network Architectures for Predictive, Generative, and Encoding Models 
 
 
5.2. Progressive Training 
The rows in Figure 3 corresponding to the generative and encoding models enhance generation 
and encoding with a “progressive structure” as detailed in (Karras et al. 2017). In a progressive structure, 
we start at low resolutions, then increase resolution in stages and retrain the blocks until we reach the 
target image resolution of 256 x 256 pixels (three colors plus the mask). We label the resolution stages 
by  height and  width,  say  4  x  4  pixels  or  32  x  32  pixels.  When  the  model  is  trained,  we  obtain  lower 

18 
 
resolution  images  by  down-sampling  from  the  full  image.  The  input  and  output  image  resolutions  are 
given by the corresponding block. For example, we obtain 32 x 32 images as the 4
th
 block in the encoder 
model. During generation, at  each stage in the progressive  structure, the  immediately lower resolution 
image is blended with the stage’s resolution according to an annealing schedule, in which the trained 
image  progressively  includes  less of  the  low  resolution  image.  Both  the  encoder  and  generator  sample 
for multiple  iterations  before  moving  to  next  resolution—the  number  of  samples  is  a  hyper-parameter 
set  using  the  validation  data.  The  advantage  of  a  progressive  structure  is  that,  as  the  model  learns  to 
encode  or  generate,  it  maintains  knowledge  from  previous  images  effectively. Rather  than  starting 
model  training  from  a  completely  blank  slate  at  full  resolution,  the  model  has  already  learned 
information about the product design at lower resolutions.  
5.3. Stabilization and Tuning of Model Training 
Deep learning models do not always have well-behaved parameter estimation procedures. This 
is especially true for the models in Figure 3, which feature  complex deep learning models that balance 
multiple  competing  and/or  adversarial  loss  function terms.  We  therefore  seek  to  avoid  unbounded 
“back-propagated” gradients that lead to catastrophic failures in model training (e.g., outputting images 
of  only  black  pixels).  We  stabilize training  with  the  spectral  normalization  layer  in  each  block.  This 
promotes Lipschitz continuity to regularize  the model by dividing the raw output  weights of each layer 
by the largest singular value of the matrix of weights. See Miyato et al. 2018. We also manually enforce 
both  soft  and  hard  constraints  on  portions  of  the  model  architecture. For  example,  we  bound the 
variance of the Gaussian random variables in the KL-divergence terms and use floating point safeguards 
to  ameliorate  the potential numerical  instability  introduced in  §4 by  the  logarithms  and  various 퐿
푝
-
norms. 
We  tune  model  training  by  scaling  the  contribution  of  each  loss  term  in  Table  1  to  its 
corresponding encoder, generator, or predictor loss with user-defined multiplicative scaling terms. This 
creates  a  balancing  act  between  the  seven  loss  terms  given  their  endogenous  interdependency  during 
training.  Further  tuning  is  often  domain  specific  (e.g.,  the  scaled  importance  of  the  vehicle  body style 
versus  relative  to  its  orientation). Empirically  we  found  that  the  KL-divergence  loss  terms  were  best 
scaled to 1/10 or less relative to the loss terms for reconstructing images reconstruction loss, as well as 
annealed from zero at start of training to a maximum value after model convergence. 
We  stabilize  model  training  by  tuning  the  rate  at  which  the  competing  models  are  updated. 
Empirically,  we  found  that  the  generative  model  must  be  updated  substantially  more  often  than  the 
encoding model; from 10 times as much to as little as two. We found that this ratio depends empirically 

19 
 
on the stage of model training. This may be unique to our application which combines likelihood-based 
VAE  with  adversarial  training.  Typically, generative GAN models  are  updated  less  often  than  encoding 
models (Arjovsky,  Chintala,  and  Bottou  2017) and  benefit  from  unequal  learning  rates (Heusel  et  al. 
2017). By contrast our training ratio favors minimizing 퐷
퐾퐿
(푝|푞) rather than 퐷
퐾퐿
(푞|푝). 
5.4. Gradient Backpropagation Using Local Reparameterization 
We  train  the  model by  minimizing  the  loss  functions  in  Table  1  with  first-order  stochastic 
gradient methods using mini-batches of training data. Specifically, we use the Adam stochastic gradient 
optimizer (Kingma  and  Ba  2015).  Stochastic  gradient  methods  are  justified  given their  empirical 
performance and scalability via the backpropagation algorithm. Backpropagation simplifies an otherwise 
large  calculation  of  a multi-parameter gradient  to  an  equivalent  series  of  smaller  iterative  gradient 
calculations. Gradients  for  a  given loss  in  Table  1  propagate  from  the  layer  calculating  the  loss 
backwards to “earlier” layers, thereby taking advantage of the compositional structure of network layers 
and the chain rule of differentiation (Lagrange 1797). 
To use gradient methods, we employ the “reparameterization trick” used in Kingma and Welling 
(2013). We rewrite   the   otherwise   intractable   gradient   of an expectation   over   the   embedding 
distribution  (Equation  3  and  Equation 7)  to  an  equivalent  tractable  formulation  by  splitting  the 
stochastic Gaussian embedding distribution into a deterministic neural net and an independent additive 
stochastic  term. With  this simplification we more easily  compute  an unbiased estimate  of  the  gradient 
using  Monte  Carlo  samples  of  the  independent  additive  term. We  similarly  use  this  reparametrization 
trick when we do not have access to product attributes during training and inference. In this case we use 
a  relaxation  of  the  otherwise  non-differentiable  categorical  attribute  variables  called  the  Gumbel-
Softmax (Jang, Gu, and Poole 2016). 
6. Case Study: Aesthetic Design of U.S. Automotive Market SUV/CUVs 
Our machine learning augmentation has two goals (1) predict consumer evaluations of aesthetic 
designs (ratings) for a sample of proposed designs created and tested by an automotive partner and (2) 
generate new aesthetic designs that are likely to be rated highly. As an initial test of the proposed model 
(Figure  2)  we  evaluate  (1)  whether  the  trained  VAE/GAN  model  can  predict  ratings  of  SUVs  and  CUVs 
that  were  evaluated in our partner’s theme clinics and (2) whether high-predicted-appeal  designs 
generated by the VAE/GAN model are rated highly and low-predicted-appeal designs are rated poorly. 
6.1. Data: Images Rated in Theme Clinics 
We obtained aesthetic ratings for images of the 203 unique SUVs/CUVs from model years 2010-

20 
 
2014 (MY2010-14) tested in our partner’s theme clinics. Our partner collected ratings from 178 targeted 
consumers in  one  of  their  theme  clinics. Following  established  procedures  for  their  theme  clinics,  our 
partner targeted consumers who were rigorously screened and selected to be interested in purchasing 
in the target category. Respondents were incentive aligned using our partners’ standard methods, both 
fiscally and with knowledge that their input would guide future aesthetic design. 
Ratings  were  obtained  from  a  web-based  survey  co-located  with  the  theme  clinic.  Warm-up 
questions  motivated   respondents   (credibly)  that   their   ratings   would   affect   aesthetic   design   and 
introduced our partner’s standard pairwise-semantic-differential rating-scale (most unappealing to most 
appealing). We anchored respondents’ ratings by asking each respondent to rate five pre-chosen  pairs 
of images—prechosen in pretests to be most divisive on the pairwise ratings scale. The five image pairs 
were the same for all respondents, but randomly counterbalanced between respondents. 
Respondents each rated ten  sequential  pages  of  SUVs/CUVs  in which  each  page  contained  five 
images.  To  test  respondent  consistency,  the  2
nd
 and  8
th
 page  and  the  3
rd
 and  9
th
 page  contained  the 
same  images  randomly  ordered.  After  extensive  pretesting,  the  survey  was  implemented  by  our 
automotive partner. To maintain consistency among images and mitigate image-color biases, all images 
were reduced to greyscale and shown with a side viewpoint. (Unrated and generated images are three-
color.) Appendix A4 provides an example rating page. 
To  maintain  data  quality prior  to  any  further  analysis,  we  eliminated  respondents  who  were 
judged to be inconsistent based on Krippendorf’s 훼 where 훼= 1 – (observed disagreement among like 
images)/(expected disagreement due to chance). Krippendorf’s 훼 is a generalization of other interrater 
reliability measures such as Fleiss’ 휅 and Cohen’s 휅 (Krippendorff 2011). The cutoff was 훼= 0.75, which 
eliminated 38 respondents (21%). 
Ratings from consistent users were aggregated to a mean value for each of the 203 unique SUVs 
in MY2010-14, which were assigned to corresponding vehicle viewpoints to result in a full data of 7,308 
rated  images by  giving  the  same  mean  rating  to  all  viewpoints. We randomly split  the  full  data  into 
training, validation, and testing data at a ratio of 50%:25%:25%. (Same-model SUVs and CUVs remained 
together to ensure that validation or testing information did not leak into the training data.) 
6.2. Data: Unrated Full-Color Images 
 Although  high-quality  full-color  images  are  readily  available  on  the  web,  almost  all  of  these 
images are copyrighted and could not be used without permission to train our model. Fortunately, high-
quality images are available from aggregators and are used often by automotive firms in their marketing 
communications. The typical cost is about $50,000 per month. We obtained 180,000 unrated SUV/CUV 

21 
 
images from our partner firm and a proprietary (unnamed) aggregator. All images were rescaled to 256 
x 256  pixel  images  and  included  several  attributes. We  used  conventional computer  vision  tools to 
obtain masks and attributes that were not coded by the firm, such as color and viewpoint. 
7. Evaluation of the Machine Learning Augmentation 
7.1. Predictive Ability 
 We  evaluate  the  model  on the 1,836  rated  images  in  the  held-out  testing  set. Table  2  reports 
the  mean  absolute  error  (MAE)  for  predicted-versus-actual ratings  on  the  held-out  data.  Our  model 
predicts  well  with  a  MAE  of  0.372 of  a  scale  point.  Figure  4  provides  example  predictions  for  eight 
SUVs/CUVs. To put the MAE of the predicted model in perspective, we compare its predictive ability to a 
series  of  baseline  models  that  vary  from  naïve  to  sophisticated, we used  the  same  training  and 
validation  data  to  develop  the  benchmarks  and  spend  considerable  effort  optimizing  the  sophisticated 
benchmarks so that the benchmarks provide a meaningful comparison. 
 Naïve  baselines.  The  most  naïve  baseline  is  that  respondents  select  the  scale  midpoint.  This 
baseline represents zero  information. A  less naïve  baseline  uses  global  information  from  the  training 
respondents by assuming that all variation about the median (average) rating is noise. 
Sophisticated  benchmark 1:  Random  Forest  and Computer  Vision Features. Computer  vision 
and  machine  learning  have a  long  history  of  processing  high-dimensional  image  and  video  data  for 
object  detection  and  image  segmentation. Conventional methods reduce  high-dimensional  visual  data 
to a small set of “hand engineered” features chosen based on experience of successful prediction. These 
features are used in conventional machine learning methods such as support vector machines. 
Our benchmark  uses three  types  of  hand-engineered  features  from  computer  vision: (1) 
Histogram  of  oriented  gradients  (HOG) features encode  edge  and  shape  information. HOG  features 
divide the  image  into  a  grid  of  image  patches,  calculate the  gradients  of  each  patch,  and  bin  these 
gradients  into  a  histogram. Edge orientation and shape intensity are contained in the gradients’ 
direction and magnitude values. (2) A downscaled version of the image itself (e.g., 256 x 256 to 32 x 32). 
And (3) histograms of color values for each red, green, and blue image channel. These features are used 
in a  random  forest with  100  trees. We  chose  a random  forest because it performed  best  when  tested 
against  other common machine  learning  approaches: support  vector machines,  Gaussian  process 
regression, and L1/L2-regularized linear regression. 
Sophisticated benchmark 2: Pre-trained Deep Learning Model. Many researchers in marketing 
(and  machine  learning) use “pre-trained” open-source neural  networks  trained  for  one  prediction  task 
and repurposed  for another prediction  task.  As  a  sophisticated  benchmark,  we  used  the  pre-trained 

22 
 
VGG16 deep  learning model  trained  on  the  ImageNet  database.  This  benchmark outperformed  other 
common pre-trained models (e.g., ResNet50, InceptionV3) for our prediction task. The VGG16 model is a 
pyramid  of  sixteen  stacked  layers  (13  convolutional  and  3  fully  connected)  that  sequentially  reduce 
images in size until they are classified in the last layer. 
The  initial  layers  of  VGG16  transform  pixels  to  edges  and lines  found  in  visual  images. For  our 
benchmark,  we maintain  the  initial  layers  and  replace  the  last  classification  layer  with  two  batch-
normalized  fully-connected  rectified-linear layers  followed by a regression layer. (This architecture  was 
chosen using validation  data.) We  train  the  model  in  two  steps.  We  first  freeze  the  pre-trained  layers 
and use our data to train the new layers. We then fine-tune the entire neural network with scaled-down 
back-propagated gradients. The two-step procedure improves the benchmark’s prediction.  
Results. The  proposed machine  learning augmentation  outperforms  both the  naïve baselines 
and the sophisticated benchmarks. The improvements are substantial. The sophisticated benchmarks do 
well  relative  to  the  naïve  benchmarks  and the  proposed  VAE/GAN  deep-network  does  well  relative  to 
the sophisticated benchmarks.  
Table 2. Predictive Test of Machine Learning Augmentation versus Baselines and Benchmarks 
Prediction Model Mean Absolute Error (std. dev.) Improvement 
Baseline: Scale Midpoint (Zero Information) 
0.601  
(n/a) 
0.0% 
Baseline: Median Rating in Training Images 
(Best Uniform) 
0.603 
(n/a) 
~0.0 % 
Benchmark: Computer Vision Features and 
Random Forest (Conventional Machine Learning) 
0.450 
(0.003) 
25.3 % 
Benchmark: VGG16 with Fine-Tuned Final Layers 
(Pre-trained Deep Learning) 
0.434 
(0.008) 
28.0% 
Proposed Machine Learning Augmentation 
(Custom Deep Learning) 
0.372  
(0.004) 
38.3 % 
 

23 
 
Figure 4. Examples of Predictive Accuracy for Machine Learning Augmentation 
 
7.2. Generative Capability 
From  embeddings  to  images.  Our  first  test  is  whether  or  not  the  embeddings  (and  attributes) 
can  create  credible  product  aesthetic  images.  We  begin  by  sampling  points  in  the  embedding  space, 
conditioned on desired attributes, then moving smoothly around that space. Each sampled point is on a 
hypersphere,   such   that   interpolation   is   smooth   in   spherical   coordinates. For   each   point   in   the 
embedding space, we generate a high-dimensional image. We judge that the images are realistic and are 
valuable  inputs  to  the  design  team  given  their  ability  to  be  controllably  morphed.  We  provide  a 
demonstration video at https://vimeo.com/334094197. 
Consumer  evaluations. To  test  consumer  reaction, we generated  50 targeted  images: 25  were 
predicted by  the  VAE/GAN to  be  rated highly and  25  were  predicted  to  be  rated poorly.  Figure  5 
provides examples of generated images of each type. For consistency, we generated each image to be a 
light  gray  SUV/CUV  from  the  side  view. We  added  diversity  with  masks  from other  body  styles  (e.g., 
sedans, hatchbacks). The generated designs were morphed slightly to ensure plausibility by respondents 
and to mitigate the effect of biases (Lopez, Miller, and Tucker 2019). Using the methods of §6.1, we used 
181 respondents  from  a  professional Internet panel (ProdegeMR,  at  $4  per  respondent) to  rate  these 
images. Using  industry  standards,  we  screened  respondents to be SUV/CUV “intenders.” To  maintain 
quality,  we  pretested  the  survey  carefully.  Prior  to  any  data  analysis,  following  best  market-research 
practices, we used “trap” questions to eliminate professional respondents, consistency checks to 
eliminate   inattentive   respondents,   and   response   timings   (and   pattern   checking)   to   eliminate 

24 
 
respondents who were just “clicking through.” In total, we eliminated 53% of the initial 385 respondents 
who began the survey. 
Respondents generally preferred images that were predicted to be rated high over images that 
were predicted to be rated low. In our data, respondents confirmed our predictions 74.0% of the time, 
well above random. We are encouraged by this initial test. 
Figure 5. Example Generated Images (See also https://vimeo.com/334094197) 
 
8. Conclusion 
8.1. Discussion and Summary 
 Deep learning methods are beginning to affect all aspects of marketing science, sometimes with 
methods  customized  to  the  challenge,  sometimes  by  using  tuned  pre-trained  models.  Many  of  these 
methods  rely  on  hard-to-quantify unstructured data  such  as  natural  language  or  images.  We  focus  on 
consumers’  aesthetic  judgments  by  using  state-of-the-art   machine   learning   to   augment   human 
judgment.  The  augmentation  comes  in  two  forms.  First, we predict  consumer  evaluations  of new 
potential aesthetic designs  from  images.  Second,  we controllably generate  new  SUV/CUV  images  to 
enhance creative design. 
 These  goals  are  challenging.  We  developed  a machine  learning augmentation  that  combines 
many  concepts.  We  derive  a version  of  the semi-supervised VAE from  a  probabilistic  perspective  to 
maximize  the  likelihood  that  an  image  is  encoded  well  and  rated  as  predicted,  while  using  a  low-
dimensional embedding to “bottleneck” information between a predictive and generative model. Within 
the  VAE  framework,  we  include  attributes  to  carry  information  about  images  and  masks  to  constrain 
target  images  to  be  realistic.  We  add adversarial training  concepts  from the GAN literature to improve 

25 
 
training of realistic generated images while retaining VAE probabilistic interpretation so that the output 
does not  collapse  to  known  images.  Finally,  we  use  a  variety  of  engineering  ideas  (e.g., spectral 
normalization, progressive  training, residual  connections,  adaptively balanced training losses)  to  tune 
the deep learning model so that it is able to properly converge during training. The end result is a model 
that   predicts   image   ratings   substantially   better   than   other machine   learning benchmarks   and 
controllably generates images that are perceived as valuable boosts to creativity. 
An important contribution is our modeling decisions that address key managerial issues required 
for using machine intelligence within existing design processes. These contributions are a key difference 
of  our  work  when  contrasted  with  recent  deep  learning  approaches;  e.g., (Kang  et  al.  2017;  Pan  et  al. 
2017; Vasileva et al. 2018, Sbai et al. 2019) and the review  by (Deng, Loy, and Tang 2017). We  address 
the  delicate  integration  between  machine  intelligence  and  existing  human  workflows,  a  point  stressed 
heavily  in  our  working  interactions  with  marketing  and  design  professionals. We focus on augmenting 
rather automating human  expertise  and  human  creativity, and ensuring all  models  are meaningfully 
controllable   by   the   respective   teams   within   the   firm. For   example, conditional   independence 
assumptions  enable full model  decomposition into the  predictive  and  generative  models,  allowing 
iterative  and  asynchronous  training  and  usage  by  teams. Another  example includes  deriving  our  work 
from the VAE probabilistic  framework rather  than  GANs,  trading  off  generative  realism  for  generative 
diversity for creative design. 
The  second  managerial  issue  we  address  is  the  relatively  limited  amount  of  rated  data  on 
product images and aesthetic ratings. This was due to the expense required to collect rated data as well 
as  show  many  unique  designs  exist; our rated data  on new-SUV/CUV  design  images were only  203 
unique SUV/CUVs over five years of theme clinics. If we were to train the deep learning model on these 
images  alone,  the embeddings  and  the  generative  capability  would  be  weak if  not  impossible. We 
overcome  this  issue  using  semi-supervised  learning  to combine the expensive rated “small data,” with 
the inexpensive and significantly larger “big data” of unrated images. Combining small data and big data 
made it feasible to train a deep learning model that does well on the theme-clinic-based data found in 
firms. 
8.2. Limitations and Further Research 
 The SUV/CUV application is a proof-of-concept developed to augment a real automotive design 
team. New  vehicles  take  many  years  and  $1-5  billion  in  investment (Blonigen,  Knittel,  and  Soderbery 
2013). Over  time  we  will  learn whether machine  learning augmentation  has  documented  monetary 
benefits. Directly assessing the financial value of aesthetics is challenging given its interrelatedness with 

26 
 
confounding factors such as functional attributes, brand identity, and aesthetic trends (Person, Snelders, 
and  Schoormans  2016). Recent  promising  work  into  disentangling  these  factors  includes  those  that 
explicitly control of covariation in functional and form attributes (Kang et al. 2016; Zhang et al. 2019), as 
well as those  that temporally model aesthetic trends (Yoganarasimhan 2017). For now, our work relies 
on  predictive  statistics  and  human  judgment  for  validation.  We  hope  that  other  researchers  will  test 
machine  learning augmentation  in  other  industries,  perhaps  industries  in  which  the  new  product 
development cycle is shorter and less expensive. 
 Our model was engineered to be effective for vehicles after a heavy degree of engineering and 
model tuning,  with  much  of  the  engineering  challenge coming from  the  combination  of  VAE  and  GAN 
concepts. Many recent deep learning advances have focused on design generation using GANs, and, as a 
result,  lack  the  latent  space  structure  needed  for  the  predictive  model. When  generation alone is  the 
primary  goal,  GANs  tend  to  outperform  other  models  including  VAEs  and  flow-based  approaches;  we 
direct  readers  to  recent  GAN  applications  for  aesthetics (Kang  et  al.  2017;  Pan  et  al.  2017;  Sbai  et  al. 
2019). 
A natural next step is to assess the degree to which the proposed approach augments designer 
creativity. While perhaps less straightforward to measure, similar questions have seen recent marketing 
interest in applications such as idea generation (Toubia and Netzer 2017). Assuming our efforts continue 
to be guided by real design needs and managerial problems, this trend of various research streams being 
integrated bodes well for a future of hybrid human and machine intelligence.  

27 
 
Appendices 
A1. Summary of Notation 
푖,푗 indexes product images 
푑 
indexes dimension of high-dimensional image space (i.e., a pixel) 
푘 
indexes dimension of low-dimensional embedding 
푐,푙 
indexes c
th
 product attribute (e.g., brand) with 푙 attribute levels (e.g., Cadillac) 
푋
푖
 
product image 푖 
푥
푖푑
 
pixel 푑 of product image 푖  
푋
̂
푖
 
product image (generated) 
푥̂
푖푑
 
pixel 푑 of product image 푖 (generated ) 
푦
푖
 
aesthetic rating (known) 
푦̂
푖
 
aesthetic rating (predicted) 
ℎ
⃗⃗
푖
 
product embedding vector 
푎⃗
푖
 
product attributes vector (if known) 
푎̂
푖
 
product attributes vector (predicted) 
푀
푖
 
product mask (if known) 
푚
푖푑
 
pixel 푑 of mask for product 푖 
푀
̂
푖
 
product mask (generated) 
푚̂
푖푑
 
pixel 푑 of mask for product 푖 (generated) 
A2. Derivation of Approximate Log-Likelihood in Equations 1 
§4.1 decomposed 푝(푦
푖
,푋
푖
|푎⃗
푖
,훽
⃗
), the  joint likelihood  of  a  product  image, 푋
푖
,  and  its  aesthetic 
rating, 푦
푖
,  conditioned  on  product  attributes, 푎⃗
푖
, into  the  predictive  model  and  generative  model. We 
seek to  maximize  the  log-likelihood, log푝
(
푦
푖
,푋
푖
|푎⃗
푖
,훽
⃗
)
, for every datum 푖 in  our  training  data  with 
respect  to  the  model  parameters 훽
⃗
.  However,  parameter  estimation  and  inference  of  this  high-
dimensional   likelihood   is   an   intractable   problem. Instead we approximate the likelihood   using 
variational inference. We  first  assume  the  existence  of  low-dimensional  latent embeddings, ℎ
⃗⃗
푖
.  We 
introduce ℎ
⃗⃗
푖
 via marginalization of ℎ
⃗⃗
푖
 over the  joint  density in the second line  of (A.1). We expand this 
density to the predictive model and generative model as well as a prior over the product embedding. 
(A.1) 
log푝
(
푦
푖
,푋
푖
|푎⃗
푖
,훽
⃗
)
 
=log∫푝
(
푦
푖
,푋
푖
,ℎ
⃗⃗
푖
|푎⃗
푖
,훽
⃗
)
dℎ
⃗⃗
 

28 
 
=log∫푝
푝푟푒푑
(
푦
푖
|ℎ
⃗⃗
푖
,훽
⃗
)
푝
푔푒푛
(
푋
푖
|ℎ
⃗⃗
푖
,훽
⃗
)
푝
푝푟푖표푟
(
ℎ
⃗⃗
푖
|푎⃗
푖
,훽
⃗
)
dℎ
⃗⃗
 
We seek to learn an embedding distribution rather than just  a point estimate of ℎ
⃗⃗
푖
. We  do not 
explicitly  assume  this  form  of  the  new  joint  density  with  the  introduced product  embedding, ℎ
⃗⃗
푖
,  and 
instead  introduce  a  tractable  distribution  which  we  will  use  to  approximate  it, 푞
푒푛푐
(
ℎ
⃗⃗
푖
|푋
푖
,푎⃗
푖
,훽
⃗
)
, 
resulting in the “encoder model.” 
(A.2) 
log∫푝
푝푟푒푑
(
푦
푖
|ℎ
⃗⃗
푖
,훽
⃗
)
푝
푔푒푛
(
푋
푖
|ℎ
⃗⃗
푖
,훽
⃗
)
푝
푝푟푖표푟
(
ℎ
⃗⃗
푖
|푎⃗
푖
,훽
⃗
)
dℎ
⃗⃗
 
=log∫
푝
푝푟푒푑
(
푦
푖
|ℎ
⃗⃗
푖
,훽
⃗
)
푝
푔푒푛
(
푋
푖
|ℎ
⃗⃗
푖
,훽
⃗
)
푝
푝푟푖표푟
(
ℎ
⃗⃗
푖
|푎⃗
푖
,훽
⃗
)
푞
푒푛푐
(
ℎ
⃗⃗
푖
|푋
푖
,푎⃗
푖
,훽
⃗
)
푞
푒푛푐
(
ℎ
⃗⃗
푖
|푋
푖
,푎⃗
푖
,훽
⃗
)
dℎ
⃗⃗
 
=logE
ℎ
⃗⃗⃗
푖
~푞
푒푛푐
(ℎ
⃗⃗
푖
|푋
푖
,푎⃗
푖
,훽
⃗
)
[
푝
푝푟푒푑
(
푦
푖
|ℎ
⃗⃗
푖
,훽
⃗
)
푝
푔푒푛
(
푋
푖
|ℎ
⃗⃗
푖
,훽
⃗
)
푝
푝푟푖표푟
(
ℎ
⃗⃗
푖
|푎⃗
푖
,훽
⃗
)
푞
푒푛푐
(
ℎ
⃗⃗
푖
|푋
푖
,푎⃗
푖
,훽
⃗
)
]
 
Our  new  goal  is  to  find  the  best  encoder  model, 푞
푒푛푐
(
ℎ
⃗⃗
푖
|푋
푖
,푎⃗
푖
,훽
⃗
)
, for  each  datum 푖 from  an 
assumed family of tractable densities. In other words, we aim to estimate hyperparameters of the latent 
product embedding, ℎ
⃗⃗
푖
, which index a unique element within an assumed variational distribution family. 
This results in unique variational parameters for each datum 푖 which we  implicitly include  in the global 
set of model parameters, 훽
⃗
. 
Estimating  these  parameters  using  sampling  techniques  (e.g.,  MCMC)  is intractable, hence  we 
cast sampling as an optimization problem using a lower bound of the  expectation in Equation (A.2) via 
Jensen’s inequality. This approximation is known as the “evidence lower  bound,” which is less than or 
equal to the intractable high-dimensional joint density, log푝
(
푦
푖
,푋
푖
|푎⃗
푖
,훽
⃗
)
. 
(A.3) 
logE
ℎ
⃗⃗⃗
푖
~푞
푒푛푐
(ℎ
⃗⃗
푖
|푋
푖
,푎⃗
푖
,훽
⃗
)
[
푝
푝푟푒푑
(
푦
푖
|ℎ
⃗⃗
푖
,훽
⃗
)
푝
푔푒푛
(
푋
푖
|ℎ
⃗⃗
푖
,훽
⃗
)
푝
푝푟푖표푟
(
ℎ
⃗⃗
푖
|푎⃗
푖
,훽
⃗
)
푞
푒푛푐
(
ℎ
⃗⃗
푖
|푋
푖
,푎⃗
푖
,훽
⃗
)
]
 
≥E
ℎ
⃗⃗⃗
푖
~푞
푒푛푐
(ℎ
⃗⃗
푖
|푋
푖
,푎⃗
푖
,훽
⃗
)
[
log 
푝
푝푟푒푑
(
푦
푖
|ℎ
⃗⃗
푖
,훽
⃗
)
푝
푔푒푛
(
푋
푖
|ℎ
⃗⃗
푖
,훽
⃗
)
푝
푝푟푖표푟
(
ℎ
⃗⃗
푖
|푎⃗
푖
,훽
⃗
)
푞
푒푛푐
(
ℎ
⃗⃗
푖
|푋
푖
,푎⃗
푖
,훽
⃗
)
]
 
 
With  the  logarithm  moved  inside  the  expectation,  we  decompose  the  joint  density  into  three 
separate  terms:  the  predictive  model,  the  generative  models,  and  the  ratio  of  the  encoder  and  prior 
model. Under  the expectation  of  the  encoder  model,  this  last  term  ends  up  being Kullback-Leibler 

29 
 
divergence between the encoder and the prior over the embedding, D
퐾퐿
(
log 푞
푒푛푐
||푝
푝푟푖표푟
)
. 
(A.4) 
E
ℎ
⃗⃗⃗
푖
~푞
푒푛푐
(ℎ
⃗⃗
푖
|푋
푖
,푎⃗
푖
,훽
⃗
)
[
log 
푝
푝푟푒푑
(
푦
푖
|ℎ
⃗⃗
푖
,훽
⃗
)
푝
푔푒푛
(
푋
푖
|ℎ
⃗⃗
푖
,훽
⃗
)
푝
푝푟푖표푟
(
ℎ
⃗⃗
푖
|푎⃗
푖
,훽
⃗
)
푞
푒푛푐
(
ℎ
⃗⃗
푖
|푋
푖
,푎⃗
푖
,훽
⃗
)
]
 
=E
ℎ
⃗⃗⃗
푖
~푞
푒푛푐
(ℎ
⃗⃗
푖
|푋
푖
,푎⃗
푖
,훽
⃗
)
[
log 푝
푝푟푒푑
(
푦
푖
|ℎ
⃗⃗
푖
,훽
⃗
)]
+E
ℎ
⃗⃗⃗
푖
~푞
푒푛푐
(ℎ
⃗⃗
푖
|푋
푖
,푎⃗
푖
,훽
⃗
)
[
log 푝
푔푒푛
(
푋
푖
|ℎ
⃗⃗
푖
,훽
⃗
)]
−E
ℎ
⃗⃗⃗
푖
~푞
푒푛푐
(ℎ
⃗⃗
푖
|푋
푖
,푎⃗
푖
,훽
⃗
)
[
log 
푞
푒푛푐
(
ℎ
⃗⃗
푖
|푋
푖
,푎⃗
푖
,훽
⃗
)
푝
푝푟푖표푟
(
ℎ
⃗⃗
푖
|푎⃗
푖
,훽
⃗
)
]
 
=E
ℎ
⃗⃗⃗
푖
~푞
푒푛푐
(ℎ
⃗⃗
푖
|푋
푖
,푎⃗
푖
,훽
⃗
)
[
log 푝
푝푟푒푑
(
푦
푖
|ℎ
⃗⃗
푖
,훽
⃗
)]
+E
ℎ
⃗⃗⃗
푖
~푞
푒푛푐
(ℎ
⃗⃗
푖
|푋
푖
,푎⃗
푖
,훽
⃗
)
[
log 푝
푔푒푛
(
푋
푖
|ℎ
⃗⃗
푖
,훽
⃗
)]
−D
퐾퐿
(log 푞
푒푛푐
(
ℎ
⃗⃗
푖
|푋
푖
,푎⃗
푖
,훽
⃗
)
||푝
푝푟푖표푟
(
ℎ
⃗⃗
푖
|푎⃗
푖
,훽
⃗
)
) 
=ℓ
푎푝푝푟표푥
푖
(훽
⃗
) 
These  three  terms  comprise  the  approximation, ℓ
푎푝푝푟표푥
푖
(훽
⃗
), that  we maximize. Since  the 
Kullback-Leibler divergence term is negative, maximizing the overall approximation includes minimizing 
distributional  dissimilarity  between  the  posterior  of  the  embedding  given  by  the  encoder  model, 
푞
푒푛푐
(
ℎ
⃗⃗
푖
|푋
푖
,푎⃗
푖
,훽
⃗
)
,  and  the  distributional  prior  that  we  choose, 푝
푝푟푖표푟
(
ℎ
⃗⃗
푖
|푎⃗
푖
,훽
⃗
)
. If  we  minimize  this 
divergence  to zero, the approximate  likelihood  is  equal  to the true  likelihood,  i.e., log푝
(
푦
푖
,푋
푖
|푎⃗
푖
,훽
⃗
)
=
ℓ
푎푝푝푟표푥
푖
(훽
⃗
).   Thus,   maximizing ℓ
푎푝푝푟표푥
푖
(
훽
⃗
)
 lower   bounds   the   previously   intractable   likelihood 
maximization of log푝
(
푦
푖
,푋
푖
|푎⃗
푖
,훽
⃗
)
. 
A3. Derivation of Approximate Log-Likelihood from Equations 3 
We derive Equation 3 using the same reasoning as in Appendix A2. The only difference between 
Equation 1  and  Equation  3  is  the  additional  term, 퐷
퐾퐿
(
푞
푎푡푡푟
(
휋⃗⃗
푖
|
푋
푖
,훽
⃗
퐸
)
| 푝
푎푡푡푟
(휋⃗⃗
푖
|푎⃗
푖
)
)
. This  term is the 
product attribute classifier with associated cross entropy loss term given in Table 1. We need this term 
to  train  the  encoder  model  to  be  able to  predict  product  attributes when  they  are  not  in  the  data,  in 
particular, during prediction of new designs from generative model. 
Adding the latent variables for parameters of the multinomial attribute classifier, 휋⃗⃗
푖
, results in a 
double  integral  and  a corresponding  expectation  over  the  joint  density  of  both ℎ
⃗⃗
푖
 and 휋⃗⃗
푖
.  Our 
assumptions  on  factorization  of  the  latent  terms  splits into  two  KL-divergence  terms  in  the  last  line of 
the derivation. See Keng (2017) for additional discussion on the relation between KL-divergence and the 
cross entropy loss term.  

30 
 
(A.4) 
log푝
(
푦
푖
,푋
푖
|푎⃗
푖
,훽
⃗
)
 
=log∫∫푝
(
푦
푖
,푋
푖
,ℎ
⃗⃗
푖
,휋
푖
⃗⃗⃗⃗|푎⃗
푖
,훽
⃗
)
dℎ
⃗⃗
푑휋⃗⃗ 
=log∫∫푝
푝푟푒푑
(
푦
푖
|ℎ
⃗⃗
푖
,훽
⃗
)
푝
푔푒푛
(
푋
푖
|ℎ
⃗⃗
푖
,훽
⃗
)
푝
푝푟푖표푟
(
ℎ
⃗⃗
푖
|푎⃗
푖
,훽
⃗
)
푝
푎푡푡푟
(
휋⃗⃗
푖
|푎⃗
푖
,ℎ
⃗⃗
푖
,훽
⃗
)
dℎ
⃗⃗
푑휋⃗⃗ 
=log∫∫
푝
푝푟푒푑
(
푦
푖
|ℎ
⃗⃗
푖
,훽
⃗
)
푝
푔푒푛
(
푋
푖
|ℎ
⃗⃗
푖
,훽
⃗
)
푝
푝푟푖표푟
(
ℎ
⃗⃗
푖
|푎⃗
푖
,훽
⃗
)
푝
푎푡푡푟
(
휋⃗⃗
푖
|푎⃗
푖
,ℎ
⃗⃗
푖
,훽
⃗
)
푞
(
ℎ
⃗⃗
푖
,휋⃗⃗
푖
|푎⃗
푖
,푋
푖
,훽
⃗
)
푞
(
ℎ
⃗⃗
푖
,휋⃗⃗
푖
|푎⃗
푖
,푋
푖
,훽
⃗
)
dℎ
⃗⃗
푑휋⃗⃗ 
=logE
ℎ
⃗⃗⃗
푖
,휋
⃗⃗⃗
푖
~푞(ℎ
⃗⃗⃗
푖
,휋
⃗⃗⃗
푖
|푎
⃗⃗
푖
,푋
푖
,훽
⃗⃗⃗
)
[
푝
푝푟푒푑
(
푦
푖
|ℎ
⃗⃗
푖
,훽
⃗
)
푝
푔푒푛
(
푋
푖
|ℎ
⃗⃗
푖
,훽
⃗
)
푝
푝푟푖표푟
(
ℎ
⃗⃗
푖
|푎⃗
푖
,훽
⃗
)
푝
푎푡푡푟
(
휋⃗⃗
푖
|푎⃗
푖
,ℎ
⃗⃗
푖
,훽
⃗
)
푞
(
ℎ
⃗⃗
푖
,휋⃗⃗
푖
|푎⃗
푖
,푋
푖
,훽
⃗
)
]
 
≥E
ℎ
⃗⃗⃗
푖
,휋
⃗⃗⃗
푖
~푞(ℎ
⃗⃗⃗
푖
,휋
⃗⃗⃗
푖
|푎
⃗⃗
푖
,푋
푖
,훽
⃗⃗⃗
)
[
log 
푝
푝푟푒푑
(
푦
푖
|ℎ
⃗⃗
푖
,훽
⃗
)
푝
푔푒푛
(
푋
푖
|ℎ
⃗⃗
푖
,훽
⃗
)
푝
푝푟푖표푟
(
ℎ
⃗⃗
푖
|푎⃗
푖
,훽
⃗
)
푝
푎푡푡푟
(
휋⃗⃗
푖
|푎⃗
푖
,ℎ
⃗⃗
푖
,훽
⃗
)
푞
(
ℎ
⃗⃗
푖
,휋⃗⃗
푖
|푎⃗
푖
,푋
푖
,훽
⃗
)
]
 
=E
ℎ
⃗⃗⃗
푖
,휋
⃗⃗⃗
푖
~푞(ℎ
⃗⃗⃗
푖
,휋
⃗⃗⃗
푖
|푎
⃗⃗
푖
,푋
푖
,훽
⃗⃗⃗
)
[
log 푝
푝푟푒푑
(
푦
푖
|ℎ
⃗⃗
푖
,훽
⃗
)
+log 푝
푔푒푛
(
푋
푖
|ℎ
⃗⃗
푖
,훽
⃗
)
+log 
푝
푝푟푖표푟
(
ℎ
⃗⃗
푖
|푎⃗
푖
,훽
⃗
)
푞
푒푛푐
(
ℎ
⃗⃗
푖
|푋
푖
,푎⃗
푖
,훽
⃗
)
+log 
푝
푎푡푡푟
(
휋⃗⃗
푖
|푎⃗
푖
,훽
⃗
)
푞
푎푡푡푟
(
휋⃗⃗
푖
|푋
푖
,훽
⃗
)
]
 
 
=E
휋
⃗⃗⃗
푖
~푞(휋
⃗⃗⃗
푖
|푋
푖
,훽
⃗⃗⃗
)
[
E
ℎ
⃗⃗⃗
푖
~푞(ℎ
⃗⃗⃗
푖
|푎
⃗⃗
푖
,푋
푖
,훽
⃗⃗⃗
)
[
log 푝
푝푟푒푑
(
푦
푖
|ℎ
⃗⃗
푖
,훽
⃗
)
+log 푝
푔푒푛
(
푋
푖
|ℎ
⃗⃗
푖
,훽
⃗
)
−log 
푞
푒푛푐
(
ℎ
⃗⃗
푖
|푋
푖
,푎⃗
푖
,훽
⃗
)
푝
푝푟푖표푟
(
ℎ
⃗⃗
푖
|푎⃗
푖
,훽
⃗
)
−log 
푞
푎푡푡푟
(
휋⃗⃗
푖
|푋
푖
,훽
⃗
)
푝
푎푡푡푟
(
휋⃗⃗
푖
|푎⃗
푖
,훽
⃗
)
]]
 
=E
ℎ
⃗⃗⃗
푖
~푞(ℎ
⃗⃗⃗
푖
|푎
⃗⃗
푖
,푋
푖
,훽
⃗⃗⃗
)
[
log 푝
푝푟푒푑
(
푦
푖
|ℎ
⃗⃗
푖
,훽
⃗
)
+log 푝
푔푒푛
(
푋
푖
|ℎ
⃗⃗
푖
,훽
⃗
)
−log 
푞
푒푛푐
(
ℎ
⃗⃗
푖
|푋
푖
,푎⃗
푖
,훽
⃗
)
푝
푝푟푖표푟
(
ℎ
⃗⃗
푖
|푎⃗
푖
,훽
⃗
)
]
−E
휋
⃗⃗⃗
푖
~푞(휋
⃗⃗⃗
푖
|푋
푖
,훽
⃗⃗⃗
)
[
log 
푞
푎푡푡푟
(
휋⃗⃗
푖
|푋
푖
,훽
⃗
)
푝
푎푡푡푟
(
휋⃗⃗
푖
|푎⃗
푖
,훽
⃗
)
]
 
=E
ℎ
⃗⃗⃗
푖
~푞(ℎ
⃗⃗⃗
푖
|푎
⃗⃗
푖
,푋
푖
,훽
⃗⃗⃗
)
[
log 푝
푝푟푒푑
(
푦
푖
|ℎ
⃗⃗
푖
,훽
⃗
)]
+E
ℎ
⃗⃗⃗
푖
~푞(ℎ
⃗⃗⃗
푖
|푎
⃗⃗
푖
,푋
푖
,훽
⃗⃗⃗
)
[
log 푝
푔푒푛
(
푋
푖
|ℎ
⃗⃗
푖
,훽
⃗
)]
−D
퐾퐿
[
푞(ℎ
⃗⃗
푖
|푎⃗
푖
,푋
푖
,훽
⃗
)||푝
푝푟푖표푟
(
ℎ
⃗⃗
푖
|푎⃗
푖
,훽
⃗
)]
−D
퐾퐿
(푞
푎푡푡푟
(
휋⃗⃗
푖
|푋
푖
,훽
⃗
)
| 푝
푎푡푡푟
(
휋⃗⃗
푖
|푎⃗
푖
,훽
⃗
)
) 

31 
 
 
A4. Example Rating Page from Aesthetic Rating Survey used in Theme Clinic 
 
 
 
  

32 
 
 
References 
Aaker DA, Keller KL (1990) Consumer evaluations of brand extensions. Journal of Marketing 54(1):27–41. 
Adidas AG (2017) Adidas AG 2017 Annual Report. 
Ansari A, Li Y, Zhang JZ (2018) Probabilistic topic model for hybrid recommender systems: A stochastic 
variational bayesian approach. Marketing Science 37(6):987–1008. 
Arjovsky M, Chintala S, Bottou L (2017) Wasserstein generative adversarial networks. International 
Conference on Machine Learning. 214–223. 
Berlyne DE (1971) Aesthetics and Psychobiology (Appleton-Century-Crofts, East Norwalk, CT, US).  
Berthelot D, Schumm T, Metz L (2017) BEGAN: Boundary Equilibrium Generative Adversarial Networks. 
arXiv:1703.10717 [cs, stat]. 
Blei DM, Kucukelbir A, McAuliffe JD (2017) Variational Inference: A Review for Statisticians. Journal of 
the American Statistical Association 112(518):859–877. 
Bloch PH (1995) Seeking the ideal form: Product design and consumer response. Journal of Marketing 
59(3):16. 
Blonigen BA, Knittel CR, Soderbery A (2013) Keeping it Fresh: Strategic Product Redesigns and Welfare 
(National Bureau of Economic Research). 
Bouchard C, Aoussat A, Duchamp R (2006) Role of sketching in conceptual design of car styling. Journal 
of Design Research 5(1):116. 
Braun M, McAuliffe J (2010) Variational inference for large-scale models of discrete choice. Journal of 
the American Statistical Association 105(489):324–335. 
Chakraborty I, Kim M, Sudhir K (2019) Attribute Sentiment Scoring with Online Text Reviews: Accounting 
for Language Structure and Attribute Self-Selection. Cowles Foundation Discussion Paper No. 
2176. 
Chan TH, Mihm J, Sosa ME (2018) On styles in product design: An analysis of U.S. design patents. 
Management Science 64(3):1230–1249. 
Chen X, Kingma DP, Salimans T, Duan Y, Dhariwal P, Schulman J, Sutskever I, Abbeel P (2016) Variational 
lossy autoencoder. arXiv:1611.02731 [cs, stat]. 
Cho H, Hasija S, Sosa M (2015) How Important is Design for the Automobile Value Chain? (Social Science 
Research Network, Rochester, NY). 
Clement J (2007) Visual influence on in-store buying decisions: An eye-track experiment on the visual 
influence of packaging design. Journal of Marketing Management 23(9–10):917–928. 
Coates D (2003) Watches Tell More Than Time: Product Design, Information, and the Quest for Elegance 
(McGraw-Hill London). 
Cooper RG (1990) Stage-gate systems: A new tool for managing new products. Business horizons 
33(3):44–54. 
Creusen MEH, Schoormans JPL (2005) The different roles of product appearance in consumer choice. 
Journal of Product Innovation Management 22(1):63–81. 
Crilly N, Moultrie J, Clarkson PJ (2004) Seeing things: Consumer response to the visual domain in product 
design. Design Studies 25(6):547–577. 
Danneels E, Kleinschmidtb EJ (2001) Product innovativeness from the firm’s perspective: Its dimensions 
and their relation with project selection and performance. Journal of Product Innovation 
Management 18(6):357–373.  
Deng Y, Loy CC, Tang X (2017). Image aesthetic assessment: An experimental survey. IEEE Signal 
Processing Magazine, 34(4), 80-106. 

33 
 
Dilokthanakul N, Mediano PAM, Garnelo M, Lee MCH, Salimbeni H, Arulkumaran K, Shanahan M (2016) 
Deep unsupervised clustering with gaussian mixture variational autoencoders. arXiv:1611.02648 
[cs, stat]. 
Dotson J, Beltramo M, Feit E, Smith R (2016). Modeling the Effect of Images on Product Choices. SSRN 
Electronic Journal. 
Dzyabura D, Hauser JR, El Kihal S, Ibragimov M (2018) Leveraging the power of images in predicting 
product return rates. SSRN Electronic Journal. 
Evgeniou T, Pontil M (2004) Regularized multi–task learning. Proceedings of the Tenth ACM SIGKDD 
International Conference on Knowledge Discovery and Data Mining. (ACM), 109–117. 
Goodfellow I, Pouget-Abadie J, Mirza M, Xu B, Warde-Farley D, Ozair S, Courville A, Bengio Y (2014). 
Generative adversarial nets. Advances in Neural Information Processing Systems. 2672-2680. 
Hartley J (1996) Brands Through the Lens of Style. Quest and Associates. 
Hauser J, Eggers F, Selove M (2018). The Strategic Implications of Scale in Choice-Based Conjoint 
Analysis. 
Hekkert P, Snelders D, Wieringen PC (2003) ‘Most advanced, yet acceptable’: Typicality and novelty as 
joint predictors of aesthetic preference in industrial design. British Journal of Psychology 
94(1):111–124. 
Heljakka A, Solin A, Kannala J (2018) Pioneer networks: Progressively growing generative autoencoder. 
arXiv:1807.03026 [cs, stat]. 
Heljakka A, Solin A, Kannala J (2019) Towards photographic image manipulation with balanced growing 
of generative autoencoders. arXiv:1904.06145 [cs, stat]. 
Hertenstein JH, Platt MB, Veryzer RW (2005) The impact of industrial design effectiveness on corporate 
financial performance*. Journal of Product Innovation Management 22(1):3–21. 
Heusel M, Ramsauer H, Unterthiner T, Nessler B, Hochreiter S (2017) GANs trained by a two time-scale 
update rule converge to a local nash equilibrium. Advances in Neural Information Processing 
Systems. 6626–6637. 
Hoffman M, Blei D, Wang C, Paisley J (2013). Stochastic variational inference. Journal of Machine 
Learning Research 14(1):1303-1347. 
Homburg C, Schwemmle M, Kuehnl C (2015) New product design: Concept, measurement, and 
consequences. Journal of Marketing 79(3):41–56. 
Huang H, Li Z, He R, Sun Z, Tan T (2018) IntroVAE: Introspective variational autoencoders for 
photographic image synthesis. Advances in Neural Information Processing Systems. 31(1):52–63.  
Ishigaki T, Terui N, Sato T, Allenby G (2018). Personalized market response analysis for a wide variety of 
products from sparse transaction data. International Journal of Data Science and Analytics 
5(4):233-248. 
Jang E, Gu S, Poole B (2016) Categorical reparameterization with gumbel-softmax. arXiv:1611.01144 [cs, 
stat]. 
Jindal RP, Sarangee KR, Echambadi R, Lee S (2016) Designed to succeed: Dimensions of product design 
and their impact on market share. Journal of Marketing 80(4):72–89. 
Jordan MI, Ghahramani Z, Jaakkola TS, Saul LK (1999) An introduction to variational methods for 
graphical models. Machine learning 37(2):183–233. 
Kang N, Ren Y, Feinberg FM, Papalambros PY (2016) Form + function: Optimizing aesthetic product 
design via adaptive, geometrized preference elicitation. Working Paper - University of Michigan. 
Kang WC, Fang C, Wang Z, McAuley J (2017) Visually-aware fashion recommendation and design with 
generative image models. 2017 IEEE International Conference on Data Mining (ICDM). 207–216. 
Keng (2017) Semi-supervised Learning with Variational Autoencoders. Available: https://bit.ly/2O9RvF8. 
Karjalainen TM, Snelders D (2010) Designing visual recognition for the brand. Journal of Product 
Innovation Management 27(1):6–22. 

34 
 
Karras T, Aila T, Laine S, Lehtinen J (2017) Progressive growing of gans for improved quality, stability, and 
variation. arXiv preprint arXiv:1710.10196. 
Keller KL (2003) Brand Synthesis: The multidimensionality of brand knowledge. Journal of Consumer 
Research 29(4):595–600. 
Kingma DP, Ba J (2015) Adam: A method for stochastic optimization. International Conference on 
Learning Representation. (San Diego, California). 
Kingma DP, Mohamed S, Rezende DJ, Welling M (2014) Semi-supervised learning with deep generative 
models. Advances in Neural Information Processing Systems. 3581–3589. 
Kingma DP, Welling M (2013) Auto-encoding variational bayes. arXiv preprint arXiv:1312.6114. 
Kreuzbauer R, Malter AJ (2005) Embodied cognition and new product design: Changing product form to 
influence brand categorization. Journal of Product Innovation Management 22(2):165–176. 
Krippendorff K (2011) Computing Krippendorff’s alpha-reliability. 
Landwehr JR, Labroo AA, Herrmann A (2011) Gut liking for the ordinary: Incorporating design fluency 
improves automobile sales forecasts. Marketing Science 30(3):416–429. 
Larsen ABL, Sønderby SK, Winther O (2015) Autoencoding beyond pixels using a learned similarity 
metric. arXiv preprint arXiv:1512.09300. 
Liu L, Dzyabura D, Mizik N (2017) Visual listening in: Extracting brand image portrayed on social media. 
Liu X, Lee D, Srinivasan K (2018) Large scale cross-category analysis of consumer review content on sales 
conversion leveraging deep learning. Workshops at the Thirty-Second AAAI Conference on 
Artificial Intelligence. 
Liu Y, Li KJ, Chen H, Balachander S (2017) The effects of products’ aesthetic design on demand and 
marketing-mix effectiveness: The role of segment prototypicality and brand consistency. Journal 
of Marketing 81(1):83–102. 
Lopez C, Miller S, Tucker C (2019). Exploring biases between human and machine generated designs. 
Journal of Mechanical Design, 141(2), 021104. 
Makhzani A, Shlens J, Jaitly N, Goodfellow I, Frey B (2015) Adversarial autoencoders. arXiv preprint 
arXiv:1511.05644. 
Manoogian J II (2013) Vehicle design process used at general motors. 
Martindale C (1990) The Clockwork Muse: The Predictability of Artistic Change (Basic Books, New York, 
NY). 
Miyato T, Kataoka T, Koyama M, Yoshida Y (2018) Spectral normalization for generative adversarial 
networks. arXiv preprint arXiv:1802.05957. 
Noble CH, Kumar M (2010) Exploring the appeal of product design: A grounded, value-based model of 
key design elements and relationships. Journal of Product Innovation Management 27(5):640–
657. 
Norman DA (2004) Emotional Design: Why We Love (or Hate) Everyday Things (Basic books, New York, 
NY). 
Olshausen BA, Field DJ (1996) Emergence of simple-cell receptive field properties by learning a sparse 
code for natural images. Nature 381(6583):607. 
Orsborn S, Cagan J, Boatwright P (2009) Quantifying aesthetic form preference in a utility function. 
Journal of Mechanical Design 131(6):061001. 
Orth UR, Malkewitz K (2008) Holistic package design and consumer brand impressions. Journal of 
marketing, 72(3):64-81.  
Orme B, Chrzan K (2017). Becoming an Expert in Conjoint Analysis: Choice Modelling for Pros. Sawtooth 
Software. 
Palazzolo M, Feinberg F (2015) Modeling consideration set substitution. Working Paper - University of 
Michigan. 

35 
 
Pan Y, Burnap A, Hartley J, Gonzalez R, Papalambros PY (2017) Deep design: Product aesthetics for 
heterogeneous markets. Proceedings of the 23rd ACM SIGKDD International Conference on 
Knowledge Discovery and Data Mining. KDD ’17. (ACM, New York, NY, USA), 1961–1970. 
Pauwels K, Silva-Risso J, Srinivasan S, Hanssens DM (2004) New products, sales promotions, and firm 
value: The case of the automobile industry. Journal of Marketing 68(4):142–156. 
Person O, Snelders D, Karjalainen TM, Schoormans J (2007) Complementing intuition: insights on styling 
as a strategic tool. Journal of Marketing Management 23(9–10):901–916. 
Person O, Snelders D, Schoormans J (2016) Assessing the performance of styling activities: An interview 
study with industry professionals in style-sensitive companies. Design Studies 42:33–55. 
Ranganath R, Tran D, Blei DM (2015) Hierarchical variational models. arXiv:1511.02386 [cs, stat]. 
Ranscombe C, Hicks B, Mullineux G, Singh B (2012) Visually decomposing vehicle images: Exploring the 
influence of different aesthetic features on consumer perception of brand. Design Studies 
33(4):319–341. 
Reid T, Gonzalez R, Papalambros PY (2010) Quantification of perceived environmental friendliness for 
vehicle silhouette design. Journal of Mechanical Design 132(10):101010. 
Reid T, MacDonald E, Du P (2013) Impact of product design representation on customer judgment. 
Journal of Mechanical Design 135(9):091008. 
Reppel AE, Szmigin I, Gruber T (2006) The iPod phenomenon: identifying a market leader’s secrets 
through qualitative marketing research. The Journal of Product and Brand Management; Santa 
Barbara 15(4):239–249. 
Rubera G (2015) Design innovativeness and product sales’ evolution. Marketing Science 34(1):98–115. 
Sbai O, Elhoseiny M, Bordes A, LeCun Y, Couprie C (2019) DesIGN: Design inspiration from generative 
networks. Leal-Taixé L, Roth S, eds. Computer Vision – ECCV 2018 Workshops. (Springer 
International Publishing, Cham), 37–44. 
Shu R, Bui HH, Zhao S, Kochenderfer MJ, Ermon S (2018) Amortized inference regularization. 
arXiv:1805.08913 [cs, stat]. 
Sohn K, Lee H, Yan X (2015) Learning structured output representation using deep conditional 
generative models. Advances in Neural Information Processing Systems. 3483–3491. 
Sun C, Ghose A, Liu X (2018) Automating Online-Offline Data Multi-View Merger for Integrated 
Marketing. Available at SSRN: http://dx.doi.org/10.2139/ssrn.3265400. 
Timoshenko A, Hauser JR (2019) Identifying customer needs from user-generated content. Marketing 
Science 38(1):1-20. 
Toffoletto G (2013) The strategic value of design. A model derived from the existing literature and six 
case studies of design driven organizations. Politecnico di Milano. 
Toubia O, Netzer O (2017) Idea generation, creativity, and prototypicality. Marketing Science 36(1):1–20. 
Ulyanov D, Vedaldi A, Lempitsky V (2018) It takes (only) two: Adversarial generator-encoder networks. 
Thirty-Second AAAI Conference on Artificial Intelligence. 
Vasileva, M, Plummer B, Dusad K, Rajpal S, Kumar R, Forsyth D (2018). Learning type-aware embeddings 
for fashion compatibility. In Proceedings of the European Conference on Computer Vision (ECCV). 
390-405. 
Vlasic B (2011) Once upon a car: The fall and resurrection of America’s big three auto makers–GM, Ford, 
and Chrysler (William Morrow). 
Yoganarasimhan H (2017) Identifying the presence and cause of fashion cycles in data. Journal of 
Marketing Research 54(1):5–26. 
Zhang W, Yang Z, Jiang H, Nigam S, Yamakawa S, Furuhata T, Shimada K, Kara LB (2019) 3D shape 
synthesis for conceptual design and optimization using variational autoencoders. 
arXiv:1904.07964 [cs, stat]. 
Zhao J, Mathieu M, LeCun Y (2016) Energy-based Generative Adversarial Network. arXiv:1609.03126.  

Hierarchical Sequence to Sequence Voice Conversion with Limited Data
Praveen Narayanan, Punarjay Chakravarty, Francois Charette, Gint Puskorius
Ford Greenfield Labs, Palo Alto, CA
{pnaray11,pchakra5,fcharett,gpuskori}@ford.com
Abstract
We  present  a  voice  conversion  solution  using  recurrent  se-
quence  to  sequence  modeling  for  DNNs.   Our  solution  takes
advantage of recent advances in attention based modeling in the
fields  of  Neural  Machine  Translation  (NMT),  Text-to-Speech
(TTS)  and  Automatic  Speech  Recognition  (ASR).  The  prob-
lem consists of converting between voices in a parallel setting
when<source,target>audio pairs are available.  Our seq2seq
architecture makes use of a hierarchical encoder to summarize
input audio frames.  On the decoder side, we use an attention
based architecture used in recent TTS works.  Since there is a
dearth of large multispeaker voice conversion databases needed
for training DNNs, we resort to training the network with a large
single speaker dataset as an autoencoder.  This is then adapted
for the smaller multispeaker voice conversion datasets available
for voice conversion.  In contrast with other voice conversion
works that useF
0
, duration and linguistic features, our system
uses mel spectrograms as the audio representation. Output mel
frames are converted back to audio using a wavenet vocoder.
Index Terms:  voice conversion,  seq2seq,  TTS, ASR, DNNs,
attention
1. Introduction
Recently, sequence to sequence models have been adapted with
great success in producing realistic sounding speech in TTS sys-
tems [1, 2, 3, 4, 5].   Likewise,  it has been demonstrated that
ASR can be handled excellently by seq2seq architectures.   In
TTS, the system takes in a text or phoneme sequence and out-
puts a speech representation as output.  On the other hand, in
ASR, one feeds in an audio representation, and the system per-
forms  the  task  of  classifying  audio  into  text  or  phoneme.   In
voice conversion, both the input and output sequences are audio
representations.  The problem is related to both ASR and TTS
in that like ASR, the DNN must learn to summarize input audio
frames into a hidden context, and like in TTS, it must decode
audio  frames  from  the  latent  context  in  a  temporal,  attentive
fashion.
In voice conversion, we seek to convert a speech utterance
from a source speaker A to make it sound like an utterance from
a target speaker B. There are two pertinent scenarios, the first of
which is when both the source and target speakers are uttering
the same text (the ’parallel’ case), and the second is when the ut-
terances don’t match (the ’non-parallel’ case). We focus on par-
allel voice conversion in this work with DNNs. While the larger
goal of this work is to address the more important problem of
non-parallel  voice  conversion  (producing  parallel  datasets  for
conversion is not easy), we start with the arguably simpler task
of demonstrating how we can achieve this in the parallel sce-
nario using seq2seq models.
While we can go about the voice conversion task by first
performing ASR on the source voice, and then sending the text
obtained to a TTS engine, our approach leads to an end-to-end
Figure  1:System  Diagram:   Our  Attention  based  Encoder-
Decoder  architecture  for  Voice  Conversion  takes  in  a  mel-
spectrogram  for  the  source  speaker  and  outputs  the  mel-
spectrogram for the target speaker.
solution wherein one doesn’t have to train an ASR and TTS en-
gine separately. Our approach has a simpler processing pipeline
as it only needs audio transcripts (with no accompanying text or
need for segmentation), and can be converted directly to target
representations.   A  notable  aspect  of  this  work  is  that  it  gets
around the problem of limited parallel data for voice conversion
by pretraining a much larger, single speaker TTS corpus as an
autoencoder and then performing transfer learning on the avail-
able, diminutive voice conversion datasets. Without this adapta-
tion technique it becomes difficult to effectively carry out voice
conversion without having access to larger, expensive to obtain
parallel datasets.
We train the system using Maximum Likelihood to mini-
mize the L1 error between the generated and target mel spectro-
grams.
2. Related Work
The traditional pipeline for parallel voice conversion is through
use  of  Gaussian  Mixture  Models  (GMMs)  [6,  7,  8]  or  Deep
Neural  Networks  (DNNs)  [9,  10,  11,  12].   After  first  align-
ing  source  and  target  features  using  Dynamic  Time  Warping
(DTW)[13],  the  model  is  trained  so  that  it  learns  to  produce
the target given the source features for each frame. A disadvan-
tage of these methods is that they need aligned, parallel data.
Moreover,  conversions  performed  on  spectral  features  disre-
gard dependencies on other controlling factors such as prosody
and fundamental frequency, duration and rhythm. Furthermore,
transforming features on a frame basis disregards temporal con-
text dependencies.  The dependence on fundamental frequency
is often handled by performing a linear transformation in the
logarithmic domain. A good review article of the topic is found
in [14].
Non-negative Matrix Factorization (NMF) [15],  tradition-
ally used for sound source separation and speech enhancement,
has also been used for VC [16].  NMF factorizes a matrix into
two non-negative factors, the basis or dictionary matrix and the
activation matrix. In the case of VC with parallel training data,
arXiv:1907.07769v1  [eess.AS]  15 Jul 2019

dictionaries  for  speaker  1  and  speaker  2  are  first  constructed
separately.   Subsequently,  given  test  source  data  (speaker  1),
the  previously  learnt  dictionary  for  speaker  1  is  used  to  fac-
torize the source voice into a set of source activations, or con-
tributions of speaker 1 dictionary to speaker 1 utterance.  The
same  is  done  for  speaker  2.    The  activations  for  the  source
speaker utterance are then combined with the dictionary atoms
of  the  target  speaker  utterance  to  transform  speaker  1  utter-
ance  into  speaker  2.   NMF  based  methods,  like  GMMs,  also
require alignment of parallel voice samples using Dynamic Pro-
gramming, and other pre-processing steps like the Short-term-
Fourier-Transform (STFT).
Recent  sequence  to  sequence  modeling  approaches  for
voice  conversion  have  largely  been  inspired  by  advances  in
seq2seq practice in NMT, TTS and ASR, in that they involve
an encoder-decoder model as the underlying machinery.   It is
often  advantageous  to  classify  the  input  waveform  into  text
or  phoneme,  and  use  that  information  to  inform  the  decoder
model of the content that the input audio representation embod-
ies [17, 18]. Our work is most similar to [17], and we compare
and  contrast  salient  aspects  of  both  models.   In  both models,
the overall architecture is a seq2seq model inspired by the ASR
work [19] (with a hierarchical encoder stack), and the TTS work
Tacotron [1] and derivatives. However, in [17], the encoder out-
puts are augmented by features extracted with an ASR model,
while our approach comprises end-to-end neural networks with-
out need for labeled data. There are also several ancillary com-
ponents such as the use of additional losses and postprocessing
networks.  Also, we use a Convolutional filter bank, Highway
network to extract ’context’ as a prelude to processing them in
the multilayer hierarchy of encoder RNNs.   Nevertheless,  we
wish  to  emphasize  that  a  substantive  difference  between  the
two works is the training philosophy,  in how the data limita-
tion problem is handled.  We elaborate on this in the following
paragraphs with additional examples from the literature.
Pertinent  to  our  discussion  are  seq2seq  modeling  works
[20, 21].  In these works, additional loss terms are introduced
to encourage the model to learn alignment and to preserve lin-
guistic context.  Alignment is maintained by noting that the at-
tention curve is predominantly diagonal (in the voice conver-
sion problem) between source and target, and including in the
loss function a diagonal penalty matrix - a term referred to as
guided attention in the TTS work [22]. An additional consider-
ation is to prevent the decoder from ’losing’ linguistic context,
as would arise when it simply learns to reconstruct the output of
the target.  This was addressed by using additional neural net-
works that ensure that the hidden representation produced by
the encoder (similar reasoning applies to the decoder) was ca-
pable of reconstructing the input, and thereby retained context
information.  These manifest as additional loss terms - we also
glean a similarity to cycle consistency losses [23] - that they call
’context preservation losses’. Also noteworthy is that these ap-
proaches use non-recurrent architectures for their seq2seq mod-
eling.
We suspect that the problems that motivated the design of
these additional losses have their provenance in the diminutive
size of the training corpus (CMU Arctic was used, with1132
utterances per speaker) which is hardly sufficient to learn a di-
verse respresentation with good generalization capabilities.  In
our work, we arrive at a slightly different way to overcome the
data limitation problem as compared with these works, which
do so by augmenting data with ASR training [17, 18], and by in-
troducing additional losses [20, 21]. Our solution makes use of
transfer learning by first pretraining with a large, single speaker
corpus, and then adapting to the smaller, pertinent corpus (CMU
Arctic) in question.
Developments in the generative modeling (primarily, Varia-
tional Autoencoders [24] and Generative Adversarial Networks
[25]) front have led to their use in voice conversion problems. In
[26], a learned similarity metric obtained through a GAN dis-
criminator is used to correct oversmoothed speech that results
from maximum likelihood training,  which imposes a particu-
lar form for the loss function (usually the MSE). A conditional
VAEGAN [27] setup is used in [28] to implement voice conver-
sion, with conditioning on speakers, together with a Wasserstein
GAN  discriminator  [29]  to  fix  the  blurriness  issue  associated
with VAEs.  Moreover, an important apparatus that is of use in
training non-parallel voice setups consists of Cycle Consistency
Losses from the famous CycleGAN [23] work for images. This
forms a building block in the papers [30] and [31].
A natural extension to our work is to explore a generative
solution to Voice Conversion as in some of the works above,
in order to apply our architectural components to non-parallel
setups.
Our  work  is  influenced  by  recent  TTS  works  involving
transfer  learning  and  speaker  adaptation.   The  recently  pub-
lished  work  [32]  demonstrates  a  methodology  to  use  adapt  a
trained network for new speakers with a wavenet.  Likewise, in
[33],  a speaker embedding is extracted using a discriminative
network for unseen,  new speakers which is then used to con-
dition a TTS pipeline similar to Tacotron.  This philosophy is
also used in [34] where schemes are used to learn speaker em-
beddings  extracted  separately  or  trained  as  part  of  the  model
during adaptation.  In all these contexts, it is emphasized that
the onus is on adapting to small, limited data corpuses, thereby
circumventing the need to obtain large datasets to train these
models from scratch.  In our work, we use the same idea to get
around the problem of not having enough data to train in the
voice conversion dataset under consideration.  However, in our
work, instead of producing new speaker embeddings, we retrain
the model for each new< source,target >pair, a process that
is rapid owing to the small size of the corpus.
An interesting alternative to using recurrent (or autoregres-
sive)  seq2seq  modeling  for  TTS  or  VC  is  to  use  differential
memory as a way to store speech related information.   In the
VoiceLoop architecture [35, 36, 37],  the input is transformed
with a shallow fully connected network into a context, with at-
tention  being  used  to  compare  with  the  memory  buffer.   The
memory buffer itself is updated by replacing its first element
with  a  newly  computed  representation  vector.   With  this  ap-
proach,  which  also  uses  speaker  embeddings,  the  network  is
able to adapt to new speakers with only a few samples, in addi-
tion to having a much reduced network complexity (only shal-
low fully connected layers are used).
3. Architecture
We  use  an  attention  based  encoder-decoder  network  for  our
voice conversion task. The network architecture borrows heav-
ily from recent developments in TTS [1] and ASR [19].  The
system takes in an audio representation (mel-spectrogram) as
input, and encodes it into a hidden representation in recurrent
fashion.  This hidden representation is then processed by an at-
tention based decoder into output mel-spectrograms. In order to
convert the mel frames back to audio, we employ a widely used
wavenet vocoder implementation available online [38].  In the
Tacotron2 [2] work, it was demonstrated that using wavenet as
a neural vocoder produced audio samples whose quality was su-

Figure 2:The Pre-net and the CBH layers that are used to pro-
cess the input mel-spectrogram frames.  Output tensor sizes at
each step of processing are indicated by the side of the unit.
perior to those from the Griffin-Lim procedure used in Tacotron
[1].
A system diagram showing the various components of the
model is shown in Figure 1. We describe its components in the
following subsections.
3.1. Encoder
3.1.1.  Prenet
The prenet is a bottleneck layer containing full connections with
a ReLU nonlinearity and dropout [1, 39].  The purpose of this
layer is to enable the model to generalize to unseen input with
dropout. Mechanisms to achieve this effect in sequence models
are teacher forcing, scheduled sampling and professor forcing
[40, 41, 42]. Prenet processes vectors of 80 dimensions to yield
output of the same size. A dropout ratio of0.5is used.
3.1.2.  CBH: Convolutional Banks and Highway layers
Originally proposed in the context of Neural Machine Transla-
tion [43] and later used in [1] where it was named CBHG (Con-
volutional  Banks,  Highway  and  Gated  Recurrent  Units),  this
layer served as a processing mechanism to accumulate ’word’
level context when the input is text.  For our voice conversion
task, the effect is similar, in that neighboring speech frames are
filtered so as to abstract the equivalent phoneme level represen-
tation, mixed with speaker characteristics and prosodic content.
Together  with  the  hierarchical  RNN  encoder  units  described
later, we could view this assemblage as an implementation of
CBHG. The Pre-net and CBH layers, along with the tensor out-
put sizes at each step of the processing are shown in Figure  2
and described below.
Convolutional Filter BanksA bank of 1-D convolutional
filters of size(1,3,5)are used to capture n-grams of varying
width.  The input sequence is convolved with each of these fil-
ters  and  the  results  from  all  filters  are  concatenated  together.
Each convolution filter preserves the original length of the se-
quence by padding it to extend original length byw−1, where
the filter is of widthw, followed by BatchNorm and ReLU oper-
ations. The filter maps obtained are then stacked in the channel
dimension with4output channels being produced for each con-
volution.  This is followed by a max-pool operation with stride
1, which maintains the length of the sequence.  A 1-D convo-
lutional projection operation then reduces the sequence length
to  the  original  size,  followed  by  a  final  linear  layer  that  also
maintains representation length.
Highway LayersThe Highway layer is like a Resnet block
with a skip connection that is a shortcut for information flow
that skips the intermediate layers, but with learnable weights to
determine the extent of the information skip. We use 4 highway
layers.
3.1.3.  Hierarchical Recurrent Encoder
We design our encoder as a stack of bidirectional layers, reduc-
ing the sequence length by a factor of2as the data flows up the
stack (Figure 3).  This construction was first proposed in [19]
in the context of speech recognition with DNNs. The encoder’s
task is to summarize audio input to an intermediate hidden rep-
resentation embodying linguistic content, akin to text. However
(and this might be argued as a desirable attribute of DNN pro-
cessing), we make no attempt to disentangle content (text) and
voice  characteristics  (style)  in  this  case.   We  assume  that  the
DNN automatically learns to disentangle content and style as
part of the training process, and that during the decoding pro-
cess, the first speaker’s voice characteristics are discarded and
the second speaker’s voice is injected into the content.
The  reasoning  behind  using  a  hierarchical  reduction  of
timesteps is that speech frames are highly inflated,  redundant
descriptors of linguistic content mixed with speaker and dura-
tion  information.   A  single  phoneme  could  thus  span  several
(∼10) frames. It therefore makes sense to reduce or cluster the
speech frames so as to contain more relevant information.  By
reducing the number of timesteps, we are implicitly performing
this clustering operation to distill the pertinent linguistic content
at the top of the stack. The reduction in timesteps is also favor-
able as regards learning attention, the rationale being that as the
decoder examines all the frames of the encoder to extract atten-
tion parameters, it is useful to aggregate relevant information so
that it has a smaller set to work with, which helps in speeding
up the computation and in helping the model learn alignment.
In order to reduce the number of input timesteps, we accu-
mulate two neighboring frames, and then pass the concatenated
features along to the bidirectional RNN layer above. In our ex-
periments,  we use a stack of2recurrent reduction layers,  re-
sulting in an overall reduction in the number of timesteps by a
factor of4.
The basic unit of the hierarchical recurrent encoder is the
bi-directional  GRU.  This  bi-directional  Gated  Recurrent  Unit
(shown  separately  in  the  diagram  asL→RandR→L)
passes  over  the  input  sequence  twice:  left  to  right  and  from
right to left, and concatenates the two passes.  Each GRU has
150 hidden units, and outputs a dimensionality 150xT, where T
is input sequence length.  After concatenation of theL→R
andR→Loutputs,  one  gets  a  dimensionality  300xT.  The
sequence length itself is reduced to T/2 after GRU1 and to T/4
after GRU2 as a result of accumulating 2 neighbouring frames
at each step. GRU0 is a pre-processing recurrent unit that does
not  have  this  accumulation  and  reduction  of  time  steps.   The
details of the pyramidal encoding, with tensor sizes after each
step are shown in Figure 3.
3.2. Attention Decoder
The decoder architecture is inspired by the Tacotron TTS setup
[1].   As  in  the  Tacotron  work,  the  decoder  has  the  following
components:

Figure 3:Hierarchical Bi-directional Recurrent Encoder with
an indication of the tensor sizes at each step.  The number of
hidden units in each GRU is 150.   Each pyramidal GRU unit
(GRU 1 and 2) decreases the sequence length by 1/2. Left-right
and right-left GRU units each output a 150xT matrix, that are
concatenated to give a 300xT matrix, with T as input sequence
length.
1.  Prenet
2.  Attention RNN
3.  Decoder RNNs with residuality
We describe the components in more detail below.  How-
ever,  before  doing  so,  it  is  useful  to  have  in  mind  an  overall
picture of how the data flows through the decoder stack. To that
end, we present a brief description of the calculations at a high
level.
The decoder’s task is to transform linguistic content from
the source speaker to that of the target speaker in a temporal
way, conditioned on frames generated previously. The linguistic
content is provided by the hierarchical encoder described previ-
ously, which condenses the source speaker’s utterances into an
intermediate  hidden  representation  embodying  linguistic  con-
tent.   The  decoder’s  task  is  therefore  to  ingest  this  linguistic
content, and imbue it with the target speaker’s voice character-
istics.   In the current setup,  the DNN implicitly adds the tar-
get speaker’s voice characteristics (i.e.  duration, pitch) to the
encoder summary.  It is designed as a complex stack of unidi-
rectional RNNs trained to emit output spectrogram frames con-
ditioned on all previous frames emitted, together with the en-
coder’s representation of the context.
The  attention  modeling  ensures  that  the  target’s  spectro-
gram frames are aligned with the appropriate frames of the in-
put.  Attention computations are ubiquitous in sequence to se-
quence  modeling.   While  decoding  output  sequence  frames  -
this could be in any general sequence modeling task,  such as
NMT, ASR, or TTS - attention helps to focus on the appropriate
frame of the input sequence so that the decoder is able to de-
cide what it should emit in a more precise way.  This aspect is
especially important when the sequence length becomes large,
for the decoder’s task becomes much more difficult in emitting
sequential output based on a single, global context that the en-
coder provides.  Moreover, it is seen in experiments that atten-
tion modeling is essential for the system to generalize to unseen
input.  Our experiments seem to be in line with the notion that
for the speech model to perform well on unseen data, it is in fact
necessary for the model to learn proper alignment.
We now proceed to describe in more detail the components
of the decoder.
3.2.1.  Prenet
As with the encoder, we transform target data through a set of
bottleneck layers (two in total) using dropout.  We use dropout
in  order  to  regularize  the  model  and  prevent  overfitting,  and
hence  it  is  a  very  essential  component.   We  use  a  stack  of2
prenet layers (full connections with ReLU non-linearity and a
dropout ratio of0.5) yielding vectors of size256and128re-
spectively.
3.2.2.  The Hybrid Content-Location Attention Model
We use attention modeling [44, 45, 2] as a way of focusing the
generator on the most relevant section of the input sequence.
We have a state sequence output by the encoder (hidden) units
at the top of the hierarchical stack:h= (h
1
,···h
L
).  The se-
quence output by the decoder units iss= (s
1
,···s
T
).   The
input spectrogram sequence isx= (x
1
,···x
L
)and the output
spectrogram sequence isy= (y
1
,···y
T
). At the ith step of the
generation process, the recurrent sequence generator, the RNN,
generates states
i
by using they
i
’s up to that point, the previous
s
i−1
and the hidden encoder output(h
1
,···h
L
). The attention
model is used to inform the generator which encoder statesh
j
are important for the generation of thiss
i
, and this is done with
an attentional neural network, which learns to produce the at-
tention or alignment vectorα
i
, which is a vector of normalized
importance weights used to weight the hidden encoder stateh.
This is then used to produce the context vectorc
i
, which is a
weighted sum of the encoder statesh
j
:
s
i
=RNN(s
i−1
,[c
i
,y
i−1
])(1)
c
i
=
∑
j
α
ij
h
j
(2)
The  context  vectorc
i
,  concatenated  with  the  spectogram
output prediction of the previous time stepy
i−1
is used to con-
dition the production of the decoder output for the current time
steps
i
.
The attention vectorα
ij
is obtained by softmax normaliza-
tion (to between 0 and 1) with aβtemperature parameter, over
the scorese
ij
.
α
ij
=softmax(βe
ij
)(3)
whereβis the softmax temperature that sharpens the attention
([45]).
The scores or un-normalized attention energiese
ij
is the
central part of the attention modeling, and is done for each hid-
den  encoder  stateh
j
separately.   There  are  two  ways  of  cal-
culating  these  attention  energies.Content based attention
is  dependent  on  the  content  or  encoder  hidden  state:e
ij
=
score(s
i−1
,h
j
).Location based attentionis dependent on the
location of the previous generator state, or where the attention
was previously focused:e
ij
=score(alpha
i−1
).  This is nor-
mally implemented as a 1-D convolutional kernel (with learnt

Figure 4:The decoder RNN. Att represents the Attention RNN,
RNNa and b represent the first and second layers of the decoder
RNNs.   Red  arrows  indicate  residual  connections  and  purple
arrows indicate the generated output being fed back to the at-
tention RNN (along with input) to generate the attention out-
put. Output of the second decoder is transformed to the dimen-
sions of the output spectrogram using a fully connected layer
(Project).
weights) centred around the previous position. We use a hybrid
attention model, with both content and location based scoring.
Location scoring is done by convolving the previous attention
α
i−1
withF. This is then combined with content scoring:
f
i
=F∗α
i−1
(4)
e
ij
=v
T
tanh((W
1
s
i−1
)
T
(W
2
h
j
) +Uf
ij
)(5)
where vectorvand matricesF,W1,W2andUare trainable
weights,  implemented as a feed-forward neural network.   We
use a form inspired by Luong’s multiplicative attention mecha-
nism [44] to determine the mapping between hidden units and
attention energies in equation 5.
3.3. Decoder RNNs with residuality
The attention RNN’s output is now processed by two RNN lay-
ers  with  residuality,  before  transforming  them  back  to  audio
frames.
g
1
i
=RNN
1
(s
i
,g
1
i−1
) +s
i
(6)
g
2
i
=RNN
2
(g
1
i
,g
2
i−1
) +g
1
i
(7)
This is depicted in the equations (6), (7).  Here, the super-
scripts1,2represent the first and second decoder layers.  The
second term in these equations contain the residual signal from
the input.  In this case,s
i
represents the output from the atten-
tion RNN andg
1
i
andg
2
i
denote the hidden units from the first
and second decoder layers. We use the same number of dimen-
sions (300) in all the decoder RNN layers.
Finally,  the  output  of  the  last  residual  decoder  layer  is
transformed back to the dimensions of the output (80bins) by
sending it to a fully connected layer and adding a ReLU non-
linearity to it.
Figure 5:Feature extractor, depicted through attention align-
ment and mel spectrograms produced by training the network to
produce ljspeech voices, with source and target being the same.
4. Autoencoder pretraining and transfer
learning
Voice conversion with DNNs for parallel data is a difficult un-
dertaking owing to the lack of availability of large multispeaker
voice  conversion  datasets.    To  get  around  this  problem,  we
first pretrain our network as anautoencoderwith a large sin-
gle speaker TTS corpus [46], with the source and target voices
being the same.  After this network is trained - a guideline for
this is to see if system learns alignment - we adapt the network
for the smaller, multispeaker voice conversion data.
Transfer  learning  can  be  seen  as  a  way  to  mitigate  data
insufficiency problems in the speech domain.  This is particu-
larly trenchant owing to the lack of availability of good quality
speech datasets (large corpuses,  and with sufficient diversity)
that can be obtained inexpensively.
The system is trained using the L1 loss between source and
target voices.  The Adam optimizer is used with a learning rate
of10
−4
for the pretraining task, and0.5×10
−5
for the voice
adaptation task. The optimizer parametersβ
1
,β
2
were0.9and
0.999respectively.
5. Experimental setup
Our experimental procedure consists of two steps, as mentioned
in section 4.  We first pretrain the network with a large single-
speaker corpus in which the source and the target are the same.
After this, we allow the network to adapt to the desired source
and target data.
5.1. Datasets
For autoencoder pretraining, we use the LJSpeech dataset [46].
This dataset contains13100short utterances from a single fe-
male speaker reading passages from7audio books, with a to-
tal  audio  amounting  to  about24hours  recorded  on  a  Mac-
book Pro in a home setting with a sampling rate of22050 Hz.
The main task is to perform voice conversion (by adapting the
pretrained network trained above) on the much smaller CMU
Arctic  dataset  [47]  containing1132utterances  from  several
speakers.   We  used  the  male  speakers  ”bdl”,  ”rms”  and  the
female  speakers  ”clb”  and  ”slt”  for  experiments.   The  train-
ing/test/validation split was1000,66and66respectively. Since
this corpus has a sampling rate of16000 Hz, we upsample this
dataset to22050 Hz,  generate audio through the pipeline and
then  downsample  it  back  to  the  original  sampling  rate.   This
measure was adopted instead of downsampling the large corpus
to the target sampling rate because we found that the system
was unable to learn at the lower rate of16 kHz.

Figure  6:Voice  conversion  from  male  (bdl)  to  female  (slt)
voice,  depicted  through  attention  alignment  and  mel  spectro-
grams produced by adapting to small CMU Arctic voice corpus.
Table  1:Network  architecture  hyperparameters.Conv
k
-c-
BN-ReLU-Dropout(f) denotes a convolution of widthk,cout-
put  channels,  BatchNorm,  ReLU,  with  a  dropout  off(=0.1).
Conv
3
-80-Dropout(f)-ReLU-Linear  denotes  a  convolution  of
width3, with80output channels, dropout off(=0.1), followed
by ReLU and a linear projection to the same size output. Prenet
layers are full connections (e.g. FC-256would be a linear con-
nection to an output of size256) but with dropout of0.5.  All
other network components use a dropout of0.1
Encoder PrenetFC-80-ReLU-Dropout(0.5)
CBHConv
k
-BN-480-ReLU-Dropout(0.1)
k= 1,3,5,7,···,25
Maxpool (stride=1) and stack
Conv
3
-80-Dropout(0.1)-ReLU-Linear
Highway layer stack of4
BiGRU0300 cells (f+b); Dropout(0.1)
Hierarchical BiGRU2 layers, 300 cells (f+b);
Dropout(0.1)
Decoder PrenetFC-256-ReLU-Dropout(0.5)
FC-256-ReLU-Dropout(0.5)
Attention GRU600 cells; Dropout(0.1)
Residual GRU 1,2600 cells; Dropout(0.1)
5.2. Example Conversions
In figure 5, we present visualizations of source and target spec-
trograms, conversion and alignment curve for the pretrained au-
toencoder  feature  extractor  using  the  large  LJSpeech  corpus.
The alignment curve in this case shows more decoder timesteps
than the encoder (by a factor of4) because of the hierarchical
encoding scheme which reduces the number of timesteps in the
encoder.
In figure 6, we present corresponding visualizations for the
transfer  learning  experiment  wherein  we  convert  from  male
(bdl)  to  female  (slt)  voice.    Starting  with  a  network  whose
weights are pretrained with the large LJSpeech corpus as an au-
toencoder, we allow the network to adapt to the smaller CMU-
Arctic  dataset,  using1000paired  training  examples.   As  can
be seen, while the conversion is plausible, the transfer learning
spectrogram is somewhat ‘blurry’ owing to the limited amount
of data and the use of the L1 loss,  which makes the spectro-
grams appear oversmoothed. While the alignment curve is more
or less linear, it has a few ’kinks’ (unlike the ljspeech curve) in
keeping with the slight differences that arise in the alignment
path as compared with the case where both source and target
are the same.
5.3. Wavenet Implementation
We  use  a  popular  open  source  wavenet  implementation  [38]
available  online  to  recover  audio  from  mel  spectrograms.
Wavenet  is  an  autoregressive  architecture  [48]  especially  de-
signed for audio generation.  Related architecutures have been
used for generative modeling tasks in other domains:  ByteNet
[49] for text,  PixelCNN [50] for images and Video Pixel Net
[51] for videos. This type of architecture, at a high level works
on a temporal (in the sense that there is a certain temporal order-
ing of data) basis by stacking dilated convolutions with expo-
nentially growing receptive field sizes (e.g.2,4,8,16). Mask-
ing is carried out so as to only allow information from the past.
In wavenet, instead of masking, one simply uses all the inputs
from the past for the operations as the data already has an im-
plicit temporal order to it. The architecture also uses gating and
skip connections to allow better information flow through the
network stack.
A drawback of this type of architecture is that while training
is fast, inference is slow owing to the sample level autoregres-
sive nature of the setup, in that every sample generated is con-
ditioned on all previous samples; the upshot being that with raw
audio (22000samples per second), the calculations become ex-
tremely expensive.  To alleviate these issues, themes from flow
based generative modeling techniques (with some of the ideas
originally proposed in order to improve the expressiveness of
VAE priors [52, 53] by successively transforming them) were
adapted for fast inference during the sampling stage [54, 55].
To use as a vocoder backend, we present the wavenet with
mel-spectrograms as conditioning features.  These are upsam-
pled  (with  transpose  convolutions)  to  match  the  target  rate
with4upsampling  layers.   This  network  has24layers  with
(512,512,256)channels for residuals, gating and skips respec-
tively.  The setup uses mixtures of logistics to model the16bit
(65536bins) raw waveform.   This architecture was also used
to compare against the WaveGlow implementation in [55].  A
more extensive list of hyperparameters is available online [38].
6. Conclusions
In this work,  we demonstrated a way to overcome data limi-
tations (an all too common malady in the speech world) with
a trick to extract linguistic features by pretraining with a large
corpus so that it learns to reconstruct the input voice. These fea-
tures serve as a useful starting point for transfer learning in the
limited data corpus. The architecture proposed is slightly elab-
orate, in that it resorts to hierarchically reducing the number of
timesteps on the encoder side.  The basis for this proposal was
in keeping with the fact that the content embedded in the input
waveforms - viewed as words or phoneme like entities - is much
smaller than the size of the waveforms (5 words vs 100 audio
frames, 10 phonemes vs 100 audio frames, etc.).  With this in-
tuition,  the hierarchical reduction in timesteps is viewed as a
mechanism to extract phoneme like entities by compressing the
content in the input mel spectrogram. Our task is in a sense, to
extract a style independent representation on the encoder side.
The decoder then learns to inject the target speaker’s content
using exactly the same type of architecture as in the Tacotron
works [1, 2].   The output spectrograms are converted back to
audio using a wavenet vocoder, yielding plausible conversions,
demonstrating that our approach is indeed legitimate.
The  system  is  sensitive  to  hyperparameters.   We  noticed
the  capacity  of  the  CBHG  network  is  particularly  important,
and adding dropout at various places helps in generalizing to

the small dataset.  However, dropout also leads to ’blurriness’.
Cleaning  up  the  output  is  probably  necessary  with  a  postnet,
which we have not implemented.
We hope to release code and samples to allow for experi-
mentation.
7. References
[1]  Y.  Wang,  R.  J.  Skerry-Ryan,  D.  Stanton,  Y.  Wu,  R.  J.  Weiss,
N. Jaitly, Y. Xiao, Z. Chen, S. Bengio, Q. Le, Y. Agiomyrgian-
nakis,  R. Clark,  and R. A. Saurous,  “Tacotron:  Towards end to
end speech synthesis,”arXiv preprint arXiv:1703.10135, 2017.
[2]  J.  Shen,  R.  Pang,  R.  J.  Weiss,  N.  Jaitly,  Z.  Yang,  Z.  Chen,
Y. Zhang, Y. Wang, R. Skerry-Ryan, R. A. Sauros, Y. Agiomyr-
giannakis,   and  Y.  Wu,   “Natural  tts  synthesis  by  condition-
ing  wavenet  on  mel  spectrogram  predictions,”arXiv  preprint
arXiv:1712.05884, 2017.
[3]  S. O. Arik, M. Chrzanowski, A. Coates, G. Diamos, A. Gibiansky,
Y.  Kang,  X.  Li,  J.  Miller,  A.  Ng,  J.  Raiman,  S.  Sengupta,  and
M. Shoeybi, “Deep voice: Real-time neural text-to-speech,”arXiv
preprint arXiv:1702.07825, 2017.
[4]  S. O. Arik, G. Diamos, A. Gibiansky, J. Miller, K. Peng, W. Ping,
and Y. Zhou, “Deep voice 2: Multi-speaker text-to-speech,”arXiv
preprint arXiv:1705.08947, 2017.
[5]  W. Ping, K. Peng, S. O. Arik, A. Kannan, S. Narang, J. Raiman,
and  J.  Miller,  “Deep  voice  3:  Scaling  text-to-speech  with  con-
volutional sequence learning,”arXiv preprint arXiv:1710.07654,
2017.
[6]  A. Kain and M. Macon,  “Spectral voice conversion for text-to-
speech synthesis,” inICASSP, IEEE International Conference on
Acoustics,  Speech and Signal Processing - Proceedings,  vol. 1.
IEEE, 1998, pp. 285–288.
[7]  T.  Toda,   A.  W.  Black,   and  K.  Tokuda,   “Voice  conversion
based  on  maximum-likelihood  estimation  of  spectral  parameter
trajectory,”Trans.  Audio,   Speech  and  Lang.  Proc.,   vol.  15,
no.  8,  pp.  2222–2235,  Nov.  2007.  [Online].  Available:   https:
//doi.org/10.1109/TASL.2007.907344
[8]
[9]  S.  Desai,  E.  V.  Raghavendra,  B.  Yegnanarayana,  A.  W.  Black,
and   K.   Prahallad,   “Voice   conversion   using   artificial   neural
networks,”   inProceedings   of   the   2009   IEEE   International
Conference   on   Acoustics,    Speech   and   Signal   Processing,
ser.  ICASSP  ’09.Washington,   DC,  USA:  IEEE  Computer
Society,   2009,   pp.   3893–3896.   [Online].   Available:https:
//doi.org/10.1109/ICASSP.2009.4960478
[10]  S. Desai, A. W. Black, and B. Yegnanarayana, “Voice conversion
using artificial neural networks,” inIEEE Transactions on Audio,
Speech and Language Processing, vol. 18, no. 5, July 2010.
[11]  L. Sun,  S. Yang,  K. Li,  and H. Meng,  “Voice conversion using
deep bidirectional long short-term memory,” inProceedings of the
2015  IEEE  International  Conference  on  Acoustics,  Speech  and
Signal Processing,  ser. ICASSP ’15.Washington,  DC, USA:
IEEE Computer Society, 2015, pp. 4869–4873.
[12]  L. Sun, K. Li, S. Kang, and H. Meng, inIEEE International Con-
ference on Multimedia and Expo, 2016.
[13]  M.   M
 ̈
uller,Information   Retrieval   for   Music   and   Motion.
Springer, 2007.
[14]  S.   H.   Mohammadi   and   A.   Kain,   “An   overview   of   voice
conversion systems,”Speech Commun., vol. 88, no. C, pp. 65–82,
Apr. 2017. [Online]. Available: https://doi.org/10.1016/j.specom.
2017.01.008
[15]  Y. Li, M. Sun, H. Van Hamme, X. Zhang, and J. Yang, “Robust hi-
erarchical learning for non-negative matrix factorization with out-
liers,”IEEE Access, vol. 7, pp. 10 546–10 558, 2019.
[16]  R. Takashima, T. Takiguchi, and Y. Ariki, “Exemplar-based voice
conversion  using  sparse  representation  in  noisy  environments,”
IEICE Transactions on Fundamentals of Electronics, Communi-
cations and Computer Sciences, vol. 96, no. 10, pp. 1946–1953,
2013.
[17]  J.-X.  Zhang,  Z.-H.  Ling,  L.-J.  Liu,  Y.  Jiang,  and  L.-R.  Dai,
“Sequence-to-sequence acoustic modeling for voice conversion,”
arXiv preprint arXiv:1810.06865, 2018.
[18]  J.  Zhang,  Z.  Ling,  Y.  Jiang,  L.  Liu,  C.  Liang,  and  L.  Dai,
“Improving  sequence-to-sequence  acoustic  modeling  by  adding
text-supervision,”CoRR,  vol.  abs/1811.08111,  2018.  [Online].
Available: http://arxiv.org/abs/1811.08111
[19]  W. Chan, N. Jaitly, Q. V. Le, and O. Vinyals, “Listen, attend and
spell,”arXiv preprint arXiv:1508.01211, 2015.
[20]  K.  Tanaka,  H.  Kameoka,  T.  Kaneko,  and  N.  Hojo,  “Atts2s-vc:
Sequence-to-sequence voice conversion with attention and con-
text preservation mechanisms,”arXiv preprint arXiv:1811.04076,
2018.
[21]  H.  Kameoka,  K.  Tanaka,  T.  Kaneko,  and  N.  Hojo,  “Convs2s-
vc  fully  convolutional  sequence-to-sequence  voice  conversion,”
arXiv preprint arXiv:1811.01609, 2018.
[22]  H. Tachibana, K. Uenoyama, and S. Aihara, “Efficiently trainable
text-to-speech system based on deep convolutional networks with
guided  attention,”CoRR,  vol.  abs/1710.08969,  2017.  [Online].
Available: http://arxiv.org/abs/1710.08969
[23]  J.   Zhu,   T.   Park,   P.   Isola,   and   A.   A.   Efros,   “Unpaired
image-to-image   translation   using   cycle-consistent   adversarial
networks,”CoRR, vol. abs/1703.10593, 2017. [Online]. Available:
http://arxiv.org/abs/1703.10593
[24]  D.  Kingma  and  M.  Welling,  “Autoencoding  variational  bayes,”
arXiv preprint arXiv:1312.6114, 2013.
[25]  I. J. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Wade-
Farley, S. Ozair, A. Courville, and Y. Bengio, “Generative adver-
sarial networks,”arXiv preprint arXiv:1406.2661, 2014.
[26]  T.   Kaneko,   H.   Kameoka,   K.   Hiramatsu,   and   K.   Kashino,
“Sequence-to-sequence  voice  conversion  with  similarity  met-
ric  learned  using  generative  adversarial  networks,”  inINTER-
SPEECH, 2017.
[27]  A. B. L. Larsen, S. K. Sønderby, and O. Winther, “Autoencoding
beyond  pixels  using  a  learned  similarity  metric,”CoRR,  vol.
abs/1512.09300,  2015.  [Online].  Available:  http://arxiv.org/abs/
1512.09300
[28]  C.   Hsu,    H.   Hwang,    Y.   Wu,    Y.   Tsao,    and   H.   Wang,
“Voice   conversion   from   unaligned   corpora   using   variational
autoencoding   wasserstein   generative   adversarial   networks,”
CoRR,  vol.  abs/1704.00849,  2017.  [Online].  Available:    http:
//arxiv.org/abs/1704.00849
[29]  M.  Arjrovsky,  S.  Chintala,  and  L.  Bottou,  “Wasserstein  gan,”
arXiv preprint arXiv:1701.07875, 2017.
[30]  T.  Kaneko  and  H.  Kameoka,  “Parallel-data-free  voice  conver-
sion using cycle-consistent adversarial networks,”arXiv preprint
arXiv:1711.11293, 2017.
[31]  H. Kameoka and T. Kaneko, “Stargan-vc: Non-parallel many-to-
many voice conversion with star generative adversarial networks,”
arXiv preprint arXiv:1806.02169, 2018.
[32]  Y. Chen, Y. M. Assael, B. Shillingford, D. Budden, S. E. Reed,
H. Zen, Q. Wang, L. C. Cobo, A. Trask, B. Laurie, C ̧ . G
 ̈
ulc ̧ehre,
A.  van  den  Oord,   O.  Vinyals,   and  N.  de  Freitas,   “Sample
efficient  adaptive  text-to-speech,”CoRR,  vol.  abs/1809.10460,
2018. [Online]. Available: http://arxiv.org/abs/1809.10460
[33]  Y.  Jia,   Y.  Zhang,   R.  J.  Weiss,   Q.  Wang,   J.  Shen,   F.  Ren,
Z.  Chen,  P.  Nguyen,  R.  Pang,  I.  Lopez-Moreno,  and  Y.  Wu,
“Transfer  learning  from  speaker  verification  to  multispeaker
text-to-speech  synthesis,”CoRR,  vol.  abs/1806.04558,   2018.
[Online]. Available: http://arxiv.org/abs/1806.04558
[34]  S.
 ̈
O.  Arik,  J.  Chen,  K.  Peng,  W.  Ping,  and  Y.  Zhou,  “Neural
voice cloning with a few samples,”CoRR, vol. abs/1802.06006,
2018. [Online]. Available: http://arxiv.org/abs/1802.06006
[35]  Y.  Taigman,  L.  Wolf,  A.  Polyak,  and  E.  Nachmani,  “Voice
synthesis  for  in-the-wild  speakers  via  a  phonological  loop,”
CoRR,  vol.  abs/1707.06588,  2017.  [Online].  Available:    http:
//arxiv.org/abs/1707.06588

[36]  E. Nachmani, A. Polyak, Y. Taigman, and L. Wolf, “Fitting new
speakers  based  on  a  short  untranscribed  sample,”CoRR,  vol.
abs/1802.06984,  2018.  [Online].  Available:  http://arxiv.org/abs/
1802.06984
[37]  E.   Nachmani   and   L.   Wolf,   “Unsupervised   polyglot   text   to
speech,”CoRR, vol. abs/1902.02263, 2019. [Online]. Available:
http://arxiv.org/abs/1902.02263
[38]  R.  Yamamoto,  “Wavenet  vocoder,”  2018.  [Online].  Available:
https://github.com/r9y9/wavenetvocoder
[39]  N.  Srivastava,   G.  Hinton,   A.  Krizhevsky,   I.  Sutskever,   and
R.  Salakhutdinov,  “Dropout:   a  simple  way  to  prevent  neural
networks   from   overfitting,”Journal   of   Machine   Learning
Research,  vol.  15,  pp.  1929–1958,  2014.  [Online].  Available:
http://jmlr.org/papers/v15/srivastava14a.html
[40]  R.   J.   Williams   and   D.   Zipser,   “A   learning   algorithm   for
continually  running  fully  recurrent  neural  networks,”Neural
Comput.,   vol.  1,   no.  2,   pp.  270–280,   Jun.  1989.  [Online].
Available: http://dx.doi.org/10.1162/neco.1989.1.2.270
[41]  S. Bengio, O. Vinyals, N. Jaitly, and N. Shazeer, “Scheduled sam-
pling  for  sequence  prediction  with  recurrent  neural  networks,”
arXiv preprint arXiv:1506.03099, 2015.
[42]  A. Lamb, A. Goyal, Y. Zhang, S. Zhang, A. Courville, and Y. Ben-
gio,  “Professor forcing:  A new algorithm for training recurrent
networks,”arXiv preprint arXiv:1610.09038, 2016.
[43]  J. Lee, K. Cho, and T. Hoffman, “Fully character-level neural ma-
chine translation without explicit segmentation,”arXiv prepring
arXiv:1610.03017, 2016.
[44]  M.-T. Luong, H. Pham, and C. D. Manning, “Effective approaches
to  attention-based  neural  machine  translation,”arXiv  preprint
arXiv:1508.04025, 2015.
[45]  J. Chorowski, D. Bahdanau, D. Serdyuk, K. Cho, and Y. Bengio,
“Attention based models for speech recognition,”arXiv preprint
arXiv:1506.07503, 2015.
[46]  K.   Ito,   “The   lj   speech   dataset,”   2017.   [Online].   Available:
https://keithito.com/LJ-Speech-Dataset/
[47]  J.   Kominek   and   A.   W.   Black,   “Cmu   arctic   databases   for
speechsynthesis,”    Language   Technology   Institute,    Carnegie
Mellon  University,  Pittsburgh,  PA,  2003.  [Online].  Available:
http://festvox.org/cmuarctic/index.html
[48]  A.   van   den   Oord,   S.   Dieleman,   H.   Zen,   K.   Simonyan,
O.  Vinyals,  A.  Graves,  N.  Kalchbrenner,  A.  W.  Senior,  and
K.   Kavukcuoglu,   “Wavenet:A   generative   model   for   raw
audio,”CoRR,  vol.  abs/1609.03499,  2016.  [Online].  Available:
http://arxiv.org/abs/1609.03499
[49]  N.  Kalchbrenner,  L.  Espeholt,  K.  Simonyan,  A.  van  den  Oord,
A.  Graves,  and  K.  Kavukcuoglu,  “Neural  machine  translation
in  linear  time,”CoRR,  vol.  abs/1610.10099,   2016.  [Online].
Available: http://arxiv.org/abs/1610.10099
[50]  A.  van  den  Oord,  N.  Kalchbrenner,  O.  Vinyals,  L.  Espeholt,
A. Graves, and K. Kavukcuoglu, “Conditional image generation
with  pixelcnn  decoders,”CoRR,  vol.  abs/1606.05328,   2016.
[Online]. Available: http://arxiv.org/abs/1606.05328
[51]  N. Kalchbrenner, A. van den Oord, K. Simonyan, I. Danihelka,
O.  Vinyals,   A.  Graves,   and  K.  Kavukcuoglu,   “Video  pixel
networks,”CoRR, vol. abs/1610.00527, 2016. [Online]. Available:
http://arxiv.org/abs/1610.00527
[52]  D. J. Rezende and S. Mohamed, “Variational normalizing flows,”
arXiv preprint arXiv:1505.05770, 2015.
[53]  D.   P.   Kingma,   T.   Salimans,   and   M.   Welling,   “Improving
variational  inference  with  inverse  autoregressive  flow,”CoRR,
vol. abs/1606.04934, 2016. [Online]. Available:  http://arxiv.org/
abs/1606.04934
[54]  A. van den Oord, Y. Li, I. Babuschkin, K. Simonyan, O. Vinyals,
K. Kavukcuoglu, G. van den Driessche, E. Lockhart, L. C. Cobo,
F. Stimberg,  N. Casagrande,  D. Grewe,  S. Noury,  S. Dieleman,
E.   Elsen,   N.   Kalchbrenner,   H.   Zen,   A.   Graves,   H.   King,
T.   Walters,   D.   Belov,   and   D.   Hassabis,   “Parallel   wavenet:
Fast high-fidelity speech synthesis,”CoRR, vol. abs/1711.10433,
2017. [Online]. Available: http://arxiv.org/abs/1711.10433
[55]  R.   Prenger,   R.   Valle,   and   B.   Catanzaro,   “Waveglow:A
flow-based generative network for speech synthesis,”CoRR, vol.
abs/1811.00002,  2018.  [Online].  Available:  http://arxiv.org/abs/
1811.00002 

Federated PCA with Adaptive Rank Estimation
Andreas Grammenos
1,3∗
, Rodrigo Mendoza-Smith
2
, Cecilia Mascolo
1
, Jon Crowcroft
1,3
1
Computer Lab, University of Cambridge
2
Engineering Department, University of Oxford
3
Alan Turing Institute
Abstract
In many online machine learning and data science tasks such as data summarisation
and feature compression,d-dimensional vectors are usually distributed across a
large number of clients in a decentralised network and collected in a streaming fash-
ion. This is increasingly common in modern applications due to the sheer volume of
data generated and the clients’ constrained resources. In this setting, some clients
are required to compute an update to a centralised target model independently
using local data while other clients aggregate these updates with a low-complexity
merging algorithm. However, some clients with limited storage might not be able
to store all of the data samples ifdis large, nor compute procedures requiring at
leastΩ(d
2
)storage-complexity such as Principal Component Analysis, Subspace
Tracking, or general Feature Correlation. In this work, we present a novel federated
algorithm for PCA that is able to adaptively estimate the rankrof the dataset and
compute itsrleading principal components when onlyO(dr)memory is available.
This inherent adaptability implies thatrdoes not have to be supplied as a fixed
hyper-parameter which is beneficial when the underlying data distribution is not
known in advance, such as in a streaming setting. Numerical simulations show that,
while using limited-memory, our algorithm exhibits state-of-the-art performance
that closely matches or outperforms traditional non-federated algorithms, and in
the absence of communication latency, it exhibits attractive horizontal scalability.
1    Introduction
In recent years, the advent of edge computing in smartphones, IoT and cryptocurrencies has induced
a paradigm shift in distributed model training and large-scale data analysis. Under this new paradigm,
data is generated by commodity devices with hardware limitations and severe restrictions on data-
sharing and communication, which makes the centralisation of the data extremely difficult. This has
brought new computational challenges since algorithms do not only have to deal with the sheer volume
of data generated by networks of devices, but also leverage the algorithm’s voracity, accuracy, and
complexity with constraints on hardware capacity, data access, and device-device communication. In
light of this, the necessity of being able to analyse large-scale decentralised datasets and extract useful
insights out of them is becoming more prevalent than ever before. Seminal work in this domain has
been made, but mainly in the context of deep neural networks, see McMahan et al.(2016); Kone
ˇ
cn
`
y
et al.(2016). Specifically, in Kone
ˇ
cn
`
y et al.(2016) afederatedmethod for training of neural networks
was proposed.  In this setting one assumes that each of a large number of independentclientscan
contribute to the training of a centralised model by computing local updates with their own data and
sending them to the client holding the centralised model for aggregation. Ever since the publication of
this seminal work, interest in federated algorithms for training neural networks has surged, see Smith
et al.(2017), He et al.(2018),  Geyer et al.(2017). Despite of this, federated adaptations of classical
∗
Correspondence to: Andreas Grammenos<ag926@cl.cam.ac.uk>
Preprint. Under review.
arXiv:1907.08059v1  [cs.LG]  18 Jul 2019

data analysis techniques are still missing. Out of the many techniques available, Principal Component
Analysis (PCA) Pearson (1901); Jolliffe (2011) is arguably the most ubiquitous one for discovering
linear structure or reducing dimensionality in data, so has become an essential component in inference,
machine-learning, and data-science pipelines. In a nutshell, given a matrixY∈R
d×n
ofnfeature
vectors of dimensiond,PCAaims to build a low-dimensional subspace ofR
d
that captures the
directions of maximum variance in the data contained inY. Apart from being a fundamental tool
for data analysis,PCAis often used to reduce the dimensionality of the data to minimise the cost
of computationally expensive operations. For instance, before applying t-SNE Maaten and Hinton
(2008) or UMAP McInnes et al.(2018). Hence, a federated algorithm forPCAis not only desired
when data-ownership is sought to be preserved, but also from a computational viewpoint.
Herein, we propose a federated algorithm for PCA. The computation ofPCAis related to the Singular
Value Decomposition (SVD) Eckart and Young (1936); Mirsky (1966) which can decompose any
matrix into a linear combination of orthonormal rank-1 matrices weighted by positive scalars.  In
the context of high-dimensional data, the main limitation stems from the fact that, in the absence
of structure, performingPCAon a matrixY∈R
d×n
requiresO(d
2
n+d
3
)computation time
andO(d
2
)memory.  This cubic computational complexity and quadratic storage dependency on
dmakes the cost ofPCAcomputation prohibitive for high-dimensional data, though it can often
be circumvented when the data is sparse or has other type of exploitable structure.  Moreover, in
some decentralised applications, the computation has to be done in commodity devices withO(d)
storage capabilities, so aPCAalgorithm withO(d)memory dependency is highly desirable. On this
front, there have been numerous recent works in the streaming setting that try to tackle this problem,
see Mitliagkas et al.(2014, 2013); Marinov et al.(2018); Arora et al.(2012, 2016); Boutsidis et al.
(2015).  However, most of these methods do not naturally scale well nor can they be parallelised
efficiently despite their widespread use, e.g. Bouwmans and Zahzah (2014); Boutsidis et al.(2015).
To overcome these issues a reliable and federated scheme for large decentralised datasets is highly
desirable. In this work, we exploit a known paradigm from the randomised linear algebra literature
dubbedsketch and solveWoodruff et al.(2014). This paradigm aims to save computational costs by
producing asummary, or reduced representation of the data, to approximately solve an instance of the
original problem. In matrix computation terms, this paradigm is particularly suitable if summaries
can be computed incrementally as the data is discovered, such as in the streaming setting.
Summary of contributions
:  Our main contribution is a modular, federated algorithm forPCA
designed for the combined setting of stochastic and streaming data. Our algorithm is comprised out
of two distinct and independent components: (1) An algorithm for the incremental, decentralised
computation of local updates toPCA, (2) a low-complexity merging procedure to aggregate these
incremental updates together.   The incremental component is based on a scheme for streaming
linear dimensionality reduction proposed in Eftekhari et al.(2018) which belongs to the family of
deterministic sketching algorithms in the sequence Ghashami et al.(2016); Liberty (2013); Ghashami
and Phillips (2014). However, contrary to previous algorithms, our algorithm is able to adaptively
estimate the rankrand adjust the number of principal components by controlling the contribution of
the least significant singular value to the total variance. The aggregation component in the streaming
setting is the result of a corollary ofSVD(Lemma 1),  which leads to an improved version of
the algorithm proposed in Rehurek (2011). Moreover, our algorithm is designed to work under the
assumption that we are only allowed to doone passthrough each column ofYusing anO(d)-memory
device.
2    Notation & Preliminaries
This section introduces the notational conventions used throughout the paper. For integersm≤nwe
use the shorthand[m,n] ={m,···,n}and[n]for the special casem= 1. We use lowercase lettersy
for scalars, bold lowercase lettersyfor vectors, bold capitalsYfor matrices, and calligraphic capitals
Yfor subspaces. IfY∈R
d×n
andS⊂[m], thenY
S
is the block composed of columns indexed by
S. In particular, whenS= [k]for somek∈Nwe writeY
[k]
. We reserve0
m×n
for the zero matrix
inR
m×n
andI
n
for the identity matrix inR
n×n
. Additionally, we use‖·‖
F
to denote the Frobenius
norm operator and‖·‖to denote the`
2
norm. IfY∈R
d×n
we letY=UΣV
T
be its fullSVD
formed from unitaryU∈R
d×d
andV∈R
n×n
and diagonalΣ∈R
d×n
havingΣ
i,i
=σ
i
(Y)≥0.
The valuesσ
1
(Y)≥ ··· ≥σ
k
(Y)are the singular values ofY.  If1≤r≤min(m,n), we let
ρ
2
r
(Y) =
∑
i≥r+1
σ
2
i
(Y)
be theresidualofY∈R
m×n
andSVD
r
(Y) =U
r
Σ
r
V
T
r
be itsbest
2

rank-rapproximation, which is the solution to
inf
Z∈R
d×n
‖Z−Y‖
F
subject torank (Z)≤r.
We will often abuse notation and writeSVD
r
(Y)to denote the triplet[U
r
,Σ
r
,V
r
]. Both uses of
SVD
r
should be clear from the context. Finally, we let[Q,R] =QR(Y)be the QR factorisation of
Yandλ
1
(Y)≥···≥λ
k
(Y)be its eigenvalues whend=n.
Streaming Model:A data stream is defined as a feature vector sequencey
t
0
,y
t
1
,y
t
2
,...with the
property thatt
i+1
−t
i
>0for anyi∈N.  In this work, we shall assume that data streams are
vectors inR
d
indexed by the natural numbers, which at any timen∈Ncan be arranged in a matrix
Y∈R
d×n
.
Federated learning:Federated Learning Kone
ˇ
cn
`
y et al.(2016) is a machine-learning paradigm that
considers how a large number ofclientsowning different data-points can contribute to the training
of acentralised modelby locally computing updates with their own data and merging them to the
centralised model without sharing data between each other. Our method resembles the distributed
agglomerative summary model (DASM) Tanenbaum and Van Steen (2007) in which updates are
aggregated in a “bottom-up” approach following a tree-structure. That is, by arranging the nodes in a
tree-like hierarchy in such a way that for any sub-tree, the leaves compute intermediate results and
propagate them to the roots for merging or summarisation. In our model, the summaries only have to
travel upwards only once to be combined. This permits minimal synchronisation between the nodes
so, for the purposes of this work, we do not model any issues related to synchronisation.
3    Federated PCA
We consider a decentralised datasetD={y
1
,...,y
n
}⊂R
d
scattered acrossMclients. The dataset
Dcan be stored in a matrixY=
[
Y
1
|Y
2
|···|Y
M
]
∈R
d×n
withndand such thatY
i
∈R
d×n
i
is owned by clienti∈[M]. We assume that eachY
i
is generated in a streaming fashion and that due
to resource limitations it cannot be stored in full. Furthermore, under the DASM we assume that the
Mclients in the network can be arranged in a tree-like structure withq >1levels and approximately
` >1leaves per node.  Without loss of generality, in this paper we assume thatM=`
q
.  Our
federated algorithm forPCAis given in Algorithm 1.
Algorithm 1:Federated PCA
Data:Y=
[
Y
1
|···|Y
M
]
∈R
d×n
such thatY
i
∈R
d×n
i
belongs to clienti∈[M];
r∈[d], rank estimate;k, number of subspace aggregations per batch;
α,β, bounds onσ
τ,r
if local updates are computed withSAPCA;
Result:(U
′
,Σ
′
)∈R
d×r
×R
r×r
such thatU
′
≈U
[r]
andΣ
′
≈Σ
[r]
withSVD(Y) =UΣV
T
;
Y
1,i
←Y
i
fori∈[M];
foreach levelp∈[q]do
//Phase I: Estimate local updates
foreach clienti∈[M/`
p−1
]in levelpdo
[U
p,i
,Σ
p,i
,∼]←SVD
r
(Y
p,i
)
end
//Phase II: Merging estimations
Obtain(U
p+1,i
,Σ
p+1,i
)by merging
{(
U
p,i
,Σ
p,i
)}
i∈[M/`
p−1
]
recursively on batches of sizek;
end
(U
′
,Σ
′
)←
(
U
q+1,1
[r]
,Σ
q+1,1
[r]
)
;
Note that Algorithm 1, invokes two separate sets of procedures corresponding to the computation
of  local  updates  and  the  merging  of  resulting  sub-spaces.   In  the  inner-most  loop,  each  client
i∈[M/`
p−1
]collects  or  generatesY
p,i
in  a  streaming  fashion  and  computes  an  estimate  of
SVD
r
(Y
p,i
)usingSPCAorSAPCA(Algorithm 3). Then, the estimates for levelpare aggregated
by the callingmerge(Algorithm 2) recursively on subspace batches of sizek. Due to the recursive
nature of the procedure, onlyM/`
p
log(M/`
p
) =`
q−p
log(`
q−p
)merging operations are required at
levelp. Detailed descriptions of Algorithms 2-3 are given in the following sections.
3

3.1    Merging
Our algorithmic constructions are built upon the concept ofsubspace mergingin which two subspaces
S
1
= (U
1
,Σ
1
)∈R
r
1
×d
×R
r
1
×r
1
andS
2
= (U
2
,Σ
2
)∈R
r
2
×d
×R
r
2
×r
2
aremergedtogether to
produce a subspaceS= (U,Σ)∈R
r×d
×R
r×r
describing the combinedrprincipal directions of
S
1
andS
2
. One can merge two sub-spaces by computing a truncatedSVDon a concatenation of their
bases. Namely,
[U,Σ,V
T
]←SVD
r
([λU
1
Σ
1
,U
2
Σ
2
]),(1)
whereλ∈(0,1]aforgetting factorthat allocates less weight to the previous subspaceU
1
.  An
efficient version of(1)is presented in Algorithm 4 (Appendix). In Rehurek (2011), it is shown how
(1)can be further improved whenV
T
is not required and we have knowledge thatU
1
andU
2
are
already orthonormal. This is done by building a basisU
′
forspan((I−U
1
U
1
T
)U
2
)
via the QR
factorisation and then computing theSVDdecomposition of a matrixXsuch that
[U
1
Σ
1
,U
2
Σ
2
] = [U
1
,U
′
]X(2)
It is shown in  (Rehurek, 2011, Chapter 3) that this yields anXof the form
X=
[
U
T
1
U
1
Σ
1
U
T
1
U
2
Σ
2
U
′
T
U
1
U
′T
U
2
Σ
2
]
=
[
Σ
1
U
T
1
U
2
Σ
2
0R
p
Σ
2
]
(3)
where[U,R
p
] =QR((I−U
1
U
T
1
)U
2
). This procedure is shown in Algorithm 2.
Algorithm 2:MergeSubspaces (Fastest subspace-merging algorithm)
Data:(U
1
,Σ
1
)∈R
d×r
1
×R
r
1
×r
1
,(U
2
,Σ
2
)∈R
d×r
2
×R
r
2
×r
2
, subspaces to be merged;
r∈[r], rank estimate ;λ
1
∈(0,1), forgetting factor forU
1
;λ
2
≥1, enhancing factor forU
2
;
Result:(U
′
,Σ
′
)∈R
d×r
×R
r×r
merged subspace;
Z
r
←U
T
1
U
2
;
[U
p
,R
p
]←QR(U
2
−U
1
Z
r
);
[U
R
,Σ
′
,∼]←SVD
r
([
λ
1
Σ
1
Z
r
Σ
2
0λ
2
R
p
Σ
2
])
;
U
′
←[U
1
,U
p
]U
R
;
The merging procedure outlined above can be generalised to multiple subspaces. A proof of this was
given by Iwen and Ong (2016). In Lemma 1 we extend this result to the case of streaming data. The
proof is delayed to the Appendix.
Lemma 1
(Streaming partialSVDuniqueness).LetY=
[
Y
1
|Y
2
|···|Y
M
]
∈R
d×n
withnd
andY
i
∈R
d×n
i
withSVDgiven byY
i
=
ˆ
U
i
ˆ
Σ
i
(
ˆ
V
i
)
T
.  Assume streaming data and that at any
given time only onlybn
i
vectors can be stored in each client. LetZ:= [
ˆ
U
1
ˆ
Σ
1
|···|
ˆ
U
M
ˆ
Σ
M
],
and letY=
ˆ
U
ˆ
Σ
ˆ
V
T
andZ=
ˆ
U
′
ˆ
Σ
′
(
ˆ
V
′
)
T
be the reducedSVDdecompositions ofYandZ. Then
ˆ
Σ=
ˆ
Σ
′
, and
ˆ
U=
ˆ
U
′
B, whereBis a unitary block diagonal matrix. If none of the nonzero singular
values are repeated thenB=I.
We stress that result proved in Iwen and Ong (2016) is incremental, butnotstreaming. This means
that every result has to be computed in-full in order to be processed, merged, and propagated for the
user to get a final result, so is not fit for a federated computing approach.
3.2    Estimation of local updates: Streaming, adaptivePCA
In this section we introduceSPCAandSAPCAwhich are the streaming algorithms clients use to
compute local updates to the centralised model. Consider a sequence{y
1
,...,y
n
}⊂R
d
of feature
vectors and let their concatenation at timeτ≤nbe
Y
[τ]
= [
y
1
y
2
···y
τ
]∈R
d×τ
.(4)
A block of sizeb∈Nis formed by takingbcontiguous columns ofY
[τ]
. Hence, a matrixY
[τ]
with
r≤b≤τinducesK=dτ/beblocks. For convenience, we assumeK∈N, so thatτ=Kb∈N. In
this case, blockk∈[K]corresponds to the sub-matrix containing columnsS
k
= [(k−1)b+ 1,kb].
4

It is assumed that all blocksS
k
are owned and observed exclusively by clienti∈[M], but that due to
resource limitations it can not store them all. Hence, once clientihas observedY
S
k
∈R
d×b
it uses
it to update its estimate
̂
Y
[(k−1)b],r
of therprincipal components ofY
[kb]
and then releasesY
S
k
from memory. If
̂
Y
0,r
is the empty matrix, therprincipal components ofY
[τ]
can be estimated by
̂
Y
[kb],r
=SVD
r
([
̂
Y
[(k−1)b],r
Y
S
k
])
∈R
d×kb
.(5)
This algorithm is calledMOSESand was proposed in Eftekhari et al.(2018).  Its output afterK
iterations is
̂
Y
[Kb],r
= SVD
r
(Y
[τ]
)
, which, as mentioned above, contains both an estimate of leading
rprincipal components ofY
[τ]
and the projection ofY
[τ]
onto this estimate.  The local subspace
estimation of our federated algorithm is inspired on an implementation of iteration(5)presented
in Eftekhari et al.(2018). However, our algorithm is designed to achieve substantial computational
savings by only tracking the left principal subspace and, contrary to other algorithms, the singular
value estimates. Additionally, the nodes in our algorithm can adjust, independently of each other,
their rank estimate based on the distribution of the data seen so far. This is convenient because we
expect to have nodes which observe different distributions and will likely require to adjust the number
of principal components kept in order to accurately track the data distribution over time. Whileenergy
thresholding methodsAl-Kandari and Jolliffe (2005); Papadimitriou et al.(2005) are a natural and
established way to achieved this, these methods only work well when updates are performed for each
feature vector. Moreover, according to our experiments, they also under-perform with block-based
approaches. To this end, we propose a simple and efficient regularisation scheme based solely on the
estimate of the current singular values and their contribution to the total approximation discovered so
far. Specifically, lettingσ
τ,i
be thei-th singular value of the dataset at timeτ >0, we useσ
τ,r
to
control thelower boundon the total variance
∑
r
i=1
σ
τ,i
. We do this by lettingα,β >0be minimum
and maximum contributions to the variance of the dataset and enforcing
C
τ,r
=
σ
τ,r
∑
r
i=1
σ
τ,i
∈[α,β].(6)
That is, by increasingrwheneverC
τ,r
> βand decreasing it whenC
τ,r
< α.  This adjustment
happens only once per block in order to prevent the addition of too many principal components in
one go, but point out that a number of variations to this strategy are possible. For example, a user
could also implement ahold-offduration to prevent updates inrfor a predefined number of blocks.
Our algorithm is presented in Algorithm 3. We use the labelsSPCAandSAPCAto distinguish the
variant with adaptive rank estimation.
Note that Algorithm 3 can, if desired, explicitly maintain the estimates of principal components
along with the projected data.  Moreover, its storage and computational requirements are nearly
optimal for the given objective since, at iterationk, it only requiresO(r(d+kr))bits of memory and
O(r
2
(d+kb)) =O(r
2
(d+kr))flops. We point out thatSPCAinherits some theoretical guarantees
which ensure that its output differs from the offlineSVDin only a small polynomial factor, see
Appendix B. Finally, in Lemma 2 we provide a simple bound on the error ofSAPCAtogether with
an guarantee on time-order independence in the data, which is essential in a decentralised, federated
system to guarantee robustness. The proofs to these statements are given in the Appendix.
Lemma 2(SPCA/SAPCAproperties).LetY∈R
d×n
,r∈[d], andα,β >0. Then,
1.‖Y−
ˆ
Y‖
F
≤ρ
r
min
(Y)where
ˆ
Y=  SAPCA(Y,r,α,β)andr
min
=r
min
(α,β)is the
minimum rank estimated bySAPCA.
2.IfP∈R
n×n
is a row permutation of the identity,  thenSPCA(Y) = SPCA(YP).  A
similar result holds forSAPCA.
4    Experimental Evaluation
To validate our scheme, we evaluate the empirical performance ofSAPCAby comparing it against
competing algorithms using synthetic and real datasets
2
.  All our experiments were computed on
a server using Dual Intel Xeon X5650 CPUs with12cores at2.66GHz,32GB1333MHz ECC
2
To foster reproducibility both code and datasets used are made publicly available here:https://github.
com/andylamp/federated_pca.
5

Algorithm 3:StreamingPCA/ Streaming AdaptivePCA(SPCA/SAPCA)
Data:Feature vectors{y
t
}
t∈[τ]
∈R
d
, withτ=Kb;
r∈[d], rank estimate ;b∈[r,∞)the desired block size;
α,β, bounds onσ
τ,r
(If algorithm is SPCA);
Result:{(
̂
U
kb,r
,
̂
Σ
kb,r
) :k∈[K]}, estimations of the principal subspaces for thek-th block.
fork∈[K]do
Y
S
k
←
[
y
(k−1)b+1
···y
kb
]
, //S
k
= [(k−1)b+ 1,kb];
ifk= 1then
[
̂
U
b,r
,
̂
Σ
b,r
,∼]←SVD
r
(Y
S
k
);
else
Z
k
←
̂
U
T
(k−1)b,r
Y
S
k
∈R
r×b
;
[
̂
U
k
,R
k
]←QR(Y
k
−
̂
U
(k−1)b,r
Z
k
);
[U
p
,
̂
Σ
kb,r
,∼]←SVD
r
([
̂
Σ
(k−1)b,r
Z
k
0
b×r
R
k
])
;
̂
U
kb,r
←[
̂
U
(k−1)b,r
̂
U
k
]U
p
;
end
ifAlgorithm isSAPCAthen
ifσ
r
> β
∑
r
i=1
σ
i
then
r←r+ 1
̂
U
kb,r
←[
̂
U
kb,r
,e
r
],e
r
∈R
d
isr-th canonical vector.
else ifσ
r
< α
∑
r
i=1
σ
i
then
r←r−1
̂
U
kb,r
←(
̂
U
kb,r
)
[r]
end
end
end
DDR3 RAM, and Matlab R2019a (build 9.6.0.1099231). The algorithms considered in this instance
are,SAPCA, GROUSE Balzano and Wright (2013), Frequent Directions (FD) Desai et al.(2016);
Luo et al.(2017), the Power Method (PM) Mitliagkas et al.(2014), and a variant of Projection
Approximation Subspace Tracking (PAST) Yang (1995), named SPIRIT (SP) Papadimitriou et al.
(2005). AsSPCAis derived from MOSES Eftekhari et al.(2018) and returns the same subspace and
singular values as MOSES given afixedr; hence, a comparison with MOSES is not done. We assume
a dataset like(4)and that for each algorithmalgand eacht∈[τ]an estimate
ˆ
Y
alg
= SVD
r
(Y
t
)
is
computed along with the Frobenius-norm error and Mean Squared Error (MSE). That is,
Err
alg,F
t,r
=‖Y
t
−
̂
Y
alg
t,r
‖
2
F
,Err
alg,mse
t,r
=
1
t
‖Y
t
−
̂
Y
alg
t,r
‖
2
F
, alg∈{SAPCA,GROUSE,FD,PM,SP}.
4.1SAPCAperforms favourably compared to other methods in synthetic and real datasets
Figures 1a and 1b show the results of our experiments on synthetic dataSynth(α)
d×n
⊂R
d×n
with(d,n) = (400,4000)generated independently from a zero-mean multivariate Gaussian with
covariance matrixSΛS
T
, whereS∈R
d×d
is the orthogonalisation of a random Gaussian matrix
andΛ∈R
d×d
is a diagonal matrix withΛ
i,i
=i
−α
andα >0.  In the experiments, we letλbe
the forgetting factor of SP. Figure 1a comparesSPCAwith SP when(α,λ) = (1,0.9)and Figure
1b when(α,λ) = (2,1).  WhileSPCAexhibits relative stability inErr
SPCA,F
t,r
in both cases,SP
exhibits a monotonic increase in the number of principal components estimated when(α,λ) = (2,1).
This behaviour is replicated in Figures 1e and 1f whereErr
MSE
is computed onSAPCA, SP, and
variations ofSPCAand PM dubbedSPCA
lo
,SPCA
hi
, andPM
lo
with rank set to the minimum (lo)
and maximum (hi) ranks estimated bySAPCAin the simulation.  Figures 1c and 1d benchmark
SAPCAon real sensor-nodehumidityandlightdatasets
3
obtained from Deshpande et al.(2004)
both with dimensionality ofR
48×7712
.   The figures show that our method performs favourably
3
Datasets onvoltandtemperaturereadings are also available and used, see Appendix C.1 for detailed
description of these datasets and additional experiments.  Source of data:https://www.cs.cmu.edu/afs/
cs/project/spirit-1/www/data/Motes.zip
6

against all competing algorithms. Additional experiments on synthetic and real datasets are given in
Appendix C.1.
05001000150020002500300035004000
time ticks
0
10
20
30
40
PC count
PCs evolution over T (4000) with 400 feats for alpha: 1.00000
SAPCA
SP
05001000150020002500300035004000
time ticks
0
0.5
1
error (fro)
10
-3
Fro errs over T (4000) for alpha: 1.00000
SAPCA
SP
(a)‖·‖
F
and PC count on Synth(1)withλ= 0.9
05001000150020002500300035004000
time ticks
0
100
200
300
400
PC count
PCs evolution over T (4000) with 400 feats for alpha: 2.00000
SAPCA
SP
05001000150020002500300035004000
time ticks
0
0.5
1
1.5
error (fro)
10
-4
Fro errs over T (4000) for alpha: 2.00000
SAPCA
SP
(b)‖·‖
F
and PC count on Synth(2)withλ= 1
010002000300040005000600070008000
time ticks
0
5
10
fro error
10
4
fro errors for Humidity Data
SP
SAPCA
SPCA
lo
SPCA
hi
PM
lo
GROUSE
010002000300040005000600070008000
time ticks
0
1000
2000
3000
4000
fro error
fro errors for Humidity Data without SP
SAPCA
SPCA
lo
SPCA
hi
PM
lo
(c)‖·‖
F
onhumiditydataset
010002000300040005000600070008000
time ticks
0
5
10
15
fro error
10
7
fro errors for Light Data
SP
SAPCA
SPCA
lo
SPCA
hi
PM
lo
GROUSE
010002000300040005000600070008000
time ticks
0
1
2
3
4
fro error
10
6
fro errors for Light Data without SP
SAPCA
SPCA
lo
SPCA
hi
PM
lo
(d)‖·‖
F
onlightdataset
0.00010.0010.5123
alphas
0
0.5
1
1.5
2
2.5
3
error (MSE)
10
-3
Estimated vs Real Subspace MSE
SP
SAPCA
SPCA
lo
SPCA
hi
PM
lo
FD
GROUSE
(e) Err
MSE
withλ= 0.9
0.00010.0010.5123
alphas
0
0.5
1
1.5
2
2.5
3
3.5
4
4.5
5
error (MSE)
10
-3
Estimated vs Real Subspace MSE
SP
SAPCA
SPCA
lo
SPCA
hi
PM
lo
FD
GROUSE
(f) Err
MSE
withλ= 1
Figure 1: Performance ofSAPCAon synthetic and real datasets.
4.2SAPCA’s memory efficiency is considerably better on average than competing methods
Table 1 reports average and median memory-allocation profiles for each algorithm and each sensor-
node dataset provided in Deshpande et al.(2004).  The statistics were computed over a sample of
ten runs.  Table 1 shows thatSAPCA’s memory efficiency is compares favourably against other
algorithms in the experiment. See Appendix C.3 for further details and an extended discussion.
7

Table 1: Average / median memory allocations
Real Datasets
MethodHumidityLightVoltageTemperature
SAPCA138.11Kb /58.99Kb104.00Kb /76.03Kb204.58/23.47Kb187.74Kb /113.28Kb
PM905.45Kb /666.11685.48Kb /685.44Kb649.12Kb /644.35Kb657.57Kb /668.27Kb
GROUSE2896.61Kb /2896.62Kb2896.84Kb /2896.62Kb2772.86Kb /2772.62Kb3379.62Kb /3376.62Kb
FD162.70Kb /117.92Kb170.48Kb /127.91Kb114.46Kb /112.66Kb196.11Kb /118.59Kb
SP476.68Kb /405.01Kb1009.03Kb /508.11Kb348.84Kb /351.98Kb541.56Kb /437.61Kb
4.3    The federated scheme shows graceful scaling when simulated in a multi-core CPU
To simulate a federated computation environment we compare the average execution times,time(Y),
required  to  computePCAon  a  datasetY∈R
d×T
.    To  do  this,  we  fixd=  1kand  for
eachT∈ {128k,256k,384k,512k}, report
1
|L|
∑
α∈L
time(Y
α
)
whereY
α
∼Synth(α)
d×T
and
L={10
i−5
:i∈[5]}∪{2,3,4}.  In Figure 2 we report the time required to compute each sub-
problem and merge the results together under different assumptions on the number of computing
nodes (maximum of 32 in our simulation).  The real time scalings are shown in Figure 2a while
the amortised scaling, corresponding to the federated scenario of having one processing core per
client, can be seen in Figure 2b. Figure 2a shows that a regression occurs after we exceed the number
of available physical cores on our machine (in our case12) while fixingTto a specific value; this
behaviour is normal as, due to the lack of processing nodes, not all of the sub-problems can be
executed in concurrently. On the other hand, Figure 2b shows a very graceful scaling in the average
execution times in the presence of as many processing nodes as the amount of sub-problems to solve
across all values ofT. We also assume that each node is independent and completely owns its subset
of the (evolving) dataset. More details and discussion can be found in Appendix C.4.
2481632
node count
0
5
10
15
20
time (s)
T=128K
T=256K
T=384K
T=512K
(a) Real
2481632
node count
0
2
4
6
8
10
time (s)
T=128K
T=256K
T=384K
T=512K
(b) Amortised.
Figure 2:SAPCAPerformance Scaling for Real and Amortised execution time.
5    Discussion & Conclusions
We introduced a federated streaming algorithm forPCA. Our federated algorithm is the result of
two separate innovations. Namely, an adaptive streaming algorithm for computing rank-rapprox-
imations (SAPCA), and a fast subspace merging algorithm to aggregate these updates together
(MergeSubspaces).  We complement our algorithm with several theoretical results that guarantee
bounded estimation errors and as well as data permutation invariance. In particular, we extended a
result by Iwen and Ong (2016) to guarantee bounded memory inSAPCA, which is crucial to enable
horizontal scalability and bringPCAto the federated setting. Our numerical experiments show that
SAPCAperforms favourably against other methods in terms of convergence, bounded estimation
errors, low memory requirements, and also that Federated-PCAscales gracefully when simulated on
a multi-core CPU. While our algorithm comes with no guarantees on data-privacy, we point out that
it can readily implement the input-perturbation scheme described in Chaudhuri et al.(2013), but we
leave this as potential avenue for future work. Another interesting avenue of future work is to devise
a computationally efficient scheme for performingPCAin a federated setting but in the presence of
missing values.
8

References
Noriah M Al-Kandari and Ian T Jolliffe. 2005. Variable selection and interpretation in correlation
principal components.Environmetrics: The official journal of the International Environmetrics
Society16, 6 (2005), 659–672.
Raman Arora, Andrew Cotter, Karen Livescu, and Nathan Srebro. 2012. Stochastic optimization for
PCA and PLS. InCommunication, Control, and Computing (Allerton), 2012 50th Annual Allerton
Conference on. IEEE, 861–868.
Raman Arora, Poorya Mianjy, and Teodor Marinov. 2016. Stochastic optimization for multiview rep-
resentation learning using partial least squares. InInternational Conference on Machine Learning.
1786–1794.
L. Balzano and S. J Wright. 2013.   On GROUSE and incremental SVD. InIEEE International
Workshop on Computational Advances in Multi-Sensor Adaptive Processing (CAMSAP). IEEE,
1–4.
Christos Boutsidis, Dan Garber, Zohar Karnin, and Edo Liberty. 2015. Online principal components
analysis. InProceedings of the twenty-sixth annual ACM-SIAM symposium on Discrete algorithms.
Society for Industrial and Applied Mathematics, 887–901.
Thierry Bouwmans and El Hadi Zahzah. 2014. Robust PCA via principal component pursuit: A review
for a comparative evaluation in video surveillance.Computer Vision and Image Understanding
122 (2014), 22–34.
Kamalika Chaudhuri, Anand D Sarwate, and Kaushik Sinha. 2013.  A near-optimal algorithm for
differentially-private principal components.The Journal of Machine Learning Research14, 1
(2013), 2905–2943.
Amey Desai, Mina Ghashami, and Jeff M Phillips. 2016. Improved practical matrix sketching with
guarantees.IEEE Transactions on Knowledge and Data Engineering28, 7 (2016), 1678–1690.
Amol Deshpande, Carlos Guestrin, Samuel R Madden, Joseph M Hellerstein, and Wei Hong. 2004.
Model-driven data acquisition in sensor networks. InProceedings of the Thirtieth international
conference on Very large data bases-Volume 30. VLDB Endowment, 588–599.
C. Eckart and G. Young. 1936.  The approximation of one matrix by another of lower rank.Psy-
chometrika1 (1936), 211–218.https://doi.org/10.1007/BF02288367
Armin  Eftekhari,  Raphael  A  Hauser,  and  Andreas  Grammenos.  2018.   MOSES:  A  Streaming
Algorithm for Linear Dimensionality Reduction.arXiv preprint arXiv:1806.01304(2018).
Robin C Geyer, Tassilo Klein, and Moin Nabi. 2017.  Differentially private federated learning: A
client level perspective.arXiv preprint arXiv:1712.07557(2017).
Mina Ghashami, Edo Liberty, Jeff M Phillips, and David P Woodruff. 2016.  Frequent directions:
Simple and deterministic matrix sketching.SIAM J. Comput.45, 5 (2016), 1762–1792.
Mina Ghashami and Jeff M Phillips. 2014. Relative errors for deterministic low-rank matrix approxi-
mations. InProceedings of the twenty-fifth annual ACM-SIAM symposium on Discrete algorithms.
SIAM, 707–717.
Lie He, An Bian, and Martin Jaggi. 2018. Cola: Decentralized linear learning. InAdvances in Neural
Information Processing Systems. 4536–4546.
MA Iwen and BW Ong. 2016. A distributed and incremental svd algorithm for agglomerative data
analysis on large networks.SIAM J. Matrix Anal. Appl.37, 4 (2016), 1699–1718.
Ian Jolliffe. 2011. Principal component analysis. InInternational encyclopedia of statistical science.
Springer, 1094–1096.
Jakub Kone
ˇ
cn
`
y, H Brendan McMahan, Felix X Yu, Peter Richt
 ́
arik, Ananda Theertha Suresh, and
Dave Bacon. 2016. Federated learning: Strategies for improving communication efficiency.arXiv
preprint arXiv:1610.05492(2016).
9

Edo Liberty. 2013.  Simple and deterministic matrix sketching. InProceedings of the 19th ACM
SIGKDD international conference on Knowledge discovery and data mining. ACM, 581–588.
Luo Luo, Cheng Chen, Zhihua Zhang, Wu-Jun Li, and Tong Zhang. 2017. Robust Frequent Directions
with Application in Online Learning.arXiv preprint arXiv:1705.05067(2017).
Laurens van der Maaten and Geoffrey Hinton. 2008.  Visualizing data using t-SNE.Journal of
machine learning research9, Nov (2008), 2579–2605.
Teodor Vanislavov Marinov, Poorya Mianjy, and Raman Arora. 2018. Streaming Principal Component
Analysis in Noisy Settings. InInternational Conference on Machine Learning. 3410–3419.
Leland McInnes, John Healy, and James Melville. 2018. Umap: Uniform manifold approximation
and projection for dimension reduction.arXiv preprint arXiv:1802.03426(2018).
H Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, et al.2016. Communication-
efficient learning of deep networks from decentralized data.arXiv preprint arXiv:1602.05629
(2016).
L. Mirsky. 1966. Symmetric gauge functions and unitarily invariant norms.Quart. J. Math. Oxford
(1966), 1156–1159.
Ioannis Mitliagkas, Constantine Caramanis, and Prateek Jain. 2013. Memory limited, streaming PCA.
InAdvances in Neural Information Processing Systems. 2886–2894.
I. Mitliagkas, C. Caramanis, and P. Jain. 2014. Streaming PCA with many missing entries.Preprint
(2014).
Spiros Papadimitriou, Jimeng Sun, and Christos Faloutsos. 2005.  Streaming pattern discovery in
multiple time-series. InProceedings of the 31st international conference on Very large data bases.
VLDB Endowment, 697–708.
Karl Pearson. 1901. LIII. On lines and planes of closest fit to systems of points in space.The London,
Edinburgh, and Dublin Philosophical Magazine and Journal of Science2, 11 (1901), 559–572.
Radim Rehurek. 2011. Subspace tracking for latent semantic analysis. InEuropean Conference on
Information Retrieval. Springer, 289–300.
Virginia Smith, Chao-Kai Chiang, Maziar Sanjabi, and Ameet S Talwalkar. 2017. Federated multi-task
learning. InAdvances in Neural Information Processing Systems. 4424–4434.
Andrew S Tanenbaum and Maarten Van Steen. 2007.Distributed systems: principles and paradigms.
Prentice-Hall.
David P Woodruff et al.2014.  Sketching as a tool for numerical linear algebra.Foundations and
Trends
R
©in Theoretical Computer Science10, 1–2 (2014), 1–157.
Bin Yang. 1995. Projection approximation subspace tracking.IEEE Transactions on Signal processing
43, 1 (1995), 95–107.
10

A    Supplementary Material
We start, by providing the full proof for Lemma 1.
Proof.
Let the singular values ofYbe the positive square root of the eigenvalues ofYY
T
; then by
using the previously defined streaming block decomposition of a matrixYwe have the following,
YY
∗
=
M
∑
i=1
Y
i
(Y
i
)
∗
=
M
∑
i=1
ˆ
U
i
ˆ
Σ
i
(
ˆ
V
i
)
T
(
ˆ
V
i
)(
ˆ
Σ
i
)
T
(
ˆ
U
i
)
T
=
M
∑
i=1
ˆ
U
i
ˆ
Σ
i
(
ˆ
Σ
i
)
T
(U
i
)
T
Equivalently, the singular values ofZare similarly defined as the square root of the eigenvalues of
ZZ
T
.
ZZ
T
=
M
∑
i=1
(
ˆ
U
i
ˆ
Σ
i
)(
ˆ
U
i
ˆ
Σ
i
)
∗
=
M
∑
i=1
ˆ
U
i
ˆ
Σ
i
(
ˆ
Σ
i
)
∗
(
ˆ
U
i
)
∗
ThusYY
T
=ZZ
T
, hence the singular values of matrixZmust surely equal to those of matrixY.
Moreover, since the left singular vectors of bothYandZwill be also eigenvectors ofYY
T
and
ZZ
T
, respectively; then the eigenspaces associated with each - possibly repeated - eigenvalue will
also be equal thus
ˆ
U=
ˆ
U
′
B. The block diagonal unitary matrixBwhich hasbunitary blocks of
sizeb×bfor each repeated eigenvalue; this enables the singular vectors which are associated with
each repeated singular value to be rotated in the desired matrix representation
ˆ
U.
We continue with the proof of Lemma 2, which begins by proving Lemma 2.1
Proof.
IfY=UΣV
T
is theSVDofY, thenYP=UΣ
(
V
T
P
)
. SinceV
′
=P
T
Vis orthogonal,
UΣ(V
′
)
T
is theSVDofYP.  Hence, bothYandYPhave the same singular values and left
principal subspaces.
We then finalise our proof of Lemma 2 by proving Lemma 2.2
Proof.At iterationk∈[K],SPCAcomputes
ˆ
Y
SPCA
[kb],r
,  the best rank-rapproximation ofY
[kb]
using  iteration(5).    Hence,  for  eachk∈[K],  the  error  of  the  approximation  is  given  by
‖Y
[kb]
−
ˆ
Y
SPCA
[kb]
‖
F
=ρ
r
(Y
[kb]
)
.   Letr
min
=r
min
(α,β)andr
max
=r
max
(α,β)>0be the
minimum and maximum rank estimates in when runningSAPCA. The result follows from
ρ
r
max
(α,β)
(Y
[kb]
)≤‖Y
[kb]
−
ˆ
Y
SAPCA
[kb]
‖
F
≤ρ
r
min
(α,β)
(Y
[kb]
).
Now we present in Algorithm 4 the full implementation of the basic subspace merging algorithm
which is a direct consequence of Lemma 1, with the only addition of the forgetting factorλthat
only serves the purpose of giving more significance to the “newer” subspace. Following this, we can
improve upon Algorithm 4 by exploiting the fact that the input subspaces are alreadyorthonormal
hence we can transform the Algorithm 4 to Algorithm 5. The key intuition comes from the fact that
we can incrementally updateUby usingU←Q
p
U
R
. To do this we need to first create a subspace
basis which spansU
1
andU
2
, namelyspan(Q
p
) =span([U
1
,U
2
]). This is done by performing
[Q
p
,R
p
] = QR([λ
1
U
1
Σ
1
,λ
2
U
2
Σ
2
])and useR
p
to perform an incremental update. However,R
p
is not diagonal, so a furtherSVDneeds to be applied on it, which yields the required singular values
and the rotation matrix to apply ontoQ
p
to represent the new subspace basis.
11

Algorithm 4:Basic MergeSubspaces algorithm
Data:U
1
∈R
d×r
1
, first subspace
Σ
1
∈R
r
1
×r
1
, first subspace singular values
U
2
∈R
d×r
2
, second subspace
Σ
2
∈R
r
2
×r
2
, second subspace singular values
r∈[r], , the desired rankr
λ∈(0,1), forgetting factor
λ
2
≥1, enhancing factor
Result:U
′
∈R
d×r
, merged subspace
Σ
′
∈R
r×r
, merged singular values
[U
′
,Σ
′
, ̃]←SVD
r
([λ
1
U
1
Σ
1
,λ
2
U
2
Σ
2
])
Algorithm 5:Faster MergeSubspaces algorithm
Data:U
1
∈R
d×r
1
, first subspace
Σ
1
∈R
r
1
×r
1
, first subspace singular values
U
2
∈R
d×r
2
, second subspace
Σ
2
∈R
r
2
×r
2
, second subspace singular values
r∈[r], , the desired rankr
λ
1
∈(0,1), forgetting factor
λ
2
≥1, enhancing factor
Result:U
′
∈R
d×r
, merged subspace
Σ
′
∈R
r×r
, merged singular values
[Q
p
,R
p
]←QR(λ
1
U
1
Σ
1
|λ
2
U
2
Σ
2
)
[U
R
,Σ
′
, ̃]←SVD
r
(R
p
)
U
′
←Q
p
U
R
B    SAPCA Inherited Guarantees
We note thatSAPCAin Algorithm 3 inherits some theoretical guarantees from MOSES presented
in Eftekhari et al.(2018). Specifically, letμbe anunknownprobability measure supported onR
d
with zero mean. The informal objective is to find anr-dimensional subspaceUthat provides the best
approximation with respect to the mass ofμ. That is, provided thatyis drawn fromμ, the target is to
find anr-dimensional subspaceUthat minimises thepopulation riskby solving
min
U∈G(d,r)
E
y∼μ
‖y−P
U
y‖
2
2
.(7)
where the GrassmanianG(d,r)is the manifold of allr-dimensional subspaces inR
d
andP
U
∈R
d×d
is the orthogonal projection ontoU. Unfortunately, the value ofμis unknown and cannot be used
to directly solve(7), but provided we have access to a block of samples{y
t
}
τ
t=1
∈R
d
that are
independently drawn fromμ, then (7) can be reformulated using theempirical riskby
min
U∈G(d,r)
1
τ
τ
∑
t=1
‖y
t
−P
U
y
t
‖
2
2
.(8)
Given that
∑
τ
t=1
‖y
t
−P
U
y
t
‖
2
2
=‖Y
τ
−P
U
Y
τ
‖
2
F
, it follows by the EYM Theorem Eckart and
Young (1936); Mirsky (1966), thatP
U
Y
τ
is thebestrank-rapproximation toY
τ
which is given by
Y
τ,r
= SVD
r
(Y
τ
). Therefore,U=Y
τ,r
= span(Y
τ,r
), which implies that‖Y
τ
−P
Y
τ,r
Y
τ
‖
2
F
=
‖Y
τ
−Y
τ,r
‖
2
F
=ρ
2
r
(Y
τ
), so the solution of(8)equalsρ
2
r
(Y
τ
)/τ. For completeness the full MOSES
theorem is shown below.
Theorem 1(Moses Eftekhari et al.(2018)).Suppose{y
t
}
τ
t=1
⊂R
d
are independently drawn from
a zero-mean Gaussian distribution with covariance matrixΞ∈R
d×d
and formY
τ
= [y
1
···y
τ
]∈
R
d×τ
. Letλ
1
≥···≥λ
d
be the eigenvalues ofΞandρ
2
r
=ρ
2
r
(Ξ)be its residual. Define
η
r
=
λ
1
λ
r
+
√
2αρ
2
r
p
1
3
λ
r
,(9)
12

Let
̂
Y
τ,r
be defined as in(5),
̂
Y
τ,r
=  span(
̂
Y
τ,r
)andα,p,cbe constants such that1≤α≤
√
τ/logτ,p >1andc >0. Then, ifb≥max(αp
1
3
r(p
1
6
−1)
−2
,cαr)andτ≥pη
2
r
b, it holds, with
probability at mostτ
−cα
2
+e
−cαr
that
‖Y
τ
−
̂
Y
τ,r
‖
2
F
τ
.G
α,b,p,r,τ
(10)
E
y∼μ
‖y−P
̂
Y
τ,r
y‖
2
2
.G
α,b,p,r,τ
+α(d−r)λ
1
√
logτ
τ
(11)
where
G
α,b,p,r,τ
=
αp
1
3
4
pη
2
r
(p
1
3
−1)
2
min
(
λ
1
λ
r
ρ
2
r
,rλ
1
+ρ
2
r
) (
τ
pη
2
r
b
)
pη
2
r
−1
.
Notably, the condition ofτ≥pη
2
r
bis only required in order to obtain a tidy bound and is not necessary
in the general case. Moreover, this implies that, when considering only asymptotic dominant terms of
Theorem 1,
‖Y
τ
−
̂
Y
τ,r
‖
2
F
∝
(
τ
b
)
pη
2
r
−1
‖Y
τ
−Y
τ,r
‖
2
F
,(12)
Practically speaking, assumingrank(Ξ)≤randρ
2
r
(Ξ) =
∑
d
i=r+1
λ
i
(Ξ)we can read that,
̂
Y
τ,r
=
Y
τ,r
=Y
τ
meaning that the outputs of offline truncatedSVDand Eftekhari et al. (2018) coincide.
B.1    Interpretation of SPCA as streaming, stochastic algorithm for PCA
It is easy to interpret SPCA as a streaming, stochastic algorithm for PCA. To see this, note that
(7)is equivalent to maximisingE
y∼μ
‖UU
T
y‖
2
F
overZ={U∈R
d×r
:U
T
U=I
r×r
}The
restrictionU
T
U=I
r×r
can be relaxed toU
∗
U4I
r
, whereA4Bdenotes thatB−Ais a
positive semi-definite matrix. Using the Schur’s complement, we can formulate this program to
maxE
y∼μ
〈UU
T
,yy
T
〉
s.t.
[
I
n
U
U
T
I
r
]
<0(13)
Note that,(13)has an objective function that is convex and that the feasible set is also conic and
convex. However, its gradient can only be computed whenμ, since otherwiseΞ=E[yy
T
]∈R
d×d
is unknown. Ifμis known, and an iterate of the form
̂
S
t
is provided, we could draw a random vector
y
t+1
∈R
d
moving along the direction of2y
t+1
y
∗
t+1
̂
S
t
. This is becauseE[2y
t+1
y
∗
t+1
̂
S
t
] = 2Ξ
̂
S
t
which is then followed by back-projection onto the feasible setZ. Namely,
̂
S
t+1
=P
(
S
t
+ 2α
t+1
y
t+1
y
∗
t+1
̂
S
t
)
,(14)
One can see that in(14),P(A)projects onto the unitary ball of the spectral norm by clipping at one
all ofA’s singular values exceeding one.
C    Evaluation Details
C.1    Synthetic Datasets
For the tests on synthetic datasets, the vectors{y
t
}
τ
t=1
are drawn independently from a zero-mean
Gaussian distribution with the covariance matrixΞ=SΛS
T
, whereS∈O(d)is a generic basis
obtained by orthogonalising a standard random Gaussian matrix. The entries of the diagonal matrix
Λ∈R
d×d
(the eigenvalues of the covariance matrixΞ) are selected according to the power law,
namely,λ
i
=i
−α
, for a positiveα. To be more succinct, wherever possible we employ MATLAB’s
notation for specifying the value ranges in this section.
13

To assess the performance ofSAPCA, we letY
t
= [y
1
,···,y
t
]∈R
d×t
be the data received by
timetand
̂
Y
spca
t,r
be the output ofSPCAat timet.
4
Then, the error incurred bySAPCAis
1
t
‖Y
t
−
̂
Y
sapca
t,r
‖
2
F
,(15)
Recall, that the above error is always larger than the residual ofY
t
, namely,
‖Y
t
−
̂
Y
sapca
t,r
‖
2
F
≥‖Y
t
−Y
t,r
‖
2
F
=ρ
2
r
(Y
t
).(16)
In the expression above,Y
t,r
= SVD
r
(Y
t
)is a rank-rtruncatedSVDofY
t
andρ
2
r
(Y
t
)is the
corresponding residual.
Additionally, we compareSAPCAagainstSPCA, GROUSE Balzano and Wright (2013), FD Desai
et al.(2016), PM Mitliagkas et al.(2013) and a version of PAST Papadimitriou et al.(2005); Yang
(1995).  Interestingly and contrary to bothSPCA&SAPCA, the aforementioned algorithms are
onlyable to estimate the principal components of the data andnottheir projected data on-the-fly.
Although, it has to noted that in this setup we are only interested in the resulting subspaceUalong
with its singular valuesΣbut is worth mentioning that the projected data, if desired, can be kept as
well. More specifically, let
̂
S
g
t,r
∈G(d,r)be the span of the output of GROUSE, with the outputs of
the other algorithms defined similarly. Then, these algorithms incur in errors
1
t
‖Y
t
−P
̂
S
v
t,r
Y
t
‖
2
F
, v∈g,f,p,spca,
where we have used the notationP
A
∈R
d×d
to denote the orthogonal projection onto the subspace
A. Even though robust FD Luo et al.(2017) improves over FD in the quality of matrix sketching,
since the subspaces produced by FD and robust FD coincide, there is no need here for computing a
separate error for robust FD.
Throughout our synthetic dataset experiments we have used an ambient dimensiond= 400, and for
eacha∈(0.0001,0.001,0.5,1,2,3)generatedN= 4000feature vectors inR
d
using the method
above. This results in a set of with four datasets of sizeR
d×N
. Furthermore, in our experiments we
used a block size ofb= 50forSAPCAandSPCA, while for PM we choseb=d. FD & GROUSE
perform singular updates and do not need a block-size value. Additionally, the step size for GROUSE
was set to2and the total sketch size for FD was set2r. In all cases, unless otherwise noted in the
respective graphs the starting rank for all methods in the synthetic dataset experiments was set to
r= 10.
We evaluated our algorithm using the aforementioned error metrics on a set of datasets generated
as described above.  The results for the differentavalues are shown in Figure 3, which shows
SAPCA can achieve an error that is significantly smaller than SP while maintaining a small number
of principal components throughout the evolution of the algorithms in the absence of a forgetting
factorλ. When a forgetting factor is used, as is shown in 4 then the performance of the two methods
is similar. This figure was produced on pathological datasets generated with an adversarial spectrum.
It can be seen that in SPIRIT the need for PC’s increases dramatically for no apparent reason, whereas
SAPCAbehaves favourably.
Additionally, in order to bound ourSAPCAalgorithm in terms of the expected error, we used the
SPCAwith a low and high bound each set to the lowest and highest estimatedr-rank ofSAPCA
during its execution.  We fully expectSAPCAto fall within these bounds.  On the other hand,
Figure 4 shows that a drastic performance improvement occurs when using an exponential forgetting
factor for SPIRIT with valueλ= 0.9, but the generated subspace is of inferior quality when compared
to the one produced bySAPCA.
C.2    Real Datasets
Again as with the synthetic datasets, across all real dataset experiments we used an ambient dimension
dandNequal to the dimensions of each dataset. Similarly to the previous section, we used a block
4
Recall, sinceblock-based algorithms like SAPCA, do not update their estimate after receiving feature vector
but per each block for convenience in with respect to the evaluation against other algorithms (which might have
different block sizes or singular updates), we properlyinterpolatetheir outputs over time.
14

05001000150020002500300035004000
time ticks
0
100
200
300
PC count
PCs evolution over T (4000) with 400 feats for alpha: 0.00010
SAPCA
SP
05001000150020002500300035004000
time ticks
0
0.1
0.2
0.3
error (fro)
Fro errs over T (4000) for alpha: 0.00010
SAPCA
SP
(a)α= 00.0001.
05001000150020002500300035004000
time ticks
0
100
200
300
PC count
PCs evolution over T (4000) with 400 feats for alpha: 0.00100
SAPCA
SP
05001000150020002500300035004000
time ticks
0
0.05
0.1
0.15
0.2
error (fro)
Fro errs over T (4000) for alpha: 0.00100
SAPCA
SP
(b)α= 0.001.
05001000150020002500300035004000
time ticks
0
100
200
300
400
PC count
PCs evolution over T (4000) with 400 feats for alpha: 0.50000
SAPCA
SP
05001000150020002500300035004000
time ticks
0
0.5
1
error (fro)
10
-3
Fro errs over T (4000) for alpha: 0.50000
SAPCA
SP
(c)α= 0.5.
05001000150020002500300035004000
time ticks
0
100
200
300
400
PC count
PCs evolution over T (4000) with 400 feats for alpha: 1.00000
SAPCA
SP
05001000150020002500300035004000
time ticks
0
1
2
3
4
error (fro)
10
-4
Fro errs over T (4000) for alpha: 1.00000
SAPCA
SP
(d)α= 1.
05001000150020002500300035004000
time ticks
0
100
200
300
400
PC count
PCs evolution over T (4000) with 400 feats for alpha: 3.00000
SAPCA
SP
05001000150020002500300035004000
time ticks
0
0.5
1
1.5
error (fro)
10
-4
Fro errs over T (4000) for alpha: 3.00000
SAPCA
SP
(e)α= 3.
Figure 3: More Pathological examples for adversarial Spectrums.
size ofb= 50forSAPCA,SPCAandb=dfor PM. The step size for GROUSE was again set to
2and the total sketch size for FD equal to2r. Additionally, we used the same bounding technique
as with the synthetic datasets to bound the error ofSAPCAusingSPCAwith lowest and highest
estimation of ther-rank and note that we fully expectSAPCAto fall again within these bounds.
Finally, to enhance readability we split the errors over time in two plots SP’s & GROUSE’s exploding
errors significantly skew the plots.
Humidity readings sensor node dataset evaluation.Firstly, we evaluate our methods against a
dataset that has an ambient dimensiond=  48and is comprised out ofN=  7712total feature
vectors thus its total size beingR
48×7712
. This dataset is highly periodic in nature and has a larger
lower/higher value deltas when compared to the other datasets. The initial rank used for all algorithms
wasr= 10.  The errors are plotted in logarithmic scale and can be seen in Figure 1c and we can
clearly see thatSAPCAoutperforms the competing algorithms while being within the expected
SPCA
low
&SPCA
high
bounds.
15

05001000150020002500300035004000
time ticks
0
5
10
PC count
PCs evolution over T (4000) with 400 feats for alpha: 0.00010
SAPCA
SP
05001000150020002500300035004000
time ticks
0
0.1
0.2
0.3
0.4
error (fro)
Fro errs over T (4000) for alpha: 0.00010
SAPCA
SP
(a)α= 0.001.
05001000150020002500300035004000
time ticks
0
5
10
PC count
PCs evolution over T (4000) with 400 feats for alpha: 0.00100
SAPCA
SP
05001000150020002500300035004000
time ticks
0
0.1
0.2
0.3
error (fro)
Fro errs over T (4000) for alpha: 0.00100
SAPCA
SP
(b)α= 0.001.
05001000150020002500300035004000
time ticks
0
10
20
30
40
PC count
PCs evolution over T (4000) with 400 feats for alpha: 0.50000
SAPCA
SP
05001000150020002500300035004000
time ticks
0
1
2
3
4
error (fro)
10
-3
Fro errs over T (4000) for alpha: 0.50000
SAPCA
SP
(c)α= 0.5.
05001000150020002500300035004000
time ticks
0
10
20
30
40
PC count
PCs evolution over T (4000) with 400 feats for alpha: 2.00000
SAPCA
SP
05001000150020002500300035004000
time ticks
0
1
2
3
4
error (fro)
10
-4
Fro errs over T (4000) for alpha: 2.00000
SAPCA
SP
(d)α= 2.
05001000150020002500300035004000
time ticks
0
10
20
30
40
PC count
PCs evolution over T (4000) with 400 feats for alpha: 3.00000
SAPCA
SP
05001000150020002500300035004000
time ticks
0
1
2
3
4
error (fro)
10
-4
Fro errs over T (4000) for alpha: 3.00000
SAPCA
SP
(e)α= 3.
Figure 4: Performance measurements across the spectrum (when using forgetting factorλ= 0.9).
Light readings sensor node dataset evaluation.
Secondly, we evaluate the aforementioned meth-
ods again a dataset that has an ambient dimensiond= 48and is comprised out ofN= 7712feature
vectors thus making its total sizeR
48×7712
. It contains mote light readings can be characterised as a
much more volatile dataset when compared to the Humidity one as it contains much more frequent
and rapid value changes while also having the highest value delta of all mote datasets evaluated.
Again, as with Humidity dataset we used an initial seed rankr= 10while keeping the rest of the
parameters as described above, the errors over time for all algorithms is shown in Figure 1d plotted
logarithmic scale. As before,SPCAoutperforms the other algorithms while being again within the
expectedSPCA
low
&SPCA
high
bounds.
Temperature readings sensor node dataset evaluation.The third dataset we evaluate contains
temperature readings from the mote sensors and has an ambient dimensiond=  56containing
N=  7712feature vectors thus making its total sizeR
56×7712
.   Like the humidity dataset the
temperature readings exhibit periodicity in their value change and rarely have spikes. As previously
we used a seed rank ofr= 20and the rest of the parameters as described in the synthetic comparison
above, the errors over time for all algorithms is shown in Figure 6a plotted in logarithmic scale. It
16

01002003004005006007008009001000
Singular values
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
Value
Scree plot of alpha:   0.50
(a) Pathological spectrum (λ= 1,α= 0.5).
12345678910
Singular values
0
0.2
0.4
0.6
0.8
1
1.2
Values
Adaptive Singular value significance
SAPCA
a=.5
GT
a=.5
SAPCA
a=1
GT
a=1
SAPCA
a=2
GT
a=2
(b) Adaptive Singular Values estimation.
Figure 5:  Pathological SV Spectrum Example (5a) and Adaptive SV estimation for variousα’s
against the true ones (5b).
is again evident thatSAPCAoutperforms the other algorithms while being within theSPCA
low
&
SPCA
high
bounds.
Voltage readings sensor node dataset evaluation.Finally, the fourth and final dataset we evaluate
has an ambient dimension ofd= 46containsN= 7712feature vectors thus making its sizeR
46×7712
.
Similar to the Light dataset this is an contains very frequent value changes, has large value delta
which can be expected during operation of the nodes due to various reasons (one being duty cycling).
As with the previous datasets we use a seed rank ofr= 10and leave the rest of the parameters as
described previously. Finally, the errors over time for all algorithms is shown in Figure 6a and are
plotted in logarithmic scale. As expected,SAPCAhere outperforms the competing algorithms while
being within the required error bounds.
010002000300040005000600070008000
time ticks
0
1
2
3
fro error
10
5
fro errors for Temperature Data
SP
SAPCA
SPCA
lo
SPCA
hi
PM
lo
GROUSE
010002000300040005000600070008000
time ticks
0
1
2
3
4
fro error
10
4
fro errors for Temperature Data without SP
SAPCA
SPCA
lo
SPCA
hi
PM
lo
(a) Temperature.
010002000300040005000600070008000
time ticks
0
100
200
300
400
fro error
fro errors for Volt Data
SP
SAPCA
SPCA
lo
SPCA
hi
PM
lo
GROUSE
010002000300040005000600070008000
time ticks
0
5
10
fro error
fro errors for Volt Data without SP
SAPCA
SPCA
lo
SPCA
hi
PM
lo
(b) Volt.
Figure 6: Comparisons against Temperature (6a) & Volt (6b) datasets with respect to the Frobenious
norm error, Top figures include SPIRIT (SP), SAPCA, SPCA, PM, & GROUSE and Bottom figures
only show SAPCA, SPCA, & PM due to exploding errors of the other methods.
C.3    Memory Evaluation
We benchmarked each of the methods used against its competitors and found ourSAPCAalgorithm
to perform favourably. With respect to the experiments, in order to ensure accurate measurements, we
started measuring after clearing the previous profiler contents. The tool used in all profiling instances
wasMATLAB’s built-in memory profiler.
These empirical results support the theoretical claims about the storage optimality ofSAPCA. In
terms of average and median memory allocations,SAPCAis most of the times better than the
competitors. Naturally, since PM requires the materialisation of larger block sizes in turn it requires
17

010002000300040005000600070008000
time ticks
0
2
4
6
8
10
fro error
10
15
fro errors for Humidity Data
SP
SAPCA
SPCA
lo
SPCA
hi
PM
lo
GROUSE
FD
010002000300040005000600070008000
time ticks
0
1000
2000
3000
4000
fro error
fro errors for Humidity Data without SP
SAPCA
SPCA
lo
SPCA
hi
PM
lo
(a) Humidity.
010002000300040005000600070008000
time ticks
0
0.5
1
1.5
2
2.5
fro error
10
24
fro errors for Light Data
SP
SAPCA
SPCA
lo
SPCA
hi
PM
lo
GROUSE
FD
010002000300040005000600070008000
time ticks
0
1
2
3
4
5
fro error
10
6
fro errors for Light Data without SP
SAPCA
SPCA
lo
SPCA
hi
PM
lo
(b) Light.
010002000300040005000600070008000
time ticks
0
5
10
15
fro error
10
17
fro errors for Temperature Data
SP
SAPCA
SPCA
lo
SPCA
hi
PM
lo
GROUSE
FD
010002000300040005000600070008000
time ticks
0
1
2
3
4
5
fro error
10
4
fro errors for Temperature Data without SP
SAPCA
SPCA
lo
SPCA
hi
PM
lo
(c) Temperature.
010002000300040005000600070008000
time ticks
0
1
2
3
fro error
10
7
fro errors for Volt Data
SP
SAPCA
SPCA
lo
SPCA
hi
PM
lo
GROUSE
FD
010002000300040005000600070008000
time ticks
0
2
4
6
8
10
fro error
fro errors for Volt Data without SP
SAPCA
SPCA
lo
SPCA
hi
PM
lo
(d) Volt.
Figure 7: Performance for Real Datasets (with FD) is shown for Humidity (7a), Light (7b), Tempera-
ture (7c), and Volt (7d) respectively.
more memory than bothSAPCAand FD. Moreover, GROUSE, in its reference implementation
requires the instantiation of the whole matrix again; this is because the reference version of GROUSE
is expected to run on a subset of a sparse matrix which is copied locally to the function - since in
this instance we require the entirety of the matrix to be allocated and thus results in a large memory
overhead. An improved, more efficient GROUSE implementation would likely solve this particular
issue.
C.4    Federated Evaluation
As per our evaluation, our algorithm has the flexibility of not having its merges bounded by the
ambient dimensiond.  This is especially true when operating on a memory limited scenario as
the minimum number of feature vectors that need to be kept has to be a multiple of the ambient
dimensiondin order to provide their theoretical guarantees (such as in Mitliagkas et al.(2014)).
Further, in the case of having an adversarial spectrum (e.g.  as in Figure 5a), energy thresholding
quickly overestimates the number of required principal components, unless a forgetting factor is used,
but at the cost of approximation quality and robustness as it can me seen throughout our experiments
when dealing with pathological spectrums. Notably, in a number of runs SP ended up with linearly
dependent columns in the generated subspace and failed to complete. This is an inherent limitation of
Gram-Schmidt orthonormalisation procedure used in the reference implementation and substituting it
with a more robust one (such asQR) decreased its efficiency throughout our experiments.
C.5    Time-Order Independence Empirical Evaluation
Apart from theoretically proving our time order independence hypothesis in Lemma 2, we also
empirically validate it for a range ofαvalues usingd= 100features andn= 10k. All algorithms
were resilient - up to small errors - toYpermutation as was expected, butSAPCAbeing based
heavily onSVDfollows its produced subspaces much more evidently when compared against the
other methods very closely. The figures show the errors for recovery ranksr5(8a),20(8b),50(8c),
18

and75(8d). It has to be noted, that legends are subscripted withs(e.g.gr
s
) compare against the
SVDoutput while the others against its own output of the perturbation against the originalY.
1e-05  0.0001  0.0010.010.11234
alphas
-2
0
2
4
6
8
10
12
errors (mse)
10
-3
spca
spca
s
pm
pm
s
gr
gr
s
sp
sp
s
(a) Errors forr= 5.
1e-05  0.0001  0.0010.010.11234
alphas
-2
0
2
4
6
8
10
12
errors (mse)
10
-3
spca
spca
s
pm
pm
s
gr
gr
s
sp
sp
s
(b) Errors forr= 20.
1e-05  0.0001  0.0010.010.11234
alphas
-2
0
2
4
6
8
10
12
errors (mse)
10
-3
spca
spca
s
pm
pm
s
gr
gr
s
sp
sp
s
(c) Errors forr= 50.
1e-05  0.0001  0.0010.010.11234
alphas
-2
0
2
4
6
8
10
12
errors (mse)
10
-3
spca
spca
s
pm
pm
s
gr
gr
s
sp
sp
s
(d) Errors forr= 75.
Figure 8: Mean Subspace errors of20permutations ofY∈R
100×10000
forrequals5(a),20(b),50
(c) and75(d).
19 

Robust data-driven discovery of governing physical laws using a new
subsampling-based sparse Bayesian method to tackle four challenges
(large noise, outliers, data integration, and extrapolation)
Sheng Zhang
a
, Guang Lin
a,b,c,∗
a
Department of Mathematics, Purdue University, West Lafayette, IN 47907, USA
b
School of Mechanical Engineering, Purdue University, West Lafayette, IN 47907, USA
c
Department of Statistics, Purdue University, West Lafayette, IN 47907, USA
Abstract
The derivation of physical laws is a dominant topic in scientific research.   We propose a new method capable of
discovering the physical laws from data to tackle four challenges in the previous methods.  The four challenges are:
(1) large noise in the data, (2) outliers in the data, (3) integrating the data collected from different experiments, and (4)
extrapolating the solutions to the areas that have no available data. To resolve these four challenges, we try to discover
the governing differential equations and develop a model-discovering method based on sparse Bayesian inference and
subsampling. The subsampling technique is used for improving the accuracy of the Bayesian learning algorithm here,
while it is usually employed for estimating statistics or speeding up algorithms elsewhere.  The optimal subsampling
size is moderate, neither too small nor too big. Another merit of our method is that it can work with limited data by the
virtue of Bayesian inference. We demonstrate how to use our method to tackle the four aforementioned challenges step
by step through numerical examples:  (1) predator-prey model with noise, (2) shallow water equations with outliers,
(3) heat diffusion with random initial and boundary conditions,  and (4) fish-harvesting problem with bifurcations.
Numerical results show that the robustness and accuracy of our new method is significantly better than the other
model-discovering methods and traditional regression methods.
Keywords:machine learning, Bayesian inference, subsampling, outlier, data integration, extrapolation
1. Introduction
The search for physical laws has been a fundamental aim of science for centuries.  The physical laws are critical
to the understanding of natural phenomena and the prediction of future dynamics.  They are either derived by other
known physical laws or generalized based on empirical observations of physical behavior.  We focus on the second
task, which is also called data-driven discovery of governing physical laws. It deals with the case where experimental
data are given while the governing physical model is unclear. Traditional methods for discovering physical laws from
∗
Corresponding author.
Email address:guanglin@purdue.edu(Guang Lin)
arXiv:1907.07788v1  [stat.ML]  17 Jul 2019

data include interpolation and regression.  Supposex:R→Ris an unknown physical law.  Given data
{
t
i
,x(t
i
)
}
N
i=1
,
traditional methods approximate the expression ofx(t) in terms of a class of functions oft.  This approach has two
limitations:
•If the data are collected from different experiments, traditional methods would not be able to use all of the data
together to discover the physical laws. For example, free falls from different initial height [x(t)=x
0
−(1/2)gt
2
]
follow the same physical law but they have different trajectories. Traditional methods can only use the data on
the same trajectory to discover the path and predict future motion. However, using all the data can increase the
accuracy.
•Traditional methods are incapable of extrapolating to the areas where no data are given.
To resolve these two limitations, we adopt the strategy: first, discover the differential equations thatx(t) satisfies;
second, solve the differential equations analytically or numerically. For the free fall example, we can use all the data
from different trajectories together to discover the differential equationx
′
(t)=−gtand extrapolate to any other given
initial height. This discovery pattern is applicable to a larger class of models than traditional methods and derives the
governing differential equations, which provide insights to the governing physical laws behind the observations [1].
Many fundamental laws are formulated in the form of differential equations, such as Maxwell equations in classical
electromagnetism, Einstein field equations in general relativity, Schrodinger equation in quantum mechanics, Navier-
Stokes equations in fluid dynamics, Boltzmann equation in thermodynamic, predator-prey equations in biology, and
Black-Scholes equation in economics. While automated techniques for generating and collecting data from scientific
measurements are more and more precise and powerful, automated processes for extracting knowledge in analytic
forms from data are limited [2]. Our goal is to develop automated algorithms for extracting the governing differential
equations from data.
Consider a differential equation of the form
d x
dt
=f(t,x),(1)
with the unknown functionf(t,x).  Given the data
{
t
i
,x
i
,x
′
i
}
N
i=1
collected from a space governed by this differential
equation, wherex
i
=x(t
i
) andx
′
i
=(d x/dt)(t
i
), automated algorithms for deriving the expression off(t,x) are studied
from various approaches.   One of the approaches assumes thatf(t,x) is a linear combination of simple functions
oftandx.  First, construct a moderately large set of basis-functions that may contain all the terms off(t,x); then,
apply algorithms to select a subset that is exactly all the terms off(t,x) from the basis-functions and estimate the
corresponding weights in the linear combination.
Suppose the basis-functions are chosen asf
1
(t,x),f
2
(t,x),...,f
M
(t,x).   Then we need to estimate the weights
w
1
,w
2
,...,w
M
in the following linear combination:
d x
dt
=w
1
f
1
(t,x)+w
2
f
2
(t,x)+···+w
M
f
M
(t,x).(2)
2

Given the data
{
t
i
,x
i
,x
′
i
}
N
i=1
, wherex
i
=x(t
i
) andx
′
i
=(d x/dt)(t
i
), the above problem becomes a regression problem as
follows:


























x
′
1
x
′
2
.
.
.
x
′
N


























=


























f
1
(t
1
,x
1
)f
2
(t
1
,x
1
)···f
M
(t
1
,x
1
)
f
1
(t
2
,x
2
)f
2
(t
2
,x
2
)···f
M
(t
2
,x
2
)
.
.
.
.
.
.
.
.
.
.
.
.
f
1
(t
N
,x
N
)f
2
(t
N
,x
N
)···f
M
(t
N
,x
N
)




















































w
1
w
2
.
.
.
w
M


























+,(3)
where=
[

1
,
2
,...,
N
]
T
is the model error. Let
η=
[
x
′
1
,...,x
′
N
]
T
(4)
Φ    =


















f
1
(t
1
,x
1
)···f
M
(t
1
,x
1
)
.
.
.
.
.
.
.
.
.
f
1
(t
N
,x
N
)···f
M
(t
N
,x
N
)


















(5)
w=
[
w
1
,...,w
M
]
T
.(6)
Equation (3) may be written in the vector form as follows:
η= Φw+.(7)
Now the problem is to estimate the weight-vectorwgiven a known vectorηand a known matrixΦ.
Since many physical systems have few terms in the equations, the set of basis-functions usually has many more
terms thanf(t,x):M#{terms inf(t,x)}, which suggests the use of sparse methods to select the subset of basis-
functions  and  estimate  the  weights.   These  sparse  methods  can  be  sequential  threshold  least  squares  (also  called
sparse identification of nonlinear dynamics (SINDy)) [3, 4], lasso (least absolute shrinkage and selection operator)
[5, 6], or threshold sparse Bayesian regression [1]. Sequential threshold least squares does least-square regression and
eliminates the terms with small weights iteratively (Algorithm 1); lasso solves the following optimization problem:
min
w
{
1
2N
||η−Φw||
2
2
+λ||w||
1
}
,(8)
where  the  regularization  parameterλmay  be  fitted  by  cross-validation  (Algorithm  2);  threshold  sparse  Bayesian
regression calculates the posterior distribution ofwgiven the data and then filters out small weights, iteratively until
convergence (Algorithm 3). A comparison of these three sparse methods is illustrated in [1] and shows that threshold
sparse Bayesian regression is more accurate and robust than the other two methods.
The same mechanism as above also applies to the discovery of general differential equations including higher-
order differential equations and implicit differential equations [1], besides the differential equations of the form (1).
Nevertheless,  the mechanism is described in the pattern (1) here for convenience and simplification,  so that more
attention is given to the essence of the algorithm itself.  In addition, to apply the algorithm to real-world problems,
dimensional analysis can be incorporated in the construction of the basis-functions [1].  Any physically meaningful
3

equation has the same dimensions on every term, which is a property known as dimensional homogeneity. Therefore,
when summing up terms in the equations, the addends should be of the same dimension.
Sparse regression methods for data-driven discovery of differential equations are developed recently with a wide
range of applications, for example, inferring biological networks [7], sparse identification of a predator-prey system
[8], model selection via integral terms [9], extracting high-dimensional dynamics from limited data [10], recovery
of chaotic systems from highly corrupted data [11], model selection for dynamical systems via information criteria
[12], model predictive control in the low-data limit [13], sparse learning of stochastic dynamical systems [14], model
selection for hybrid dynamical systems [15], identification of parametric partial differential equations [16], extracting
structured dynamical systems with very few samples [17], constrained Galerkin regression [18], rapid model recovery
[19], convergence of the SINDy algorithm [20].  Moreover, other methods for data-driven discovery of differential
equations are proposed as well, for instance, deep neural networks [21, 22, 23] and Gaussian process [24]. One of the
advantages of the sparse regression methods is the ability to provide explicit formulas of the differential equations,
from which further analysis on the systems may be performed, while deep neural networks usually provide “black
boxes”, in which the mechanism of the systems is not very clearly revealed. Another advantage of the sparse regression
methods is that they do not require too much prior knowledge of the differential equations, while Gaussian process
methods have restrictions on the form of the differential equations and are used to estimate a few parameters.
Previous  developments  and  applications  based  on  sparse  regression  methods  mostly  employ  either  sequential
threshold least squares or lasso,  or their variations.   One of the reasons why data-driven discovery of differential
equations has not yet been applied to industry is the instability of its methods.  Previous methods require the data
of very high quality,  which is usually not the case in industry.   Although threshold sparse Bayesian regression is
more accurate and robust than the other two methods and provides error bars that quantify the uncertainties [1], its
performance is still unsatisfactory if the provided data are of large noise or contain outliers. Therefore, it is instructive
to improve the threshold sparse Bayesian regression algorithm and apply it to the fields above, as this will improve
the overall performance of the method in most cases.  In this paper, we develop a subsampling-based technique for
improving the threshold sparse Bayesian regression algorithm, so that the new algorithm is robust to large noise and
outliers. Note that subsampling methods are usually employed for estimating statistics [25] or speeding up algorithms
[4] in the literatures, but the subsampling method in this paper is used for improving the accuracy of the Bayesian
learning algorithm.  In practice, denoising techniques can be used to reduce part of the noise and outliers in the data
before our algorithm is performed.
The remainder of this paper is structured as follows.  In Section 2, we introduce the threshold sparse Bayesian
regression algorithm.  In Section 3, we detail our new subsampling-based algorithm.  In Section 4, we investigate
the robustness of our new algorithm through an example of discovering the predator-prey model with noisy data.  In
Section 5, we discuss how to use our new algorithm to remove outliers, with an example of discovering the shallow
water equations using the data corrupted by outliers. In Section 6, we tackle the challenge of data integration through
an example of discovering the heat diffusion model with random initial and boundary conditions.  In Section 7, we
4

η
w
1
w
2
···
w
M
σ
2
α
1
α
2
···
α
M
Figure 1: Graphical structure of the sparse Bayesian model.
tackle the challenge of extrapolation through an example of discovering the fish-harvesting model with bifurcations.
Finally, the summary is given in Section 8.
2. Threshold sparse Bayesian regression
2.1.  Bayesian hierarchical model setup
Letηbe a knownN×1 vector,Φbe a knownN×Mmatrix,w=
[
w
1
,w
2
,...,w
M
]
T
be the weight-vector to be
estimated sparsely, andbe the model error:
η= Φw+.(9)
We adopt a sparse Bayesian framework based on RVM (relevance vector machine [26], which is motivated by au-
tomatic relevance determination [27, 28]) to estimate the weight-vectorw.  The Bayesian framework assumes that
the model errors are modeled as independent and identically distributed zero-mean Gaussian with varianceσ
2
.  The
variance may be specified beforehand, but in this paper it is fitted by the data. The model gives a multivariate Gaussian
likelihood on the vectorη:
p
(
η|w,σ
2
)
=
(
2πσ
2
)
−N/2
exp
{
−
|
|η−Φw
|
|
2
2σ
2
}
.(10)
Now we introduce a Gaussian prior over the weight-vector.  The prior is governed by a set of hyper-parameters, one
hyper-parameter associated with each component of the weight-vector:
p
(
w|α
)
=
M
∏
j=1
N
(
w
j
|0,α
−1
j
)
,(11)
whereα=
[
α
1
,α
2
,...,α
M
]
T
.  The values of the hyper-parameters are estimated from the data.  See Figure 1 for the
graphical structure of this model.
2.2.  Inference
The posterior over all unknown parameters given the data can be decomposed as follows:
p
(
w,α,σ
2
|η
)
=p
(
w|η,α,σ
2
)
p
(
α,σ
2
|η
)
.(12)
5

As analytic computations cannot be performed in full, we approximatep
(
α,σ
2
|η
)
using the Dirac delta function at
the maximum likelihood estimation:
(
ˆα
ML
,ˆσ
2
ML
)
=arg max
α,σ
2
{
p
(
η|α,σ
2
)
}
=arg max
α,σ
2
{
∫
p
(
η,w|α,σ
2
)
dw
}
=arg max
α,σ
2
{
∫
p
(
η|w,σ
2
)
p
(
w|α
)
dw
}
=arg max
α,σ
2
{
(
2π
)
−N/2
∣
∣
∣
σ
2
I+ ΦA
−1
Φ
T
∣
∣
∣
−1/2
exp
{
−
1
2
η
T
(
σ
2
I+ ΦA
−1
Φ
T
)
−1
η
}}
,(13)
withA=diag
(
α
1
,α
2
,...,α
M
)
. We may use the Dirac delta function as an approximation on the basis that this point-
estimate is representative of the posterior in the sense that the integral calculation for the posterior using the point-
estimate is roughly equal to the one obtained by sampling from the full posterior distribution [26]. This maximization
is a type-II maximum likelihood and can be calculated using a fast method [29]. Now, we may integrate outαandσ
2
to get the posterior over the weight-vector:
p
(
w|η
)
=
∫∫
p
(
w,α,σ
2
|η
)
dαdσ
2
=
∫∫
p
(
w|η,α,σ
2
)
p
(
α,σ
2
|η
)
dαdσ
2
≈
∫∫
p
(
w|η,α,σ
2
)
δ
(
ˆα
ML
,ˆσ
2
ML
)
dαdσ
2
=p
(
w|η,ˆα
ML
,ˆσ
2
ML
)
=
p
(
η|w,ˆσ
2
ML
)
p
(
w|ˆα
ML
)
p
(
η|ˆα
ML
,ˆσ
2
ML
)
[Bayes’ rule]
=
(
2π
)
−M/2
∣
∣
∣
ˆ
Σ
∣
∣
∣
−1/2
exp
{
−
1
2
(
w−ˆμ
)
T
ˆ
Σ
−1
(
w−ˆμ
)
}
=N
(
w|ˆμ,
ˆ
Σ
)
,(14)
in which the posterior covariance and mean are:
ˆ
Σ    =
[
ˆσ
−2
ML
Φ
T
Φ +diag
(
ˆα
ML
)
]
−1
(15)
ˆμ=ˆσ
−2
ML
ˆ
ΣΦ
T
η.(16)
Therefore the posterior for each weight can be deduced from (14):
p(w
j
|η)=N
(
w
j
|ˆμ
j
,
ˆ
Σ
j j
)
,(17)
with  mean  ˆμ
j
and  standard  deviation
ˆ
Σ
1/2
j j
.   Thus  the  mean  posterior  prediction  of  the  weight-vectorwand  other
quantities that we want to obtain are determined by the values ofηandΦ. This is the beauty of the Bayesian approach:
there is no need to determine a regularization parameter via expensive cross-validation, and moreover likelihood values
and confidence intervals for the solution can be easily calculated [30]. Another merit of the Bayesian approach is that
it can work with limited data since it incorporates prior information into the problem to supplement limited data.
6

2.3.  Implementation
In practice the optimal values of many hyper-parametersα
j
in (13) are infinite [26], and thus from (15)-(17) the
posterior distributions of many components of the weight-vector are sharply peaked at zero. This leads to the sparsity
of the resulting weight-vector.  To further encourage the accuracy and robustness, a thresholdδ≥0 is placed on the
model to filter out possible disturbance present in the weight-vector. Then the weight-vector is reestimated using the
remaining terms, iteratively until convergence.  The entire procedure is summarized in Algorithm 3.  A discussion
about how to choose the threshold and its impact on the solution is detailed in [1].As the threshold is a parameter
representing the model complexity, we may use machine learning algorithms such as cross-validation to determine it.
Note that in Algorithm 3, ˆμis more and more sparse after each loop by design. Thus the convergence of the algorithm
is guaranteed given the convergence of the calculation of maximum likelihood in (13).
In this paper, we define an error bar value that quantifies the quality of the posterior estimated model as follows:
error bar=
M
∑
j=1
ˆμ
j
,0
ˆ
Σ
j j
ˆμ
2
j
,(18)
where each estimated variance
ˆ
Σ
j j
is divided by the square of the corresponding estimated mean  ˆμ
2
j
to normalize the
variance on each weight.  This definition adds up all the normalized variances of each weight present in the result,
and penalizes the unsureness of the estimations.  In other words, a smaller error bar value means smaller normalized
variances and higher posterior confidence, and implies higher model quality.  If given a set of candidate models for
the data, the preferred model would be the one with the minimum error bar value.
As a comparison, other sparse regression algorithms are listed:  sequential threshold least squares (Algorithm 1)
and lasso (Algorithm 2).
3. Subsampling-based threshold sparse Bayesian regression
3.1.  Motivation
In the regression problem (3), when we have more data than the number of unknown weights:N>M, we may
use a subset of the data
{
t
i
,x
i
,x
′
i
}
N
i=1
to estimate the weights.   We do this on the basis that the data sets collected
from  real-world  cases  may  contain  outliers  or  a  percentage  of  data  points  of  large  noise.   Classical  methods  for
parameter estimation, such as least squares, fit a model to all of the presented data.  These methods have no internal
mechanism for detecting or discarding outliers. Other robust regression methods designed to overcome the limitations
of  traditional  methods  include  iteratively  reweighted  least  squares  [31,  32],  random  sample  consensus  [33],  least
absolute deviations [34], Theil-Sen estimator [35, 36], repeated median regression [37, 38], but they do not fit very
well into the framework of data-driven discovery of differential equations. Classical methods for parameter estimation
are averaging methods based on the assumption (the smoothing assumption) that there will always be enough good
values to smooth out any gross noise [33]. In practice the data may contain more noise than what the good values can
7

Algorithm 1:Sequential threshold least squares:η= Φw+
Input:η,Φ, threshold
Output:ˆμ
Solve ˆμin (Φ
T
Φ) ˆμ= Φ
T
η;
For components of ˆμwith absolute value less than the threshold, set them as 0;
whileˆμ,0 do
Delete the columns ofΦwhose corresponding weight is 0, gettingΦ
′
;
Solve ˆμ
′
in (Φ
′T
Φ
′
) ˆμ
′
= Φ
′T
η;
Update the corresponding components of ˆμusing ˆμ
′
;
For components of ˆμwith absolute value less than the threshold, set them as 0;
ifˆμis the same as the one on the last loopthen
break;
end
end
Algorithm 2:Lasso:η= Φw+
Input:η,Φ
Output:ˆμ
ˆμ=arg min
w
{
1
2N
||η−Φw||
2
2
+λ||w||
1
}, whereλis fitted by five-fold cross-validation with minimum mean
squared error (MSE) on validation sets.
ever compensate, breaking the smoothing assumption.  To deal with this situation, an effective way is to discard the
“bad” data points (outliers or those of large noise), and use the rest “good” data points to run estimations.  Based on
this idea, we propose an algorithm called subsampling-based threshold sparse Bayesian regression (SubTSBR) in this
paper. This method filters out bad data points by the means of random subsampling.
3.2.  Implementation
SubTSBR approaches the problem by randomly selecting data points to estimate the weights and using a measure
(error bar) to evaluate the estimations.  When an estimation is “good” (small error bar), our algorithm identifies the
corresponding selected data points as good data points and the estimation as the final result.   To be specific,  our
algorithm is given a user-preset subsampling sizeS(<N) and the number of loopsL(≥1) at the very beginning. For
each loop, a subset of the data consisting ofSdata points is randomly selected:
{
t
k
i
,x
k
i
,x
′
k
i
}
S
i=1
(
⊂
{
t
i
,x
i
,x
′
i
}
N
i=1
)
and
8

Algorithm 3:Threshold sparse Bayesian regression:η= Φw+
Input:η,Φ, threshold
Output:ˆμ,
ˆ
Σ
Calculate the posterior distributionp
(
w|η
)
inη= Φw, and let the mean be ˆμ;
For components of ˆμwith absolute value less than the threshold, set them as 0;
whileˆμ,0 do
Delete the columns ofΦwhose corresponding weight is 0, and let the result beΦ
′
;
Calculate the posterior distributionp
(
w
′
|η
)
inη= Φ
′
w
′
, and let the mean be ˆμ
′
;
Update the corresponding components of ˆμusing ˆμ
′
;
For components of ˆμwith absolute value less than the threshold, set them as 0;
ifˆμis the same as the one on the last loopthen
break;
end
end
Set the submatrix of
ˆ
Σcorresponding to non-zero components of ˆμas the last estimated posterior variance in
the preceding procedure, and set the other elements of
ˆ
Σas 0.
used to estimate the weightsw
1
,w
2
, . . . ,w
M
in the following regression problem:


























x
′
k
1
x
′
k
2
.
.
.
x
′
k
S


























=


























f
1
(t
k
1
,x
k
1
)f
2
(t
k
1
,x
k
1
)···f
M
(t
k
1
,x
k
1
)
f
1
(t
k
2
,x
k
2
)f
2
(t
k
2
,x
k
2
)···f
M
(t
k
2
,x
k
2
)
.
.
.
.
.
.
.
.
.
.
.
.
f
1
(t
k
S
,x
k
S
)f
2
(t
k
S
,x
k
S
)···f
M
(t
k
S
,x
k
S
)




















































w
1
w
2
.
.
.
w
M


























+,(19)
wheref
1
(t,x),f
2
(t,x),...,f
M
(t,x) are the basis-functions andis the model error.  This regression problem can be
symbolized into the form as follows:
η= Φw+,(20)
which is (9). By running Algorithm 3, we obtain a differential equation:
d x
dt
=ˆμ
1
f
1
(t,x)+ˆμ
2
f
2
(t,x)+···+ˆμ
M
f
M
(t,x),(21)
along with an error bar calculated by (18).  After repeating this procedureLtimes with different randomly selected
data points, the differential equation with the smallest error bar among all the loops is chosen as the final result of the
whole subsampling algorithm.  Our algorithm has two user-preset parameters:  the subsampling size and the number
of loops.  Their impact on the accuracy of the final result is discussed in Section 4 with an example.  Note that the
above mechanism is described in the pattern (1) for convenience and simplification.  It also applies to higher-order
9

Algorithm 4:Subsampling-based threshold sparse Bayesian regression:η= Φw+
Input:η,Φ, threshold, subsampling sizeS, the number of loopsL
Output:ˆμ,
ˆ
Σ
LetI
N×N
be theN×Nidentity matrix, whereNis the number of rows inΦ;
forr=1to Ldo
LetP
r
be anS×Nsubmatrix ofI
N×N
with randomly chosen rows;
Use Algorithm 3 to solve the problemP
r
η=P
r
Φw+, getting ˆμ
r
,
ˆ
Σ
r
;
Calculate [error bar]
r
using ˆμ
r
,
ˆ
Σ
r
and (18);
end
LetR=arg min
r
{[error bar]
r
};
Let ˆμ=ˆμ
R
and
ˆ
Σ =
ˆ
Σ
R
.
differential equations and implicit differential equations, as long as the differential equations can be symbolized into
the form (20). The SubTSBR procedure is summarized in Algorithm 4, where the for-loop can be coded parallelly.
3.3.  Why it works
The numerical results in this paper show that our subsampling algorithm can improve the overall accuracy in
the discovery of differential equations,  and the error bar (18) is capable of evaluating the estimations.   The given
data
{
t
i
,x
i
,x
′
i
}
N
i=1
contain a part of data points of small noise and a part of data points of large noise.  When a subset
consisting of only data points of small noise is selected, our algorithm would estimate the weights well and indicate
that this is the case by showing a small error bar (18).   As we do not know which data points are of small noise
and which data points are of large noise before the model is discovered, we select a subset from the data randomly,
repeating multiple times.  When it happens that the selected data points are of small noise, we would have a good
estimation of the weights and at the same time recognize this case.
The  numerical  results  also  show  that  in  order  to  attain  optimal  performance,  the  subsampling  size  should  be
moderate, neither too small nor too big, while the number of loops is as big as possible when computing time permits.
As the correctness of the governing differential equations is crucial,  computing time can be a secondary issue to
consider.  In practice, we can increase the number of loops gradually and stop the algorithm when the smallest error
bar among all the loops drops below a certain preset value or the smallest error bar stops decreasing.
4. The challenge of large noise
4.1.  Problem description
The noise in the data can hinder model-discovering algorithms from getting the correct results. Here we detail the
mechanism of our algorithm, tune the parameters, and investigate the robustness against noise.
10

(a)(b)
Figure 2: The true predator-prey model and the noisy data. (a) Population vs time. (b) Population(predator) vs population(prey).
4.2.  Example: the predator-prey model with noise
The predator-prey model is a system of a pair of first-order nonlinear differential equations and is frequently used
to describe the interaction between two species, one as a predator and the other as prey.  The population change by
time is as follows:
d x
dt
=αx−βxy(22)
dy
dt
=δxy−γy,(23)
wherexis the number of the prey,yis the number of the predator, andα,β,δ,γare positive real parameters describing
the interaction of the two species. In this example, we fix the parameters as follows:
d x
dt
=
1
2
x−
3
2
xy(24)
dy
dt
=xy−
1
2
y.(25)
We assume that we do not know about the formula of the system (24) - (25), neither the terms nor the parameters, and
try to discover the model using noisy data.
4.2.1.  Data collection
We first generate 200 data points from the system (24) - (25), with the initial valuex
0
=0.6 andy
0
=0.2, during
timet=0 tot=20.  Then independent and identically distributed white noiseN(0,0.02
2
) is added to all the datax
and all the datay. See Figure 2 for the true model and the noisy data.
4.2.2.  Calculate numerical derivatives using total-variation derivative
Now we need to calculate the derivatives of the data to estimate the left-hand-side terms in (24) - (25). The noise
in the data would be amplified greatly if the derivatives are calculated using numerical differentiation. See Figure 3a
11

(a)(b)
Figure  3:  (a)  The  true  derivatives  of  the  data  and  the  approximated  derivatives  using  gradient.   (b)  The  true  derivatives  of  the  data  and  the
approximated derivatives using total-variation derivative (tvd).
for the approximated derivatives using gradient.  Therefore, we use total-variation derivative [39, 40] instead.  For a
real functionf(t) on [0,L], total-variation derivative computes the derivatives offas the minimizer of the functional:
F(u)=λ
∫
L
0
|u
′
|+
1
2
∫
L
0
|Au+f(0)−f|
2
,(26)
whereAu(t)=
∫
t
0
uis the operator of antidifferentiation andλis a regularization parameter that controls the balance
between the two terms.  The numerical implementation is introduced in [40].  See Figure 3b for the approximated
derivatives ofx(t) andy(t) using total-variation derivative withλ=0.02.
As we can see in Figure 3, the robust differentiation method is critical for getting high-quality derivatives. Besides
total-variation derivative,  many other methods are available for robust differentiation.   Another approach is to use
denoising techniques to reduce the noise in the data before taking derivatives. For example, a neural network is used
to denoise data and approximate derivatives in [41].  Those methods may have better performance in practical use,
depending on the situation.  Here we do not use denoising techniques for the sake of demonstrating the robustness
of our algorithm against noise.  In practice, the denoised data may still contain noise.  Our algorithm can be used
following the denoising processes and may achieve good results.
4.2.3.  Discover the model using different sparse algorithms
If sequential threshold least squares (Algorithm 1) is applied to discover the model (24) - (25), we get the following
result:
d x
dt
=−1.122+3.539x+5.896y−4.243x
2
−6.604xy−13.612y
2
+1.770x
3
+3.844x
2
y
+1.874xy
2
+11.588y
3
(27)
dy
dt
=0.230−1.613x−0.427y+2.636x
2
+3.302xy−1.781y
2
−1.525x
3
−1.080x
2
y
−1.735xy
2
+2.408y
3
.(28)
12

If lasso (Algorithm 2) is used, we have:
d x
dt
=0.085+0.219x−0.363y+0.001xy−0.043y
2
+0.074x
3
−0.265x
2
y−1.592xy
2
+0.773y
3
(29)
dy
dt
=−0.037+0.154x−0.349y+0.100xy−0.087y
2
−0.051x
3
+0.220x
2
y+0.953xy
2
−0.030y
3
.(30)
If TSBR (Algorithm 3) is used, we get:
d x
dt
=0.230(0.018)x+0.443(0.104)y−2.448(0.434)y
2
−1.929(0.130)xy
2
+3.132(0.442)y
3
(31)
dy
dt
=−0.641(0.033)y+1.609(0.133)xy−0.578(0.122)x
2
y,(32)
with error bars 0.1174 and 0.0538, where the numbers in front of each term read as “mean (standard deviation)” of
the corresponding weights.  Note that sequential threshold least squares, lasso, and TSBR use all 200 data points at
the same time to discover the model respectively.
In contrast, if SubTSBR (Algorithm 4) is applied to discover the model, we have:
d x
dt
=0.491(0.015)x−1.458(0.041)xy(33)
dy
dt
=−0.487(0.017)y+0.971(0.031)xy,(34)
with error bars 0.0018 and 0.0022.  The approximated weights in (33) - (34) are slightly smaller in absolute value
than the true weights in (24) - (25) because when we calculate the numerical derivatives, total-variation derivative
(26) smooths out some variation in the derivatives.  This defect does not have much impact on the result and can
be addressed by using different methods to calculate the derivatives or collecting the derivatives along with the data
directly.   Here  the  subsampling  size  is  60  and  the  number  of  loops  is  30.   All  methods  in  this  example  have  the
threshold set at 0.1 and use monomials generated by{1,x,y}up to degree three as basis-functions (10 terms in total).
The result of SubTSBR (33) - (34) approximates the true system (24) - (25) significantly better than the other sparse
algorithms. Although the data contain a considerable amount of noise, SubTSBR successfully finds the exact terms in
the true system and accurately estimates the parameters. See Figure 4 for the final selected data points in SubTSBR.
See Figure 5 for the dynamics calculated by the systems derived from each algorithm.  Note that since the data are
collected fromt=0 tot=20, Figure 5a shows the approximation and Figure 5b shows the prediction.
4.2.4.  Basis-selection success rate vs subsampling size and the number of loops
In SubTSBR (Algorithm 4), we have two parameters to set, one of which is the subsampling size and the other is
the number of loops. Here we first investigate the impact on the basis-selection success rate by different subsampling
sizes. In Figure 6a, each curve is drawn by fixing the number of loops. Then given each subsampling size, SubTSBR
is applied to the data set collected above.  This method is performed 1000 times for each fixed number of loops and
subsampling size.  Then the percentage of successful identification of the exact terms in the system (24) - (25) is
calculated and plotted. In the discovery process, the most difficult part is to identify the exact terms in the system. If
the exact terms are successfully identified, it is usually easy to estimate the weights.
13

Figure 4: The final selected data points in SubTSBR.
(a)
(b)
Figure 5:  (a) Approximated dynamics by SubTSBR, TSBR, lasso, and sequential threshold least squares fromt=0 tot=20.  (b) Predicted
dynamics fromt=0 tot=100.
Figure 6a shows that for each fixed number of loops, basis-selection success rate goes up and then down when
the subsampling size increases.  When the subsampling size equals 200, all the data points are used and SubTSBR
is equivalent to TSBR (Algorithm 3).  In this case the true terms cannot be identified.  In addition, for each chosen
number of loops there is an optimal subsampling size, and the optimal subsampling size increases by the number of
loops.
Now we investigate the impact on the basis-selection success rate by different numbers of loops.  In Figure 6b,
each curve is drawn by fixing the subsampling size. Then given each number of loops, SubTSBR is applied to the data
set to discover the model.  The discovery is done 1000 times for each fixed subsampling size and number of loops.
Then the percentage of successful identification of the exact terms in the system (24) - (25) is calculated and plotted.
Figure 6b shows that for each fixed subsampling size, basis-selection success rate keeps going up when the number
of loops increases. In addition, the larger the subsampling size is, more loops are needed for the basis-selection success
rate to reach a certain level.  This is because our data set is polluted by Gaussian noise and naturally contains some
data points of large noise and some of small noise. As the subsampling size gets bigger, it is less likely for each of the
14

(a)(b)
Figure 6:  The total number of data points is 200.   (a) Basis-selection success rate vs subsampling size,  with different numbers of loops.   (b)
Basis-selection success rate vs the number of loops, with different subsampling sizes.
random subsets of data to exclude the data points of large noise. When more loops are used, the likelihood for one of
the loops to exclude the data points of large noise increases.  As long as one of the loops excludes the data points of
large noise, this loop may successfully select the true basis functions and have the smallest error bar. If it happens, the
final result would come from this loop and SubTSBR selects the true basis functions successfully in this one of 1000
runs. This explains why the curves of smaller subsampling size go up faster.
On the other hand, when more data points are used, the noise inside the subsamples gets smoothed out easier
in the regression (20).   If all the included data points in the subsample are of small noise,  then the result from a
larger subsampling size may be a better one. This explains why the saturated basis-selection success rate is higher for
larger subsampling size within a certain range. In conclusion, there is tradeofffor larger subsampling size—it is more
difficult to include only data points of small noise while it is easier to smooth out the noise inside the subsample.
4.2.5.  Adjusted error bar and auto-fitting of subsampling size
In real-world applications, the case is usually more complicated and the problem of setting the best subsampling
size is subtle. Since the true equations are unknown, the basis-selection success rate cannot be calculated. Therefore,
drawing a curve like the ones in Figure 6 to find the best subsampling size is not available. Here we define an adjusted
error bar as an indicator for the quality of the approximated model and fit the subsampling size automatically.
The error bar defined in (18) depends on the number of data points used and the quality of the approximated
model. When the subsampling size is within a reasonable range, the quality of the approximated model does not differ
too much, so the error bar is dominated by the number of data points (see Figure 7). By the formula (18), the error bar
is negatively correlated with the number of data points.  If we want to compare results among different subsampling
sizes,  we need to adjust the error bar such that it is independent of the subsampling size.   Inspired by the rate of
convergence of Monte Carlo method, we give the following empirical formula:
adjusted error bar=[error bar]×[subsampling size]
0.5
.(35)
15

Figure 7: Error bar vs subsampling size. The total number of data points is 200.
In Figure 8, we can see that the adjusted error bar almost only depends on the quality of the approximated model.
Note that we have the best models when the subsampling size is between 60 and 80 (see Figure 6a). Meanwhile, the
percentile curves in Figure 8 indicate that the optimal subsampling sizes are in about that range.  This observation
confirms that the adjusted error bar depends on the quality of the discovered model.  The better the model is,  the
smaller the adjusted error bar is.
Now, we do not have to set the subsampling size at the beginning but we may try different subsampling sizes to
discover the model, and the best result can be selected from all the results with different subsampling sizes. (In Figure
7 and Figure 8, for each fixed number of loops and subsampling size, we run SubTSBR 1000 times and discover 1000
models with their error bars or adjusted error bars.  Then the 25th, 50th, and 75th percentiles of these error bars or
adjusted error bars are plotted.)
4.2.6.  A new data set with larger noise
Here we use a new data set with white noiseN(0,0.05
2
) to discover the predator-prey model (24) - (25).  All
other settings remain the same.  Corresponding to Figure 2, the noisy data are presented in Figure 9a and Figure 9b.
Corresponding to Figure 6, the basis-selection success rates are presented in Figure 9c and Figure 9d.  With larger
noise, the chance of successfully picking out the true terms from the basis-functions is lower. As a result, more loops
would be needed in this case.  Figure 9d only demonstrates the results with the numbers of loops up to 80, but many
more loops may be used in practical problems.  As for computation time, it takes about 15 seconds to discover the
dynamical system in this example with subsampling size 60 and the number of loops 1000 on one core of the CPU
Intel i7-6700HQ (coded in MATLAB 2018a).
4.2.7.  Another new data set with smaller noise
Now we use another new data set with white noiseN(0,0.005
2
) to discover the predator-prey model (24) - (25).
All other settings remain the same.  The numerical results are presented in Figure 10.  In this case, we have a large
portion of data points of small noise to use, so a 100% basis-selection success rate can be reached with just 20 loops.
16

(a)(b)
(c)(d)
Figure 8: Adjusted error bar vs subsampling size, with different numbers of loops. The total number of data points is 200.
Also, the noise inside the subsamples is small, so we do not need a large subsampling size to smooth out the noise
inside the subsamples. The basis-selection success rate is very high even with a subsampling size of 20.
5. The challenge of outliers
5.1.  Problem description
The outliers in the data can cause serious problems in the estimations and should be removed.  The subsampling
procedure in Algorithm 4 is designed to be resistant to outliers.  Here we calculate how many loops are needed to
exclude the outliers from a data set. Then we apply our theory to an example.
5.2.  The number of loops needed to remove outliers
Suppose we are givenNdata points, a portionpof which are outliers. Suppose the subsampling size isS. We try
to determine the number of loopsLsuch that with confidenceq, at least one of theLrandomly selected subsets of the
data does not contain any outlier.
17

(a)(b)
(c)(d)
Figure 9: (a) and (b) The noisy data with larger noise than the ones in Figure 2. (c) and (d) The basis-selection success rates with larger noise than
the ones in Figure 6.
The number of outliers ispNand the number of “good” data points is (1−p)N. For a random subset of sizeSnot
containing any outlier, the probability is
(1−p)
(1−p)N−1
N−1
(1−p)N−2
N−2
···
(1−p)N−S+1
N−S+1
.(36)
Whenp1 andSN, the probability is approximately
(1−p)
S
.(37)
For a random subset of sizeScontaining at least one outlier, the probability is
1−(1−p)
S
.(38)
ForLrandom subsets of sizeSeach containing at least one outlier, the probability is
[1−(1−p)
S
]
L
.(39)
ForLrandom subsets of sizeSat least one subset not containing any outlier, the probability is
1−[1−(1−p)
S
]
L
.(40)
18

(a)(b)
(c)(d)
Figure 10: (a) and (b) The noisy data with smaller noise than the ones in Figure 2. (c) and (d) The basis-selection success rates with smaller noise
than the ones in Figure 6.
Set the probability greater than or equal toq:
1−[1−(1−p)
S
]
L
≥q.(41)
Then we have
L≥
log(1−q)
log(1−(1−p)
S
)
.(42)
See Figure 11 for the relationship between the subsampling sizeS, the portion of outliersp, and the minimum number
of loopsLwhenq=0.99.
5.3.  Example: shallow water equations with outliers
Consider the following 2-D conservative form of shallow water equations:
∂h
∂t
+
∂(hu)
∂x
+
∂(hv)
∂y
=0(43)
∂(hu)
∂t
+
∂(hu
2
+(1/2)gh
2
)
∂x
+
∂(huv)
∂y
=0(44)
∂(hv)
∂t
+
∂(huv)
∂x
+
∂(hv
2
+(1/2)gh
2
)
∂y
=0(45)
19

Figure 11: The relationship between the subsampling sizeS, the portion of outliersp, and the minimum number of loopsLwhenq=0.99 in (42).
The black curves are the contours with fixed minimumL.
on (x,y)∈[0,39]×[0,39] andt∈[0,∞), with reflective boundary conditions and a water drop initiating gravity
waves, wherehis the total fluid column height, (u,v) is the fluid’s horizontal flow velocity averaged across the vertical
column, andg=9.8 m s
−2
is the gravitational acceleration. The first equation can be derived from mass conservation,
the last two from momentum conservation. Here, we have made the assumption that the fluid density is a constant.
5.3.1.  Data collection
We generate the numerical solution to the shallow water equations using Lax-Wendrofffinite difference method
with∆x= ∆y=1 and∆t=0.02.  See Figure 12.  The data are collected att=36 and the partial derivatives∂h/∂x,
∂u/∂x,∂v/∂x,∂h/∂y,∂u/∂y, and∂v/∂yare calculated by the three-point central-difference formula.  The calculation
of the partial derivatives∂h/∂t,∂u/∂t, and∂v/∂tuses the points from two adjacent time frames. Assume that only the
central 36×36 part of the data is made accessible and 2% of them are added on the values ofh,u, andvby independent
and identically distributed random error∼ U(0.5,1), the uniform distribution on [0.5,1].  There are 36×36=1296
accessible data points. See Figure 12d. Thus, the accessible data to discover the model are:
{
h
i
,u
i
,v
i
,
(
∂h
∂t
)
i
,
(
∂u
∂t
)
i
,
(
∂v
∂t
)
i
,
(
∂h
∂x
)
i
,
(
∂u
∂x
)
i
,
(
∂v
∂x
)
i
,
(
∂h
∂y
)
i
,
(
∂u
∂y
)
i
,
(
∂v
∂y
)
i
}
1296
i=1
,(46)
2% of which are outliers.
5.3.2.  Discovery of the model
We apply the dimensional analysis method introduced in [1] to construct the basis-functions of the same dimension
as∂h/∂t(m s
−1
) to discover it:h(∂u/∂x),h(∂v/∂x),h(∂u/∂y),h(∂v/∂y),u,u(∂h/∂x),u(∂h/∂y),v,v(∂h/∂x),v(∂h/∂y),
(∂h/∂t)(∂h/∂x), (∂h/∂t)(∂h/∂y).  Similarly, we can construct the basis-functions of the same dimension as∂u/∂tand
∂v/∂t(m s
−2
)  to  discover  them:u(∂u/∂x),u(∂v/∂x),u(∂u/∂y),u(∂v/∂y),v(∂u/∂x),v(∂v/∂x),v(∂u/∂y),v(∂v/∂y),
(∂h/∂t)(∂u/∂x), (∂h/∂t)(∂v/∂x), (∂h/∂t)(∂u/∂y), (∂h/∂t)(∂v/∂y),g(∂h/∂x),g(∂h/∂y). The threshold for all algorithms
20

(a)(b)
(c)(d)
Figure 12: Surface plot displays height colored by momentum. (a) A water drop falls into the pool. (b) The gravity waves are traveling and being
reflected by the boundary. (c) The water surface state when the data are collected. (d) The accessible data are corrupted by outliers.
is set at 0.1. If sequential threshold least squares (Algorithm 1) is applied, we get the following result:
∂h
∂t
=−0.990h
∂u
∂x
−0.988h
∂v
∂y
−0.710u
∂h
∂x
+0.395u
∂h
∂y
+0.409v
∂h
∂x
−0.709v
∂h
∂y
+0.267
∂h
∂t
∂h
∂y
(47)
∂u
∂t
=−0.748u
∂u
∂x
−1.931u
∂v
∂x
+2.173u
∂u
∂y
+0.269v
∂u
∂x
+1.506v
∂v
∂x
−2.114v
∂u
∂y
+1.907
∂h
∂t
∂v
∂x
−1.956
∂h
∂t
∂u
∂y
−1.011g
∂h
∂x
(48)
∂v
∂t
=−0.480u
∂v
∂x
−0.155u
∂u
∂y
+0.118u
∂v
∂y
+1.093v
∂v
∂x
−0.743v
∂u
∂y
−0.723v
∂v
∂y
−0.195
∂h
∂t
∂u
∂x
+3.128
∂h
∂t
∂v
∂x
−3.018
∂h
∂t
∂u
∂y
+0.195
∂h
∂t
∂v
∂y
−1.007g
∂h
∂y
.(49)
21

If lasso (Algorithm 2) is used, we have:
∂h
∂t
=−0.988h
∂u
∂x
+0.001h
∂v
∂x
−0.987h
∂v
∂y
+0.004u−0.733u
∂h
∂x
+0.358u
∂h
∂y
+0.409v
∂h
∂x
−0.710v
∂h
∂y
+0.180
∂h
∂t
∂h
∂y
(50)
∂u
∂t
=−0.587u
∂u
∂x
+0.049u
∂v
∂x
+0.017u
∂u
∂y
+0.112v
∂u
∂x
−0.466v
∂v
∂x
−0.005v
∂u
∂y
−1.011g
∂h
∂x
(51)
∂v
∂t
=−0.469u
∂v
∂x
+0.049u
∂v
∂y
+0.165v
∂v
∂x
−0.621v
∂v
∂y
−1.006g
∂h
∂y
.(52)
If TSBR (Algorithm 3) is used, we get:
∂h
∂t
=−0.990h
∂u
∂x
−0.988h
∂v
∂y
−0.705u
∂h
∂x
+0.375u
∂h
∂y
+0.402v
∂h
∂x
−0.696v
∂h
∂y
+0.207
∂h
∂t
∂h
∂y
(53)
∂h
∂t
=−0.750u
∂u
∂x
−2.042u
∂v
∂x
+2.283u
∂u
∂y
+0.265v
∂u
∂x
+1.557v
∂v
∂x
−2.172v
∂u
∂y
−1.011g
∂h
∂x
(54)
∂v
∂t
=−0.635u
∂v
∂x
+0.118u
∂v
∂y
+1.106v
∂v
∂x
−0.767v
∂u
∂y
−0.725v
∂v
∂y
−0.189
∂h
∂t
∂u
∂x
+0.157
∂h
∂t
∂v
∂x
+0.174
∂h
∂t
∂v
∂y
−1.007g
∂h
∂y
.(55)
In contrast, if SubTSBR (Algorithm 4) is applied to discover the model, we have:
∂h
∂t
=−1.001h
∂u
∂x
−0.996h
∂v
∂y
−0.932u
∂h
∂x
−0.986v
∂h
∂y
(56)
∂u
∂t
=−0.939u
∂u
∂x
−1.051v
∂u
∂y
−0.998g
∂h
∂x
(57)
∂v
∂t
=−1.023u
∂v
∂x
−0.980v
∂v
∂y
−1.002g
∂h
∂y
,(58)
where the subsampling size is 162, which is one eighth of all the accessible data, and the number of loops is 120,
which is the minimumLcalculated by (42) with confidence 0.99.  Note that the system of equations (43) - (45) is
equivalent to
∂h
∂t
+h
∂u
∂x
+h
∂v
∂y
+u
∂h
∂x
+v
∂h
∂y
=0(59)
∂u
∂t
+u
∂u
∂x
+v
∂u
∂y
+g
∂h
∂x
=0(60)
∂v
∂t
+u
∂v
∂x
+v
∂v
∂y
+g
∂h
∂y
=0.(61)
Therefore, SubTSBR gives the best result.
6. The challenge of data integration
6.1.  Problem description
Data integration is the process of combining the data from different sources into meaningful and valuable informa-
tion.  In many cases, collecting enough data from a single experiment is difficult to achieve due to limited resources.
22

For instance, the experiments may need to be done at multiple different time or different locations.  When the data
are from multiple experiments, although they are generated by the same model, the initial conditions or boundary
conditions used to generate them may be different or even unmeasurable.  Traditional interpolation and regression
methods are not applicable to these cases since these methods require all the data to be from the same curve.   A
significant advantage of our method of discovering governing differential equations is that the data are allowed to be
from different experiments, as long as the model behind them is the same.
On top of that, if the initial condition and boundary condition can be formulated into algebraic equations and we
are given data at the initial state and boundary, we may symbolize the initial condition and boundary condition into
the form (7) and discover them using our method.  The only difference in this case is that the algebraic equations do
not have any derivative term.
Finally, with the discovered differential equation, initial condition, and boundary condition, we may reconstruct
the solutions to the model and make predictions.
6.2.  Example: heat diffusion with random initial and boundary conditions
Consider the following 1-D heat diffusion equation:
∂u
∂t
=
1
2
∂
2
u
∂x
2
(62)
onx∈[0,5] andt∈[0,∞) with random initial condition:
u(x,0)=−
1
2
ξ
1
x(x−5)(63)
and random boundary condition:
u(0,t)=ξ
2
sin (2t)−ξ
2
3
cost+ξ
2
3
(64)
u(5,t)=ξ
2
ξ
3
sint−ξ
3
sin (t+
π
4
)+
ξ
3
√
2
2
,(65)
whereξ
1
,ξ
2
,ξ
3
are independent random variables:
•ξ
1
∼U(0,1), the uniform distribution on [0,1];
•ξ
2
∼U(0,1), the uniform distribution on [0,1];
•ξ
3
∼N(0,0.5
2
), the normal distribution with mean 0 and standard deviation 0.5.
Whenξ
1
=ξ
2
=ξ
3
=0.5, the solution of the heat diffusion equation is displayed in Figure 13.
6.2.1.  Data collection and discovery of the model
We collect data at the grid points onx∈[0,5] andt∈[0,5] illustrated in Figure 13b from 20 solutions generated
by 20 sets of independent random variables{ξ
1
,ξ
2
,ξ
3
}. There are 11×11×20=2420 data points. Then we calculate
23

(a)(b)
Figure 13:  Solution of the 1-D heat diffusion equation (62) withξ
1
=ξ
2
=ξ
3
=0.5.  (a) Surface plot.  (b) Image plot with scaled colors.  Grid
points: [•] all data points to collect from the model [©] data points used to discover PDE [?] data points used to discover boundary condition []
data points used to discover initial condition.
derivatives using the five-point central-difference formula. Note that the derivatives are only calculated at the interior
grid points (marked as [©] in Figure 13b). Next we discover the PDE using our algorithm SubTSBR with subsampling
size 245, which is one fourth of all interior grid points, and 30 loops.  The basis-functions are monomials generated
by{1,x,t,u,∂u/∂x,∂
2
u/∂x
2
}up to degree 3. There are 56 terms. The result is:
∂u
∂t
=0.498
∂
2
u
∂x
2
.(66)
After that, we discover the boundary condition using SubTSBR with subsampling size 55, which is one fourth of
all lower boundary points or upper boundary points, and 30 loops.  The basis-functions are monomials generated by
{1,ξ
2
,ξ
3
,t,sint,cost}up to degree 3. There are 56 terms. The result is:
u(0,t)=1.000ξ
2
3
+2.000ξ
2
sintcost−1.000ξ
2
3
cost(67)
u(5,t)=0.707ξ
3
−0.707ξ
3
sint−0.707ξ
3
cost+1.000ξ
2
ξ
3
sint.(68)
Next we discover the initial condition using SubTSBR with subsampling size 55, which is one fourth of all initial
points, and 30 loops. The basis-functions are monomials generated by{1,ξ
1
,x,sinx,cosx}up to degree 3. There are
35 terms. The result is:
u(x,0)=2.500ξ
1
x−0.500ξ
1
x
2
.(69)
6.2.2.  Prediction
Now we predict the solution whenξ
1
=ξ
2
=ξ
3
=0.5.   Fix theξ
1
,ξ
2
,ξ
3
values in (67) - (69) and solve the
PDE (66) onx∈[0,5] andt∈[0,15].  We get the solution of the heat diffusion equation predicted by discovering
PDE in Figure 14c and 14d.  The true model is solved by (62) and fixingξ
1
=ξ
2
=ξ
3
=0.5 in (63) - (65).  Its
solution is displayed in Figure 14a and 14b.   As a comparison,  the solution predicted by least-squares regression
is displayed in Figure 14e and 14f, whereu(x,t,ξ
1
,ξ
2
,ξ
3
) is fitted by a linear combination of monomials generated
24

tMSE by discovering PDEMSE by least-squares regression
00.0000000.003998
1.50.0000650.001693
3.00.0000940.001908
4.50.0000760.002779
6.00.0001070.021333
7.50.0001050.641847
9.00.0000943.882689
10.50.00005510.631797
12.00.00005818.003597
13.50.00006224.832532
15.00.00004836.988403
Table 1: Mean squared error (MSE) of the predicted solutions in Figure 14 by discovering PDE and least-squares regression at different timet.
by{1,x,sinx,cosx,t,sint,cost,ξ
1
,ξ
2
,ξ
3
}up to degree 3.  There are 220 terms.  Here we use the same data set for
discovering PDE to do the regression. The solution is drawn by fixingξ
1
=ξ
2
=ξ
3
=0.5:u(x,t,0.5,0.5,0.5). Figure
14 shows that both of discovering PDE and least-squares regression approximate the true model well ont∈[0,5], but
discovering PDE predicts the true model much better ont∈[5,15]. Least-squares regression starts to fail whent≥6
because the data are collected withint∈[0,5] and least-squares regression is a kind of interpolation method. It does
not work well outside the region with known data.  In contrast, discovering PDE is a kind of extrapolation method,
which works beyond the original observation range. See Figure 15 for the solutions at different timetand Table 1 for
the mean squared error (MSE) at different timet.
Note that we do not use any data fromξ
1
=ξ
2
=ξ
3
=0.5 to discover the PDE, initial condition, or boundary
condition.  Instead, we use the data from 20 randomly generated sets of independent random variables{ξ
1
,ξ
2
,ξ
3
}.
Predictions at otherξ
1
,ξ
2
,ξ
3
values can be derived in the same way by fixing theξ
1
,ξ
2
,ξ
3
values in (67) - (69) and
solving (66). The prediction at{ξ
1
,ξ
2
,ξ
3
}does not need any data from the same{ξ
1
,ξ
2
,ξ
3
}.
Also note that we do not need any information aboutξ
1
,ξ
2
,ξ
3
to discover the PDE. If the values ofξ
1
,ξ
2
,ξ
3
are
unknown,  we can still discover the PDE but unable to discover the initial condition or boundary condition in this
example.  If given a new initial condition and boundary condition, we can still make prediction using the discovered
PDE, while we are not able to do so using regression methods.
25

(a)(b)
(c)(d)
(e)(f)
Figure 14:  (a) (b) The true model solved by (62) with initial and boundary conditions (63) - (65).  (c) (d) The solution predicted by discovering
PDE, solved by (66) with initial and boundary conditions (67) - (69). (e) (f) The solution predicted by least-squares regression. All withξ
1
=ξ
2
=
ξ
3
=0.5.
26

(a)(b)
(c)(d)
(e)(f)
Figure 15:  The true model, the solution predicted by discovering PDE, and the solution predicted by least-squares regression, at different timet.
All settings are the same as Figure 14.
27

7. The challenge of extrapolation
7.1.  Problem description
Here we demonstrate how to tackle the challenge of extrapolation through an example of discovering a differential
equation with bifurcations. When the differential equations have bifurcations, the solutions may have different behav-
ior in different areas.  If the data are given within a region, traditional interpolation and regression methods may not
be able to capture the behavior or make predictions outside that region.  On the contrary, the method of discovering
differential equations is not impacted by bifurcations and it can extrapolate to the areas where no data are given.
7.2.  Example: fish-harvesting problem with bifurcations
Consider the following fish-harvesting problem:
d x
dt
=x(4−x)−H,(70)
wherex(t) is the population of the fish at timetandH≥0 is the constant rate at which the fish are harvested. In this
example, we fixH=3:
d x
dt
=x(4−x)−3.(71)
Settingd x/dt=0, we have:
x(4−x)−3=0,(72)
whose solutions are
x=1 andx=3.(73)
When the fish populationxis between 1 and 3, the population grows up; otherwise, it goes down. See Figure 16b.
7.2.1.  Data collection and discovery of the model
We generate data ont∈[0,2] using five random initial valuesx
0
∼ U(1,3), the uniform distribution on [1,3],
and we collect data at the nodes illustrated in Figure 16a. Then the derivatives are calculated by the five-point central-
difference formula. Note that the derivatives are not calculated at the first two and last two data points in each curve.
There are 80 data points with derivative. Next we discover the ODE using our algorithm SubTSBR with subsampling
size 40, a half of all the data points with derivative, and 30 loops.  The basis-functions are monomials generated by
{1,t,x}up to degree 10. There are 66 terms. The result is:
d x
dt
=−2.9998+3.9998x−1.0000x
2
.(74)
28

(a)(b)
(c)(d)
Figure 16:  (a) The data are generated by five random initial values and collected at the nodes.  (b) The solutions to the true model (71).  (c) The
solutions to the discovered model (74). (d) The solutions calculated by least-squares regression.
7.2.2.  Prediction
Now we predict the solutions using the discovered ODE (74) and 40 evenly spaced initial valuesx
0
.  See Figure
16c. The solutions calculated by the true model with the same initial values are shown in Figure 16b. As a comparison,
the  solutions  predicted  by  least-squares  regression  are  displayed  in  Figure  16d,  where  the  data  are  all  100  nodes
illustrated in Figure 16a, andu(t,x
0
) is fitted by a linear combination of monomials generated by{1,t,x
0
}up to degree
11 with the constraintu(0,x
0
)=x
0
. There are 66 coefficients to be estimated. Then the solutions are drawn by fixing
x
0
at each value.
Although the data are generated by initial valuesx
0
between 1 and 3, the discovered model (74) extrapolates to
other initial values and almost perfectly predicts the behavior of the true model. By contrast, least-squares regression
barely approximates the behavior of the true model in the area where the data are given and is not able to extrapolate.
8. Summary
In this paper, we have analyzed four challenges in the data-driven discovery of physical laws:  (1) large noise in
the data, (2) outliers in the data, (3) integrating the data collected from different experiments, and (4) extrapolating the
29

solutions to the areas that have no available data. To tackle these challenges, we have adopted the strategy: first, dis-
cover the governing differential equations; second, solve the differential equations analytically or numerically. On top
of that, we have proposed a new model-discovering algorithm, the subsampling-based threshold sparse Bayesian re-
gression algorithm. This new algorithm is a generalization and improvement of the original threshold sparse Bayesian
regression algorithm first introduced in [1].  Our new algorithm is designed to be robust to large noise and outliers
via incorporating a subsampling technique in the sparse Bayesian inference.  The new algorithm has two user-preset
parameters, the subsampling size and the number of loops. The subsampling size should be moderate and can be fitted
automatically using the adjusted error bar defined in this paper, while the number of loops is the bigger the better. In
practice, we can increase the number of loops gradually and stop the algorithm when the smallest error bar among all
the loops drops below a certain preset value or the smallest error bar stops decreasing. The minimum number of loops
needed to remove a certain percentage of outliers has also been calculated.
Four examples have been given in this paper:  the predator-prey model with noise, shallow water equations with
outliers, heat diffusion with random initial and boundary conditions, and fish-harvesting problem with bifurcation.
They demonstrate that our new algorithm is able to overcome the four aforementioned challenges and is significantly
better than the other model-discovering methods (sequential threshold least squares, lasso, and the original threshold
sparse Bayesian regression algorithm) and traditional regression method (least squares).  In practice, denoising pro-
cesses may be applied followed by our new algorithm to attain optimum performance. On top of that, the success of
the subsampling strategy proposed in this paper justifies the effectiveness of the defined error bar as an indicator for
the quality of the discovered model.
Acknowledgments
We acknowledge the support from the National Science Foundation (DMS-1555072, DMS-1736364, and DMS-
1821233). We thank Elizabeth A. Robbins for proofreading this manuscript.
30

[1]  S. Zhang, G. Lin, Robust data-driven discovery of governing physical laws with error bars, Proceedings of the Royal Society A: Mathematical,
Physical and Engineering Science 474 (2217) (2018) 20180305.doi:10.1098/rspa.2018.0305.
URLhttp://rspa.royalsocietypublishing.org/lookup/doi/10.1098/rspa.2018.0305
[2]  M. Schmidt, H. Lipson, Distilling Free-Form Natural Laws from Experimental Data, Science 324 (5923) (2009) 81–85.doi:10.1126/
science.1165893.
URLhttp://www.sciencemag.org/lookup/doi/10.1126/science.1165893
[3]  S. L. Brunton, J. L. Proctor, J. N. Kutz, Discovering governing equations from data by sparse identification of nonlinear dynamical systems,
Proceedings of the National Academy of Sciences 113 (15) (2016) 3932–3937.doi:10.1073/pnas.1517384113.
URLhttp://www.pnas.org/lookup/doi/10.1073/pnas.1517384113
[4]  S. H. Rudy, S. L. Brunton, J. L. Proctor, J. N. Kutz, Data-driven discovery of partial differential equations, Science Advances 3 (4) (2017)
e1602614.doi:10.1126/sciadv.1602614.
URLhttp://advances.sciencemag.org/lookup/doi/10.1126/sciadv.1602614
[5]  R. Tibshirani, Regression shrinkage and selection via the lasso, Journal of the Royal Statistical Society. Series B (Methodological) (1996)
267–288.
[6]  H. Schaeffer, Learning partial differential equations via data discovery and sparse optimization, Proceedings of the Royal Society A: Mathe-
matical, Physical and Engineering Science 473 (2197) (2017) 20160446.doi:10.1098/rspa.2016.0446.
URLhttp://rspa.royalsocietypublishing.org/lookup/doi/10.1098/rspa.2016.0446
[7]  N. M. Mangan, S. L. Brunton, J. L. Proctor, J. N. Kutz, Inferring Biological Networks by Sparse Identification of Nonlinear Dynamics, IEEE
Transactions on Molecular, Biological and Multi-Scale Communications 2 (1) (2016) 52–63.doi:10.1109/TMBMC.2016.2633265.
URLhttp://ieeexplore.ieee.org/document/7809160/
[8]  M. Dam, M. Brns, J. Juul Rasmussen, V. Naulin, J. S. Hesthaven, Sparse identification of a predator-prey system from simulation data of a
convection model, Physics of Plasmas 24 (2) (2017) 022310.doi:10.1063/1.4977057.
URLhttp://aip.scitation.org/doi/10.1063/1.4977057
[9]  H. Schaeffer, S. G. McCalla, Sparse model selection via integral terms, Physical Review E 96 (2).doi:10.1103/PhysRevE.96.023302.
URLhttp://link.aps.org/doi/10.1103/PhysRevE.96.023302
[10]  H.  Schaeffer,  G.  Tran,  R.  Ward,  Extracting  Sparse  High-Dimensional  Dynamics  from  Limited  Data,  arXiv:1707.08528  [math]ArXiv:
1707.08528.
URLhttp://arxiv.org/abs/1707.08528
[11]  G. Tran, R. Ward, Exact Recovery of Chaotic Systems from Highly Corrupted Data, Multiscale Modeling & Simulation 15 (3) (2017) 1108–
1129.doi:10.1137/16M1086637.
URLhttp://epubs.siam.org/doi/10.1137/16M1086637
[12]  N. M. Mangan, J. N. Kutz, S. L. Brunton, J. L. Proctor, Model selection for dynamical systems via sparse regression and information criteria,
Proceedings of the Royal Society A: Mathematical, Physical and Engineering Science 473 (2204) (2017) 20170009.doi:10.1098/rspa.
2017.0009.
URLhttp://rspa.royalsocietypublishing.org/lookup/doi/10.1098/rspa.2017.0009
[13]  E.  Kaiser,  J.  N.  Kutz,  S.  L.  Brunton,  Sparse  identification  of  nonlinear  dynamics  for  model  predictive  control  in  the  low-data  limit,
arXiv:1711.05501 [physics]ArXiv: 1711.05501.
URLhttp://arxiv.org/abs/1711.05501
[14]  L. Boninsegna, F. Nske, C. Clementi, Sparse learning of stochastic dynamical equations, The Journal of Chemical Physics 148 (24) (2018)
241723.doi:10.1063/1.5018409.
URLhttp://aip.scitation.org/doi/10.1063/1.5018409
[15]  N. M. Mangan, T. Askham, S. L. Brunton, J. N. Kutz, J. L. Proctor, Model selection for hybrid dynamical systems via sparse regression,
arXiv:1808.03251 [math]ArXiv: 1808.03251.
31

URLhttp://arxiv.org/abs/1808.03251
[16]  S.  Rudy,  A.  Alla,  S.  L.  Brunton,  J.  N.  Kutz,  Data-driven  identification  of  parametric  partial  differential  equations,  arXiv:1806.00732
[math]ArXiv: 1806.00732.
URLhttp://arxiv.org/abs/1806.00732
[17]  H.  Schaeffer,  G.  Tran,  R.  Ward,  L.  Zhang,  Extracting  structured  dynamical  systems  using  sparse  optimization  with  very  few  samples,
arXiv:1805.04158 [cs, math]ArXiv: 1805.04158.
URLhttp://arxiv.org/abs/1805.04158
[18]  J.-C. Loiseau, S. L. Brunton, Constrained sparse Galerkin regression, Journal of Fluid Mechanics 838 (2018) 42–67.doi:10.1017/jfm.
2017.823.
URLhttps://www.cambridge.org/core/product/identifier/S0022112017008230/type/journal_article
[19]  M. Quade, M. Abel, J. N. Kutz, S. L. Brunton, Sparse Identification of Nonlinear Dynamics for Rapid Model Recovery, Chaos: An Interdis-
ciplinary Journal of Nonlinear Science 28 (6) (2018) 063116, arXiv: 1803.00894.doi:10.1063/1.5027470.
URLhttp://arxiv.org/abs/1803.00894
[20]  L. Zhang, H. Schaeffer, On the Convergence of the SINDy Algorithm, arXiv:1805.06445 [cs, math]ArXiv: 1805.06445.
URLhttp://arxiv.org/abs/1805.06445
[21]  S.  H.  Rudy,  J.  N.  Kutz,  S.  L.  Brunton,  Deep  learning  of  dynamics  and  signal-noise  decomposition  with  time-stepping  constraints,
arXiv:1808.02578 [math]ArXiv: 1808.02578.
URLhttp://arxiv.org/abs/1808.02578
[22]  M. Raissi, P. Perdikaris, G. E. Karniadakis, Physics Informed Deep Learning (Part I): Data-driven Solutions of Nonlinear Partial Differential
Equations, arXiv:1711.10561 [cs, math, stat]ArXiv: 1711.10561.
URLhttp://arxiv.org/abs/1711.10561
[23]  M. Raissi, P. Perdikaris, G. E. Karniadakis, Physics Informed Deep Learning (Part II): Data-driven Discovery of Nonlinear Partial Differential
Equations, arXiv:1711.10566 [cs, math, stat]ArXiv: 1711.10566.
URLhttp://arxiv.org/abs/1711.10566
[24]  M. Raissi, G. E. Karniadakis, Machine Learning of Linear Differential Equations using Gaussian Processes, Journal of Computational Physics
348 (2017) 683–693, arXiv: 1701.02440.doi:10.1016/j.jcp.2017.07.050.
URLhttp://arxiv.org/abs/1701.02440
[25]  B. Efron, C. Stein, The Jackknife Estimate of Variance, The Annals of Statistics 9 (3) (1981) 586–596.doi:10.1214/aos/1176345462.
URLhttp://projecteuclid.org/euclid.aos/1176345462
[26]  M. E. Tipping, Sparse Bayesian learning and the relevance vector machine, Journal of machine learning research 1 (Jun) (2001) 211–244.
[27]  D. J. C. MacKay, Bayesian Methods for Backpropagation Networks, in: E. Domany, J. L. van Hemmen, K. Schulten, E. Domany, J. L. van
Hemmen, K. Schulten (Eds.), Models of Neural Networks III, Springer New York, New York, NY, 1996, pp. 211–254.doi:10.1007/
978-1-4612-0723-8_6.
URLhttp://link.springer.com/10.1007/978-1-4612-0723-8_6
[28]  R. M. Neal, Bayesian Learning for Neural Networks, Vol. 118 of Lecture Notes in Statistics, Springer New York, New York, NY, 1996.
doi:10.1007/978-1-4612-0745-0.
URLhttp://link.springer.com/10.1007/978-1-4612-0745-0
[29]  M. E. Tipping, A. C. Faul, Fast marginal likelihood maximisation for sparse Bayesian models, in: AISTATS, 2003.
[30]  A. Schmolck, R. Everson, Smooth relevance vector machine:  a smoothness prior extension of the RVM, Machine Learning 68 (2) (2007)
107–135.doi:10.1007/s10994-007-5012-z.
URLhttp://link.springer.com/10.1007/s10994-007-5012-z
[31]  P. W. Holland, R. E. Welsch, Robust regression using iteratively reweighted least-squares, Communications in Statistics - Theory and Methods
6 (9) (1977) 813–827.doi:10.1080/03610927708827533.
32

URLhttp://www.tandfonline.com/doi/abs/10.1080/03610927708827533
[32]  R. Chartrand, Wotao Yin, Iteratively reweighted algorithms for compressive sensing, in: 2008 IEEE International Conference on Acoustics,
Speech and Signal Processing, IEEE, Las Vegas, NV, USA, 2008, pp. 3869–3872.doi:10.1109/ICASSP.2008.4518498.
URLhttp://ieeexplore.ieee.org/document/4518498/
[33]  M. A. Fischler, R. C. Bolles, Random sample consensus:  a paradigm for model fitting with applications to image analysis and automated
cartography, Communications of the ACM 24 (6) (1981) 381–395.doi:10.1145/358669.358692.
URLhttp://portal.acm.org/citation.cfm?doid=358669.358692
[34]  O.  J.  Karst,  Linear  Curve  Fitting  Using  Least  Deviations,  Journal  of  the  American  Statistical  Association  53  (281)  (1958)  118.doi:
10.2307/2282572.
URLhttps://www.jstor.org/stable/2282572?origin=crossref
[35]  H.  Theil,  A  Rank-Invariant  Method  of  Linear  and  Polynomial  Regression  Analysis,  in:  A.  J.  H.  Hallet,  J.  Marquez,  B.  Raj,  J.  Koerts
(Eds.), Henri Theils Contributions to Economics and Econometrics, Vol. 23, Springer Netherlands, Dordrecht, 1992, pp. 345–381.doi:
10.1007/978-94-011-2546-8_20.
URLhttp://www.springerlink.com/index/10.1007/978-94-011-2546-8_20
[36]  P. K. Sen, Estimates of the Regression Coefficient Based on Kendall’s Tau, Journal of the American Statistical Association 63 (324) (1968)
1379.doi:10.2307/2285891.
URLhttps://www.jstor.org/stable/2285891?origin=crossref
[37]  A. F. Siegel, Robust regression using repeated medians, Biometrika 69 (1) (1982) 242–244.doi:10.1093/biomet/69.1.242.
URLhttps://academic.oup.com/biomet/article-lookup/doi/10.1093/biomet/69.1.242
[38]  P. J. Rousseeuw,  Least Median of Squares Regression,  Journal of the American Statistical Association 79 (388) (1984) 871–880.doi:
10.1080/01621459.1984.10477105.
URLhttp://www.tandfonline.com/doi/abs/10.1080/01621459.1984.10477105
[39]  L. I. Rudin, S. Osher, E. Fatemi, Nonlinear total variation based noise removal algorithms, Physica D: Nonlinear Phenomena 60 (1-4) (1992)
259–268.doi:10.1016/0167-2789(92)90242-F.
URLhttp://linkinghub.elsevier.com/retrieve/pii/016727899290242F
[40]  R. Chartrand, Numerical Differentiation of Noisy, Nonsmooth Data, ISRN Applied Mathematics 2011 (2011) 1–11.doi:10.5402/2011/
164564.
URLhttps://www.hindawi.com/archive/2011/164564/
[41]  J. Lagergren, J. T. Nardini, G. M. Lavigne, E. M. Rutter, K. B. Flores, Learning partial differential equations for biological transport models
from noisy spatiotemporal data, arXiv:1902.04733 [math]ArXiv: 1902.04733.
URLhttp://arxiv.org/abs/1902.04733
33 

MintNet: Building Invertible Neural Networks with
Masked Convolutions
Yang Song
∗
Stanford University
yangsong@cs.stanford.edu
Chenlin Meng
∗
Stanford University
chenlin@cs.stanford.edu
Stefano Ermon
Stanford University
ermon@cs.stanford.edu
Abstract
We propose a new way of constructing invertible neural networks by combining
simple building blocks with a novel set of composition rules.  This leads to a
rich set of invertible architectures, including those similar to ResNets. Inversion
is achieved with a locally convergent iterative procedure that is parallelizable
and very fast in practice.  Additionally, the determinant of the Jacobian can be
computed analytically and efficiently, enabling their generative use as flow models.
To demonstrate their flexibility, we show that our invertible neural networks are
competitive with ResNets on MNIST and CIFAR-10 classification. When trained as
generative models, our invertible networks achieve new state-of-the-art likelihoods
on MNIST, CIFAR-10 and ImageNet 32×32, with bits per dimension of 0.98, 3.32
and 4.06 respectively.
1    Introduction
Invertible neural networks have many applications in machine learning. They have been employed to
investigate representations of deep classifiers [14], understand the cause of adversarial examples [13],
learn transition operators for MCMC [26,17], create generative models that are directly trainable by
maximum likelihood [6, 5, 22, 15, 9, 1], and perform approximate inference [25, 16].
Many applications of invertible neural networks require that both inverting the network and computing
the Jacobian determinant be efficient. While typical neural networks are not invertible, achieving these
properties often imposes restrictive constraints to the architecture. For example, planar flows [25]
and Sylvester flow [2] constrain the number of hidden units to be smaller than the input dimension.
NICE [5] and Real NVP [6] rely on dimension partitioning heuristics and specific architectures
such as coupling layers, which could make training more difficult [1]. Methods like FFJORD [9],
i-ResNets [1] have fewer architectural constraints. However, their Jacobian determinants have to be
approximated, which is problematic if repeatedly performed at training time as in flow models.
In this paper, we propose a new method of constructing invertible neural networks which are flexible,
efficient to invert, and whose Jacobian can be computedexactlyand efficiently. We use triangular
matrices as our basic module.  Then, we provide a set of composition rules to recursively build
more complex non-linear modules from the basic module, and show that the composed modules are
invertible as long as their Jacobians are non-singular.  As in previous work [6,22], the Jacobians
of our modules are triangular, allowing efficient determinant computation.  The inverse of these
modules can be obtained by an efficiently parallelizable fixed-point iteration method, making the cost
of inversion comparable to that of an i-ResNet [1] block.
Using our composition rules and masked convolutions as the basic triangular building block, we
construct a rich set of invertible modules to form a deep invertible neural network. The architecture of
our proposed invertible network closely follows that of ResNet [10]—the state-of-the-art architecture
∗
Equal contribution.
Preprint. Under review.
arXiv:1907.07945v1  [cs.LG]  18 Jul 2019

of discriminative learning. We call our modelMaskedInvertibleNetwork (MintNet). To demonstrate
the capacity of MintNets, we first test them on image classification. We found that a MintNet classifier
achieves 99.6% accuracy on MNIST, matching the performance of a ResNet with a similar architecture.
On CIFAR-10, it achieves 91.2% accuracy, comparable to the 92.6% accuracy of ResNet. When using
MintNets as generative models, they achieve the new state-of-the-art results of bits per dimension
(bpd) on uniformly dequantized images.  Specifically, MintNet achieves bpd values of 0.98, 3.32,
and 4.06 on MNIST, CIFAR-10 and ImageNet 32×32, while former best (published) results are
0.99 (FFJORD [9]), 3.35 (Glow [15]) and 4.09 (Glow) respectively. Moreover, MintNet uses fewer
parameters and less computational resources. Our MNIST model uses 30% fewer parameters than
FFJORD [9]. For CIFAR-10 and ImageNet 32×32, MintNet uses 60% and 74% fewer parameters
than the corresponding Glow [15] models. When training on dataset such as CIFAR-10, MintNet
required 2 GPUs for approximately 5 days, while FFJORD [9] used 6 GPUs for approximately 5
days, and Glow [15] used 8 GPUs for approximately 7 days.
2    Background
Consider a neural networkf:R
D
→R
L
that maps a data pointx∈R
D
to a latent representation
z∈R
L
.  When for everyz∈R
L
there exists a uniquex∈R
D
such thatf(x) =z, we callfan
invertible neural network. There are several basic properties of invertible networks. First, whenf(x)
is continuous, a necessary condition forfto be invertible isD=L.  Second, iff
1
:R
D
→R
D
andf
2
:R
D
→R
D
are both invertible,f=f
2
◦f
1
will also be invertible. In this work, we mainly
consider applications of invertible neural networks to classification and generative modeling.
2.1    Classification with invertible neural networks
Neural networks for classification are usually not invertible because the number of classesLis usually
different from the input dimensionD.  Therefore, when discussing invertible neural networks for
classification, we separate the classifier into two partsf=f
2
◦f
1
: feature extractionz=f
1
(x)and
classificationy=f
2
(z), wheref
2
is usually the softmax function. We say the classifier is invertible
whenf
1
is invertible. Invertible classifiers are arguably more interpretable, because a prediction can
be traced down by inverting latent representations [14, 13].
2.2    Generative modeling with invertible neural networks
An invertible networkf:x∈R
D
7→z∈R
D
can be used to warp a complex probability density
p(x)to a simple base distributionπ(z)(e.g., a multivariate standard Gaussian) [5,6].  Under the
condition that bothfandf
−1
are differentiable, the densities ofp(x)andπ(z)are related by the
following change of variable formula
logp(x) = logπ(z) + log|det(J
f
(x))|,(1)
whereJ
f
(x)denotes  the  Jacobian  off(x)and  we  requireJ
f
(x)to  be  non-singular  so  that
log|det(J
f
(x))|is well-defined.   Using this formula,p(x)can be easily computed if the Jaco-
bian determinantdet(J
f
(x))is cheaply computable andπ(z)is known.
Therefore, an invertible neural networkf
θ
(x)implicitly defines a normalized density modelp
θ
(x),
which can be directly trained by maximum likelihood. The invertibility off
θ
is critical to fast sample
generation. Specifically, in order to generate a samplexfromp
θ
(x), we can first drawz∼π(z),
and warp it back through the inverse off
θ
to obtainx=f
−1
θ
(z).
Note that multiple invertible modelsf
1
,f
2
,···,f
K
can be stacked together to form a deeper invertible
modelf=f
K
◦···◦f
2
◦f
1
, without much impact on the inverse and determinant computation.
This is because we can sequentially invert each component,i.e.,f
−1
=f
−1
1
◦f
−1
2
◦···◦f
−1
K
,
and the total Jacobian determinant equals the product of each individual Jacobian determinant,i.e.,
|det(J
f
)|=|det(J
f
1
)||det(J
f
2
)|···|det(J
f
K
)|.
3    Building invertible modules compositionally
In this section, we discuss how simple blocks like masked convolutions can be composed to build
invertible modules that allow efficient, parallelizable inversion and determinant computation. To this
2

Figure 1: Illustration of a masked convolution with 3 filters and kernel size3×3. Solid checkerboard
cubes inside each filter represent unmasked weights, while the transparent blue blocks represent the
weights that have been masked out.  The receptive field of each filter on the input feature maps is
indicated by regions shaded with the pattern (the colored square) below the corresponding filter.
end, we first introduce the basic building block of our models. Then, we propose a set of composition
rules to recursively build up complex non-linear modules with triangular Jacobians. Next, we prove
that these composed modules are invertible as long as their Jacobians are non-singular. Finally, we
discuss how these modules can be inverted efficiently using numerical methods.
3.1    The basic module
We start from considering linear transformationsf(x) =Wx+b, withW∈R
D×D
, andb∈R
D
.
For a generalW, computing its Jacobian determinant requiresO(D
3
)operations.  We therefore
chooseWto be a triangular matrix. In this case, the Jacobian determinantdet(J
f
(x)) = det(W)is
the product of all diagonal entries ofW, and the computational complexity is reduced toO(D). The
linear functionf(x) =Wx+bwithWbeing triangular is ourbasic module.
Masked convolutions.
Convolution is a special type of linear transformation that is very effective
for image data.  The triangular structure of the basic module can be achieved usingmaskedcon-
volutions (e.g., causal convolutions in PixelCNN [20]).  We provide the formula of our masks in
Appendix B and an illustration of a3×3masked convolution with3filters in Fig. 1. Intuitively, the
causal structure of the filters (ordering of the pixels) enforces a triangular structure.
3.2    The calculus of building invertible modules
Complex non-linear invertible functions can be constructed from our basic modules in two steps.
First, we follow several composition rules so that the composed module has a triangular Jacobian.
Next, we impose appropriate constraints so that the module is invertible. To simplify the discussion,
we only consider modules with lower triangular Jacobians here, and we note that it is straightforward
to extend the analysis to modules with upper triangular Jacobians.
The following proposition summarizes several rules to compositionally build new modules with
triangular Jacobians using existing ones.
Proposition 1.DefineFas the set of all continuously differentiable functions whose Jacobian is
lower triangular. ThenFcontains the basic module in Section 3.1, and is closed under the following
composition rules.
•Rule of addition.f
1
∈F ∧f
2
∈F ⇒λf
1
+μf
2
∈F, whereλ,μ∈R.
•Rule of composition.f
1
∈F∧f
2
∈F ⇒f
2
◦f
1
∈F. A special case isf∈F ⇒h◦f∈
F, whereh(·)is a continuously differentiable non-linear activation function that is applied
element-wise.
The proof of this proposition is straightforward and deferred to Appendix A. By repetitively applying
the rules in Proposition 1, our basic linear module can be composed to construct complex non-linear
modules having continuous and triangular Jacobians.  Note that besides our linear basic modules,
3

Figure 2: Venn Diagram relationships between invertible functions (I), the function sets ofFand
M, functions that meet the conditions of Theorem 1 (det(J
f
)6= 0), functions whose Jacobian is
triangular and Jacobian diagonals are strictly positive (diag(J
f
)>0), functions whose Jacobian is
triangular and Jacobian diagonals are all 1s (diag(J
f
) = 1).
other functions with triangular and continuous Jacobians can also be made more expressive using the
composition rules. For example, the layers of dimension partitioning models (e.g., NICE [5], Real
NVP [6], Glow [15]) and autoregressive flows (e.g., MAF [22]) all have continuous and triangular
Jacobians and therefore belong toF.  Note that the rule of addition in Proposition 1 preserves
triangular Jacobians but not invertibility. Therefore, we need additional constraints if we want the
composed functions to be invertible.
Next, we state the condition forf∈Fto be invertible, and denote the invertible subset ofFasM.
Theorem 1.Iff∈FandJ
f
(x)is non-singular for allxin the domain, thenfis invertible.
Proof.A proof can be found in Appendix A.
The non-singularity ofJ
f
(x)constraint in Theorem 1 is natural in the context of generative modeling.
This is because in order for Eq.(1)to make sense,log|det(J
f
)|has to be well-defined, which
requiresJ
f
(x)to be non-singular.
In many cases, Theorem 1 can be easily used to check and enforce the invertibility off∈ F. For
example, the layers of autoregressive flow models and dimension partitioning models can all be
viewed as elements ofFbecause they are continuously differentiable and have triangular Jacobians.
Since the diagonal entries of their Jacobians are always strictly positive and hence non-singular, we
can immediately conclude that they are invertible with Theorem 1, thus generalizing their model-
specific proofs of invertibility.
In Fig. 2, we provide a Venn Diagram to illustrate the set of functions that satisfy the condition of
Theorem 1. As depicted by the orange set labeled bydet(J
f
)6= 0, Theorem 1 captures a subset of
Mwhere the Jacobians of functions are non-singular so that the change of variable formula is usable.
Note the condition in Theorem 1 is sufficient but not necessary. For example,f(x) =x
3
∈ Mis
invertible, butJ
f
(x= 0) = 3x
2
|
x=0
= 0is singular. Many previous invertible models with special
architectures, such as NICE, Real NVP, and MAF, can be viewed as elements belonging to subsets of
det(J
f
)6= 0.
3.3    Efficient inversion of the invertible modules
In this section, we show that when the conditions in Theorem 1 hold, not only do we know thatfis
invertible (f∈M), but also we have a fixed-point iteration method to invertfwith strong theoretical
guarantees and good performance in practice.
The pseudo-code of our proposed inversion algorithm is described in Algorithm 1. Theoretically, we
can prove that this method is locally convergent—as long as the initial value is close to the true value,
the method is guaranteed to find the correct inverse. We formally summarize this result in Theorem 2.
Theorem 2.The iterative method of Algorithm 1 is locally convergent whenever0< α <2.
4

Algorithm 1Fixed-point iteration method for computingf
−1
(z).
Require:T,α. Tis the number of iterations;0< α <2is the step size.
1:Initializex
0
2:fort←1toTdo
3:Computef(x
t−1
)
4:Computediag(J
f
(x
t−1
))
5:x
t
←x
t−1
−αdiag(J
f
(x
t−1
))
−1
(f(x
t−1
)−z)
6:end for
returnx
T
Sketch of Proof.Denoteg(x;α,z),x−αdiag(J
f
(x))
−1
[f(x)−z]and letx
∗
=f
−1
(z)be the
true inverse. We can show that the spectral radius of the Jacobian ofg(x;α,z)atx
∗
is|1−α|, which
is smaller than1when0< α <2. Then the local convergence holds true according to Ostrowski’s
Theorem (cf., Theorem 10.1.3. in [21]). We provide a more rigorous proof in Appendix A.
In practice, the method is also easily parallelizable on GPUs, making the cost of invertingf∈M
similar to that of an i-ResNet [1] layer.  Within each iteration, the computation is mostly matrix
operations that can be vectorized and run efficiently in parallel.  Therefore, the time cost will be
roughly proportional to the number of iterations,i.e.,O(T). As will be shown in our experiments,
Algorithm 1 converges fast and usually the error quickly becomes negligible whenTD. This is in
stark contrast to existing methods of inverting autoregressive flow models such as MAF [22], where
Dunivariate equations need to be solved sequentially, requiring at leastO(D)iterations. There are
also other approaches for invertingf. For example, the bisection method is guaranteed to converge
globally, but its computational cost isO(D), and is usually much more expensive than Algorithm 1.
Note that as discussed earlier, autoregressive flow models can also be viewed as special cases of our
framework. Therefore, Algorithm 1 is also applicable to inverting autoregressive flow models and
could potentially result in large improvements of sampling speed.
4    Masked Invertible Networks
We show that techniques developed in Section 3 can be used to build our Masked Invertible Network
(MintNet).  First, we discuss how we compose several masked convolutions to form the Masked
Invertible Layer (Mint layer). Next, we stack multiple Mint layers to form a deep neural network,i.e.,
the MintNet. Finally, we compare MintNets with several existing invertible architectures.
4.1    Building the Masked Invertible Layer
We construct an invertible module inMthat serves as the basic layer of our MintNet. This invertible
module, named Mint layer, is defined as
L(x) =tx+
K
∑
i=1
W
3
i
h
(
K
∑
j=1
W
2
ij
h(W
1
j
x+b
1
j
) +b
2
ij
)
+b
3
i
,(2)
wheredenotes the elementwise multiplication,{W
1
i
}|
K
i=1
,{W
2
ij
}|
1≤i,j≤K
, and{W
3
i
}|
K
i=1
are all
lower triangular matrices with additional constraints to be specified later, andt>0. Additionally,
Mint layers use a monotonic activation functionh, so thath
′
≥0. Common choices ofhinclude
ELU [4], tanh and sigmoid. Note that every individual weight matrix has the same size, and the 3
groups of weights{W
1
i
}|
K
i=1
,{W
2
ij
}|
1≤i,j≤K
and{W
3
i
}|
K
i=1
can be implemented with 3 masked
convolutions (see Appendix B). We design the form ofL(x)so that it resembles a ResNet / i-ResNet
block that also has 3 convolutions withK×Cfilters, withCbeing the number of channels ofx.
From Proposition 1 in Section 3.2, we can easily conclude thatL∈F. Now, we consider additional
constraints on the weights so thatL∈ M,i.e., it is invertible.  Note that the analytic form of its
Jacobian is
J
L
(x) =
K
∑
i=1
W
3
i
A
i
K
∑
j=1
W
2
ij
B
j
W
1
j
+t,(3)
5

withA
i
= diag(h
′
(
∑
K
j=1
W
2
ij
h(W
1
j
x+b
1
j
) +b
2
ij
)
)≥0
,B
j
= diag(h
′
(W
1
j
x+b
1
j
))≥0, and
t>0. Therefore, once we impose the following constraint
diag(W
3
i
) diag(W
2
ij
) diag(W
1
j
)≥0,∀1≤i,j≤K,(4)
we  havediag(J
L
(x))>0,  which  satisfies  the  condition  of  Theorem  1  and  as  a  conse-
quence  we  knowL∈ M.    In  practice,  the  constraint  Eq.(4)can  be  easily  implemented.
For  all1≤i,j≤K,  we  impose  no  constraint  onW
3
i
andW
1
j
,  but  replaceW
2
ij
with
V
2
ij
=W
2
ij
sign(diag(W
2
ij
)) sign(diag(W
3
i
W
1
j
))
.   Note thatdiag(V
2
ij
)
has the same signs as
diag(W
3
i
) diag(W
1
j
)and thereforediag(W
3
i
) diag(V
2
ij
) diag(W
1
j
)≥0. Moreover,V
2
ij
is almost
everywhere differentiable w.r.t.W
2
ij
, which allows gradients to backprop through.
4.2    Constructing the Masked Invertible Network
In this section, we introduce design choices that help stack multiple Mint layers together to form
an expressive invertible neural network, namely the MintNet.  The full MintNet is constructed by
stacking the following paired Mint layers and squeezing layers.
Paired Mint layers.As discussed above, our Mint layerL(x)always has a triangular Jacobian. To
maximize the expressive power of our invertible neural network, it is undesirable to constrain the
Jacobian of the network to be triangular since this limits capacity and will cause blind spots in the
receptive field of masked convolutions. We thus always pair two Mint layers together—one with a
lower triangular Jacobian and the other with an upper triangular Jacobian, so that the Jacobian of the
paired layers is not triangular, and blind spots can be eliminated.
Squeezing layers.Subsampling is important for enlarging the receptive field of convolutions.
However, common subsampling operations such as pooling and strided convolutions are usually not
invertible.  Following [6] and [1], we use a “squeezing” operation to reshape the feature maps so
that they have smaller resolution but more channels.  After a squeezing operation, the height and
width will decrease by a factor ofk, but the number of channels will increase by a factor ofk
2
. This
procedure is invertible and the Jacobian is an identity matrix. Throughout the paper, we usek= 2.
4.3    Comparison to other approaches
In what follows we compare MintNets to several existing methods for developing invertible archi-
tectures. We will focus on architectures with a tractable Jacobian determinant. However, we note
that there are models (cf., [7,19,8]) that allow fast inverse computation but do not have tractable
Jacobian determinants. Following [1], we also provide some comparison in Tab. 5 (see Appendix E).
Identities of determinants.Some identities can be used to speed up the computation of deter-
minants if the Jacobians have special structures. For example, in Sylvester flow [2], the invertible
transformation has the formf(x),x+Ah(Bx+b), whereh(·)is a nonlinear activation function,
A∈R
D×M
,B∈R
M×D
,b∈R
M
andM≤D. By Sylvester’s determinant identity,det(J
f
(x))
can be computed inO(M
3
), which is much less thanO(D
3
)ifMD. However, the requirement
thatMis small becomes a bottleneck of the architecture and limits its expressive power. Similarly,
Planar flow [25] uses the matrix determinant lemma, but has an even narrower bottleneck.
The form ofL(x)bears some resemblance to Sylvester flow. However, we improve the capacity of
Sylvester flow in two ways. First, we add one extra non-linear convolutional layer. Second, we avoid
the bottleneck that limits the maximum dimension of latent representations in Sylvester flow.
Dimension partitioning.NICE [5], Real NVP [6], and Glow [15] all depend on an affine coupling
layer.  Givend < D,xis first partitioned into two partsx= [x
1:d
;x
d+1:D
].  The coupling layer
is an invertible transformation,  defined asf:x7→z,z
1:d
=x
1:d
,z
d+1:D
=x
d+1:D

exp(s(x
1:d
)) +t(x
1:d
)
, wheres(·)andt(·)are two arbitrary functions. However, the partitioning
ofxrelies on heuristics, and the performance is sensitive to this choice (cf., [15,1]).  In addition,
the Jacobian offis a triangular matrix with diagonal[1
d
; exp(s(x
1:d
))]. In contrast, the Jacobian of
MintNets has more flexible diagonals—without being partially restricted to1’s.
6

Autoregressive transformation.By leveraging autoregressive transformations, the Jacobian can
be made triangular. For example, MAF [22] defines the invertible tranformation asf:x7→z,  z
i
=
μ(x
1:i−1
) +σ(x
1:i−1
)x
i
, whereμ(·)∈Randσ(·)∈R
+
. However, the architecture offis only an
affine combination of autoregressive functions withx, which might restrict its expressive power. In
contrast, the architecture of MintNets is arguably more flexible.
Free-form invertible models.Some work proposes invertible transformations whose Jacobians
are not limited by special structures. For example, FFJORD [9] uses a continuous version of change
of variables formula [3] where the determinant is replaced by trace.  Unlike MintNets, FFJORD
needs an ODE solver to compute its value and inverse, and uses a stochastic estimator to approximate
the trace.  Another work is i-ResNet [1] which constrains the Lipschitz-ness of ResNet layers to
make it invertible. Both i-ResNet and MintNet use ResNet blocks with 3 convolutions. The inverse
of i-ResNet can be obtained efficiently by a parallelizable fixed-point iteration method, which has
comparable computational cost as our Algorithm 1.  However, unlike MintNets whose Jacobian
determinants are exact, the log-determinant of Jacobian of an i-ResNet must be approximated by
truncating a power series and estimating each term with stochastic estimators.
5    Experiments
In this section,  we evaluate our MintNet architectures on both image classification and density
estimation. We focus on three common image datasets, namely MNIST, CIFAR-10 and ImageNet
32×32. We also empirically verify that Algorithm 1 can provide accurate solutions within a small
number of iterations. We provide more details about settings and model architectures in Appendix D.
5.1    Classification
To check the capacity of MintNet and understand the trade-off of invertibility, we test its classification
performance on MNIST and CIFAR-10, and compare it to a ResNet with a similar architecture.
On MNIST, MintNet achieves a test accuracy of 99.6%, which is the same as that of the ResNet.
On CIFAR-10, MintNet reaches 91.2% test accuracy while ResNet reaches 92.6%. Both MintNet
and ResNet achieve 100% training accuracy on MNIST and CIFAR-10 datasets.  This indicates
that MintNet has enough capacity to fit all data labels on the training dataset, and the invertible
representations learned by MintNet are comparable to representations learned by non-invertible
networks in terms of generalizability. Note that the small degradation in classification accuracy is
also observed in other invertible networks. For example, depending on the Lipschitz constant, the
gap between test accuracies of i-ResNet and ResNet can be as large as 1.92% on CIFAR-10.
5.2    Density estimation and verification of invertibility
In this section, we demonstrate the superior performance of MintNet on density estimation by training
it as a flow generative model.  In addition, we empirically verify that Algorithm 1 can accurately
produce the inverse using a small number of iterations.  We show that samples can be efficiently
generated from MintNet by inverting each Mint layer with Algorithm 1.
Density estimation.In Tab. 1, we report bits per dimension (bpd) on MNIST, CIFAR-10, and
ImageNet 32×32 datasets. It is notable that MintNet sets the new records of bpd on all three datasets.
Moreover, when compared to previous best models, our MNIST model uses 30% fewer parameters
than FFJORD, and our CIFAR-10 and ImageNet 32×32 models respectively use 60% and 74% fewer
parameters than Glow. When trained on datasets such as CIFAR-10, MintNet requires 2 GPUs for
approximately five days, while FFJORD is trained on 6 GPUs for five days, and Glow on 8 GPUs for
seven days. Note that all values in Tab. 1 are with respect to the continuous distribution of uniformly
dequantized images, and results of models that view images as discrete distributions are not directly
comparable (e.g., PixelCNN [20], IAF-VAE [16], and Flow++ [12]). To show that MintNet learns
semantically meaningful representations of images, we also perform latent space interpolation similar
to the interpolation experiments in Real NVP (see Appendix C).
Verification of invertibility.We first examine the performance of Algorithm 1 by measuring the
reconstruction error of MintNets. We compute the inverse of MintNet by sequentially inverting each
7

Table 1: MNIST, CIFAR-10, ImageNet 32×32 bits per dimension (bpd) results. Smaller values are
better.
†
Result not directly comparable because ZCA preprocssing was used.
MethodMNISTCIFAR-10ImageNet 32×32
NICE [5]4.364.48
†
-
MAF [22]1.894.31-
Real NVP [6]1.063.494.28
Glow [15]1.053.354.09
FFJORD [9]0.993.40-
i-ResNet [1]1.063.45-
MintNet (ours)0.983.324.06
(a) MNIST(b) CIFAR-10(c) ImageNet-32×32
Figure 3: Uncurated samples on MNIST, CIFAR-10, and ImageNet 32×32 datasets.
Mint layer with Algorithm 1. We used grid search to select the step sizeαin Algorithm 1 and chose
α= 3.5,1.1,1.15respectively for MNIST, CIFAR-10 and ImageNet 32×32.  An interesting fact
is for MNIST,α= 3.5actually works better than other values ofαwithin(0,2), even though it
does not have the theoretical gurantee of local convergence. As Fig. 4a shows, the normalizedL
2
reconstruction error converges within120iterations for all datasets considered. Additionally, Fig. 4b
demonstrates that the reconstructed images look visually indistinguishable to true images.
Samples.Using Algorithm 1, we can generate samples efficiently by computing the inverse of
MintNets. We use the same step sizes as in the reconstruction error analysis, and run Algorithm 1 for
120 iterations for all three datasets. We provide uncurated samples in Fig. 3, and more samples can
be found in Appendix F. In addition, we compare our sampling time to that of the other models (see
Tab. 6 in Appendix E). Our sampling method has comparable speed as i-ResNet. It is approximately
5 times faster than autoregressive sampling on MNIST, and is roughly 25 times faster on CIFAR-10
and ImageNet 32×32.
6    Conclusion
We propose a new method to compositionally construct invertible modules that are flexible, efficient
to invert, and with a tractable Jacobian. Starting from linear transformations with triangular matrices,
we apply a set of composition rules to recursively build new modules that are non-linear and more
expressive (Proposition 1). We then show that the composed modules are invertible as long as their
Jacobians are non-singular (Theorem 1), and propose an efficiently parallelizable numerical method
(Algorithm 1) with theoretical guarantees (Theorem 2) to compute the inverse. The Jacobians of our
modules are all triangular, which allows efficient and exact determinant computation.
As an application of this idea, we use masked convolutions as our basic module.  Using our com-
position rules, we compose multiple masked convolutions together to form a module named Mint
layer, following the architecture of a ResNet block.  To enforce its invertibility, we constrain the
masked convolutions to satisfy the condition of Theorem 1. We show that multiple Mint layers can
8

(a) Reconstruction error analysis.(b) Reconstructed images.
Figure 4: Accuracy analysis of Algorithm 1 on MNIST, CIFAR-10, and ImageNet 32×32 datasets.
Each curve in (a) represents the mean value of normalized reconstruction errors for 128 images. The
2nd, 4th and 6th rows in (b) are reconstructions, while other rows are original images.
be stacked together to form a deep invertible network which we call MintNet. Experimentally, we
show that MintNet performs well on MNIST and CIFAR-10 classification. Moreover, when trained
as a generative model, MintNet achieves new state-of-the-art performance on MNIST, CIFAR-10 and
ImageNet 32×32.
Acknowledgements
This research was supported by Intel Corporation, Amazon AWS, TRI, NSF (#1651565, #1522054,
#1733686), ONR (N00014-19-1-2145), AFOSR (FA9550- 19-1-0024).
References
[1]
J. Behrmann, D. D. Will Grathwohl, Ricky T. Q. Chen, and J.-H. Jacobsen. Invertible residual
networks.arXiv preprint arXiv:1811.00995, 2019.
[2]R. v. d. Berg, L. Hasenclever, J. M. Tomczak, and M. Welling. Sylvester normalizing flows for
variational inference.arXiv preprint arXiv:1803.05649, 2018.
[3]
T. Q. Chen, Y. Rubanova, J. Bettencourt, and D. K. Duvenaud.  Neural ordinary differential
equations.   In S. Bengio,  H. Wallach,  H. Larochelle,  K. Grauman,  N. Cesa-Bianchi,  and
R. Garnett, editors,Advances in Neural Information Processing Systems 31, pages 6571–6583.
Curran Associates, Inc., 2018.
[4]
D.-A. Clevert, T. Unterthiner, and S. Hochreiter. Fast and accurate deep network learning by
exponential linear units (elus).arXiv preprint arXiv:1511.07289, 2015.
[5]L. Dinh, D. Krueger, and Y. Bengio. NICE: non-linear independent components estimation. In
3rd International Conference on Learning Representations, ICLR 2015, San Diego, CA, USA,
May 7-9, 2015, Workshop Track Proceedings, 2015.
[6]L. Dinh, J. Sohl-Dickstein, and S. Bengio. Density estimation using real nvp.arXiv preprint
arXiv:1605.08803, 2016.
[7]A. N. Gomez, M. Ren, R. Urtasun, and R. B. Grosse. The reversible residual network: Back-
propagation without storing activations.  In I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach,
R. Fergus, S. Vishwanathan, and R. Garnett, editors,Advances in Neural Information Processing
Systems 30, pages 2214–2224. Curran Associates, Inc., 2017.
[8]A. N. Gomez, M. Ren, R. Urtasun, and R. B. Grosse. The reversible residual network: Back-
propagation without storing activations.  In I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach,
R. Fergus, S. Vishwanathan, and R. Garnett, editors,Advances in Neural Information Processing
Systems 30, pages 2214–2224. Curran Associates, Inc., 2017.
9

[9]W.  Grathwohl,  I.  S.  Ricky  T.  Q.  Chen,  Jesse  Bettencourt,  and  D.  Duvenaud.Ffjord:
Free-form continuous dynamics for scalable reversible generative models.arXiv preprint
arXiv:1810.01367, 2018.
[10]K. He,  X. Zhang,  S. Ren,  and J. Sun.   Deep residual learning for image recognition.   In
Proceedings of the IEEE conference on computer vision and pattern recognition, pages 770–
778, 2016.
[11]
K. He, X. Zhang, S. Ren, and J. Sun. Identity mappings in deep residual networks. InEuropean
conference on computer vision, pages 630–645. Springer, 2016.
[12]J. Ho, X. Chen, A. Srinivas, Y. Duan, and P. Abbeel. Flow++: Improving flow-based generative
models with variational dequantization and architecture design, 2019.
[13]J.-H. Jacobsen, J. Behrmann, R. Zemel, and M. Bethge. Excessive invariance causes adversarial
vulnerability. InInternational Conference on Learning Representations, 2019.
[14]J.-H. Jacobsen, A. W. Smeulders, and E. Oyallon.  i-revnet:  Deep invertible networks.  In
International Conference on Learning Representations, 2018.
[15]D. P. Kingma and P. Dhariwal. Glow: Generative flow with invertible 1x1 convolutions.arXiv
preprint arXiv:1807.03039, 2018.
[16]D. P. Kingma, T. Salimans, R. Jozefowicz, X. Chen, I. Sutskever, and M. Welling. Improved
variational inference with inverse autoregressive flow.   In D. D. Lee,  M. Sugiyama,  U. V.
Luxburg, I. Guyon, and R. Garnett, editors,Advances in Neural Information Processing Systems
29, pages 4743–4751. Curran Associates, Inc., 2016.
[17]D. Levy, M. D. Hoffman, and J. Sohl-Dickstein.  Generalizing hamiltonian monte carlo with
neural networks. InInternational Conference on Learning Representations, 2018.
[18]
I. Loshchilov and F. Hutter. Sgdr: Stochastic gradient descent with warm restarts.arXiv preprint
arXiv:1608.03983, 2016.
[19]
M. MacKay, P. Vicol, J. Ba, and R. B. Grosse.   Reversible recurrent neural networks.   In
S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett, editors,
Advances in Neural Information Processing Systems 31, pages 9029–9040. Curran Associates,
Inc., 2018.
[20]A. V. Oord, N. Kalchbrenner, and K. Kavukcuoglu. Pixel recurrent neural networks. In M. F.
Balcan and K. Q. Weinberger, editors,Proceedings of The 33rd International Conference on
Machine Learning, volume 48 ofProceedings of Machine Learning Research, pages 1747–1756,
New York, New York, USA, 20–22 Jun 2016. PMLR.
[21]J. M. Ortega and W. C. Rheinboldt.Iterative solution of nonlinear equations in several variables,
volume 30. Siam, 1970.
[22]G. Papamakarios, T. Pavlakou, and I. Murray. Masked autoregressive flow for density estimation.
InAdvances in Neural Information Processing Systems, pages 2338–2347, 2017.
[23]T. T. Phuong and L. T. Phong. On the convergence proof of amsgrad and a new version.arXiv
preprint arXiv:1904.03590, 2019.
[24]S. J. Reddi, S. Kale, and S. Kumar. On the convergence of adam and beyond. InInternational
Conference on Learning Representations, 2018.
[25]
D. Rezende and S. Mohamed.  Variational inference with normalizing flows.  In F. Bach and
D. Blei,  editors,Proceedings of the 32nd International Conference on Machine Learning,
volume 37 ofProceedings of Machine Learning Research, pages 1530–1538, Lille, France,
07–09 Jul 2015. PMLR.
[26]J. Song, S. Zhao, and S. Ermon.  A-nice-mc: Adversarial training for mcmc.  InAdvances in
Neural Information Processing Systems, pages 5140–5150, 2017.
10

A    Proofs
Notations.LetJ
f
(x)denote the Jacobian offevaluated atx. We use[f(x)]
i
to denote thei-th
component of the vector-valued functionf, and[J
f
(x)]
ij
to denote theij-th entry ofJ
f
(x).  We
further usex
i
to denote thei-th component of the input vectorx∈R
D
, and
∂[f(x)]
i
∂x
j
∣
∣
x=t
to denote
the partial derivative of[f(x)]
i
w.r.t.x
j
, evaluated atx=t.
Proposition 1.
DefineFas the set of all continuously differentiable functions whose Jacobian is
lower triangular. ThenFcontains the basic module in Section 3.1, and is closed under the following
composition rules.
•Rule of addition.f
1
∈F ∧f
2
∈F ⇒λf
1
+μf
2
∈F, whereλ,μ∈R.
•Rule of composition.f
1
∈F∧f
2
∈F ⇒f
2
◦f
1
∈F. A special case isf∈F ⇒h◦f∈
F, whereh(·)is a continuously differentiable non-linear activation function that is applied
element-wisely.
Proof.Since the basic modules have the formf(x) =Wx+b, whereWis a lower triangular matrix,
we immediately know thatfis continuously differentiable andJ
f
is lower triangular, thereforef∈F.
Next, we prove the closeness properties ofFone by one.
•Rule of addition.f=λf
1
+μf
2
is continuously differentiable, andJ
f
is lower triangular.
This is because
∂f
/∂x=
∂(λf
1
+μf
2
)
/∂x=λ
∂f
1
/∂x+μ
∂f
2
/∂x
, and both
∂f
1
/∂x
and
∂f
2
/∂x
are continuous and lower triangular.
•Rule of composition
.f=f
2
◦f
1
is continuously differentiable and has a lower triangular
Jacobian. This is because
∂f
/∂x=
∂(f
2
◦f
1
)
/∂x=
∂f
2
/∂x
∣
∣
x=f
1
(x)
∂f
1
/∂x, and both
∂f
2
/∂xand
∂f
1
/∂x
are continuous and lower triangular. As a special case, we choosef
1
=h, wherehis
a continuously differentiable univariate function. Since the Jacobian ofhis diagonal and
continuous, we haveh∈F. Thereforeh◦f
2
∈Fholds true for allf
2
∈F.
The following two lemmas will be very helpful for proving Theorem 1.
Lemma 1.J
f
(x)is lower triangular for allx∈R
D
implies[f(x)]
i
is a function ofx
1
,...,x
i
, and
does not depend onx
i+1
,···,x
D
.
Proof.Due to the fact thatJ
f
(x)is lower triangular, we have[J
f
(x)]
i,j
=
∂[f(x)]
i
∂x
j
= 0for any
j > i. Whenx
1
,...,x
j−1
,x
j+1
,...,x
D
are fixed, we have
[f(x
1
,...,x
j−1
,x
j
,x
j+1
,x
D
)]
i
= [f(x
1
,...,x
j−1
,0,x
j+1
,...,x
D
)]
i
+
∫
x
j
0
∂[f(t)]
i
∂t
j
dt
j
(5)
= [f(x
1
,...,x
j−1
,0,x
j+1
,...,x
D
)]
i
.(6)
This implies that[f(x)]
i
does not depend onx
j
for anyj > i. In other words,f(x)is only a function
ofx
1
,...,x
i
.
Lemma 2.diag(J
f
(x)J
f
(0))>0implies that for any1≤i≤n, either (i)∀x∈R
D
: [J
f
(x)]
ii
>
0or (ii)∀x∈R
D
: [J
f
(x)]
ii
<0.  That is,[f(x)]
i
is monotonic w.r.t.x
i
whenx
1
,···,x
i−1
are
fixed.
Proof.Clearlydiag(J
f
(x)J
f
(0))>0is equivalent to∀1≤i≤n,x∈R
D
: [J
f
(x)]
ii
[J
f
(0)]
ii
=
∂[f(x)]
i
∂x
i
∂[f(x)]
i
∂x
i
∣
∣
x=0
>0
.  This means for anyx∈R
D
,[J
f
(x)]
ii
=
∂[f(x)]
i
∂x
i
6= 0and it shares the
same sign with[J
f
(0)]
ii
=
∂[f(x)]
i
∂x
i
∣
∣
x=0
, a constant that is either strictly positive or strictly negative.
This further implies that whenx
1
,···,x
i−1
are fixed,
∂[f(x)]
i
∂x
i
is either strictly positive or strictly
negative for allx
i
∈R, and[f(x)]
i
is therefore monotonic w.r.t.x
i
.
11

Theorem 1.Iff∈FandJ
f
(x)is non-singular for allxin the domain, thenfis invertible.
Proof.
Assume  without  loss  of  generality  thatJ
f
(x)is  lower  triangular.   We  first  prove  that
diag(J
f
(x)J
f
(0))>0by contradiction.   Assumingdiag(J
f
(x)J
f
(0))≤0,  then∃1≤i≤
n,x
′
∈R
D
such that[J
f
(x
′
)]
ii
[J
f
(0)]
ii
≤0. BecauseJ
f
(x)is always triangular and non-singular,
we immediately conclude that[J
f
(x
′
)]
ii
[J
f
(0)]
ii
<0.  Assume without loss of generality that
[J
f
(0)]
ii
>0and[J
f
(x
′
)]
ii
<0. Then, by the intermediate value theorem, we know that∃t∈(0,1)
such that[J
f
(tx
′
)]
ii
= 0, which contradicts that fact thatJ
f
(x)is always non-singular.
Next, we prove that for allzin the range off(x), there exists a uniquexsuch thatf(x) =z. To
obtainx
1
, we only need to solve[f(x)]
1
=z
1
, which is an equation of variablex
1
, as concluded
from Lemma 1. Since Lemma 2 implies that[f(x)]
1
is monotonic w.r.t.x
1
, we know that[f(x)]
1
has
a unique inversex
1
wheneverz
1
is in the range of[f(x)]
1
. Now assume we have already obtained
x
1
,...,x
k
,  wherek≥1.  In this case,  Lemma 1 asserts that[f(x)]
k+1
=z
k+1
is an equation
of variablex
k+1
.  Again Lemma 2 implies that[f(x)]
k+1
is a monotonic function ofx
k+1
given
x
1
,···,x
k
, which implies further that[f(x)]
k+1
=z
k+1
has a unique solutionx
k+1
wheneverz
k+1
is in the range of[f(x)]
k+1
. By induction, we can solve forx
1
,x
2
,···,x
D
by repetitively employing
this procedure, which concludes thatf
−1
(z) = (x
1
,...,x
D
)
ᵀ
exists, and can be determined uniquely.
Theorem 2.The iterative method of Algorithm 1 is locally convergent whenever0< α <2.
Proof.Letzbe any value in the range off(x)andg(x;α,z),x−αdiag(J
f
(x))
−1
[f(x)−z],
wherediag(A)
−1
denotes a diagonal matrix whose diagonal entries are the reciprocals of those ofA.
The iterative method of Algorithm 1 can be written asx
t
=g(x
t−1
;α,z). Because of Theorem 1,
there exists a uniquex
∗
∈R
D
such thatf(x
∗
) =z, in which caseg(x
∗
;α,z) =x
∗
. Applying the
product rule, we have
J
g
(x
∗
;α,z) =I−αdiag(J
f
(x
∗
))
−1
J
f
(x
∗
),
whereJ
g
(x
∗
;α,z)denotes the Jacobian ofg(x;α,z)evaluated atx
∗
.  SinceJ
f
(x
∗
)is triangular,
J
g
(x
∗
;α,z)will also be triangular. Therefore, the only eigenvalue ofJ
g
(x
∗
;α,z)is1−α, due to
the fact that the only solution to the equation systemdet(λI−J
g
(x
∗
;α,z)) = (λ−1 +α)
D
= 0
isλ= 1−α.  Since0< α <2, the spectral radius ofJ
g
(x
∗
;α,z)satisfiesρ(J
g
(x
∗
;α,z)) =
|1−α|<1. Then the Ostrowski Theorem (cf., Theorem 10.1.3. in [21]) shows that the sequence
{x
1
,x
2
,···,x
t
}obtained byx
t
=g(x
t−1
;α,z)converges locally tox
∗
ast→∞.
B    Masked convolutions
Convolution is a special type of linear transformation that proves to be very effective for image data.
The basic invertible module can be implemented using masked convolutions (e.g., causal convolutions
in PixelCNN [20]).  Consider a 2D convolutional layer withC
in
input feature maps,C
out
filters, a
kernel size ofR×Rand a zero-padding ofb
R
/2c. We assumeRis an odd integer andC
out
=C
in
so
that the input and output of the convolutional layer have the same shape. LetW∈R
C
out
×C
in
×R×R
be the weight tensor of this layer. We define a maskM∈{0,1}
C
out
×C
in
×R×R
that satisfies
M[i,j,m,n] =
{
0,ifi < jori=j∧m >b
R
/2cori=j∧m=b
R
/2c∧n >b
R
/2c,
1,Otherwise.
(7)
The masked convolution then usesMWas the weight tensor. In Fig. 1, we provide an illustration
on a3×3masked convolution with3filters.
In MintNet,L(x)is efficiently implemented with 3 masked convolutional layers.  The weights
and masks are denoted as(W
1
,M
1
),(W
2
,M
2
)and(W
3
,M
3
), which separately correspond to
{W
1
i
}
K
i=1
,{W
2
ij
}
1≤i,j≤K
,{W
3
j
}
K
j=1
in Eq.(2).  LetCbe the number of input feature maps, and
suppose the kernel size isR×R. The shapes ofW
1
,W
2
andW
3
are respectively(KC,C,R,R),
(KC,KC,R,R)and(C,KC,R,R). The masks of them are simple concatenations of copies of the
mask in Eq.(7). For instance,M
1
consists ofKcopies of Eq.(7), andM
2
consists ofK×Kcopies.
12

Figure 5:  MintNet interpolation of hidden representation.Left:MintNet MNIST latent space
interpolation.Middle:MintNet CIFAR-10 latent space interpolation.Right:MintNet ImageNet
32×32 latent space interpolation.
Using masked convolutions,L(x)can be concisely written as
L(x) =tx+ (W
3
M
3
)~h
(
(W
2
M
2
)~h
(
(W
1
M
1
)~x+b
1
)
+b
2
)
+b
3
,(8)
whereb
1
,b
2
,b
3
are biases, and~denotes the operation of discrete 2D convolution.
C    Interpolation of hidden representations
Given four imagesx
1
,x
2
,x
3
,x
4
in the dataset, letz
i
=f(x
i
), wherei= 1,2,3,4, be the corre-
sponding features in the feature domain. Similar to [6], in the feature domain, we define
z= cos(φ)(cos(φ
′
)z
1
+ sin(φ
′
)z
2
) + sin(φ)(cos(φ
′
)z
3
+ sin(φ
′
)z
4
)(9)
wherex-axis corresponds toφ
′
,y-axis corresponds toφ, and bothφandφ
′
range over{0,
π
14
,...,
7π
14
}.
We then transformzback to the image domain by takingf
−1
(z). Interpolation results are shown in
Fig. 5.
D    Experiment setup and network architecture
Hyperparameter tuning and computation infrastructure.We use the standard train/test split of
MNIST, CelebA and CIFAR-10.  We tune our models by observing its training bpd.  For density
estimation on CIFAR-10 and ImageNet 32×32, the models were run on two Titan XP GPUs. In other
cases the model was run on one Titan XP GPU.
Classification setup.
Following [1], we pad the images to 16 channels with zeros. This corresponds
to the first convolution in ResNet which increases the number of channels to 16. Both ResNet and our
MintNet are trained with AMSGrad [24] for 200 epochs with the cosine learning rate schedule [18]
and an initial learning rate of 0.001. Both networks use a batch size of 128.
Classification architecture.
The ResNet contains 38 pre-activation residual blocks [11], and each
block has three3×3convolutions. The architecture is divided into 3 stages, with 16, 64 and 256
filters respectively.  Our MintNet uses 19 grouped invertible layers, which include a total of 38
residual invertible layers, each having three3×3convolutions. Batch normalization is applied before
each invertible layer. Note that batch normalization does not affect the invertibility of our network,
because during test time it uses fixed running average and standard deviation and is an invertible
operation. We use 2 squeezing blocks at the same position where ResNet applies subsampling, and
matches the number of filters used in ResNet. To produce the logits for classification, both MintNet
and ResNet first apply global average pooling and then use a fully connected layer (see Tab. 2).
Density estimation setup.
We mostly follow the settings in [22]. All training images are dequan-
tized and transformed using the logit transformation.  Networks are trained using AMSGrad [23].
13

On MNIST, we decay the learning rate by a factor of 10 at the 250th and 350th epoch, and train
for 400 epochs. On CIFAR-10, we train with cosine learning rate decay for a total of 200 epochs.
On ImageNet 32×32, we train with cosine learning rate decay for a total of 350k steps. All initial
learning rates are 0.001.
Density estimation architecture.
For density estimation on MNIST, we use 20 paired Mint layers
with 45 filters each. For both CIFAR-10 and ImageNet 32×32, we use 21 paired Mint layers, each of
which has 255 filters. For all the three datasets, two squeezing operations are used and are distributed
evenly across the network (see Tab. 3 and Tab. 4).
Tuning the step size for sampling.We perform grid search to find hyperparamterαfor Algorithm 1
using a minibatch of 128 images. More specifically, we start fromα= 1to 5 with a step size 0.5
for MNIST, CIFAR-10, and ImageNet 32×32, and compute the normalizedL
2
reconstruction error
with respect to the number of iterations. The normalizedL
2
error is defined as‖x−y‖
2
2
/D, where
x∈R
D
andy∈R
D
are two image vectors corresponding to the original and reconstructed images.
We find that the algorithm converges most quickly whenαis in intervals[3,4],[1,2]and[1,2]for
MNIST, CIFAR-10 and ImageNet 32×32 respectively. Then we perform a second round grid search
on the corresponding interval with a step size 0.05. In this case, we are able to find the bestα, that is
α= 3.5,1.1,1.15for the corresponding datasets.
Verification of invertibility.To verify the invertibility of MintNet, we study the normalizedL
2
reconstruction error for MNIST, CIFAR-10 and ImageNet 32×32. TheL
2
reconstruction error is
computed for 128 images on all three datasets. We plot the exponential of the mean log reconstruction
errors in Fig. 4.  The shaded area corresponds to the exponential of the standard deviation of log
reconstruction errors.
14

Table 2: MintNet image classification network architecture.
NameConfigurationReplicate Block
Paired Mint Block1
with Batch Normalization
batch normalization
3×3lower triangular masked convolution, 1 filter
×6
leaky relu activation
3×3lower triangular masked convolution,1filter
leaky relu activation
3×3lower triangular masked convolution,1filter
batch normalization
3×3upper triangular masked convolution,1filter
leaky relu activation
3×3upper triangular masked convolution,1filter
leaky relu activation
3×3upper triangular masked convolution,1filter
Squeezing Layer2×2squeezing layer—
Paired Mint Block2
with Batch Normalization
batch normalization
3×3lower triangular masked convolution, 1 filter
×6
leaky relu activation
3×3lower triangular masked convolution,1filter
leaky relu activation
3×3lower triangular masked convolution,1filter
batch normalization
3×3upper triangular masked convolution,1filter
leaky relu activation
3×3upper triangular masked convolution,1filter
leaky relu activation
3×3upper triangular masked convolution,1filter
Squeezing Layer2×2squeezing layer—
Paired Mint Block3
with Batch Normalization
batch normalization
3×3lower triangular masked convolution, 1 filter
×7
leaky relu activation
3×3lower triangular masked convolution,1filter
leaky relu activation
3×3lower triangular masked convolution,1filter
batch normalization
3×3upper triangular masked convolution,1filter
leaky relu activation
3×3upper triangular masked convolution,1filter
leaky relu activation
3×3upper triangular masked convolution,1filter
Output Layer
average pooling
—
fully connected layer
softmax layer
15

Table 3: MintNet MNIST density estimation network architecture.
NameConfigurationReplicate Block
Paired Mint Block1
3×3lower triangular masked convolution, 45 filters
×6
elu activation
3×3lower triangular masked convolution,45filters
elu activation
3×3lower triangular masked convolution,45filters
3×3upper triangular masked convolution,45filters
elu activation
3×3upper triangular masked convolution,45filters
elu activation
3×3upper triangular masked convolution,45filters
Squeezing Layer2×2squeezing layer—
Paired Mint Block2
3×3lower triangular masked convolution, 45 filters
×6
elu activation
3×3lower triangular masked convolution,45filters
elu activation
3×3lower triangular masked convolution,45filters
3×3upper triangular masked convolution,45filters
elu activation
3×3upper triangular masked convolution,45filters
elu activation
3×3upper triangular masked convolution,45filters
Squeezing Layer2×2squeezing layer—
Paired Mint Block3
3×3lower triangular masked convolution, 45 filters
×8
elu activation
3×3lower triangular masked convolution,45filters
elu activation
3×3lower triangular masked convolution,45filters
3×3upper triangular masked convolution,45filters
elu activation
3×3upper triangular masked convolution,45filters
elu activation
3×3upper triangular masked convolution,45filters
16

Table 4: MintNet CIFAR-10 and Imagenet 32×32 density estimation network architecture.
NameConfigurationReplicate Block
Paired Mint Block1
3×3lower triangular masked convolution, 85 filters
×7
elu activation
3×3lower triangular masked convolution,85filters
elu activation
3×3lower triangular masked convolution,85filters
3×3upper triangular masked convolution,85filters
elu activation
3×3upper triangular masked convolution,85filters
elu activation
3×3upper triangular masked convolution,85filters
Squeezing Layer2×2squeezing layer—
Paired Mint Block2
3×3lower triangular masked convolution, 85 filters
×7
elu activation
3×3lower triangular masked convolution,85filters
elu activation
3×3lower triangular masked convolution,85filters
3×3upper triangular masked convolution,85filters
elu activation
3×3upper triangular masked convolution,85filters
elu activation
3×3upper triangular masked convolution,85filters
Squeezing Layer2×2squeezing layer—
Paired Mint Block3
3×3lower triangular masked convolution, 85 filters
×7
elu activation
3×3lower triangular masked convolution,85filters
elu activation
3×3lower triangular masked convolution,85filters
3×3upper triangular masked convolution,85filters
elu activation
3×3upper triangular masked convolution,85filters
elu activation
3×3upper triangular masked convolution,85filters
17

E    Additional tables
Table 5: Comparison to some common invertible models.
PropertyNICEReal-NVPGlowFFJORDi-ResNetMintNet
Analytic Forward333733
Analytic Inverse337777
Non-volume Preserving733333
Exact Likelihood333773
Table 6: Sampling time for 64 samples for MintNet, i-ResNet and autoregressive method on the same
model architectures. The time is evaluated on a NVIDIA TITAN Xp.
MethodMNISTCIFAR-10ImageNet 32×32
i-ResNet [1] (100 iterations)11.56s99.41s92.53s
Autoregressive (1 iteration)63.61s2889.64s2860.21s
MintNet (120 iterations) (ours)12.81s117.83s120.78s
18

F    More Samples
In this section, we provide more uncurated MintNet samples on MNIST, CIFAR-10 and ImageNet
32×32.
Figure 6: MintNet MNIST samples.
19

Figure 7: MintNet CIFAR-10 samples.
Figure 8: MintNet ImageNet 32×32 samples.
20 

On the Evaluation of Conditional GANs
Terrance DeVries
∗
University of Guelph
Vector Institute
terrance@uoguelph.ca
Adriana Romero
Facebook AI Research
adrianars@fb.com
Luis Pineda
Facebook AI Research
lep@fb.com
Graham W. Taylor
University of Guelph
Vector Institute
Canada CIFAR AI Chair
gwtaylor@uoguelph.ca
Michal Drozdal
Facebook AI Research
mdrozdzal@fb.com
Abstract
Conditional Generative Adversarial Networks (cGANs) are finding increasingly
widespread use in many application domains. Despite outstanding progress, quan-
titative evaluation of such models often involves multiple distinct metrics to assess
different desirable properties such as image quality, intra-conditioning diversity,
and conditional consistency, making model benchmarking challenging.  In this
paper, we propose the Fréchet Joint Distance (FJD), which implicitly captures
the above mentioned properties in asingle metric. FJD is defined as the Fréchet
Distance of thejoint distributionof images and conditionings, making it less sensi-
tive to the often limited per-conditioning sample size. As a result, it scales more
gracefully to stronger forms of conditioning such as pixel-wise or multi-modal
conditioning. We evaluate FJD on a modified version of the dSprite dataset as well
as on the large scale COCO-Stuff dataset, and consistently highlight its benefits
when compared to currently established metrics. Moreover, we use the newly intro-
duced metric to compare existing cGAN-based models, with varying conditioning
strengths, and show that FJD can be used as a promisingsinglemetric for model
benchmarking.
1  Introduction
Generative models are finding progressive widespread use in many domains [6,19,46,35,44].
Among the most promising approaches, Variational Auto-Encoders (VAEs) [20], auto-regressive
models [43,42] and Generative Adversarial Networks (GANs) [9] have been driving significant
progress, with the latter at the forefront of a wide-range of applications [24,52,32,46,1,38,34]. In
particular, significant research has emerged from practical applications, which require the generation
to be conditioned on prior information. For example, tasks such as image inpainting, super-resolution
or text-to-image synthesis have been successfully addressed within the framework ofconditional
generation, with conditional GANs (cGANs) among the most competitive approaches. Despite these
outstanding advances, quantitative evaluation of GANs remains a challenge [41, 5].
In the last few years, a significant number of evaluation metrics for GANs have been introduced in the
literature [30,50,16,12,2,33,11,55,49,37,18]. Although there is no clear consensus on which
quantitative metric is most appropriate to benchmark GAN-based models, the Inception Score (IS)
[33] and Fréchet Inception Distance (FID) [12] have been extensively used. However, both IS and
∗
Work done during internship with Facebook AI Research.
Preprint. Under review.
arXiv:1907.08175v1  [cs.CV]  11 Jul 2019

FID were introduced in the context ofunconditionalgeneration and, hence, focus on capturing certain
desirable properties such asvisual qualityandsample diversity, which do not fully encapsulate all
the different phenomena that arise during conditional image generation.
In particular, inconditionalgeneration, we care aboutvisual quality,intra-conditioning diversity–
i.e. sample diversity per conditioning, andconditional consistency– i.e. verifying that the generation
respects its conditioning.  Although visual quality is captured by both metrics, IS is agnostic to
intra-conditioning diversity and FID only captures it indirectly.
2
Moreover, neither of them is able to
capture conditional consistency. In order to overcome this shortcoming, researchers have resorted
to reporting conditional consistency metrics in conjunction with FID [54,29]. Consistency metrics
often use some form of concept detector to ensure that the requested conditioning appears in the
generated image as expected. Although intuitive to use, these metrics require pre-trained models that
cover the same target concepts in the same format as the conditioning (i.e. classifiers for image-level
class conditioning, object detectors for bounding box conditioning, semantic segmentation for mask
conditioning), which may or may not be available off-the-shelf. Moreover, using different metrics to
evaluate different desirable properties may hinder the process of model selection, as there might not
be a single model that surpasses the rest in all measures. Alternatively, researchers have proposed
to calculate FID per conditioning [26], which should in principle capture all desirable properties.
However,  it is worth noting that FID is strongly affected by the number of samples [4] and in
conditional generation,only a few samplesare usually available per conditioning (e.g. in the case of
mask conditioning, we only have a single sample per unique conditioning).
In this paper we introduce a new metric called Fréchet Joint Distance (FJD), which is able to
implicitly assess image quality,  intra-conditioning diversity,  and conditional consistency,  while
scaling gracefully to scenarios where each unique conditioning has a limited number of samples. FJD
computes the Fréchet Distance (FD) on an embedding of the joint image-conditioning distribution
and, thus, inherently has access to a larger sample size, while introducing only small computational
overhead over FID. We evaluate the properties of FJD on a variant of the synthetic dSprite dataset
[23] as well as the large scale COCO-Stuff dataset [7]. We provide an analysis on the behavior of
both FID and FJD under different types of conditioning and evaluate existing cGAN models with the
newly introduced metric. Our experiments show that (1) FJD captures the three highlighted properties
of conditional generation; (2) it can be applied to any kind of conditioning (e.g. class, bounding box
or mask conditioning); and (3) when applied to existing cGAN-based models, FJD demonstrates its
potential to be used as a promisingunifiedmetric for cGAN benchmarking.
2  Related Work
Conditional GANs have witnessed outstanding progress in recent years. Significant effort has been
devoted to improving training strategies and enhancing architecture designs. Training stability has
been improved through the introduction of techniques such as spectral normalization [25] and the
two time-scale update rule [12]. Architecturally, conditional generation has been improved through
the use of auxiliary classifiers [27] and the introduction of a projection-based conditioning for the
discriminator [26]. Image quality has also benefited from the incorporation of self-attention [52], as
well as increases in model capacity and batch size [6].
All of this progress has led to impressive results, paving the road towards the challenging generation
of more complex scenes. To this end, new forms of conditioning have been explored in the literature.
A flurry of works have tackled the problem of image-to-image translation, either from a deterministic
perspective [16,57,47], or from that of conditional generation [58,1,15,22,29], to account for
the multimodal nature of the problem. Image-to-image conditional generation has also been framed
as a mask-to-image or bounding box-to-image task [14,13,29,54].  The vast majority of these
methods are compared in terms ofqualitative assessment(e.g. user preference studies),visual
qualitymetrics such as IS or FID as well asconditional consistencymetrics such as objection
detection/segmentation mean Intersection over Union (mIoU), per pixel-accuracy or, in the case
of  style  transfer  applications,  image  similarity  metrics  such  as  Mean  Squared  Error  (MSE)  or
Structural Similarity (SSIM). Additionally, diversity of the models is often evaluated by way of the
2
FID compares image distributions and, as such, should be able to roughly capture the intra-conditioning
diversity. Since it cares about image marginal distribution exclusively, it would fail to capture intra-conditioning
diversity when changes only affect the image-conditioning joint distribution. See supplementary material.
2

Learned Perceptual Image Patch Similarity (LPIPS) [53]. Text-conditioned image generation has also
been enjoying increasing attention [32,51,52,40,14,17]. These methods follow image-to-image
evaluation in the use of IS and FID to estimate visual quality, and also apply pre-trained image
captioning models paired with text-based metrics such as BLEU [28], METEOR [3] or CIDEr [45]
to measure conditional consistency. More recently, dialogue-conditioned image generation has also
been introduced [8,36]. In these cases, metrics evaluating object location and relational similarity
are included to assess conditional consistency.
One major limitation of commonly used conditional consistency and diversity metrics is that they
require having access to pre-trained models for each given task (e.g. a classification model to test class
consistency). As an alternative, Intra-FID [26] has been proposed in the context of class-conditioned
image generation. Intra-FID calculates an FID score separately for each conditioning and reports the
average score over all conditionings. This method captures intra-class variability without requiring a
dedicated pre-trained model for the dataset. However, it scales poorly with the number of unique
conditions, as the computationally intensive FID calculation must be repeated for each case, and
because FID behaves poorly when the sample size is small [4].  Furthermore, in cases where the
conditioning cannot be broken down into a set of discrete classes (e.g. pixel-based conditioning),
Intra-FID is intractable. As a result, it has not been applied beyond class-conditioning.
Beyond IS and FID, a number of GAN evaluation metrics have emerged in the literature. Most of these
metrics either focus on the separability between generated images and real images [21,30,50,16],
compute the distance between distributions [10,12,2], assess sample quality and diversity from
conditional or marginal distributions [33,11,55], measure the similarity between generated and real
images [49,48,37,18] or are log-likelihood based [41]. Despite this progress, there is still no clear
consensus on which metrics are most appropriate to use, and the vast majority of available metrics
are only concerned with unconditional generation. We refer the reader to [5] for a detailed overview
and insightful discussion of existing metrics.
3  Review of Fréchet Inception Distance (FID)
FID aims to compare the statistics of generated samples to samples from a real dataset. Given two
multivariate Gaussian distributionsN(μ,Σ)andN(ˆμ,
ˆ
Σ), Fréchet Distance (FD) is defined as:
d
2
(
(μ,Σ),(ˆμ,
ˆ
Σ)
)
=||μ−ˆμ||
2
2
+Tr
(
Σ+
ˆ
Σ−2(Σ
ˆ
Σ)
1/2
)
.(1)
When evaluating a generative model,N(μ,Σ)represents the data (reference) distribution, obtained by
fitting a Gaussian to images from a reference dataset andN(ˆμ,
ˆ
Σ)represents the learned (generated)
distribution, a result of fitting to samples from a generative model.
In FID, both the real images and model samples are embedded in a learned feature space using a
pre-trained Inception v3 model [39]. Thus, the Gaussian distributions are defined in the embedded
space. More precisely, given a dataset of images{x
(i)
}
N
i=0
, a set of model samples{ˆx
(i)
}
M
i=0
and an
Inception embedding functionf, we estimate the Gaussian parametersμ,Σ,ˆμand
ˆ
Σas:
μ=
1
N
N
∑
i=0
f(x
(i)
),Σ=
1
N−1
N
∑
i=0
(
f(x
(i)
)−μ
)(
f(x
(i)
)−μ
)
T
,(2)
ˆμ=
1
M
M
∑
i=0
f(ˆx
(i)
),
ˆ
Σ=
1
M−1
M
∑
i=0
(
f(ˆx
(i)
)−ˆμ
)(
f(ˆx
(i)
)−ˆμ
)
T
.(3)
4  Fréchet Joint Distance (FJD)
In conditional image generation, a dataset is composed of image-conditioning pairs{(x
(i)
,y
(i)
)}
N
i=0
,
where the conditioning can take variable forms, such as image-level classes, bounding box annotations
or segmentation masks.  The goal of conditional image generation is to produce realistic looking,
diverse imagesˆxthat areconsistentwith the conditioningˆy.  Thus, a set of model samples with
corresponding conditioning can be defined as:{(ˆx
(i)
,ˆy
(i)
)}
M
i=0
.
3

As discussed in Section 3, the Fréchet distance compares any two Gaussians defined over arbitrary
spaces. In FJD, we propose to compute the FD between two Gaussians defined over thejoint image-
conditioning embedding space. More precisely, given an image Inception embedding functionf, a
conditioning embedding functionhand a merging functiongthat combines the image embedding
with the conditioning embedding into a joint one, we can estimate the respective Gaussian parameters
μ,Σ,ˆμand
ˆ
Σas:
μ=
1
N
N
∑
i=0
g
(
f(x
(i)
),h(y
(i)
)
)
,ˆμ=
1
M
M
∑
i=0
g
(
f(ˆx
(i)
),h(ˆy
(i)
)
)
,(4)
Σ=
1
N−1
N
∑
i=0
(
g
(
f(x
(i)
),h(y
(i)
)
)
−μ
)(
g
(
f(x
(i)
),h(y
(i)
)
)
−μ
)
T
,(5)
ˆ
Σ=
1
M−1
M
∑
i=0
(
g
(
f(ˆx
(i)
),h(ˆy
(i)
)
)
−ˆμ
)(
g
(
f(ˆx
(i)
),h(ˆy
(i)
)
)
−ˆμ
)
T
.(6)
Note  that  by  computing  the  FD  over  the  joint  image-conditioning  distribution,  we  are  able  to
simultaneously assess image quality, conditional consistency, and intra-conditioning diversity, all of
which are important factors in evaluating the quality of conditional image generation models.
FJD uses the same image embedding function as the FID score, namely a pre-trained Inception v3
model [39]. The choice ofhandgare discussed in the remainder of this section.
Conditioning embedding function:h.
The purpose of the embedding functionhis to reduce the
dimensionality and extract a useful feature representation of the conditioning. As such, the choice
ofhwill vary depending on the type of conditioning. As the majority of the conditioning used in
our experiments contains spatial information, we use a pre-trained Inception v3 model
3
to embed all
class, bounding box, and mask conditioning into a single unified space for our experiments. Class
labels are tiled spatially so that they have the same height and width as the images.
To match the required dimensionality of the image embedding with that of the conditioning, we
apply a fixed linear random projectionrto the conditioning tensory∈R
H,W,C
, whereH,Wand
Crepresent tensor height, width and number of channels, respectively.  As a result, we obtain an
embedded conditioning matching the dimensionality of the image spacer(y)∈R
H,W,3
. An example
of the conditioning after random projection can be found in Figure 1.  After projection, we feed
r(y)through an Inception v3 network to extract a 2048-dimensional embeddingf(r(y))from the
final pooling layer. Finally, we multiply the conditioning embedding by a scaling factorα, whereα
allows us to control for the relative importance offversush. Note that if the magnitude of the image
embedding is much greater than that of the conditioning embedding, then a generative model that
produces good quality images without regard for the conditioning may score the same as a model that
does properly respect conditioning, reducing the effectiveness of the metric.
We do not scale the image embedding so that it can act as a reference magnitude comparable with
FID. As a recommendation we suggest settingαto be equal to the ratio between the averageL
2
norm of the image embedding and the conditioning embedding. We note thatαshould be calculated
on data from the reference distribution (real data distribution), and then applied to all conditioning
embeddings thereafter. Thus,h(y) =αf(r(y)).
Merging function:g.
We consider and evaluate four different merging strategies: (1) concatenation
g(f(x),h(y)) = [f(x),h(y)], where[  ]represents the vector concatenation operation; (2) summa-
tiong(f(x),h(y)) =f(x) +h(y); (3) element-wise multiplicationg(f(x),h(y)) =f(x)h(y);
and (4) random projectiong(f(x),h(y)) =r
′
([f(x),h(y)]), wherer
′
is a linear random projection.
Although all discussed merging strategies are suitable to represent joint image-conditioning embed-
dings, we recommend using concatenation due to it providing the best correlation with conditional
consistency in our experiments.  We refer the reader to the supplementary material for a detailed
ablation study.
3
We use the PyTorch pre-trained Inception v3 in our experiments.
4

5  Evaluation of Fréchet Joint Distance
In this section, we start by introducing the datasets used in our analysis. we then demonstrate that
FJD captures the three desiderata of conditional image generation, namely image quality, conditional
consistency and intra-conditioning diversity.
5.1  Datasets
Figure 1: Image, class, bounding box, and mask samples: dSprite-textures (left), COCO-Stuff (right).
dSprite-textures.The dSprite dataset [23] is a synthetic dataset where each image depicts a simple
2D shape on a black background. Each image can be fully described by a set of factors, including
shape, scale, rotation,xposition, andyposition. We augment the dSprite dataset to createdSprite-
texturesby adding seven texture patterns for each sample.  Additionally, we include class labels
indicating shape, as well as bounding boxes and mask labels for each sample (see Figure 1 (left)).
In total, the dataset contains 5,160,960 unique images. This synthetic dataset allows us to exactly
control our sample distribution and, thereby, simulate a generator with desired image-conditioning
inconsistencies.
COCO-Stuff.The COCO-Stuff dataset [7] consists of 164,000 natural images with pixel-level
annotations, including 80 “thing” classes and 91 “stuff” classes.  Following [17], we select only
images containing between 3 and 8 objects, and also ignore any objects that occupy less than 2%
of the total image area. After filtering the dataset we are left with 74,121 training images and 3,074
validation images. Similar to our dSprite-textures dataset, COCO-Stuff provides image-level class
labels, as well as bounding boxes and mask annotations. Examples of images together with available
annotations are depicted on Figure 1 (right).
5.2  Image Quality
0.000.050.100.150.200.25
Image Noise Level
0
25
50
75
100
125
150
175
Distance
Dsprite
0.000.050.100.150.200.25
Image Noise Level
0
25
50
75
100
125
150
175
Distance
COCO
FID
FJD, label
FJD, bbox
FJD, mask
Figure 2:Image quality:Comparison between FID
and FJD for class, bounding box, and mask condition-
ing under varying noise levels added to images.
In this subsection, we aim to test the sensi-
tivity of FJD to image quality perturbations.
To do so, we use either a random draw of
10k dSprite-textures samples, or the entire
COCO-Stuff  training  set.   By  duplicating
each set of samples,  we build areference
dataset and agenerateddataset.  Then, we
simulate a generative model that produces
low quality images by adding Gaussian noise
drawn fromN(0,σ)to the generated dataset
images and then clipping to the data range,
whereσ∈[0,0.25]and  pixel  values  are
normalized to the range[0,1].  We repeat
this experiment for both dSprite-textures and
COCO-Stuff datasets and all three types of
conditioning: class, bounding box, and mask.
Results are shown in Figure 2, where we plot both FID and FJD scores as a function of the added
Gaussian noise (σis indicated on thex-axis as Image Noise Level). We find that, in all cases, FJD
tracks FID very closely, indicating that it successfully captures image quality. Interestingly, we note
that FJD increases slightly compared to FID as image quality decreases, likely due to a decrease in
perceived conditional consistency.
5

0.00.51.01.52.02.53.0
Offset
0
1
2
3
4
5
6
7
Distance
Scale
050100150
Offset
0
1
2
3
4
5
6
7
Distance
Orientation
051015
Offset
0
1
2
3
4
5
6
7
Distance
X Position
051015
Offset
0
1
2
3
4
5
6
7
Distance
Y Position
FJD, class
FJD, bbox
FJD, mask
FID, image
Figure 3:Conditional consistency:Change in FJD with respect to offset on Dsprite-textures dataset
for class, bounding box and mask conditionings.
5.3  Conditional Consistency
In this subsection, we aim to highlight the sensitivity of FJD to conditional consistency. In particular,
we target specific types of inconsistencies, such as incorrect scale, orientation, or position. For these
experiments, we use only the dSprite-textures dataset, where we can control the degree to which
conditional consistency is violated.  We draw two sets of10k samples from the dSprite-textures
dataset: one to represent a reference dataset, and another to represent a generated dataset. For30%
of the generated dataset samples we swap conditionings of pairs of samples that are identical in all
but one of the attributes (scale, orientation,xposition oryposition). For example, if one generated
sample has attributexposition 4 and a second generated sample has attributexposition 7, swapping
their conditionings leads to generated samples that are offset by 3 pixels w.r.t. their ground truth
xposition.  Swapping conditionings in the this manner allows us to control for specific attributes’
conditional consistency, while keeping the image and conditioning marginal distributions unchanged.
As a result, all changes in FJD can be attributed solely to conditional inconsistencies.
Figure 3 depicts the results of this experiment for four different types of alterations: scale, orientation,
andxandypositions.  We observe that the FID between image distributions (blue dashed line)
remains constant even as the conditional inconsistencies increase.  For class conditioning (solid
orange line), FJD remains constant, as changes to scale, orientation, and position are independent of
the object class. Bounding box and mask conditionings, as they contain spatial information, produce
variations in FJD that are proportional to the offset.  Interestingly, for the orientation offsets, FJD
with mask conditioning fluctuates rather than increasing monotonically.  This behaviour is due to
the orientation-masks partially re-aligning around90
◦
and180
◦
. Each of these cases emphasize the
effective sensitivity of FJD w.r.t. conditional consistency.
5.4  Intra-conditioning Diversity
In this subsection,  we aim to test the sensitivity of FJD to intra-conditioning diversity.   To do
so, we experiment with the dSprite-textures dataset, as it allows us to simulate intra-conditioning
diversity.
4
We create our reference dataset by randomly drawing10k samples using only three
textures. Subsequently, we create less diverse generated datasets by duplicating the reference dataset
and then reducing the texture variability by increasing the proportion of points that are assigned to an
unique texture type. Moreover, we associate the choice of unique textures with different subsets of
the dataset, partitioned by attributes (shapes, scale, orientation, position); this allows us to study the
effect of conditioning type on the metric’s sensitivity to changes in diversity. Finally, we make these
modifications in such a way that the marginal distribution of textures over the entire dataset is still
roughly uniform.
The results of these experiments are shown in Figure 4, which plots the increase in FID and FJD,
for different types of conditioning, as the diversity of textures decreases. Here, diversity of 1 means
that all combinations of textures/attributes are possible, while diversity of 0 means that each texture
is associated to an unique subset of attribute values.  Not surprisingly, since a change in the joint
distribution of attributes and textures also implies a change to the image marginal distribution, we
observe that FID increases with reduced diversity. However, the increase in FJD is larger than the
increase in FID, suggesting that FJD is more sensitive to changes in intra-conditioning diversity
4
Note that for real datasets, intra-conditioning diversity is most often reduced as the strength of conditioning
increases (e.g. mask conditionings usually present a single image instantiation, presenting no diversity).
6

0.00.20.40.60.81.0
Intra-conditioning Diversity
0
5
10
15
20
25
30
35
Distance
Shape
0.00.20.40.60.81.0
Intra-conditioning Diversity
0.0
2.5
5.0
7.5
10.0
12.5
15.0
17.5
Distance
Scale
0.00.20.40.60.81.0
Intra-conditioning Diversity
0
1
2
3
4
5
Distance
Orientation
0.00.20.40.60.81.0
Intra-conditioning Diversity
0.0
0.5
1.0
1.5
2.0
2.5
3.0
3.5
4.0
Distance
X Position
FJD, class
FJD, bbox
FJD, mask
FID, image
Figure 4:Intra-conditioning diversity:FJD and FID as intra-conditioning diversity decreases.
Table 1: FJD / FID results averaged over 5 runs on COCO-stuff validation set with class, bounding
box (bbox) and mask conditionings for image resolutions64×64and128×128.
class conditioningbbox conditioningmask conditioning
FJD↓FID↓FJD↓FID↓FJD↓FID↓
6431.7±0.2   30.5±0.2   43.2±0.7   30.8±0.7   52.8±1.1   28.0±1.0
12842.7±1.8   41.6±1.8   54.5±1.1   43.1±1.1   62.1±1.3   37.7±1.2
than FID. It is interesting to note that FJD only increases over FID when the conditioning contains
information related to the attribute that is losing internal diversity.  For example, as the textural
diversity within the shape attribute is reduced, FJD with all conditioning types increases over FID,
as they all contain class information about the shape. However, in cases when such information is
not present in the conditioning, such as in the case of scale, orientation, or position, FJD of class
conditioning is similar in magnitude to FID.
6  An analysis of conditioning strengths
Table 2: Comparison of class-conditioned models
on ImageNet validation set (resolution128×128).
FJD↓FID↓Acc.↑
SN-GAN (concat)[25]38.3    37.3    18.1
SN-GAN (proj)[25]26.1    25.5    35.5
BigGAN[6]10.2    9.9    62.3
In this section, we aim to analyze how differ-
ent conditioning strengths (class, bounding box,
and mask) may influence image quality. To this
end, we train three generative models, one for
each conditioning type, on COCO-Stuff.  Two
image resolutions are considered:64×64and
128×128.  We adopt a BigGAN-style model
[6],  but modify the design such that a single
fixed architecture can be trained with any of
the three conditioning types. We do not fix the
architecture across image resolutions: the 128
architecture has more capacity than the 64 one. Architecture details are provided in the supplementary
material. We train each model 5 times, with different random seeds, and report mean and standard
deviation of both FID and FJD in Table 1. As shown in the table, as we increase the conditioning
strength (from class conditioning to mask conditioning), we notice a substantial increase in FJD
score.  We argue this is due to the information content present in each conditioning type.  On the
one hand, stronger conditionings (masks) present more information content, which in turn is easier
to violate.  On the other hand, weaker conditionings capture less information content and, hence,
become easier to satisfy.  When it comes to FID, we observe that the model with the strongest
conditioning (mask-conditioned model) achieves the best results (lowest FID). We argue that stronger
conditionings limit the degrees of freedom of the generation, and hence should be able to provide
more plausible-looking images. Samples of conditional generations from all models are available in
the supplementary material.
7  Comparison of existing conditional generation models
In this section, we seek to evaluate existing cGAN-based models in terms of FJD, and to contrast
these results to the ones provided by FID and standard conditional consistency metrics. In particular,
we focus on testing class-conditioned and image-conditioned image generation as they deal with
different conditioning strength and have been the focus of numerous works.
7

Table 3: Comparison of image-conditioned models. Results averaged over 50 runs (validation).
DatasetFacadesMaps
FJD↓FID↓SSIM↑FJD↓FID↓SSIM↑
Pix2pix[16]171.2±0.0115.7±0.023.0±6.7352.6±0.0230.4±0.014.8±8.3
BicycleGAN[58]152.2±2.3    93.8±2.220.6±6.8275.4±1.0152.7±1.014.8±7.2
MSGAN[22]154.3±2.397.5±2.317.7±6.6273.4±2.0    152.0±2.010.9±7.5
Edges2ShoesEdges2Handbags
Pix2pix[16]164.9±0.0121.9±0.064.3±14.0148.6±0.082.7±0.061.4±13.7
BicycleGAN[58]88.2±1.247.6±1.169.1±9.8    142.6±1.376.6±1.258.6±13.9
MUNIT[15]97.1±1.355.5±1.367.7±10.0147.8±1.479.5±1.354.2±13.9
Class-conditioned cGANs.Table 2 presents FJD, FID, and classification accuracy results for three
state-of-the-art class-conditioned models trained on ImageNet
5
.   Accuracy is computed as the
Inception v3 accuracy of each model’s generated samples, using their conditioning as classification
ground truth, and is presented as conditional consistency metric. Results are reported for an image
resolution of128×128on the validation set. We find that FJD follows the same trend as FID for
class-conditioned models, preserving their ranking and highlighting the FJD’s ability to capture image
quality. However, it is worth noting that all models exhibit a slightly higher FJD as compared to FID,
emphasizing each model’s potential conditional inconsistencies. When comparing FJD to accuracy,
we observe that FJD is also coherent with the conditional consistency metric (higher FJD values
correlate with lower accuracies), confirming its ability to properly assess conditional consistency.
Overall, BigGAN seems to demonstrate the best trade-off between image quality and conditional
consistency, followed by SN-GAN (projection), while SN-GAN (concatenation) exhibits the weakest
performance among compared models.
Image-conditioned cGANs.Table 3 provides the FJD, FID, and SSIM scores for state-of-the-art
models on four different image-to-image datasets:  Facades [31],  Maps [16],  Edges2Shoes and
Edges2Handbag [56].
6
We consider the validation set associated with each of the datasets and obtain
one sample per conditioning for each model. We repeat this experiment50times and report the mean
and standard deviation for the three metrics.  This experiment highlights the difficulty of ranking
models when using two independent metrics for image quality and conditional consistency. In all
datasets except Edges2Shoes, ranking the models in terms of average FID leads to a different outcome
than ranking them based on their average SSIM. Although FJD follows a similar ranking to FID,
we have seen in Section 5 that the metric is sensitive to image quality, conditional inconsistencies
and intra-conditioning diversity, simultaneously. When considering Facades and Edges2Handbags
datasets, we observe that pix2pix achieves better conditional consistency as measured by SSIM.
However, its FJD is higher than that of BicycleGAN, suggesting that it may be penalized for lower
image quality or lack of intra-conditioning diversity. Similarly, in the Maps dataset, MSGAN shows
better average FID, whereas BicyleGAN achieves better conditional consistency. When it comes to
comparing their FJD values, we note that, on average, MSGAN is better (although not significantly).
8  Conclusions
In this paper we introduce Fréchet Joint Distance (FJD), which is able to assess image quality,
conditional consistency, and intra-contioning diversity within a single metric. We compared FJD to
FID on the synthetic dSprite-textures dataset and on the large-scale COCO-Stuff dataset, validating
its ability to capture the three properties of interest across different types of conditioning,  and
highlighting its potential to be adopted as unified cGAN benchmarking metric.
Looking forward, FJD could serve as valuable metric to ground future research, as it has the potential
to help elucidate the most promising contributions within the scope of conditional generation.  A
possible future direction would be to adapt the metric to other types of conditioning such as text,
5
Pre-trained models:  BigGAN fromhttps://github.com/ajbrock/BigGAN-PyTorchand SN-GAN
https://github.com/pfnet-research/sngan_projection
6
Pre-trained models: pix2pix fromhttps://github.com/junyanz/pytorch-CycleGAN-and-pix2pix,
BicyleGAN  fromhttps://github.com/junyanz/BicycleGAN,  MSGAN  fromhttps://github.com/
HelenMao/MSGAN/and MUNIT fromhttps://github.com/nvlabs/MUNIT.
8

graphs or dialogue.  Finally, with this metric, we have reinforced a known limitation of current
datasets, namely that in the case of strong conditionings, datasets only contain a single instantiation
per conditioning that we hope to see addressed in the near future.
AcknowledgementsThe authors would like to thank Nicolas Ballas, Lluis Castrejon, Mohamed
Ishmael Belghazi, Nissan Pow, Mido Assran, Anton Bakhtin, and Vinakayk Tantia for useful and
entertaining discussions.
References
[1]
Amjad Almahairi, Sai Rajeshwar, Alessandro Sordoni, Philip Bachman, and Aaron Courville. Augmented
CycleGAN: Learning many-to-many mappings from unpaired data. In Jennifer Dy and Andreas Krause,
editors,Proceedings of the 35th International Conference on Machine Learning, volume 80 ofProceedings
of Machine Learning Research, pages 195–204, Stockholmsmässan, Stockholm Sweden, 10–15 Jul 2018.
PMLR.
[2]Martin Arjovsky,  Soumith Chintala,  and Léon Bottou.   Wasserstein generative adversarial networks.
In  Doina  Precup  and  Yee  Whye  Teh,  editors,Proceedings  of  the  34th  International  Conference  on
Machine Learning, volume 70 ofProceedings of Machine Learning Research, pages 214–223, International
Convention Centre, Sydney, Australia, 06–11 Aug 2017. PMLR.
[3]Satanjeev Banerjee and Alon Lavie.   Meteor:  An automatic metric for mt evaluation with improved
correlation with human judgments. InProceedings of the acl workshop on intrinsic and extrinsic evaluation
measures for machine translation and/or summarization, pages 65–72, 2005.
[4]Mikołaj Bi
 ́
nkowski, Dougal J. Sutherland, Michael Arbel, and Arthur Gretton. Demystifying MMD GANs.
InInternational Conference on Learning Representations, 2018.
[5]  Ali Borji. Pros and cons of GAN evaluation measures.CoRR, abs/1802.03446, 2018.
[6]Andrew Brock, Jeff Donahue, and Karen Simonyan. Large scale GAN training for high fidelity natural
image synthesis. InInternational Conference on Learning Representations, 2019.
[7]Holger Caesar, Jasper R. R. Uijlings, and Vittorio Ferrari. Coco-stuff: Thing and stuff classes in context.
InCVPR, pages 1209–1218. IEEE Computer Society, 2018.
[8]Alaaeldin El-Nouby, Shikhar Sharma, Hannes Schulz, R. Devon Hjelm, Layla El Asri, Samira Ebrahimi
Kahou, Yoshua Bengio, and Graham W. Taylor. Tell, draw, and repeat: Generating and modifying images
based on continual linguistic instruction.CoRR, abs/1811.09845, 2019.
[9]Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron
Courville, and Yoshua Bengio.  Generative adversarial nets.  In Z. Ghahramani, M. Welling, C. Cortes,
N. D. Lawrence, and K. Q. Weinberger, editors,Advances in Neural Information Processing Systems 27,
pages 2672–2680. Curran Associates, Inc., 2014.
[10]
Arthur Gretton, Karsten M. Borgwardt, Malte J. Rasch, Bernhard Schölkopf, and Alexander Smola.  A
kernel two-sample test.J. Mach. Learn. Res., 13(1):723–773, March 2012.
[11]Swaminathan Gurumurthy, Ravi Kiran Sarvadevabhatla, and R. Venkatesh Babu.  Deligan: Generative
adversarial networks for diverse and limited data.  InComputer Vision and Pattern Recognition, pages
4941–4949. IEEE Computer Society, 2017.
[12]Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter.  Gans
trained by a two time-scale update rule converge to a local nash equilibrium. In I. Guyon, U. V. Luxburg,
S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett, editors,Advances in Neural Information
Processing Systems 30, pages 6626–6637. Curran Associates, Inc., 2017.
[13]Tobias Hinz,  Stefan Heinrich,  and Stefan Wermter.   Generating multiple objects at spatially distinct
locations. InInternational Conference on Learning Representations, 2019.
[14]
Seunghoon Hong, Dingdong Yang, Jongwook Choi, and Honglak Lee.  Inferring semantic layout for
hierarchical text-to-image synthesis. InComputer Vision and Pattern Recognition, pages 7986–7994. IEEE
Computer Society, 2018.
[15]
Xun Huang, Ming-Yu Liu, Serge Belongie, and Jan Kautz.  Multimodal unsupervised image-to-image
translation. InECCV, 2018.
[16]Phillip Isola, Jun-Yan Zhu, Tinghui Zhou, and Alexei A Efros. Image-to-image translation with conditional
adversarial networks.Computer Vision and Patter Recognition (CVPR), 2017.
[17]Justin Johnson, Agrim Gupta, and Li Fei-Fei.  Image generation from scene graphs.  InCVPR, pages
1219–1228. IEEE Computer Society, 2018.
[18]Felix Juefei-Xu, Vishnu Naresh Boddeti, and Marios Savvides.  Gang of gans:  Generative adversarial
networks with maximum margin ranking.CoRR, abs/1704.04865, 2017.
9

[19]Tero Karras, Timo Aila, Samuli Laine, and Jaakko Lehtinen. Progressive growing of GANs for improved
quality, stability, and variation. InInternational Conference on Learning Representations, 2018.
[20]  Diederik P. Kingma and Max Welling. Auto-encoding variational bayes. InICLR, 2014.
[21]E. L. Lehmann and Joseph P. Romano.Testing statistical hypotheses. Springer Texts in Statistics. Springer,
third edition, 2005.
[22]
Qi Mao, Hsin-Ying Lee, Hung-Yu Tseng, Siwei Ma, and Ming-Hsuan Yang.  Mode seeking generative
adversarial networks for diverse image synthesis. InIEEE Conference on Computer Vision and Pattern
Recognition, 2019.
[23]
Loic Matthey, Irina Higgins, Demis Hassabis, and Alexander Lerchner. dsprites: Disentanglement testing
sprites dataset. https://github.com/deepmind/dsprites-dataset/, 2017.
[24]  Mehdi Mirza and Simon Osindero. Conditional generative adversarial nets.CoRR, abs/1411.1784, 2014.
[25]Takeru Miyato, Toshiki Kataoka, Masanori Koyama, and Yuichi Yoshida.  Spectral normalization for
generative adversarial networks. InInternational Conference on Learning Representations, 2018.
[26]Takeru Miyato and Masanori Koyama. cGANs with projection discriminator. InInternational Conference
on Learning Representations, 2018.
[27]
Augustus Odena, Christopher Olah, and Jonathon Shlens.  Conditional image synthesis with auxiliary
classifier GANs. InProceedings of the 34th International Conference on Machine Learning - Volume 70,
ICML’17, pages 2642–2651. JMLR.org, 2017.
[28]Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. Bleu: a method for automatic evaluation
of machine translation.  InProceedings of the 40th annual meeting on association for computational
linguistics, pages 311–318. Association for Computational Linguistics, 2002.
[29]Taesung Park, Ming-Yu Liu, Ting-Chun Wang, and Jun-Yan Zhu. Semantic image synthesis with spatially-
adaptive normalization. InProceedings of the IEEE Conference on Computer Vision and Pattern Recogni-
tion, 2019.
[30]Alec  Radford,  Luke  Metz,  and  Soumith  Chintala.   Unsupervised  representation  learning  with  deep
convolutional generative adversarial networks. InInternational Conference on Learning Representations,
2016.
[31]Radim Šára Radim Tyle
ˇ
cek. Spatial pattern templates for recognition of objects with regular structure. In
Proc. GCPR, Saarbrucken, Germany, 2013.
[32]Scott  Reed,  Zeynep  Akata,  Xinchen  Yan,  Lajanugen  Logeswaran,  Bernt  Schiele,  and  Honglak  Lee.
Generative adversarial text to image synthesis. InProceedings of the 33rd International Conference on
International Conference on Machine Learning - Volume 48, ICML’16, pages 1060–1069. JMLR.org,
2016.
[33]Tim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, Xi Chen, and Xi Chen.
Improved techniques for training gans. In D. D. Lee, M. Sugiyama, U. V. Luxburg, I. Guyon, and R. Garnett,
editors,Advances in Neural Information Processing Systems 29, pages 2234–2242. Curran Associates,
Inc., 2016.
[34]
Amaia Salvador, Michal Drozdzal, Xavier Giró i Nieto, and Adriana Romero. Inverse cooking: Recipe
generation from food images. InComputer Vision and Patter Recognition (CVPR). IEEE Computer Society,
2019.
[35]Iulian Vlad Serban, Alessandro Sordoni, Ryan Lowe, Laurent Charlin, Joelle Pineau, Aaron C. Courville,
and Yoshua Bengio.  A hierarchical latent variable encoder-decoder model for generating dialogues.  In
AAAI, pages 3295–3301. AAAI Press, 2017.
[36]Shikhar  Sharma,  Dendi  Suhubdy,  Vincent  Michalski,  Samira  Ebrahimi  Kahou,  and  Yoshua  Bengio.
Chatpainter: Improving text to image generation using dialogue.CoRR, abs/1802.08216, 2018.
[37]
Jake Snell, Karl Ridgeway, Renjie Liao, Brett D. Roads, Michael C. Mozer, and Richard S. Zemel. Learning
to generate images with perceptual similarity metrics. In2017 IEEE International Conference on Image
Processing, ICIP 2017, Beijing, China, September 17-20, 2017, pages 4277–4281, 2017.
[38]Sandeep Subramanian, Sai Rajeswar Mudumba, Alessandro Sordoni, Adam Trischler, Aaron C Courville,
and Chris Pal. Towards text generation with adversarially learned neural outlines. In S. Bengio, H. Wallach,
H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett, editors,Advances in Neural Information
Processing Systems 31, pages 7551–7563. Curran Associates, Inc., 2018.
[39]Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jonathon Shlens, and Zbigniew Wojna. Rethinking
the inception architecture for computer vision. InCVPR, pages 2818–2826. IEEE Computer Society, 2016.
[40]Qiuyuan Huang Han Zhang Zhe Gan Xiaolei Huang Xiaodong He Tao Xu, Pengchuan Zhang. Attngan:
Fine-grained text to image generation with attentional generative adversarial networks. 2018.
10

[41]Lucas Theis, Aäron van den Oord, and Matthias Bethge. A note on the evaluation of generative models. In
International Conference on Learning Representations, 2016.
[42]
Aaron van den Oord, Nal Kalchbrenner, Lasse Espeholt, koray kavukcuoglu, Oriol Vinyals, and Alex
Graves.   Conditional  image  generation  with  pixelcnn  decoders.   In  D.  D.  Lee,  M.  Sugiyama,  U.  V.
Luxburg, I. Guyon, and R. Garnett, editors,Advances in Neural Information Processing Systems 29, pages
4790–4798. Curran Associates, Inc., 2016.
[43]Aäron Van Den Oord, Nal Kalchbrenner, and Koray Kavukcuoglu.  Pixel recurrent neural networks.  In
Proceedings of the 33rd International Conference on International Conference on Machine Learning -
Volume 48, ICML’16, pages 1747–1756. JMLR.org, 2016.
[44]Aäron van den Oord, Sander Dieleman, Heiga Zen, Karen Simonyan, Oriol Vinyals, Alexander Graves,
Nal Kalchbrenner, Andrew Senior, and Koray Kavukcuoglu. Wavenet: A generative model for raw audio.
InArxiv, 2016.
[45]
Ramakrishna Vedantam, C Lawrence Zitnick, and Devi Parikh. Cider: Consensus-based image description
evaluation.  InProceedings of the IEEE conference on computer vision and pattern recognition, pages
4566–4575, 2015.
[46]Carl Vondrick, Hamed Pirsiavash, and Antonio Torralba. Generating videos with scene dynamics. In D. D.
Lee, M. Sugiyama, U. V. Luxburg, I. Guyon, and R. Garnett, editors,Advances in Neural Information
Processing Systems 29, pages 613–621. Curran Associates, Inc., 2016.
[47]Ting-Chun Wang, Ming-Yu Liu, Jun-Yan Zhu, Andrew Tao, Jan Kautz, and Bryan Catanzaro.  High-
resolution image synthesis and semantic manipulation with conditional gans. InProceedings of the IEEE
Conference on Computer Vision and Pattern Recognition, 2018.
[48]Zhou Wang, Alan C. Bovik, Hamid R. Sheikh, and Eero P. Simoncelli. Image quality assessment: From
error visibility to structural similarity.IEEE TRANSACTIONS ON IMAGE PROCESSING, 13(4):600–612,
2004.
[49]Sitao Xiang and Hao Li.   On the effects of batch and weight normalization in generative adversarial
networks.arXiv preprint arXiv:1704.03971, 2017.
[50]
Jianwei Yang, Anitha Kannan, Dhruv Batra, and Devi Parikh.  LR-GAN: layered recursive generative
adversarial networks for image generation.  InInternational Conference on Learning Representations.
OpenReview.net, 2017.
[51]
Han Zhang, Tao Xu, Hongsheng Li, Shaoting Zhang, Xiaogang Wang, Xiaolei Huang, and Dimitris
Metaxas. Stackgan: Text to photo-realistic image synthesis with stacked generative adversarial networks.
InICCV, 2017.
[52]
Han Zhang, Tao Xu, Hongsheng Li, Shaoting Zhang, Xiaogang Wang, Xiaolei Huang, and Dimitris N.
Metaxas.  Stackgan++:  Realistic image synthesis with stacked generative adversarial networks.IEEE
Transactions on Pattern Analysis and Machine Intelligence, July 2018.
[53]Richard Zhang,  Phillip Isola,  Alexei A Efros,  Eli Shechtman,  and Oliver Wang.   The unreasonable
effectiveness of deep features as a perceptual metric. InCVPR, 2018.
[54]
Bo Zhao, Lili Meng, Weidong Yin, and Leonid Sigal. Image generation from layout. InComputer Vision
and Pattern Recognition. IEEE Computer Society, 2019.
[55]Zhiming Zhou,  Han Cai,  Shu Rong,  Yuxuan Song,  Kan Ren,  Weinan Zhang,  Jun Wang,  and Yong
Yu.   Activation maximization generative adversarial nets.   InInternational Conference on Learning
Representations, 2018.
[56]Jun-Yan Zhu, Philipp Krähenbühl, Eli Shechtman, and Alexei A. Efros. Generative visual manipulation on
the natural image manifold. InComputer Vision - ECCV 2016 - 14th European Conference, Amsterdam,
The Netherlands, October 11-14, 2016, Proceedings, Part V, pages 597–613, 2016.
[57]Jun-Yan Zhu, Taesung Park, Phillip Isola, and Alexei A Efros. Unpaired image-to-image translation using
cycle-consistent adversarial networks. InComputer Vision (ICCV), 2017 IEEE International Conference
on, 2017.
[58]Jun-Yan Zhu, Richard Zhang, Deepak Pathak, Trevor Darrell, Alexei A Efros, Oliver Wang, and Eli
Shechtman. Toward multimodal image-to-image translation. InAdvances in Neural Information Processing
Systems, 2017.
11

Supplementary Material: On the Evaluation of Conditional GANs
A  Illustration of FID and FJD on two dimensional Gaussian data
In this section, we illustrate the claim made in Section 1 that FID cannot capture intra-conditioning
diversity when the joint distribution of two variables changes but the marginal distribution of one of
them is not altered.
Consider two multivariate Gaussian distributions,(X
1
,Y
1
)∼N(0,Σ
1
)and(X
2
,Y
2
)∼N(0,Σ
2
),
where
Σ
1
=
[
4    2
2    2
]
Σ
2
=
[
2.1    2
22
]
.
Figure 5 (left) shows10,000samples drawn from each of these distributions, labeled as Dist1 and
Dist2, respectively. While the joint distributions off
X
1
,Y
1
(X
1
,Y
1
)andf
X
2
,Y
2
(X
2
,Y
2
)are different
from each other, the marginal distributionsf
Y
1
(Y
1
)andf
Y
2
(Y
2
)are the same (Y
1
∼ N(0,2)and
Y
2
∼N(0,2)). Figure 5 (center) shows the histograms of the two marginal distributions computed
from10,000samples.
If we letX
i
take the role of the embedding of the conditioning variables (e.g., class labels) andY
i
take the role of the embedding of the generated variables (i.e., images), then computing FID in this
example would correspond to computing the FD betweenf
Y
1
andf
Y
2
, which iszero. On the other
hand, computing FJD would correspond to the FD betweenf
X
1
,Y
1
andf
X
2
,Y
2
, which equals0.678.
But note that Dist1 and Dist2 have different degrees of intra-conditioning diversity, as illustrated by
Figure 5 (right), where two histograms off
Y
i
|X
i
∈(0.9,1.1)
are displayed, showing marked differences
to each other (similar plots can be constructed for other values ofX
i
).  Therefore, this example
illustrates a situation in which FID is unable to capture changes in intra-conditioning diversity, while
FJD is able to do so.
Figure 5: Left: samples from two multivariate Gaussian distributions. Center: Histograms of marginal
distributions forYvariable.  Right:  Histogram of conditional distributions forYconditioned on
X∈(0.9,1.1).
B  Evaluation of merging functions
To compare different merging functions, as described in Section 4, we evaluate how well the FJD
of each joint distribution correlates to conditional consistency. To do so, we start by drawing10k
dSprite-textures samples, or the entire COCO-Stuff training set.  By duplicating those samples,
we build areferencedataset and agenerateddataset.  Then, we simulate a generative model that
produces images that are inconsistent with the conditioning by randomly permuting a subset of the
conditionings of the generated dataset, affecting the degree of conditional consistency. As a result,
neither the image distribution nor the conditioning distribution of the generated dataset are changed,
and the perturbation is only visible in the joint image-conditioning space. Thus, any change in FJD
can be attributed solely to changes in conditional consistency, resulting in high correlation between
the FJD score and the conditional consistency. Note that this experiment is repeated for three different
types of conditioning: class-conditioning, bounding box-conditioning and mask-conditioning.
Figures 6 and 7 depict FJD as a function of conditional consistency for four merging functions (con-
catenation, summation, multiplication and projection) on dSprites-textures and COCO-Stuff datasets.
12

0.40.60.81.0
Classification Accuracy
0.0
2.5
5.0
7.5
10.0
12.5
15.0
17.5
20.0
FJD
Class Conditioning
cat
sum
mul
proj
0.00.20.40.60.81.0
mIoU
0.0
2.5
5.0
7.5
10.0
12.5
15.0
17.5
20.0
FJD
Bounding Box Conditioning
cat
sum
mul
proj
0.00.20.40.60.81.0
mIoU
0.0
2.5
5.0
7.5
10.0
12.5
15.0
17.5
20.0
FJD
Mask Conditioning
cat
sum
mul
proj
Figure 6: FJD merging functions on dSprite-textures as a function of conditional consistency.
0.20.40.60.81.0
Classification Accuracy
0
5
10
15
20
25
FJD
Class Conditioning
cat
sum
mul
proj
0.40.60.81.0
mIoU
0
5
10
15
20
25
FJD
Bounding Box Conditioning
cat
sum
mul
proj
0.40.50.60.70.80.91.0
mIoU
0
5
10
15
20
25
FJD
Mask Conditioning
cat
sum
mul
proj
Figure 7: FJD merging functions on COCO-Stuff as a function of conditional consistency.
Following standard practice, we measure conditional consistency in terms of classification accuracy
between the original class labels and the ones in the generated dataset, in the class-conditioned case.
Analogously, we measure conditional consistency in terms of mIoU between the original bounding
boxes/masks and the ones in the generated dataset. As shown in the figures, all considered merging
functions are sensitive to conditional inconsistencies and they exhibit comparable behavior across
both datasets.  In particular, summation seems to consistently yield the highest FJD values across
different conditioning types (except for the mask-conditioned case of dSprites-textures), followed by
projection, concatenation and then multiplication. It is worth noting that, for the sake of comparison,
the embedding dimensionality is preserved across merging functions.
Table 4 reports the correlation between FJD and conditional consistency for all merging funcions and
conditioning types on dSprites-textures and COCO-Stuff. As shown in the table, there is a strong
negative correlation between FJD and conditional consistency for all candidate merging functions,
highlighting that FJD effectively captures conditional consistency.  Of the four strategies, simple
embedding concatenation consistently demonstrated the best correlation (although by small margin)
between FJD and conditional consistency across both conditioning types and datasets considered.
As such, we recommend to use the concatenation as merging approach in FJD, and do so in our
experiments.
Table 4: Correlation between FJD and conditional consistency for dSprite-textures and COCO-Stuff.
dSprite-texturesCOCO-stuff
Concat.Sum.Mult.Proj.Concat.Sum.Mult.Proj.
accuracy−0.986−0.986−0.980−0.986−0.978−0.976−0.974−0.976
mIoU (bbox)−0.988−0.982−0.975−0.987−0.991−0.987−0.989−0.987
mIoU (mask)−0.989−0.974−0.965−0.987−0.992−0.986−0.986−0.988
13

C  COCO-Stuff GAN Architecture Details
In order to modify BigGAN [6] to work with multiple types of conditioning we make two major
changes. The first change occurs in the generator, where we replace the conditional batch normaliza-
tion layers with SPADE [29]. This substitution allows the generator to receive spatial conditioning
such as bounding boxes or masks. In the case of class conditioning with a spatially tiled class vector,
SPADE behaves similarly to conditional batch normalization.  The second change we make is in
the discriminator.  The original BigGAN implementation utilizes a single projection layer [26] in
order to provide class conditional information to the discriminator. To extend this functionality to
bounding box and mask conditioning, we add additional projection layers after each ResBlock in the
discriminator. The input to each projection layer is a downsampled version of the conditioning that
has been resized using nearest neighbour interpolation to match the spatial resolution of each layer. In
this way we provide conditioning information at a range of resolutions, allowing the discriminator to
use whichever is most useful for the type of conditioning it has received. Aside from these specified
changes, models are trained with the same hyperparameters and training scheme as specified in [6].
D  Samples of generated images
In this section, we present some128×128samples of conditional generation for the models covered
in Section 6. In particular, Figures 8–10 show class, bounding box and mask conditioning samples,
respectively. Each row displays a conditioning, followed by 4 different samples, and finally the real
image corresponding to the conditioning.  As shown in Figure 8, conditioning on classes leads to
variable samples w.r.t. object positions, scales and textures. As we increase the conditioning strength,
we reduce the freedom of the generation and hence, in Figure 9, we observe how the variability starts
appearing in more subtle regions. Similarly, in Figure 10, taking different samples per conditioning
only changes the textures. Although the degrees of variability decrease as the conditioning strength
increases, we obtain sharper, better looking images.
Figure 8:Class-conditioning:Conditioning, samples, and ground truth image for label conditioned
GAN.
14

Figure 9:Bounding box conditioning:Conditioning, samples, and ground truth image for bounding
box conditioned GAN.
Figure 10:Mask conditioning:Conditioning, samples, and ground truth image for mask conditioned
GAN.
15